abstract,keywords,author,url,doi,issn,year,pages,volume,journal,title,ENTRYTYPE,ID
"Generative Adversarial Imitation Learning (GAIL) can learn policies without explicitly defining the reward function from demonstrations. GAIL has the potential to learn policies with high-dimensional observations as input, e.g., images. By applying GAIL to a real robot, perhaps robot policies can be obtained for daily activities like washing, folding clothes, cooking, and cleaning. However, human demonstration data are often imperfect due to mistakes, which degrade the performance of the resulting policies. We address this issue by focusing on the following features: (1) many robotic tasks are goal-reaching tasks, and (2) labeling such goal states in demonstration data is relatively easy. With these in mind, this paper proposes Goal-Aware Generative Adversarial Imitation Learning (GA-GAIL), which trains a policy by introducing a second discriminator to distinguish the goal state in parallel with the first discriminator that indicates the demonstration data. This extends a standard GAIL framework to more robustly learn desirable policies even from imperfect demonstrations through a goal-state discriminator that promotes achieving the goal state. Furthermore, GA-GAIL employs the Entropy-maximizing Deep P-Network (EDPN) as a generator, which considers both the smoothness and causal entropy in the policy update, to achieve stable policy learning from two discriminators. Our proposed method was successfully applied to two real-robotic cloth-manipulation tasks: turning a handkerchief over and folding clothes. We confirmed that it learns cloth-manipulation policies without task-specific reward function design. Video of the real experiments are available at this URL.","Generative adversarial imitation learning, Robotic cloth manipulation, Deep reinforcement learning",Yoshihisa Tsurumine and Takamitsu Matsubara,https://www.sciencedirect.com/science/article/pii/S0921889022001543,https://doi.org/10.1016/j.robot.2022.104264,0921-8890,2022,104264,158,Robotics and Autonomous Systems,Goal-aware generative adversarial imitation learning from imperfect demonstration for robotic cloth manipulation,article,TSURUMINE2022104264
"Device-to-device communication is an enabling technology for direct connection between two or more devices/users without the intermediation of a base station (BS). In heterogeneous device-to-device networks, technology such as femtocell suggests advantages such as improving coverage area, spectral efficiency, and increased capacity. However, several challenging issues like interference, resource allocation, and power control strategies need to be addressed in the macrocell?femtocell-D2D heterogeneous network. This research presents a solution for resource allocation in D2D networks by proposing a Stackelberg game approach to increase network performance and throughput. The proposed study examines a framework for a two-leader multiple-followers Stackelberg game in which the leaders are macrocell base station (MBS) and femtocell base station (FBS), and the numerous followers are D2D pairings. Based on their mobility in the cell zone, D2D users are divided into three types Each leader and follower are designed with a different utility function. The paper is focused to minimize the interference in the system and maximize the system throughput. The game is solved to a Stackelberg equilibrium and ensures D2D communication continues with optimal transmit power. The assignment of resources among various contending users using the Hungarian algorithm. The proposed model is validated through simulations in MATLAB. The results show that the proposed model reduced the interference in the network and increased the throughput of the system in terms of price, transmit power and D2D rate.","Resource management, Base station, Leader, Follower, D2D, Price, Power",Roopsi Rathi and Saurav Dixit and Shweta Bansal and Kaushal Kumar and Natalia Taskaeva and Tumanov A.Yu. and Vinod John,https://www.sciencedirect.com/science/article/pii/S0921889022001300,https://doi.org/10.1016/j.robot.2022.104222,0921-8890,2022,104222,156,Robotics and Autonomous Systems,Stackelberg game approach for resource allocation in device-to-device communication with heterogeneous networks,article,RATHI2022104222
"This paper proposes a novel robust saturated actor?critic multi-layer neural network controller for electrically-driven tractors with n-trailer with unmeasurable linear and angular velocities, uncertain complex dynamics and actuator saturation while guaranteeing a prescribed performance with employing the motor dynamics. The proposed controller consists of four control loops. In the first loop, tracking errors are transformed into constraint errors via prescribed performance bounds. Then, a kinematic controller is designed. In the second loop, an output feedback robust dynamic controller is proposed via multi-layer actor?critic neural networks to approximate model uncertainties, a high-gain observer (HGO) to estimate velocities, and an adaptive robust controller to compensate external dynamic disturbances. Afterwards, a robust actuator controller is designed in third loop by employing multi-layer actor?critic neural networks to deeply diminish unknown nonlinear functions effects, and an adaptive robust controller to handle the bounded actuator disturbances. An auxiliary subsystem is considered in the final loop to reduce the danger of actuator saturation by designing an auxiliary intermediate controller. The stability under the proposed controller is studied by the Lyapunov stability synthesis, and it is proven that tracking errors remain uniformly ultimately bounded. Finally, the validity, reliability, and effectiveness of the proposed reinforcement learning-based controller is shown by means of multiple simulations and some comparisons with a quantitative study.","Actuator saturation, Actuator dynamics, Reinforcement learning control, High-gain observer, Prescribed performance, Tractor with -trailer",Omid Elhaki and Khoshnam Shojaei,https://www.sciencedirect.com/science/article/pii/S0921889022000574,https://doi.org/10.1016/j.robot.2022.104106,0921-8890,2022,104106,154,Robotics and Autonomous Systems,Output-feedback robust saturated actor?critic multi-layer neural network controller for multi-body electrically driven tractors with n-trailer guaranteeing prescribed output constraints,article,ELHAKI2022104106
"Task and motion planning in robotics are typically addressed by separated intertwined methods. Task planners generate abstract high-level actions to be executed, while motion planners provide the associated discrete movements in the configuration space satisfying kinodynamic constraints. However, these two planning processes are strictly dependent, therefore the problem of combining task and motion planning with a uniform approach is very relevant. In this work, we tackle this issue by proposing a RRT-based method that addresses combined task and motion planning. Our approach relies on a combined metric space where both symbolic (task) and sub-symbolic (motion) spaces are represented. The associated notion of distance is then exploited by a RRT-based planner to generate a plan that includes both symbolic actions and feasible movements in the configuration space. The proposed method is assessed in several case studies provided by a real-world hospital logistic scenario, where an omni-directional mobile robot is involved in navigation and transportation tasks.","Robot planning, Sampling-based planning, Rapidly-exploring random trees, Mobile robotics",Riccardo Caccavale and Alberto Finzi,https://www.sciencedirect.com/science/article/pii/S0921889022001385,https://doi.org/10.1016/j.robot.2022.104238,0921-8890,2022,104238,157,Robotics and Autonomous Systems,A rapidly-exploring random trees approach to combined task and motion planning,article,CACCAVALE2022104238
"Rotary joint is used in robotic arm for mobility aids and rehabilitation device. The rotary joint often requires a compactness, a lightness, and a large load capacity in robotics as well as automation manufacturing. However, the experience-based design methods take a lot of time, finances, and human resources to achieve the mentioned multiple functions. To overcome the above difficulties, the article proposes a new design technique to solve the structural optimization for the rotary joint. The proposed optimization technique is formed by topology method, analysis of variance, finite element method, adaptive neuro-fuzzy inference system model, and water cycle moth-flame optimization algorithm. A new rotary joint is designed via the topology optimization. The adaptive neuro-fuzzy inference system is optimized by Taguchi technique to enhance the modeling accuracy. The geometry of the joint is optimized by the water cycle moth-flame optimization algorithm. The results found that the rotary joint can stand a torque of 357.46 N.mm with the equivalent stress up to 489.98 MPa. The difference between the optimal prediction results and simulations are 0.27% and 0.58% for the moment reaction and the equivalent stress, respectively. The small error proves the developed hybrid method has a high reliability.","Rotary joint, Topology-size optimization, Finite element method, Neural-fuzzy, Water cycle moth-flame optimization algorithm, Robotics, Automation manufacturing",Ngoc {Le Chau} and Minh Phung Dang and Chander Prakash and Dharam Buddhi and Thanh-Phong Dao,https://www.sciencedirect.com/science/article/pii/S0921889022001142,https://doi.org/10.1016/j.robot.2022.104199,0921-8890,2022,104199,156,Robotics and Autonomous Systems,"Structural optimization of a rotary joint by hybrid method of FEM, neural-fuzzy and water cycle?moth flame algorithm for robotics and automation manufacturing",article,LECHAU2022104199
"Musculoskeletal humanoids have various biomimetic advantages, of which redundant muscle arrangement is one of the most important features. This feature enables variable stiffness control and allows the robot to keep moving its joints even if one of the redundant muscles breaks, but this has been rarely explored. In this study, we construct a neural network that represents the relationship among sensors in the flexible and difficult-to-modelize body of the musculoskeletal humanoid, and by learning this neural network, accurate motions can be achieved. In order to take advantage of the redundancy of muscles, we discuss the use of this network for muscle rupture detection, online update of the intersensory relationship considering the muscle rupture, and body control and state estimation using the muscle rupture information. This study explains a method of constructing a musculoskeletal humanoid that continues to move and perform tasks robustly even when one muscle breaks.","Musculoskeletal humanoid, Redundancy, Neural networks",Kento Kawaharazuka and Manabu Nishiura and Yasunori Toshimitsu and Yusuke Omura and Yuya Koga and Yuki Asano and Kei Okada and Koji Kawasaki and Masayuki Inaba,https://www.sciencedirect.com/science/article/pii/S0921889022000331,https://doi.org/10.1016/j.robot.2022.104067,0921-8890,2022,104067,152,Robotics and Autonomous Systems,Robust continuous motion strategy against muscle rupture using online learning of redundant intersensory networks for musculoskeletal humanoids,article,KAWAHARAZUKA2022104067
"A robust walking stabilization strategy of humanoids on uneven terrain via a QP-based impedance/ admittance control is addressed in this paper. The core idea is combining the following two strategies. The first is to reduce the effect of an unexpected contact force on the centroidal momentum dynamics, and the second is to adjust post-contact reference for the swing foot with which its pose is regulated on the obstacle. The former can be achieved by replacing the task of the trajectory tracking control for the swing foot with its task-space impedance control, and the latter follows by employing the hybrid admittance control combining the admittance control with resetting the post-contact reference. In addition, an optimal set of parameters used for the admittance control is computed via the Taguchi optimal design method. The proposed algorithm is embedded into the momentum-based whole-body control (WBC) framework and verified its validity by multiple simulations with the physics engine.","Humanoid, Hybrid landing control, QP impedance control, Walking stabilization",Joonhee Jo and Gyunghoon Park and Yonghwan Oh,https://www.sciencedirect.com/science/article/pii/S0921889022000859,https://doi.org/10.1016/j.robot.2022.104148,0921-8890,2022,104148,154,Robotics and Autonomous Systems,Robust walking stabilization strategy of humanoid robots on uneven terrain via QP-based impedance/admittance control,article,JO2022104148
"This paper presents hand-impedance measurements during laparoscopic training with physically interactive manipulators. We develop a co-manipulated robotic system allowing hand-impedance measurements in an active manipulation task with occasional environmental contact. Six professional, four trainee surgeons, and ten novice subjects participated in our experimental program for a suturing activity where the novice subjects were involved in a five weeks training practice. Variable admittance controlled robots, attached to the tools with force sensors, applied step vice velocity disturbances while subjects were trying to set the needle perpendicular to the surgical driver. Hereby, impedances of the left and right hands were computed in four different directions. Then, the measured impedance parameters across all subjects were compared with respect to the participants? level of proficiency and skill progression via statistical analyses to demonstrate effectiveness of the system. Results indicate that hand-impedance in the direction of the suturing-line demonstrates a consistent change throughout training and across different levels of expertise in laparoscopy. Therefore, hand-impedance information, proposed here, can pave the way for future development of robotic assessment or assistance in laparoscopy training programs.","Human-robot interaction, Hand-impedance, Laparoscopy training",Harun Tugal and Benjamin Gautier and Benjie Tang and Ghulam Nabi and Mustafa Suphi Erden,https://www.sciencedirect.com/science/article/pii/S0921889022000732,https://doi.org/10.1016/j.robot.2022.104130,0921-8890,2022,104130,154,Robotics and Autonomous Systems,Hand-impedance measurements with robots during laparoscopy training,article,TUGAL2022104130
"This paper presents a new approach for a safe autonomous navigation based on reliable state space reachability analysis. This latter improves an already proposed flexible Navigation Strategy based on Sequential Waypoint Reaching (NSbSWR) framework (Vilca et al., 2015), while considering explicitly different uncertainties in modeling and/or perception. Indeed, NSbSWR is an emergent concept that exploits its flexibility and genericity to avoid frequent complex trajectories? planning/re-planning. The paper?s main contribution is to introduce a reachability analysis scheme as a reliable risk assessment and management policy ensuring safe autonomous navigation between the successive assigned waypoints. For this aim, interval analysis is employed to propagate uncertainties influencing the vehicle?s dynamics into the navigation system states. By solving an ordinary differential equation with uncertain variables and parameters via an interval Taylor series expansion method, all the vehicle potential reachable state-space is revealed. According to the obtained bounds of the reachable sets, a decision about the navigation safety is made. Once a collision risk is captured, the risk management layer acts to update the control parameters to master the critical situation and guarantee a proper reaching of waypoint, while avoiding any risky state. Several simulation results prove the safety, efficiency and robustness of the overall navigation under uncertainties.","Autonomous navigation, Sequential waypoint-based navigation, Risk assessment and management, Reachability analysis, Interval Taylor models",Nadhir Mansour {Ben Lakhal} and Lounis Adouane and Othman Nasri and Jaleleddine {Ben Hadj Slama},https://www.sciencedirect.com/science/article/pii/S092188902200032X,https://doi.org/10.1016/j.robot.2022.104065,0921-8890,2022,104065,152,Robotics and Autonomous Systems,Safe and adaptive autonomous navigation under uncertainty based on sequential waypoints and reachability analysis,article,BENLAKHAL2022104065
"A multi-locomotion mode ankle rehabilitation robot (MLMARR) based on the 2-UPU/RPU (U: universal; P: prismatic; R: revolute) parallel mechanism with actuators above the end effector is proposed. In addition to the rehabilitation training of the basic motion orientation of the ankle, the MLMARR enables up/down or back/forth traction rehabilitation training, ensuring the training of muscle groups and ligaments related to the ankle motion. First, degrees-of-freedom analysis is conducted based on the screw theory. Subsequently, using the closed-loop vector method and coordinate system rotation transformation, inverse position analysis is performed and the Jacobian matrix is described. In addition, three types of kinematic singularities are identified by analyzing the Jacobian matrix. Moreover, the workspace is determined by the limit boundary method. Three rehabilitation training modes are set and dynamic simulations are performed according to the ankle rehabilitation requirements; on this basis, the linear actuators can be selected reasonably. Finally, the effectiveness and accuracy of rehabilitation training are evaluated based on experimental data obtained using an MLMARR prototype. This research reveals the characteristics and superiority of the proposed MLMARR and offers the basis for the future improvement of the device.","Ankle rehabilitation robot, Multi-locomotion mode, Parallel mechanism, Performance analysis, Trajectory planning",Ya Liu and Wenjuan Lu and Huafang Wu and Yici Xia and Bo Hu and Daxing Zeng,https://www.sciencedirect.com/science/article/pii/S0921889022001427,https://doi.org/10.1016/j.robot.2022.104246,0921-8890,2022,104246,157,Robotics and Autonomous Systems,Performance analysis and trajectory planning of multi-locomotion mode ankle rehabilitation robot,article,LIU2022104246
"During the past decade, soft robotics has become a growing new field, and researchers have developed different kinds of soft robots with different actuation technologies and mechanisms. Pneumatic artificial muscles (PAMs), as one kind of the most popular soft actuators, have been widely applied to robotic systems that assist persons. However, PAMs are highly nonlinear, which makes it difficult to achieve accurate force and motion control. Another major problem is their slow response. Efforts have been made to improve the accuracy and responses of PAMs. Adding pre-tensioned springs is one efficient way to improve responses of mechatronic systems. However, the role of pre-tensioned springs in different PAMs-driven mechanical structures has not been sufficiently investigated. In this study, two joint structures combining pre-tensioned springs and PAMs were modeled and their sliding mode controllers (SMC) were designed. The control results were compared with canonical antagonistic PAMs structure in simulation experiments. Moreover, a one-joint prototype actuated by 3 PAMs connected in series with two series-connected springs, was built and used to validate the simulated model. The results with both simulation models and the prototype mechanism showed that, one of joint structure with pre-tensioned springs could achieve better step response and control accuracy than the canonical antagonistic PAMs structure.","Pneumatic artificial muscles (PAMs), Three types of joint spring-PAMs? structures, Sliding mode control",Zhongchao Zhou and Yuanyuan Wang and Wenwei Yu,https://www.sciencedirect.com/science/article/pii/S0921889021002669,https://doi.org/10.1016/j.robot.2021.104017,0921-8890,2022,104017,151,Robotics and Autonomous Systems,The role of pre-tensioned springs in 3 pneumatic artificial muscles driven joint mechanisms with sliding mode controllers,article,ZHOU2022104017
"In order to improve the efficiency and reduce the labor cost of cafeterias, an intelligent master?slave collaborative robot system is developed for cafeteria service in this paper. The developed system can automatically complete the tasks of scooping dishes, taking bowls and pouring dishes into the bowl based on master?slave collaboration. Specifically, a dynamic geometry feature graph convolution network (DGG) is devised using the 3D point cloud of the dish, which can efficiently predict the scooping positions of the different dishes. Moreover, a master?slave motion planning control method is proposed to achieve fast and smooth trajectories for both arms, which can accomplish the cafeteria service tasks collaboratively. Furthermore, we establish a dataset containing point clouds and color images of various Chinese food. Experiments demonstrate that the DGG network can achieve superior performance over other state-of-the-art point cloud segmentation networks. Besides, the designed robot system can well meet the requirements of operation accuracy and speed, confirming its practicality in cafeteria services.","Master?slave collaborative robot, Point cloud segmentation network, Master?slave motion planning",Mingyu Gao and Haiping Zhou and Yuxiang Yang and Zhekang Dong and Zhiwei He,https://www.sciencedirect.com/science/article/pii/S0921889022000690,https://doi.org/10.1016/j.robot.2022.104121,0921-8890,2022,104121,154,Robotics and Autonomous Systems,An intelligent master?slave collaborative robot system for cafeteria service,article,GAO2022104121
"When it comes to the accuracy of autonomous motion, it is necessary to consider object detection and recognition, especially for the robot application of the complex environment. This paper investigates novel dual-view 3D object detection networks combined with the Lidar point cloud and RGB image in engineering scenarios. The developed system is applied for autonomous vehicles that the detected objects are cars, cyclists, and pedestrians. Firstly, a feature extraction network based on the residual module is presented, and the specific features are from the RGB image. The point cloud is transformed into Bird?s Eye View (BEV), and the BEV feature extraction network is built based on sparse convolution. Besides, the feature maps are input into the region proposal network (RPN) to obtain the optimal proposal so that the object classification and the bounding box regression are obtained. Finally, to evaluate the flexibility of the developed framework, extensive data sets are generated through the CARLA simulator and verified on the KITTI data set and unmanned motion platform (BIT-NAZA robot), indicating that the proposed networks can achieve satisfactory performance in the real-world scenario.","Object detection, Lidar point cloud, RGB image, Sensor fusion, Autonomous system",Jing Li and Rui Li and Jiehao Li and Junzheng Wang and Qingbin Wu and Xu Liu,https://www.sciencedirect.com/science/article/pii/S0921889021002542,https://doi.org/10.1016/j.robot.2021.103999,0921-8890,2022,103999,150,Robotics and Autonomous Systems,Dual-view 3D object recognition and detection via Lidar point cloud and camera image,article,LI2022103999
"In this survey, we present the current status on robots performing manipulation tasks that require varying contact with the environment, such that the robot must either implicitly or explicitly control the contact force with the environment to complete the task. Robots can perform more and more manipulation tasks that are still done by humans, and there is a growing number of publications on the topics of (1) performing tasks that always require contact and (2) mitigating uncertainty by leveraging the environment in tasks that, under perfect information, could be performed without contact. The recent trends have seen robots perform tasks earlier left for humans, such as massage, and in the classical tasks, such as peg-in-hole, there is a more efficient generalization to other similar tasks, better error tolerance, and faster planning or learning of the tasks. Thus, in this survey we cover the current stage of robots performing such tasks, starting from surveying all the different in-contact tasks robots can perform, observing how these tasks are controlled and represented, and finally presenting the learning and planning of the skills required to complete these tasks.","Robotic manipulation, Manipulation in contact, Compliance, In-contact tasks, Impedance control",Markku Suomalainen and Yiannis Karayiannidis and Ville Kyrki,https://www.sciencedirect.com/science/article/pii/S0921889022001312,https://doi.org/10.1016/j.robot.2022.104224,0921-8890,2022,104224,156,Robotics and Autonomous Systems,A survey of robot manipulation in contact,article,SUOMALAINEN2022104224
"The combination of elasticity and rigidity found within mammalian limbs enables dexterous manipulation, agile, and versatile behavior, yet most modern robots are either primarily soft or rigid. Hybrid robots, composed of both soft and rigid parts, promote compliance to external forces while maintaining strength and stability provided by rigid robots. Most mammals have ligaments which connect bone to bone, enabling joints to passively redirect forces and softly constrain the range of motion. We present an approach to constructing a new class of hybrid joints through parametric design choices that adjust dynamic properties of the system. The inherent modularity and variability necessitate a model-free controller which can adjust to new contexts in relatively short time. Three joint examples are created along with three tasks to assess quality of the controllers, creating 9 total cases. We show the Soft Actor Critic (SAC) reinforcement learning algorithm outperforms a proportion?integral?derivative (PID) controller in 6/9 cases, yet this changes to 9/9 with a brief re-training period. This work presents a new class of hybrid robotic joints with modifiable dynamics and employs a model-free control training technique which can be fine-tuned for specific scenarios.","Robot dynamics, Deep reinforcement learning, Soft robots, Robotic manipulator, Biomimetics",A.S. Robbins and M. Ho and M. Teodorescu,https://www.sciencedirect.com/science/article/pii/S0921889022000860,https://doi.org/10.1016/j.robot.2022.104150,0921-8890,2022,104150,155,Robotics and Autonomous Systems,Model-free dynamic control of robotic joints with integrated elastic ligaments,article,ROBBINS2022104150
"As robots become part of our everyday lives, they may be required to cooperate without being aware of each other?s capabilities (e.g., because different teams have developed them), and therefore will have to trust each other to work together safely and efficiently. Starting from this premise, this work identifies trust as an essential metric to assign tasks to robots using auction-based mechanisms. We model trust by taking inspiration from popular models in the literature and adapting them to an open environment in which heterogeneous robots may dynamically enter or exit, execute assigned tasks, or verify the correct execution of tasks by other robots. Robots are considered to be heterogeneous in the sense that they may have different capabilities in executing and verifying the execution of actions. In the proposed model, ?doing an action? and ?verifying the execution of an action? are distinct, not necessarily overlapping, capabilities. Some robots may be able to do an action, whereas some robots may not be able to do it but only to observe and judge the ability of other robots to do it. After introducing the relevant formalism, the article describes the system?s architecture implemented in ROS and multiple experiments performed in simulation and with real robots (one NAO and two Pepper robots by SoftBank Robotics), providing a proof-of-concept for broader utilization of the system in cooperative robotic scenarios.","Trust, Robot?robot interaction, Task assignment, Social robotics",Alberto Grillo and Stefano Carpin and Carmine Tommaso Recchiuto and Antonio Sgorbissa,https://www.sciencedirect.com/science/article/pii/S0921889022001555,https://doi.org/10.1016/j.robot.2022.104266,0921-8890,2022,104266,157,Robotics and Autonomous Systems,Trust as a metric for auction-based task assignment in a cooperative team of robots with heterogeneous capabilities,article,GRILLO2022104266
"The jumping movement of quadruped robots is crucial, so a complete set of balanced jumping algorithms is proposed in this paper due to the flaws of the current jumping algorithms. The proposed algorithm includes trajectory planning of the Center of Mass(CoM) and four jumping phases, illustrating the jumping process in detail. Tasks that a quadruped robot with the height of 0.6 m jumps up a step with the height of 0.3 m, 0.4 m, 0.5 m and 0.6 m are the research object. Optimal Parabola Trajectory of CoM(OPTC) is solved by about ten iterations based on the fastest approaching strategy before jumping. During the first phase of jumping, Ground Reaction Forces(GRFs) are precisely distributed to control six Degrees of Freedom(DoFs) based on symmetric six-dimensional spatial mechanics decoupling solution, controlling the robot to adjust itself to the best ejecting posture. The maximum displacement error is less than 0.005 m. During the second phase, full-leg ejection is implemented to eject, guaranteeing that the robot accurately tracks the OPTC after takeoff by updating proportional virtual forces. The tracking Mean Square Error(MSE) is less than 0.06. During the third phase, the flying attitude is adjusted by swinging leg theory summarized in the paper, with the maximum pitch angle less than 4.5°. Meanwhile, the theoretical landing points of feet are calculated to lead the movement of feet, ensuring a soft landing to reduce touchdown impact. The momentary landing velocities of feet are less than 0.09 m/s. During the fourth phase, the robot buffers and brakes to a static state based on the algorithm used in the first phase. Eventually, the proposed algorithms are verified through simulating experiments on Webots physical engine, and the effectiveness and feasibility are validated by the experimental results.","Quadruped robot, Balanced jumping algorithm, Trajectory planning, Spatial mechanics decoupling, Soft landing",Bende Luo and Yinlin Luo,https://www.sciencedirect.com/science/article/pii/S0921889022001671,https://doi.org/10.1016/j.robot.2022.104278,0921-8890,2022,104278,158,Robotics and Autonomous Systems,A balanced jumping control algorithm for quadruped robots,article,LUO2022104278
"This paper proposes an inertial human motion tracking for robot programming by demonstration (PbD). An original element called heading reset is proposed to catch the drift around gravity direction. It is based on a hypothesis made on the human arm motion during a task demonstration. It is used to overcome the non-use of the magnetometer due to magnetic disturbances from robotic environment. This element is implemented in an orientation estimation algorithm and compared with three other IMU algorithms and a commercial MARG algorithm. The human arm trajectory is estimated through three IMUs sensors directly set on the arm to estimate the segment orientation (hand, forearm and arm). A specific inertial-2-segment procedure is presented as well as a procedure to estimate the transformation from human reference frame to task frame, necessary for a PbD process. Experimental tests, using a robot as a reference, have been conducted to validate the different part of the method. The heading reset and the orientation algorithm show good results. The inertial-2-segment procedure is shown to be robust. Finally, experimental tests on a human arm and physical robot validate the complete method.","Robotics, Programming by demonstration, Inertial human motion tracking",Robin Pellois and Olivier Brüls,https://www.sciencedirect.com/science/article/pii/S0921889022001154,https://doi.org/10.1016/j.robot.2022.104201,0921-8890,2022,104201,156,Robotics and Autonomous Systems,An inertial human upper limb motion tracking method for robot programming by demonstration,article,PELLOIS2022104201
"Proactive assistance in human?robot collaboration remains a challenging objective, as the spatial?temporal coordination of the human?robot motion must be considered in conjunction with the object and environmental context. In this paper, we propose an environment-adaptive probabilistic interaction primitive method using learning-from-demonstration. In particular, we propose a novel phase estimation algorithm called Single-axis Uniform Interval Interpolation, which alleviates the restriction of Gaussian or uniform distribution of phase variables. In addition, the environmental constraints in human?robot interactive skills are learned via the regression between environmental parameters and the weight vectors. The proposed method is implemented in a proactive robotic system for typical industrial-motivated human?robot collaborative scenarios, such as assistive push-button assembly and human?robot collaborative object covering. The experimental result validates the effectiveness of the proposed approach.","Learning-from-demonstration, Interactive movement primitives, Human?robot collaboration, Proactivity, Robot grasping",Kun Qian and Xin Xu and Huan Liu and Jishen Bai and Shan Luo,https://www.sciencedirect.com/science/article/pii/S0921889022000185,https://doi.org/10.1016/j.robot.2022.104046,0921-8890,2022,104046,151,Robotics and Autonomous Systems,Environment-adaptive learning from demonstration for proactive assistance in human?robot collaborative tasks,article,QIAN2022104046
"While mobile LiDAR sensors are increasingly used to scan in ecology and forestry applications, reconstruction and characterization are typically carried out offline. Motivated by this, we present an online LiDAR system which is capable of running on a handheld device. Our system is capable of creating 3D point cloud reconstructions of large forest areas, segment and track individual trees, and create an inventory for the detected trees. Segments relating to each tree are accumulated over time, and tree models are completed as more scans are captured from different perspectives. The LiDAR scans are processed in an online fashion, and feedback can be provided to the operator via a screen mounted on the device. This allows the operator to ensure the desired area is mapped satisfactorily without any gaps or missing sections. We employ a pose-graph based SLAM system with loop closures to correct for drift errors allowing us to map large areas accurately. Our mapping system also provides multi-session capability where data captured during different runs can be automatically merged in a post-processing step. In this work, we estimate the Diameter at Breast Height (DBH) of individual trees as an example parameter for the forest inventory. The DBH is estimated online by fitting a cylinder to each tree trunk through a least-squares optimization within a RANSAC loop. We demonstrate our mapping approach operating in two different forests (both ecological and commercial) with the total travel distance spanning several kilometres. Further, we also provide experimental results comparing our DBH estimation to ground-truth measurements recorded manually in an ecological forest (Wytham Woods, Oxford). We demonstrate that our DBH estimates are within ?7 cm accuracy for 90% of individual trees detected in the dataset.","Forestry, SLAM, Real-time Operation, Automated forest inventory",Alexander Proudman and Milad Ramezani and Sundara Tejaswi Digumarti and Nived Chebrolu and Maurice Fallon,https://www.sciencedirect.com/science/article/pii/S0921889022001397,https://doi.org/10.1016/j.robot.2022.104240,0921-8890,2022,104240,157,Robotics and Autonomous Systems,Towards real-time forest inventory using handheld LiDAR,article,PROUDMAN2022104240
"This paper presents the dynamic modelling and linear matrix inequality (LMI) based controller design of a distributed fog computing framework for real-time robot vision applications. A mobile robot vision system acquires the images from an application environment such as a warehouse, where articles are stacked in numerous racks. We characterise the mobile robot vision data (MRVD) using frames per second (FPS) and the image resolution. From the MRVD, object detection is performed by an open-source deep learning (DL) platform for detecting and localising various objects. However, with higher FPS together with high-resolution images, the processing time by the DL algorithm increases significantly. This necessitates the deployment of a distributed computing platform with several computing nodes. In this work, we deploy a distributed fog computing environment (DFCE) for the real-time object detection in an application environment. The processing time required to handle the MRVD is called the service time. However, for efficient auto-scaling performance, the mathematical model of the DFCE, taking into consideration the characteristics of the MRVD is necessary. In this context, we envisage the application of control theory to build the dynamic model of the DFCE. A Linear Parameter Varying (LPV) model is proposed for the DFCE with the service time as the output, the number of fog nodes as the input, and the characteristics of MRVD as the time-varying parameters. At first, an LPV model for the DFCE is derived using system identification, and the model is validated using the real-time test data. The LPV model is converted to a Polytopic LPV (PLPV) model for LMI based controller design. Finally, we develop and validate a Linear Matrix Inequality (LMI) based LPV controller to meet the service time constraints for a given application environment. For localisation and trajectory tracking with obstacle avoidance in the application environment, the mobile robot implements an Extended Kalman Filter (EKF) based simultaneous localisation and mapping (SLAM) and a bug-based path planning algorithm respectively. Finally, we present, detailed controller validation results illustrating the mobile robot navigation together with the auto-scaling control for the fog computing platform to modulate the service time.","Fog computing, LPV modelling, LMI based control, Deep learning for object detection, Mobile robot, SLAM",Dinsha Vinod and P.S. SaiKrishna,https://www.sciencedirect.com/science/article/pii/S0921889022000902,https://doi.org/10.1016/j.robot.2022.104158,0921-8890,2022,104158,155,Robotics and Autonomous Systems,Development of an autonomous fog computing platform using control-theoretic approach for robot-vision applications,article,VINOD2022104158
"While current autonomous navigation systems allow robots to successfully drive themselves from one point to another in specific environments, they typically require extensive manual parameter re-tuning by human robotics experts in order to function in new environments. Furthermore, even for just one complex environment, a single set of fine-tuned parameters may not work well in different regions of that environment. These problems prohibit reliable mobile robot deployment by non-expert users. As a remedy, we propose Adaptive Planner Parameter Learning (appl), a machine learning framework that can leverage non-expert human interaction via several modalities ? including teleoperated demonstrations, corrective interventions, and evaluative feedback ? and also unsupervised reinforcement learning to learn a parameter policy that can dynamically adjust the parameters of classical navigation systems in response to changes in the environment. appl inherits safety and explainability from classical navigation systems while also enjoying the benefits of machine learning, i.e., the ability to adapt and improve from experience. We present a suite of individual appl methods and also a unifying cycle-of-learning scheme that combines all the proposed methods in a framework that can improve navigation performance through continual, iterative human interaction and simulation training.","Mobile robot navigation, Machine learning, Motion planning",Xuesu Xiao and Zizhao Wang and Zifan Xu and Bo Liu and Garrett Warnell and Gauraang Dhamankar and Anirudh Nair and Peter Stone,https://www.sciencedirect.com/science/article/pii/S0921889022000744,https://doi.org/10.1016/j.robot.2022.104132,0921-8890,2022,104132,154,Robotics and Autonomous Systems,APPL: Adaptive Planner Parameter Learning,article,XIAO2022104132
"Feature detection is a crucial technique for a vision navigation system to estimate robot pose according to natural landmarks. It is difficult for the existing feature detection techniques to balance the feature quality, processing time and robustness for a vision-based robot in complex workspaces. An adaptive Oriented fast and Rotated Brief (ORB) feature detection method with a variable extraction radius in Region of Interest (RoI) is proposed to deal with these problems. Firstly, the original camera image is processed by means of the Laplace transform of Gaussian (LTOG) pyramid and the grayscale centroid method, in order to obtain the rotation and scale invariance for ORB features. Then, a RoI segmenting technique is developed to locate the image areas that contain potential ORB features due to obvious grayscale variation. Thirdly, the ORB features are extracted in RoIs by using a set of variable-radius templates, adaptive to different illumination conditions. Finally, a number of feature detection and robot localization experiments are conducted on a vision-based robot prototype in different scenes under complex illumination. The experimental results verify that the RoI segmenting technique can correctly preserve the grayscale-varying regions to search ORB features with scattered distribution but excluding the irrelevant areas to suppress feature noises, while the variable-radius template extraction method can detect more feature inliers in complex workspaces. Therefore, our adaptive ORB method can outperform other commonly-used algorithms in accuracy, efficiency and robustness.","Image processing, Feature detection, ORB feature, RoI segmenting, Adaptive extraction",Xing Wu and Chao Sun and Leisheng Chen and Ting Zou and Wei Yang and Haining Xiao,https://www.sciencedirect.com/science/article/pii/S0921889022001439,https://doi.org/10.1016/j.robot.2022.104248,0921-8890,2022,104248,157,Robotics and Autonomous Systems,Adaptive ORB feature detection with a variable extraction radius in RoI for complex illumination scenes,article,WU2022104248
"An overtaking trajectory planning algorithm is an essential part of autonomous vehicles, but maximizing trip efficiency (minimum travel time) while guaranteeing safety is non-trivial. In particular, to achieve optimal trajectory results in all situations using one algorithm is challenging because overtaking is a complex maneuver in which several behaviors are combined. In this paper, an overtaking algorithm that employs a finite state machine as a high-level decision maker and chance constrained model predictive control as a trajectory planner is proposed to optimize trip efficiency and ride comfort while guaranteeing safety. By combining two methods in a hierarchical structure, the proposed algorithm takes advantage of each method to realize optimality and real-time performance. Using the conditional state machine (CSM), algorithm classifies maneuver states that can ensure safety, and sets the optimal multi-vehicle constraints in each state. The chance constrained model predictive control (MPC) plans an optimal trajectory that considers the prediction uncertainty, safety, trip efficiency and ride comfort. To rigorously evaluate both trip efficiency and safety, the performance of the proposed overtaking algorithm is evaluated in a statistical manner for various level of service (LOS) scenarios. Simulation results show that the optimal trajectory was generated in a multi-vehicle situation while ensuring higher safety than the rule-based algorithm.","Autonomous vehicle, Collision avoidance, Model predictive control, Overtaking, Path planning",Seungmin Jeon and Kibeom Lee and Dongsuk Kum,https://www.sciencedirect.com/science/article/pii/S0921889021002657,https://doi.org/10.1016/j.robot.2021.104014,0921-8890,2022,104014,151,Robotics and Autonomous Systems,Overtaking decision and trajectory planning in highway via hierarchical architecture of conditional state machine and chance constrained model predictive control,article,JEON2022104014
"Resolved viscoelasticity control (RVC) method resolves multiple viscoelasticities in the task-space, including the center of gravity viscoelasticity for balancing, into the joint-space viscoelasticity. We achieved robust and compliant motions using the RVC method. In previous studies, however, the conventional knee-bent posture was used to avoid kinematic singularity, suffering from large knee joint torque. In this study, we propose an extension of the RVC that can consider the kinematic singularity. Stable knee-stretched walking has been described using a humanoid with the RVC. Using simulations and experiments, we demonstrate that this RVC method allows for stable and human-like walking while considering the singularity, reducing the knee joint torque, and improving the energy efficiency.","Balance control, Biped locomotion, Compliance Control, Humanoid robot",Ko Yamamoto and Kazuya Murotani and Tianyi Ko and Yoshihiko Nakamura,https://www.sciencedirect.com/science/article/pii/S0921889022001270,https://doi.org/10.1016/j.robot.2022.104218,0921-8890,2022,104218,157,Robotics and Autonomous Systems,Resolved viscoelasticity control for robust walking of a humanoid with knee-stretched posture considering singularity,article,YAMAMOTO2022104218
"This study focuses on the problem of determining the posture of a mobile manipulator aiming to reach a target end-effector pose. Any posture of a mobile manipulator can be described using two parameters: the pose of the mobile platform and the joint angles of the manipulator. This study proposes a posture evaluation method for determining the pose of the mobile platform while focusing on two types of uncertainty: (i) the pose error associated with the end-effector caused by the accumulated positioning error of the mobile platform and (ii) the pose estimation error of objects to be grasped. In addition to using pose errors, the proposed method considers the manipulation ability of the end-effector and the tolerance region for grasping an object by the end-effector. Furthermore, this study proposes a method based on Bayes optimization for finding acceptable moving paths for the mobile platform in environments with sparse obstacles. The effectiveness of the proposed methods was demonstrated through simulations using a mobile manipulator. According to simulation results, the proposed methods can find both moving trajectories for the mobile platform and postures for the mobile manipulator within several seconds.","Mobile manipulators, Uncertainty, Pose evaluation, Posture selection",Kimitoshi Yamazaki and Satoshi Suzuki and Yusuke Kuribayashi,https://www.sciencedirect.com/science/article/pii/S092188902200135X,https://doi.org/10.1016/j.robot.2022.104232,0921-8890,2022,104232,158,Robotics and Autonomous Systems,Approaching motion planning for mobile manipulators considering the uncertainty of self-positioning and object?s pose estimation,article,YAMAZAKI2022104232
"This article presents a dataset collected from the subterranean (SubT) environment with a current state-of-the-art sensors required for autonomous navigation. The dataset includes sensor measurements collected with RGB, RGB-D, event-based and thermal cameras, 2D and 3D lidars, inertial measurement unit (IMU), and ultra wideband (UWB) positioning systems which are mounted on the mobile robot. The overall sensor setup will be referred further in the article as a data collection platform. The dataset contains synchronized raw data measurements from all the sensors in the robot operating system (ROS) message format and video feeds collected with action and 360 cameras. A detailed description of the sensors embedded into the data collection platform and a data collection process are introduced. The collected dataset is aimed for evaluating navigation, localization and mapping algorithms in SubT environments. This article is accompanied with the public release of all collected datasets from the SubT environment. Link: Dataset","Dataset, SubT, RGB, RGB-D, Event-based and thermal cameras, 2D and 3D lidars",Anton Koval and Samuel Karlsson and Sina Sharif Mansouri and Christoforos Kanellakis and Ilias Tevetzidis and Jakub Haluska and Ali-akbar Agha-mohammadi and George Nikolakopoulos,https://www.sciencedirect.com/science/article/pii/S0921889022000951,https://doi.org/10.1016/j.robot.2022.104168,0921-8890,2022,104168,155,Robotics and Autonomous Systems,Dataset collection from a SubT environment,article,KOVAL2022104168
"In response to the needs of real-time and accurate detection of the human gait phase for lower limb exoskeleton, the movement of the human foot is taken as the research object, and the human gait phase division method based on human kinematics and dynamics information is studied. This paper presents a wearable foot gait analysis system based on inertial sensors and pressure sensors, and studies the human gait phase recognition method based on plantar acceleration and plantar pressure information. Based on the analysis of the relationship between the plantar acceleration?pressure information and the gait period, the adaptive neural fuzzy reasoning system is used to integrate the information of plantar acceleration and plantar pressure information so as to realize the fast gait phase division. The three proposed methods are compared with the standard results of the Vicon motion capture system by experiments. The experimental results show that the accuracy of the ANFIS method combining the acceleration information and the plantar pressure information to the human gait phase division is 99.16%.","Human gait, Phase division, ANFIS, Signal processing",Jiyuan Song and Aibin Zhu and Yao Tu and Han Mao and Xiaodong Zhang,https://www.sciencedirect.com/science/article/pii/S0921889022000434,https://doi.org/10.1016/j.robot.2022.104087,0921-8890,2022,104087,153,Robotics and Autonomous Systems,Adaptive neural fuzzy reasoning method for recognizing human movement gait phase,article,SONG2022104087
"Parallel kinematic manipulators (PKM) are characterized by closed kinematic loops, due to the parallel arrangement of limbs but also due to the existence of kinematic loops within the limbs. Moreover, many PKM are built with limbs constructed by serially combining kinematic loops. Such limbs are called hybrid, which form a particular class of complex limbs. Design and model-based control requires accurate dynamic PKM models desirably without model simplifications. Dynamics modeling then necessitates kinematic relations of all members of the PKM, in contrast to the standard kinematics modeling of PKM, where only the forward and inverse kinematics solution for the manipulator (relating input and output motions) are computed. This becomes more involved for PKM with hybrid limbs. In this paper a modular modeling approach is employed, where limbs are treated separately, and the individual dynamic equations of motions (EOM) are subsequently assembled to the overall model. Key to the kinematic modeling is the constraint resolution for the individual loops within the limbs. This local constraint resolution is a special case of the general constraint embedding technique. The proposed method finally allows for a systematic modeling of general PKM. The method is demonstrated for the IRSBot-2, where each limb comprises two independent loops.","Parallel kinematic manipulator (PKM), Complex limbs, Kinematic loop, Constraints, Constraint embedding, Redundancy, Inverse kinematics, Singularity, Dynamics, Multibody system, Model-based control, Screws, Lie group (3)",Andreas Müller,https://www.sciencedirect.com/science/article/pii/S0921889022001087,https://doi.org/10.1016/j.robot.2022.104187,0921-8890,2022,104187,155,Robotics and Autonomous Systems,A constraint embedding approach for dynamics modeling of parallel kinematic manipulators with hybrid limbs,article,MULLER2022104187
"This paper investigates the trajectory tracking control of an autonomous tracked vehicle. First, the desired linear and angular velocities are evaluated based on vehicle?s kinematics. An optimized backstepping controller is proposed as the kinematic controller, whereas the controller gains are optimally obtained. Next, an integral sliding mode control (SMC) is exploited based on vehicle dynamics and slipping characteristics, to obtain the desired torques that drive the vehicle and converge its trajectory to the desired one. Moreover, stability analysis of the whole system is proven based on Lyapunov theory. Finally, simulations and real-time experiments based on robot operating system (ROS) implementation are conducted to validate the effectiveness of the proposed control algorithm and compared with a hybrid backstepping-modified PID dynamic controller.","Autonomous tracked vehicles, Backstepping control, Dynamic modeling, Robot operating system (ROS), Sliding mode control (SMC)",Ahmed D. Sabiha and Mohamed A. Kamel and Ehab Said and Wessam M. Hussein,https://www.sciencedirect.com/science/article/pii/S0921889022000276,https://doi.org/10.1016/j.robot.2022.104058,0921-8890,2022,104058,152,Robotics and Autonomous Systems,ROS-based trajectory tracking control for autonomous tracked vehicle using optimized backstepping and sliding mode control,article,SABIHA2022104058
"In this paper, we present an active visual SLAM approach for omnidirectional robots. The goal is to generate control commands that allow such a robot to simultaneously localize itself and map an unknown environment while maximizing the amount of information gained and consuming as low energy as possible. Leveraging the robot?s independent translation and rotation control, we introduce a multi-layered approach for active V-SLAM. The top layer decides on informative goal locations and generates highly informative paths to them. The second and third layers actively re-plan and execute the path, exploiting the continuously updated map and local features information. Moreover, we introduce two utility formulations to account for the presence of obstacles in the field of view and the robot?s location. Through rigorous simulations, real robot experiments, and comparisons with state-of-the-art methods, we demonstrate that our approach achieves similar coverage results with lesser overall map entropy. This is obtained while keeping the traversed distance up to 39% shorter than the other methods and without increasing the wheels? total rotation amount. Code and implementation details are provided as open-source, and all the generated data is available online for consultation.","View planning for SLAM, Vision-based navigation, SLAM, Active Perception",Elia Bonetto and Pascal Goldschmid and Michael Pabst and Michael J. Black and Aamir Ahmad,https://www.sciencedirect.com/science/article/pii/S0921889022000550,https://doi.org/10.1016/j.robot.2022.104102,0921-8890,2022,104102,154,Robotics and Autonomous Systems,iRotate: Active Visual SLAM for Omnidirectional Robots,article,BONETTO2022104102
"A robotic network is a system with multiple robots connected by a communication network. Certain tasks that cannot be accomplished with available robotic resources are candidates for the use of cloud robotics, which overcomes the limitations of the robot network by adding to the network, either local or remote servers or cloud infrastructure, to aid in computational demanding tasks or storage. Previous studies have mainly focused on minimizing the cost of the robots in retrieving resources by knowing the resource allocation in advance. We develop a method for a robotic network cloud system that includes robots, fog and cloud nodes, to determine where each algorithm should be allocated so that the system achieves optimal performance, regardless of which robot initiates the request. We can find the minimum required memory for the robots and the optimal way to allocate the algorithms with the shortest time to complete each task. We experimentally compare our method with a state-of-the-art method, using real-world data, showing the improvements that can be obtained.","Cloud robotics, Robotic networks, Cloud, Fog, Edge, Memory and time optimization, Algorithm allocation",Saeid Alirezazadeh and André Correia and Luís A. Alexandre,https://www.sciencedirect.com/science/article/pii/S0921889022000835,https://doi.org/10.1016/j.robot.2022.104144,0921-8890,2022,104144,154,Robotics and Autonomous Systems,Optimal algorithm allocation for robotic network cloud systems,article,ALIREZAZADEH2022104144
"Self-reconfigurable robots can change their morphology to expose functionality that enables them to overcome challenges that fixed shape robots are unable to overcome. A reconfigurable pavement sweeping robot, Panthera, is able to reconfigure in width by compressing and expanding. This autonomous system overcomes challenges in the pavement cleaning industry, such as access to tight and narrow pavements. Reconfigurability in width enables the robot to maximize cleaning area in an expanded state and navigate through tight spaces in the compressed state, which fixed shape robots are unable to pass through. Despite its advantages, most path planning (PP) algorithms are developed for fixed shape robots, and there are little or no works done on PP for reconfigurable robots that are able to expand and compress in width. To tackle this challenge, we present a novel PP method for pavement-sweeping reconfigurable robots by drawing similarities between heat transfer analysis and PP. Heat travels from the heat source to the heat sink and can only travel through a conductive material. Similarly, PP enables the robot to move from start to goal while accessing the feasible areas. Our proposed path planner employs a thermal gradient ascent combined grid-based optimization algorithm to generate optimal paths for best smoothness, distance, and robot footprint. The path planner is tested in four virtual environments and validated in a real-world environment.","Self-reconfigurable robot, Pavement cleaning robot, Multi-objective path planning, Heat conduction, Mobile robot",Huy Do and Anh {Vu Le} and Lim Yi and Joel Chan Cheng Hoong and Minh Tran and Phan {Van Duc} and Minh Bui Vu and Oliver Weeger and Rajesh Elara Mohan,https://www.sciencedirect.com/science/article/pii/S0921889022000318,https://doi.org/10.1016/j.robot.2022.104063,0921-8890,2022,104063,152,Robotics and Autonomous Systems,Heat conduction combined grid-based optimization method for reconfigurable pavement sweeping robot path planning,article,DO2022104063
"Motion segmentation is important for autonomous robots? activities in dynamic scenes, which has been a challenging problem due to the dual motion caused by the camera and moving objects. The existing methods based on the optical or scene flow are sensitive to the environment, whereas deep learning-based methods commonly do not consider geometric constraints. Aiming at a vehicle, as the most common object in outdoor urban dynamic scenes because other objects, such as people, can be almost directly determined as a moving object, this paper proposes an object-level motion segmentation method for multiple moving objects combining geometric methods and deep learning. First, we choose three kinds of learned information, constructing object-level three-dimensional (3D) scene structure. And then, to infer motion segmentation results from learned information, we propose an instance cross-matching method to obtain instance correspondence and a motion segmentation extraction method based on instance reprojection residual to determine whether the objects are moving or not. The proposed approach is simple and direct, and it can obtain vehicle motion segmentation results from the original RGB images without using the optical or scene flow commonly used to extract motion information. Experiments on public motion segmentation datasets demonstrate that the proposed method can effectively improve the performance of vehicle motion segmentation and is superior to the most advanced methods in terms of accuracy.","Vehicle motion segmentation, Deep learning, Multiple moving objects, Dynamic SLAM, View re-projection",Min Yue and Guangyuan Fu and Ming Wu and Yuqing Zhao and Shaolei Zhang,https://www.sciencedirect.com/science/article/pii/S092188902200094X,https://doi.org/10.1016/j.robot.2022.104166,0921-8890,2022,104166,155,Robotics and Autonomous Systems,Vehicle motion segmentation via combining neural networks and geometric methods,article,YUE2022104166
"This paper addresses the problem of mapping large surfaces with a moving sensor. In particular, it proposes image registration and mapping algorithms that enable to use in continuous motion sensors that need multiple shots to perform a measurement. These methods exploit the knowledge of the shape of the part to inspect in a both efficient and accurate fashion, thus allowing to obtain a measurement quality comparable to that of static measurements, while guaranteeing fast sensor motion and thus short scanning times. This work describes the application of these methods for the mapping of carbon fibre parts with an inspection robot equipped with a sensor estimating 3D carbon fibre orientation from multiple 2D images captured with different illumination. Experiments on carbon fibre preforms of complex 3D shape demonstrates that this system accurately reconstructs in real-time the 3D fibre orientations of the outer layer of carbon fibre parts. Accuracy assessments report small errors within the tolerances allowed by the automotive industry on flat and generic 3D surfaces. The inspection robot system presented in this paper has been demonstrated both as an in-line quality inspection robot for production of carbon fibre preforms and as a measurement device for improving the draping process in the prototyping of carbon fibre parts.","Image registration, Mapping, Sensor in motion, Quality inspection, Carbon fibre, Inspection robot",Matteo Munaro and Morris Antonello and Mauro Antonello and Emanuele Menegatti,https://www.sciencedirect.com/science/article/pii/S0921889022001129,https://doi.org/10.1016/j.robot.2022.104195,0921-8890,2022,104195,156,Robotics and Autonomous Systems,Continuous mapping of large surfaces with a quality inspection robot,article,MUNARO2022104195
"Some robotic platforms are expected to perform coverage path planning (CPP) on a daily basis. However, at times they may be expected to perform CPP in large unknown spaces, which are not fully coverable with the onboard limited energy supply. In these cases the platforms need to revisit the charging station multiple times, increasing mission times and the total energy needed, reducing the availability of the robots. This paper proposes a novel solution to this energy constrained online coverage path planning problem, showing effectiveness of this solution in various settings. The proposed solution is based on contour following and outperforms existing work in the literature. Additionally, this work presents a new lower bound for the minimum number of charges and energy consumed for both, offline and online, energy constrained coverage path planning problems.","Coverage path planning, Energy constrained, Online",Sedat Dogru and Lino Marques,https://www.sciencedirect.com/science/article/pii/S0921889022001403,https://doi.org/10.1016/j.robot.2022.104242,0921-8890,2022,104242,157,Robotics and Autonomous Systems,ECO-CPP: Energy constrained online coverage path planning,article,DOGRU2022104242
"Based on the current situation that most fire-fighting robots are operated by humans and do not have independent planning and operation abilities, in this paper an intelligent fire-fighting robot is designed using multi-sensor fusion. The robot has the functions of automatic inspection and fire-fighting, and can integrate the information of the operational environment and make decisions based multi-sensor fusion. An improved path-planning mechanism is proposed in order to overcome some disadvantages of the ant colony optimization algorithm, such as its easy tendency to reach local optimal solutions, slow convergence speed and weak global searching ability. A comprehensive evaluation method of the improved ACO is established to quantify its relevance and effectiveness. A joint calibration scheme for the color and temperature information obtained using an infrared thermal imager and a binocular vision camera was designed, and the internal and external parameters and distortion coefficient of the camera were successfully obtained. Based on the principle of binocular vision, a fire source detection and location strategy is proposed. When a fire source is detected, the location of the fire source is determined quickly and rescue path planning can be carried out, which improves the intelligence level of the fire-fighting robot. Finally, MATLAB and ROS are used to analyze the improved algorithm, and a fire site patrolling experiment is carried out. The results showed that the improved ACO greatly improves the convergence, reduces the number of iterations and greatly shortens the length of the patrol path, while the robot can effectively determine the location of the fire source efficiently during independent patrols and sound alarms, which will save precious time for fire-fighting and emergency rescue personnel.","Intelligent fire-fighting robot, Multi-sensor fusion, Path planning, Ant Colony Optimization, Fire source identification and location",Shuo Zhang and Jiantao Yao and Ruochao Wang and Zisheng Liu and Chenhao Ma and Yingbin Wang and Yongsheng Zhao,https://www.sciencedirect.com/science/article/pii/S0921889022000677,https://doi.org/10.1016/j.robot.2022.104122,0921-8890,2022,104122,154,Robotics and Autonomous Systems,Design of intelligent fire-fighting robot based on multi-sensor fusion and experimental study on fire scene patrol,article,ZHANG2022104122
"Six-degree-of-freedom (6-DOF) hovering control is important for underwater robots to perform various tasks. Our previous underwater robot study, which used tilting thrusters, could not control 6-DOF motion simultaneously owing to several mechanical and control problems. In this study, we developed a new robot with tilting thrusters and improved 6-DOF hovering performance. The maneuverability of the robot was evaluated by analyzing the force and moment of the thrust vector. Based on this, a redundant tilting mechanism without constraints was designed to solve structural problems. A proportional?integral?derivative (PID)-based control design using the decomposition and compensation method (PID-DC) that is appropriate for this mechanism, was derived. The decomposition method was used to overcome the nonlinearity of the thrust vector caused by the tilting mechanism, and the null-space projection technique was applied to minimize the thrust force and avoid the boundary of the tilting angle. A compensator based on the empirical model of the tilting thruster transferred the control input to the system with regulation. Simulation and experimental results verified the validity of the controller for the 6-DOF hovering motion of the robot, and the hovering performance was significantly improved. Furthermore, the stability of the hovering performance under tidal currents was demonstrated through disturbance experiments.","Hovering control, Underwater robot, Tilting thruster, Redundant tilting mechanism, Empirical model compensation",Jeongae Bak and Yecheol Moon and Jongwon Kim and Santhakumar Mohan and TaeWon Seo and Sangrok Jin,https://www.sciencedirect.com/science/article/pii/S0921889021002529,https://doi.org/10.1016/j.robot.2021.103995,0921-8890,2022,103995,150,Robotics and Autonomous Systems,Hovering control of an underwater robot with tilting thrusters using the decomposition and compensation method based on a redundant actuation model,article,BAK2022103995
"In order to avoid the risk of obstacles collision during the spherical underwater robot (SUR) move to target points in 3D arbitrary path planning, an underwater obstacle avoiding method was studied. Considering the uncertainty of the movement of obstacles in the actual environment, we present an uncertain moving obstacle avoiding method based on the improved velocity obstacle method. In addition, to reduce the distance and time of obstacle avoidance, the concept of the time of obstacle avoiding was designed. First, the size and velocity information of obstacles are obtained through the camera, which can provide an accurate decision basis for obstacles avoidance in the next step. Then, according to the time when the robot collides with the obstacle, the time of start and end of the obstacle avoidance is determined. The movement direction and velocity of the robot are obtained based on the improved velocity obstacle method and the movement characteristics of SUR. Finally, a detailed 3D arbitrary path planning analysis based on an improved ant colony algorithm was conducted. A series of experiments were carried out in the pool that validates the proposed methods are also presented.","Spherical underwater robot, Uncertain dynamic obstacles avoiding, 3D arbitrary path planning, Inertial measurement unit and depth sensor localization",Ruochen An and Shuxiang Guo and Liang Zheng and Hideyuki Hirata and Shuoxin Gu,https://www.sciencedirect.com/science/article/pii/S0921889021002645,https://doi.org/10.1016/j.robot.2021.104011,0921-8890,2022,104011,151,Robotics and Autonomous Systems,Uncertain moving obstacles avoiding method in 3D arbitrary path planning for a spherical underwater robot,article,AN2022104011
"Most of the world?s most advanced defense technologies are robots, and the defence industry is slowly moving toward including AI in the military robots they build. For these smart robots to make their own decisions about where to go and what to do, they need to be limited by several algorithms that run continuously and at the same time. Autonomy is the range of automated systems that can be adapted to a specific mission, residual risk, and level of team cohesion between humans and robots. Self-driving robotic systems should be collaborative, which means they should be able to interact actively with humans in a shared space or in proximity to humans and robots. Human?Robot Collaboration (HRC) works better when these COBOTs are aware of their surroundings. Mobile Robot (MR) teams whose perceptual and cognitive abilities are very well developed can help a lot with context awareness. To work well with humans, these robots should know what is going on with their human and other robot teammates so they can make decisions on their own. Also, robots should be able to share information about their surroundings so that humans can benefit from a better understanding of the situation. At the same time, humans should be able to see what the robots are doing. In this paper, we propose a knowledge-based framework for humans and robots to work together to understand the context of Defense missions. An ontological model of contexts for missions, agents, and situations; a knowledge base comprising all the tools necessary for a sort of situation; and an efficient and reliable method of collaborative learning are some of its main contributions. The framework works well in terms of how long it takes for people to talk to each other. As the team continues to expand, it can also easily manage communication challenges and a widely differing event frequency range.","Human?Robot Collaboration, Communication system, Contextual Intelligence, Military agents, Deep Learning, Defense industry, Ontology, Mobile Robotic Systems",Arodh Lal Karn and Sudhakar Sengan and Ketan Kotecha and Irina V. Pustokhina and Denis A. Pustokhin and V. Subramaniyaswamy and Dharam Buddhi,https://www.sciencedirect.com/science/article/pii/S0921889022001361,https://doi.org/10.1016/j.robot.2022.104234,0921-8890,2022,104234,157,Robotics and Autonomous Systems,ICACIA: An Intelligent Context-Aware framework for COBOT in defense industry using ontological and deep learning models,article,KARN2022104234
"This paper introduces the analysis, design and preliminary evaluation of an anthropometric self-stabilization passive exoskeleton (ASPE) with elastic band to increase the load transmission efficiency and protect and strengthen the human body during loaded walking. Firstly, we analyze the working principle of passive exoskeleton, and propose an efficient method of reducing the degrees of freedom in exoskeleton relatively, which contributes to a self-stabilization mechanism for balancing the back torque causing by the loaded backpack and assisting human hip flexion. The design of the ASPE is then introduced in detail. The novelty of the ASPE is that the human?machine interaction forces are significantly reduced by integrating the elastic band into the exoskeleton hip joint and converting load gravity into the elastic potential energy of elastic band to assist hip joint flexion. Furthermore, we analyze the dynamic modeling of the ASPE to preliminarily calculate the transmission efficiency regarding the ratio of plantar pressure of the ASPE to load gravity. Besides, we conduct the experiment of human wearing the ASPE to evaluate the performance of the ASPE regarding the ratio of the difference of human plantar pressure with and without the ASPE to load gravity. The results show that the ASPE can effectively transfer load gravity to the ground and maintain the human natural movement. The ratio of the plantar pressure of the ASPE to load gravity is more than 70% in the simulation, and when the walking speed is 4 km/h, the ASPE reduce the human plantar pressure of 68.9% compared to without wearing the ASPE during human walking with load. The results provide evidence for the efficient transmission of the newly designed ASPE during walking with loads. The application of the ASPE have benefits for subjects walking with loads, such as soldiers, to decrease their injuries and strengthen their ability.","Passive exoskeleton, Self-stabilization mechanism, Efficient transmission, Dynamic modeling",Nengbing Zhou and Yali Liu and Qiuzhi Song and Zhuo Qi and Weizhi Ren and Kun Zhang,https://www.sciencedirect.com/science/article/pii/S0921889022000392,https://doi.org/10.1016/j.robot.2022.104079,0921-8890,2022,104079,153,Robotics and Autonomous Systems,"Analysis, design and preliminary evaluation of an anthropometric self-stabilization passive exoskeleton for enhancing the ability of walking with loads",article,ZHOU2022104079
"Robotic calibration allows for the fusion of data from multiple sensors such as odometers, cameras etc., by providing appropriate transformational relationships between the corresponding reference frames. For wheeled robots equipped with exteroceptive sensors, calibration entails learning the motion model of the sensor or the robot in terms of the odometric data, and must generally be performed prior to performing tasks such as simultaneous localization and mapping (SLAM). Within this context, the current trend is to carry out simultaneous calibration of odometry and exteroceptive sensors without using additional hardware. Building upon the existing simultaneous calibration algorithms, we put forth a generalized calibration framework that can not only handle robots operating in 2D with arbitrary or unknown motion models but also handle outliers in an automated manner. We first propose an algorithm based on the alternating minimization framework applicable to two-wheel differential drive. Subsequently, for arbitrary but known drive configurations we put forth an iteratively re-weighted least squares methodology leveraging an intelligent weighing scheme. Different from the existing works, these proposed algorithms require no manual intervention and seamlessly handle outliers that arise due to both systematic and non-systematic errors. Finally, we put forward a novel Gaussian Process-based non-parametric approach for calibrating wheeled robots with unknown or un-modeled drive configurations. Detailed experiments are performed to demonstrate the accuracy, usefulness, and flexibility of the proposed algorithms. 11This paper has supplementary downloadable material (available at http://tinyurl.com/simultaneous-calibration) that includes raw-data of all the experiments and implementation codes for the proposed methodologies.","Calibration and identification, Kinematics, Wheeled robots, Sensor fusion, Extrinsic calibration",Mohan Krishna Nutalapati and Lavish Arora and Anway Bose and Ketan Rajawat and Rajesh M. Hegde,https://www.sciencedirect.com/science/article/pii/S0921889022001531,https://doi.org/10.1016/j.robot.2022.104262,0921-8890,2022,104262,158,Robotics and Autonomous Systems,A generalized framework for autonomous calibration of wheeled mobile robots,article,NUTALAPATI2022104262
"This paper proposes the development of a seven degree-of-freedom (DOF) upper extremity exoskeleton to provide robotic therapy solutions for stroke survivors whose number is increasing along with the trend of ?Aging Society?. Various robotic solutions have been illuminated and advanced along with their interfacing system in order to promote motor recovery after stroke. From this point of view, the proposed exoskeleton, RearMEX, is developed to (1) achieve active-actuation for the full range of human arm motions through the compact mechanical structure, (2) perform high force transparency through the reduction of the mechanical impedance, and (3) provide a user-interface for customized arm movements in active daily life. Especially, the exoskeleton system has a minimal impedance mode where a user can choose sequential desired postures for constituting a therapy motion by the simple button on the handgrip. Then, given a desired period for the movement, a novel interpolation method named norm-based time-allocating monotone Bézier interpolation is proposed to generate the corresponding trajectory with no jerk at each instant in the operational or configurational space. Furthermore, the disturbance observer (DOB) scheme is applied to achieve a robust tracking control performance on the interpolated trajectory even with model uncertainties and unexpected physical interactions with a wearer. The experimental results verify that the consistent performance can be achieved under various load conditions using the suggested controller.","Upper extremity exoskeleton, Rehabilitation robot, Bézier polynomials",Beomsu Kim and Kuk-Hyun Ahn and SeungKyu Nam and Dong Jin Hyun,https://www.sciencedirect.com/science/article/pii/S0921889022000720,https://doi.org/10.1016/j.robot.2022.104128,0921-8890,2022,104128,154,Robotics and Autonomous Systems,Upper extremity exoskeleton system to generate customized therapy motions for stroke survivors,article,KIM2022104128
"The critical challenge, for robot?object-interaction, is to estimate visually the pose of the target object in a 3D space and combine it into a vision-based control scheme in manipulation applications. This paper proposes a novel reliable framework for deep ConvNet combined with visual servoing using a single RGB camera. We introduce an extensive system called Deep-Visual-Servoing (DVS) that addresses an integration of: (I) training of deep-CNNs using synthetic dataset only and operates successfully in real-world scenario, (II) continuous 3 D object pose estimation as the sensing feedback in a 3D visual servoing control scheme, and (III) design, integration and experimentation of visual servoing approach based on Lyapunov?s theory. The proposed deep based learning approach, the kinematic modeling and controller design are experimentally verified and discussed using the 6 DOF UR5 manipulator.","Robot?object-interaction, Object-detection and pose estimation, Deep-learning methods, 3D visual-servoing",Abdulrahman Al-Shanoon and Haoxiang Lang,https://www.sciencedirect.com/science/article/pii/S092188902200015X,https://doi.org/10.1016/j.robot.2022.104041,0921-8890,2022,104041,152,Robotics and Autonomous Systems,Robotic manipulation based on 3-D visual servoing and deep neural networks,article,ALSHANOON2022104041
"For robots and autonomous system that rely on visual data for operating in the real world, camera calibration is an indispensable step as it relates image information to the geometric structure of the 3D world. Although it is convenient to consider a several decades old problem as something that is swiftly solvable with a dedicated toolbox, we should still push calibration methods to their practical limits in order to gain valuable insights, and especially when robots are operating in circumstances that concern human safety. In this paper we propose a camera setup calibration procedure with emphasis on visual odometry accuracy. We focus on target-based calibration and two popular datasets are used for evaluating visual odometry and SLAM algorithms, namely the EuRoC and KITTI datasets. Our procedure consists of: (i) introducing a novel highly accurate corner detection algorithm robust to challenging illumination conditions, (ii) investigating different lens distortion models, (iii) incorporating static and dynamic board deformation models, (iv) ex-post analysis of reprojection error sensitivity and calibration parameter uncertainty, and (v) grid search method based on odometry accuracy when board poses do not constrain calibration parameters well enough. The whole process significantly reduced the reprojection error when calibrating the camera setups of the EuRoC and KITTI datasets. We tested four different odometries, namely SOFT, ORB-SLAM2, VINS-FUSION, and VISO2?all four showed higher accuracy with the proposed calibration parameters. Moreover, with the proposed calibration method our SOFT2 scored 0.53% in translation and 0.0009 deg/m in rotation error rendering it currently the highest ranking algorithm on the KITTI scoreboard.","Camera calibration, Visual odometry, Visual SLAM, Parametric lens models",Igor Cvi?i? and Ivan Markovi? and Ivan Petrovi?,https://www.sciencedirect.com/science/article/pii/S0921889022001099,https://doi.org/10.1016/j.robot.2022.104189,0921-8890,2022,104189,155,Robotics and Autonomous Systems,Enhanced calibration of camera setups for high-performance visual odometry,article,CVISIC2022104189
"The haptic terrain classification is an essential component of a mobile walking robot control system, ensuring proper gait adaptation to the changing environmental conditions. In practice, such components are a part of an autonomous system and thus have to be lightweight, provide fast inference time, and guarantee robustness to minor changes in recorded sensory data. We propose transformer-based HAPTR and HAPTR2 terrain classification methods that use force and torque measurements from feet to meet these requirements. For reliable comparison of the proposed solutions, we adapt two classical machine learning algorithms (DTW-KNN and ROCKET), one temporal convolution network (TCN), and use the state-of-the-art CNN-RNN. The experiments are performed on publicly available PUTany and QCAT datasets. We show that the proposed HAPTR and HAPTR2 methods achieve accuracy on par or better than state-of-the-art approaches with a lower number of parameters, faster inference time, and improved robustness to input signal distortions. These features make HAPTR and HAPTR2 excel in terrain recognition tasks when considering real-world requirements.","Legged robots, Deep learning methods, Data sets for robot learning",Micha? Bednarek and Micha? R. Nowicki and Krzysztof Walas,https://www.sciencedirect.com/science/article/pii/S0921889022001373,https://doi.org/10.1016/j.robot.2022.104236,0921-8890,2022,104236,158,Robotics and Autonomous Systems,HAPTR2: Improved Haptic Transformer for legged robots? terrain classification,article,BEDNAREK2022104236
"This article addresses an unified solution to the trajectory tracking and path following problems for differential drive mobile robots (DDMR) considering a point of interest (PoI) with variable location relative to the vehicle. The mobile robot is modeled with an extended kinematic model avoiding typical singularities of this kind of vehicles, and allowing a straightforward definition of the corresponding inverse kinematics controller (IKC). This classical IKC fulfills the control objective with exponential error convergence but with the shortcoming of generating backward navigation when the PoI is located behind the DDMR, which is undesirable in some practical applications where the forward navigation must be preserved. This situation is theoretically analyzed, concluding that even though both forward and backward navigations correspond to equilibrium points of the closed loop, the stability of the forward navigation requires a PoI located in front of the DDMR, and the stability of the backward navigation requires a PoI located behind the DDMR. Finally, the article presents novel alternative controllers in order to always fulfill the motion objectives with stable forward navigation. Simulation results are presented to show the performance of the proposed controllers, and a real application of a robotic cane guiding its user is experimentally developed.","Trajectory tracking, Path following, Extended kinematic model, Variable point of interest, Robotic cane",Javier Gimenez and Flavio Roberti and Juan Marcos Toibero and Ricardo Carelli,https://www.sciencedirect.com/science/article/pii/S0921889022000847,https://doi.org/10.1016/j.robot.2022.104146,0921-8890,2022,104146,154,Robotics and Autonomous Systems,Motion control for a differential vehicle with variable point of interest. Application: Smart cane control,article,GIMENEZ2022104146
"Motion-intention recognition is a vital prerequisite in active training when employing a gait rehabilitation training robot. To accurately recognize the motion intention of the elderly and the people with inconveniences in the human?robot interaction process, a novel approach of motion intention recognition with safety, accuracy, and convenience, including directional intention recognition (DIR) and speed intention recognition (SIR) is proposed in this paper. Firstly, the structures of the gait rehabilitation training robot and its motion-intention recognition system are illustrated. To ensure that the user walks in any desired direction safely and naturally, an improved distance-type fuzzy reasoning algorithm combined with a shake-intent filter and second-order optimization algorithm is proposed. It effectively eliminates the control error caused by body shaking and usage habits in human?robot interaction. Furthermore, by extracting from the pressure sensor data, a novel algorithm, taking advantage of the Gaussian probability density function (PDF)?s characteristics, is proposed for SIR, which does not increase the system complexity. Finally, a multi-directional fuzzy reasoning experiment and a human?robot interaction experiment are implemented. The results show that the algorithm can accurately recognize the motion direction intention and motion speed intention of people with weak motion capability, which also improves the safety and convenience of the interaction approach. The proposed method can be integrated into a walker with similar structures, and the whole system can be applied in hospitals, families, and other places for assisting the elderly and the disabled.","Directional Intention Recognition (DIR), Gait rehabilitation training robot, Safety and accuracy, Speed Intention Recognition (SIR)",A. Donghui Zhao and B. Tianqi Zhang and C. Houde Liu and D. Junyou Yang and E. Hiroshi Yokoi,https://www.sciencedirect.com/science/article/pii/S092188902200152X,https://doi.org/10.1016/j.robot.2022.104260,0921-8890,2022,104260,158,Robotics and Autonomous Systems,Gait rehabilitation training robot: A motion-intention recognition approach with safety and convenience,article,ZHAO2022104260
"This paper tackles the problem of performing persistent and complete coverage of a target space with a minimum number of Unmanned Aerial Vehicles (UAVs). The UAVs are required to preferentially visit subareas of interest with higher frequency than the rest of the surveillance area within a predefined time threshold. A Minimum Spanning Tree based recursive algorithm is firstly proposed to estimate the upper bound of minimum number of UAVs for area coverage with visiting frequency constraints. Then an autonomous path planning strategy is proposed for persistent coverage, where a combinatorial priority function is designed as the goal assignment strategy and a modified Dijkstra algorithm is applied as the goal planning to obtain the optimum path. Finally, computer simulations have been conducted for the evaluation of the proposed solution, and the obtained results show that these algorithms can compute valid and sound solutions under different setups for the UAVs.","Persistent and complete coverage, Minimum Spanning Tree, Priority function, Modified Dijkstra algorithm",Licheng Feng and Jay Katupitiya,https://www.sciencedirect.com/science/article/pii/S0921889022001415,https://doi.org/10.1016/j.robot.2022.104244,0921-8890,2022,104244,157,Robotics and Autonomous Systems,UAV-based persistent full area coverage with dynamic priorities,article,FENG2022104244
"Semi-autonomous control strategies for prosthetic hands provide a promising way to simplify and improve the grasping process for the user by adopting techniques usually applied in robotic grasping. Such strategies endow prosthetic hands with the ability to autonomously select and execute grasps while keeping the user in the loop to intervene at any time for triggering, accepting or rejecting decisions taken by the controller in an intuitive and easy way. In this paper, we present a semi-autonomous control strategy that allows the user to perform fluent grasping of everyday objects based on a single EMG channel and a multi-modal sensor system embedded in the hand for object perception and autonomous grasp execution. We conduct a user study with 20 subjects to assess the effectiveness and intuitiveness of our semi-autonomous control strategy and compare it to a conventional electromyography-based control strategy. The results show that the workload is reduced by 25.9% compared to conventional electromyographic control, the physical demand is reduced by 60% and the grasping process is accelerated by 19.4%.","Semi-autonomous control, Prosthetic hands, Human grasping data, Context-awareness",Julia Starke and Pascal Weiner and Markus Crell and Tamim Asfour,https://www.sciencedirect.com/science/article/pii/S0921889022000689,https://doi.org/10.1016/j.robot.2022.104123,0921-8890,2022,104123,154,Robotics and Autonomous Systems,"Semi-autonomous control of prosthetic hands based on multimodal sensing, human grasp demonstration and user intention",article,STARKE2022104123
"In an ageing society, the at-home use of Socially Assistive Robots (SARs) could provide remote monitoring of their users? well-being, together with physical and psychological support. However, private home environments are particularly challenging for SARs, due to their unstructured and dynamic nature which often contributes to robots? failures. For this reason, even though several prototypes of SARs for elderly care have been developed, their commercialisation and wide-spread at-home use are yet to be effective. In this paper, we analyse how including the end users? feedback impacts the SARs reliability and acceptance. To do so, we introduce a Monitoring and Logging System (MLS) for remote supervision, which increases the explainability of SAR-based systems deployed in older adults? apartments, while also allowing the exchange of feedback between caregivers, technicians, and older adults. We then present an extensive field study showing how long-term deployment of autonomous SARs can be accomplished by relying on such a feedback loop to address any potential issue. To this end, we provide the results obtained in a 130-week long study where autonomous SARs were deployed in the apartments of 10 older adults, with the aim of possibly serving and assisting future practitioners, with the knowledge collected from this extensive experimental campaign, to fill the gap that currently exists for the widespread adoption of SARs.","Socially Assistive Robots, Long-term autonomy, Field study",Matteo Luperto and Marta Romeo and Javier Monroy and Jennifer Renoux and Alessandro Vuono and Francisco-Angel Moreno and Javier Gonzalez-Jimenez and Nicola Basilico and N. Alberto Borghese,https://www.sciencedirect.com/science/article/pii/S0921889022000963,https://doi.org/10.1016/j.robot.2022.104170,0921-8890,2022,104170,155,Robotics and Autonomous Systems,User feedback and remote supervision for assisted living with mobile robots: A field study in long-term autonomy,article,LUPERTO2022104170
"Due to the increasing complexity of today?s tasks and the demand for higher performance and robustness, using a single robot is not always expedient in robotics applications. Therefore, having multiple autonomous robotic agents collaborate utilizing explicit communication is gaining more attention. The goal of this article is to develop a distributed algorithm that allows the formation control of multiple differentially-driven mobile robots. The formation control goal is formulated in a novel manner by leveraging results on the control of a single differentially-driven mobile robot, which is sophisticated due to the present non-holonomic constraint. This results in a nonlinear distributed control problem. The fundamental functionality of the developed algorithm is analyzed in simulation scenarios. The applicability to real-life scenarios is demonstrated through experiments with custom hardware. To the best of the authors? knowledge, this is the first time that nonlinear distributed model predictive control is applied to a formation of differentially-driven mobile robots using a theoretically-founded cost function and, moreover, that the results are verified with hardware experiments.","Formation control, Model predictive control, Distributed control, Non-holonomic systems, Mobile robots, Experiments",Mario Rosenfelder and Henrik Ebel and Peter Eberhard,https://www.sciencedirect.com/science/article/pii/S0921889021002517,https://doi.org/10.1016/j.robot.2021.103993,0921-8890,2022,103993,150,Robotics and Autonomous Systems,Cooperative distributed nonlinear model predictive control of a formation of differentially-driven mobile robots,article,ROSENFELDER2022103993
"Recently, vision-based methods have exhibited promising prospects in assigning autonomous robots more capabilities for better environment perception. Since visual sensors are easily affected under extreme conditions, current image inpainting methods based on CNNs jointly with generative adversarial networks (GANs) usually generate patches quite different from the ground truth (GT), which is harmful to autonomous robots. In this paper, we propose a novel multiscale feature alignment module with an early fusion strategy to align the left and right feature maps to better capture the motion cues between them. Then, the aligned features are fused to fill holes in the left image. To aggregate the multiscale feature maps dynamically, we propose a multiscale feature aggregation module based on an attention mechanism, of which the fusion module is designed as a symmetrical architecture to adaptively incorporate the complementary contextual correlations from different feature branches. In addition, a spatial attention module able to capture the correlations among pixels is introduced into our network to enhance the inpainting capacity and generate more refined details. To evaluate the effectiveness of our proposed method, many experiments are conducted on a stereo image dataset. The quantitative and qualitative results show that our method significantly outperforms the recent state-of-the-art image inpainting methods while running over 22 fps on a single NVIDIA RTX2080Ti GPU.","Stereo image inpainting, CNN, Feature alignment, Attention mechanism",Xiaokang Yang and Hengyu Li and Jingyi Liu and Yonghao Xie and Huayan Pu and Shaorong Xie and Jun Luo,https://www.sciencedirect.com/science/article/pii/S0921889022001130,https://doi.org/10.1016/j.robot.2022.104197,0921-8890,2022,104197,156,Robotics and Autonomous Systems,A novel stereo image self-inpainting network for autonomous robots,article,YANG2022104197
"In this work, we present a framework for constructing a spatial map of an indoor environment using the concept of echolocation. More specifically, we propose a non-linear least squares (NLS) estimator which is combined with a spatial filtering technique, e.g., beamforming, to estimate both the time-of-arrival (TOA) and direction-of-arrival (DOA) of the acoustic echoes. The proposed framework is complemented with an echo detector to classify a spurious estimate and an acoustic reflector, i.e., a wall. Based on these estimators, we propose two algorithms that complement existing range sensors and aid robotic platforms in acoustic reflector localization and mapping: single-channel localization and mapping (ScLAM) and a multi-channel localization and mapping (McLAM). Compared to commonly used sensors, such as lidar, cameras and ultrasonic sensors, our proposed model-based approach can detect transparent surfaces that are typically found in an office environment and could work in audible frequency ranges. A proof-of-concept robotic platform was built to test our algorithms. According to our evaluation, both qualitative and quantitative experiments reveal that the proposed methods can detect an acoustic reflector up to a distance of 1.5 m at a signal-to-diffuse-noise ratio (SDNR) of 0 dB in a simulated environment and 10 dB in a real environment with an accuracy of 80%.","Robot audition, TOA estimation, DOA estimation, Echolocation, Localization, Mapping",Usama Saqib and Jesper Rindom Jensen,https://www.sciencedirect.com/science/article/pii/S0921889021002633,https://doi.org/10.1016/j.robot.2021.104009,0921-8890,2022,104009,150,Robotics and Autonomous Systems,A framework for spatial map generation using acoustic echoes for robotic platforms,article,SAQIB2022104009
"In order to cope with diversified tasks and unstructured environments, a parallel shape formation method for swarm robotics is introduced to adjust the system?s configuration autonomously and flexibly with the user-specified 2-D shape. Given the desired shape to be formed in the form of analytic functions, the forming task of the swarm system is divided into two sub-tasks: the edge robot forming task and the internal robot forming task. Then, the seed robot is selected through the generation and transmission of the gradient to establish the relative coordinate system, and the initial coordinates of robots are obtained through trilateral positioning. Based on that, using the artificial potential field method, under the action of gravitational force generated by the objective analytic functions and repulsion forces generated by other individuals in the neighborhood, edge individuals move to the target boundary; at the same time, internal individuals spread evenly in the target area under the action of the repulsion forces generated by each other. During the forming process, the two sub-tasks are executed in parallel, and the individuals continue to update their real-time positions by dead-reckoning until the desired shape is formed. We evaluate the feasibility and scalability of this novel method in simulation-based experiments, and implement the parallel shape formation algorithm on the Cilibot robot, a hardware system developed in our lab.","Swarm robotics, Shape formation, Task differentiation, Parallel forming, Artificial potential field",Hong-an Yang and Yuhua Li and Xin Duan and Gaopan Shen and Shaohua Zhang,https://www.sciencedirect.com/science/article/pii/S0921889022000161,https://doi.org/10.1016/j.robot.2022.104043,0921-8890,2022,104043,151,Robotics and Autonomous Systems,A parallel shape formation method for swarm robotics,article,YANG2022104043
"We study the problem of synthesizing a controller for an agent with imperfect sensing and a quantitative surveillance objective, that is, an agent is required to maintain knowledge of the location of a moving, possibly adversarial target. We formulate the problem as a one-sided partial-information game with a winning condition expressed as a temporal logic specification. The specification encodes the quantitative surveillance requirement as well as any additional tasks. Solving a partial-information game typically involves transforming it into a perfect-information belief game using a belief-set construction. Such a transformation leads to a state-space explosion, rendering the belief game computationally intractable to solve for most realistic settings. We present a belief-set abstraction technique to transform the partial-information game to a provably sound abstract belief game that can be solved efficiently using off-the-shelf reactive synthesis tools. We introduce a counterexample-guided refinement approach to automatically achieve the abstraction precision sufficient to synthesize a strategy that is provably winning on the original partial-information game. We evaluate the proposed method on multiple case-studies, implemented on hardware as well as high-fidelity ROS/Gazebo simulations where the agent must respond in real-time to a human-controlled adversary.","Synthesis, Formal methods in robotics, Temporal logic, Surveillance, Partial-information",Suda Bharadwaj and Rayna Dimitrova and Jesse Quattrociocchi and Ufuk Topcu,https://www.sciencedirect.com/science/article/pii/S0921889022000410,https://doi.org/10.1016/j.robot.2022.104084,0921-8890,2022,104084,153,Robotics and Autonomous Systems,Synthesis of strategies for autonomous surveillance on adversarial targets,article,BHARADWAJ2022104084
"Advanced human?robot interaction becomes an essential resource in Industry 4.0. Specifically, the deployment of collaborative robots (cobots) has changed the game in modern smart factories. These robotic agents assist human operators, working with them side-by-side on joint task execution. Because cobots are designed to be more co-workers than tools, fluent interaction between the operators and their robotic counterparts is critical for employees? task accomplishment and, thus, high performance. The current study investigates the relationships between four perspectives of human?robot interaction fluency (i.e., the human emotions-oriented, the human contribution-oriented, the robot-oriented, and the team-oriented fluency) and operators? subjective job performance. It also examines the mediating role of work engagement in these relationships. The analysis carried out on 190 male and female cobot operators working on the shop floor showed positive associations between human?robot interaction (HRI) fluency and job performance. The study confirmed the mediating role of work engagement in the relationships of human contribution-oriented fluency and team-oriented fluency with job performance. The obtained results suggest that HRI fluency relates to employee job performance because of the positive affective?cognitive state experienced by the operator when cooperating with a cobot in a coordinated and well-synchronized manner. The findings of the study are discussed within the theoretical framework of cognitive ergonomics, the Job Demand-Control-Support model, the job demands-resources model, and the job design perspective. The article finishes with a conclusion of the results and implications for organizational practice.","Human?robot collaboration, Human?robot interaction fluency, Cobot, Cognitive ergonomics, Job performance, Work engagement",Mateusz Paliga,https://www.sciencedirect.com/science/article/pii/S0921889022001105,https://doi.org/10.1016/j.robot.2022.104191,0921-8890,2022,104191,155,Robotics and Autonomous Systems,Human?cobot interaction fluency and cobot operators? job performance. The mediating role of work engagement: A survey,article,PALIGA2022104191
"Motion planning algorithms for dynamic environments that explicitly take into account actuator constraints require a lot of computational effort due to replanning or optimizing trajectories. This makes them limited in use, especially for autonomous reactive behaviors that need to be computed on-board. Motivated by this need, we present a new real-time method for reactive collision avoidance for systems with bounded curvature in static and dynamic environments. Our approach relies on the implementation of a local steering law that satisfies a predefined bound on path curvature. The steering law depends on a user-defined parametric function that determines the transition between obstacle-free motion and collision avoidance by enforcing an obstacle impenetrability constraint. As such, we propose a systematic procedure which modulates the velocity vector to enforce curvature constraints in complex 2D environments characterized by static and moving obstacles. We provide theoretical guarantees for collision avoidance and we demonstrate this methodology through simulations.","Real-time algorithms, Collision avoidance, Steering law, Curvature constraints, Path planning, Moving obstacles",Andrei Marchidan and Efstathios Bakolas,https://www.sciencedirect.com/science/article/pii/S0921889022000896,https://doi.org/10.1016/j.robot.2022.104156,0921-8890,2022,104156,155,Robotics and Autonomous Systems,A local reactive steering law for 2D collision avoidance with curvature constraints and constant speed,article,MARCHIDAN2022104156
"This work presents a novel stable controller for the person-following task that includes social considerations for a differential drive mobile robot equipped with an RGB-D camera and a laser range finder as main sensors. The proposed controller adapts its behavior based on the knowledge of both: a modified personal space distribution and human user velocity. Control objectives are focused hence on keeping the human user within the camera?s field-of-view while the mobile robot follows it, with a socially acceptable motion through arbitrary paths. To show the good behavior of this proposal, simulation and real experimental results are included and discussed. The asymptotic stability of the overall system is proved through the Lyapunov theory. Also, in our proposal, three state-of-the-art algorithms were integrated with the controller. In particular, a new real-time multi-person skeletal tracking system is used to obtain the relative human?robot position, a text to speech algorithm is used to confirm the commands given by the human, and also, a SLAM algorithm is used to obtain the map of the environment while the main task is being performed. Additionally, a hand gesture recognition module is included to interact with the mobile robot. This way, the robot is allowed to navigate with a socially-aware behavior in environments shared with humans. Finally, subjective and objective metrics are used as a validation method for human perception about the achieved robot motion.","Person-following control, Human?robot social interaction, Socially acceptable robot motion, Motion human-aware robot navigation, Human?robot interactive communication",Julio Montesdeoca and J. Marcos Toibero and Julian Jordan and Andreas Zell and Ricardo Carelli,https://www.sciencedirect.com/science/article/pii/S0921889022000379,https://doi.org/10.1016/j.robot.2022.104075,0921-8890,2022,104075,153,Robotics and Autonomous Systems,Person-Following Controller with Socially Acceptable Robot Motion,article,MONTESDEOCA2022104075
"Complex hydrodynamic modeling and analysis are considered as stumbling blocks in the motion study of underwater bionic robots. In recent years, reinforcement learning techniques have been applied for robot motion control in unknown environments. However, robots may act in an unconventional or dangerous manner during the learning process. These actions increase the training difficulty and decrease the training efficiency. In this study, a biological-inspired reinforcement learning control method is proposed. It realizes the self-learning movement policy of the robot with discretized swimming motions of a beaver without the need to establish motion models, such as hydrodynamics, of underwater robots. The biological-inspired model further reduces the robot?s ineffective movements during the reinforcement learning and improves training efficiency. The experiment results verify the environmental adaptation and self-learning ability of the proposed robot platform and proves the effectiveness of the reinforcement learning control method for robotic swimming based on biological inspiration. This study?s findings provide new ideas for the motion control of underwater bionic robots and further promote the application of artificial intelligence in underwater robots.","Reinforcement learning control, Q-learning, Beaver-like, Swimming, Underwater bionic robots",Gang Chen and Yuwang Lu and Xin Yang and Huosheng Hu,https://www.sciencedirect.com/science/article/pii/S0921889022000653,https://doi.org/10.1016/j.robot.2022.104116,0921-8890,2022,104116,154,Robotics and Autonomous Systems,"Reinforcement learning control for the swimming motions of a beaver-like, single-legged robot based on biological inspiration",article,CHEN2022104116
"Cameras have become increasingly common in vehicles, smartphones, and advanced driver assistance systems. The areas of application of these cameras in the world of intelligent transportation systems are becoming more and more varied: pedestrian detection, line crossing detection, navigation, ?A major area of research currently focuses on mapping that is essential for localization and navigation. However, this step generates an important problem of memory management. Indeed, the memory space required to accommodate the map of a small city is measured in tens gigabytes. In addition, several providers today are competing to produce High-Definition (HD) maps. These maps offer a rich and detailed representation of the environment for highly accurate localization. However, they require a large storage capacity and high transmission and update costs. To overcome these problems, we propose a solution to summarize this type of map by reducing the size while maintaining the relevance of the data for navigation based on vision only. The summary consists in a set of spherical images augmented by depth and semantic information and allowing to keep the same level of visibility in every directions. These spheres are used as landmarks to offer guidance information to a distant agent. They then have to guarantee, at a lower cost, a good level of precision and speed during navigation. Some experiments on real data demonstrate the feasibility for obtaining a summarized map while maintaining a localization with interesting performances.","3D mapping, Summarized mapping, Localization based vision",Imeen {Ben Salah} and Sébastien Kramm and Cédric Demonceaux and Pascal Vasseur,https://www.sciencedirect.com/science/article/pii/S0921889022000136,https://doi.org/10.1016/j.robot.2022.104037,0921-8890,2022,104037,152,Robotics and Autonomous Systems,Summarizing large scale 3D mesh for urban navigation,article,BENSALAH2022104037
"Robot manipulation tasks can be carried out effectively, provided the state representation is satisfactorily detailed. Embodiment difference, Viewpoint difference, and Domain difference are some of the challenges in learning from human demonstration. This work proposes a self-supervised and multi-viewpoint spatial and temporal features unified representation learning method. The algorithm consists of two components: (a) Spatial Component, which learns the setting of the environment, i.e., on which pixels to focus on most to get the best representation of the image regardless of point of view, and (b) Temporal Component that learns how snapshots taken from multiple viewpoints simultaneously (i.e., at the same time-step but from a different viewpoint) are similar and how these snaps are different from snaps taken at a different time-step but same viewpoint. Further, these representations are integrated with the Reinforcement Learning (RL) framework to learn accurate behaviors from videos of humans performing the manipulation task. The effectiveness of this approach is illustrated by training the robots to learn various manipulation tasks i.e., (a) grab objects (b) lift objects (c) open and close drawers from expert demonstrations provided by humans. The algorithm shows great promise and is highly successful across all the manipulation tasks. The robot learns to pick up objects of various shapes, sizes and colors having different orientations and placements on the table. The robot also successfully learns how to open and close drawers. The method is highly sample efficient and addresses the challenges of embodiment, viewpoint, and domain difference.","Self-supervised learning, Reinforcement learning, Representation learning, Imitation learning, Manipulation",Rahul Choudhary and Rahee Walambe and Ketan Kotecha,https://www.sciencedirect.com/science/article/pii/S0921889022001506,https://doi.org/10.1016/j.robot.2022.104256,0921-8890,2022,104256,157,Robotics and Autonomous Systems,Spatial and temporal features unified self-supervised representation learning networks,article,CHOUDHARY2022104256
"This paper proposes deep learning-based footstep planning using Generative Adversarial Networks (GANs) for the indoor navigation of humanoid robots. The GAN-based architecture presents an efficient and accurate path to plan the footsteps of a humanoid robot on Robot Operating System (ROS) based architecture. During navigation, humanoid robots must understand their surroundings and be able to generate footsteps accurately. Although some algorithms that are based on sampling, such as Rapidly Exploring Random Tree (RRT*) and A*, are widely used for path planning, they fail to perform in narrow paths, especially for the footstep generation of humanoid robots. The widely growing deep learning approaches such as GANs are now producing extremely surprising results in solving real-life problems. The experiments conclude that GAN based approach performs better than conventional Dijkstra?s or A* algorithms. The accuracy of the generated footsteps from the GAN-based path planner comes out to be approximately 93%.","Footstep planning, Deep learning, Generative Adversarial Networks, Humanoid robots, Path planning, Robot Operating System",Pradumn Mishra and Urja Jain and Siddharth Choudhury and Surjeet Singh and Anish Pandey and Abhishek Sharma and Ramanpreet Singh and Vimal Kumar Pathak and Kuldeep K. Saxena and Anita Gehlot,https://www.sciencedirect.com/science/article/pii/S0921889022001580,https://doi.org/10.1016/j.robot.2022.104269,0921-8890,2022,104269,158,Robotics and Autonomous Systems,Footstep planning of humanoid robot in ROS environment using Generative Adversarial Networks (GANs) deep learning,article,MISHRA2022104269
"The utility of collocating robots largely depends on the easy and intuitive interaction mechanism with the human. If a robot accepts task instruction in natural language, first, it has to understand the user?s intention by decoding the instruction. However, while executing the task, the robot may face unforeseeable circumstances due to the variations in the observed scene and therefore requires further user intervention. In this article, we present a system called Talk-to-Resolve (TTR) that enables a robot to initiate a coherent dialogue exchange with the instructor by observing the scene visually to resolve the impasse. Through dialogue, it either finds a cue to move forward in the original plan, an acceptable alternative to the original plan, or affirmation to abort the task altogether. To realize the possible stalemate, we utilize the dense captions of the observed scene and the given instruction jointly to compute the robot?s next action. We evaluate our system based on a data set of initial instruction and situational scene pairs. Our system can identify the stalemate and resolve them with appropriate dialogue exchange with 82% accuracy. Additionally, a user study reveals that the questions from our systems are more natural (4.02 on average on a scale of 1 to 5) as compared to a state-of-the-art (3.08 on average).","Human?robot interaction, Ambiguity in HRI, Spatial dialogue, Multi-level ambiguity, Language-vision grounding",Pradip Pramanick and Chayan Sarkar and Snehasis Banerjee and Brojeshwar Bhowmick,https://www.sciencedirect.com/science/article/pii/S0921889022001063,https://doi.org/10.1016/j.robot.2022.104183,0921-8890,2022,104183,155,Robotics and Autonomous Systems,Talk-to-Resolve: Combining scene understanding and spatial dialogue to resolve granular task ambiguity for a collocated robot,article,PRAMANICK2022104183
"Avoiding hybrid obstacles in unknown scenarios with an efficient flight strategy is a key challenge for unmanned aerial vehicle applications. In this paper, we introduce a more robust technique to distinguish and track dynamic obstacles from static ones with only point cloud input. Then, to achieve dynamic avoidance, we propose the forbidden pyramids method to solve the desired vehicle velocity with an efficient sampling-based method in iteration. The motion primitives are generated by solving a nonlinear optimization problem with the constraint of desired velocity and the waypoint. Furthermore, we present several techniques to deal with the position estimation error for close objects, the error for deformable objects, and the time gap between different submodules. The proposed approach is implemented to run onboard in real-time and validated extensively in simulation and real hardware tests, demonstrating our superiority in tracking robustness, energy cost, and calculating time.","Motion planning, UAVs, Point cloud, Dynamic environment",Han Chen and Peng Lu,https://www.sciencedirect.com/science/article/pii/S0921889022000665,https://doi.org/10.1016/j.robot.2022.104124,0921-8890,2022,104124,154,Robotics and Autonomous Systems,Real-time identification and avoidance of simultaneous static and dynamic obstacles on point cloud for UAVs navigation,article,CHEN2022104124
"In this study, an optimal time-safety collision trajectory planning method of manipulator is proposed. It optimizes the coupling and contradictory performance indexes of manipulator joint motion time and safety collision coefficient. The trajectory of the manipulator can be transformed into the position and time series in the joint space by Inverse Kinematics (IK). Among the splines, quintic B-spline used commonly for interpolating robotic trajectories is preferred also in this study. Under the constraints of the manipulator, non-dominated sorting genetic algorithms-II (NSGA-II) is used to optimize the objective function. The total optimized running time is shortened by 33.07 s. The main joints damage before and after optimization of safety collision have been reduced more than 49.4%. After quintic B-spline interpolation, the time-safety collision of manipulator trajectory are effectively optimized. In general, the execution efficiency of the manipulator is improved, the collision damage to the human head is reduced, and the motion control performance of TMS manipulator is improved to be widely used in medical clinic.","Multi-objective optimization, Quintic B-spline interpolation, Safety collision, Time-safety collision trajectory planning, TMS manipulator",Qiang Cheng and Xiaolong Hao and Yi Wang and Wenxiang Xu and Shijun Li,https://www.sciencedirect.com/science/article/pii/S0921889022000148,https://doi.org/10.1016/j.robot.2022.104039,0921-8890,2022,104039,152,Robotics and Autonomous Systems,Trajectory planning of transcranial magnetic stimulation manipulator based on time-safety collision optimization,article,CHENG2022104039
"This paper presents a hierarchical framework for multi-robot temporal logic task planning. We assume that each robot has its individual task specification and the robots have to jointly satisfy a global collaborative task specification, both described in finite linear temporal logic. To reduce the overall computational complexity, a central server firstly extracts and decomposes a collaborative task sequence from the automaton corresponding to the collaborative task specification, and allocates the subtasks in the sequence to robots. The robots then synthesize their initial execution strategies based on locally constructed product automatons, which integrate task requirements of the assigned collaborative tasks and their individual task specifications. Further, to reduce robots? wait time in collaborations, we propose a distributed execution strategy adjusting mechanism to iteratively improve the time efficiency of robots. Finally, we prove the completeness of the proposed framework under assumptions, and analyze its time complexity and optimality. Extensive simulation results verify the scalability and optimization efficiency of the proposed method.","Multi-robot, Task planning, Linear temporal logic",Ruofei Bai and Ronghao Zheng and Yang Xu and Meiqin Liu and Senlin Zhang,https://www.sciencedirect.com/science/article/pii/S0921889022000422,https://doi.org/10.1016/j.robot.2022.104085,0921-8890,2022,104085,153,Robotics and Autonomous Systems,Hierarchical multi-robot strategies synthesis and optimization under individual and collaborative temporal logic specifications,article,BAI2022104085
"Physical human?robot and/or robot?environment interactions require robust contact stability because an unstable interaction could harm the human or environment. Maintaining effective contact performance while preserving robust contact stability still remains a considerable challenge. This is especially true when interacting with uncertain environments, which are characterized as systems experiencing sudden impedance changes from low to high. Although many existing control methods can be useful for practical interaction controls, they may not be applicable to some uncertain environments; they require either a priori knowledge of the environments before contact or time to update parameters while assuming contact stability during adaptation. This paper proposes a new robust interaction control strategy, the stability enforcement-then-performance enhancement, to provide effective contact performance while guaranteeing robust interaction stability in uncertain environments. The proposed strategy first stabilizes the interaction system by regulating a force input command to the robot system. For robustness to uncertain environments, this regulation is based on the robot?s own stability limit only. Performance enhancement then follows by adjusting the motion commands or adapting the robot?s impedance parameters because continuous stable contact can be maintained by the stability enforcement control even in uncertain environments. Theoretical analysis and typical contact experiments demonstrate the effectiveness of the proposed control strategy.","Adaptive control, Contact stability, Impedance control, Interaction control, Robust control, Uncertain environment",Sehun Kim and Jeha Ryu,https://www.sciencedirect.com/science/article/pii/S0921889022000021,https://doi.org/10.1016/j.robot.2022.104023,0921-8890,2022,104023,151,Robotics and Autonomous Systems,Robust interaction control for environments having uncertainties,article,KIM2022104023
"Different authors have addressed a number of problems in the area of distributed control proposing convincing solutions to specific problems such as static coverage, dynamic coverage/exploration, rendezvous, flocking, formation control. However, a major limitation of problem-specific approaches is a fundamental lack of flexibility when the group meets unexpected conditions and has to change its goal on the fly. In this paper, we show that a large class of distributed control problems can be cast into a general framework based on the adoption of the Lloyd methodology. The adoption of a unified framework enables efficient solutions for the specific problems guaranteeing at the same time important safety and functional properties and a large degree of flexibility in the execution of group tasks. The paper sets the theoretical basis for this development and proves the efficacy of the proposed solutions through extensive simulations and experimental results.","Distributed control, Collective behaviours, Lloyd-based algorithms",Manuel Boldrer and Luigi Palopoli and Daniele Fontanelli,https://www.sciencedirect.com/science/article/pii/S092188902200118X,https://doi.org/10.1016/j.robot.2022.104207,0921-8890,2022,104207,156,Robotics and Autonomous Systems,A unified Lloyd-based framework for multi-agent collective behaviours,article,BOLDRER2022104207
"Robots manipulating deformable linear objects (DLOs) ? such as surgical sutures in medical robotics, or cables and hoses in industrial assembly ? can benefit substantially from accurate and fast differentiable predictive models. However, the off-the-shelf analytic physics models fall short of differentiability. Recently, neural-network-based data-driven models have shown promising results in learning DLO dynamics. These models have additional advantages compared to analytic physics models, as they are differentiable and can be used in gradient-based trajectory planning. Still, the data-driven approaches demand a large amount of training data, which can be challenging for real-world applications. In this paper, we propose a framework for learning a differentiable data-driven model for DLO dynamics with a minimal set of real-world data. To learn DLO twisting and bending dynamics in a 3D environment, we first introduce a new suitable DLO representation. Next, we use a recurrent network module to propagate effects between different segments along a DLO, thereby addressing a critical limitation of current state-of-the-art methods. Then, we train a data-driven model on synthetic data generated in simulation, instead of foregoing the time-consuming and laborious data collection process for real-world applications. To achieve a good correspondence between real and simulated models, we choose a set of simulation model parameters through parameter identification with only a few trajectories of a real DLO required. We evaluate several optimization methods for parameter identification and demonstrate that the differential evolution algorithm is efficient and effective for parameter identification. In DLO shape control tasks with a model-based controller, the data-driven model trained on synthetic data generated by the resulting models performs on par with the ones trained with a comparable amount of real-world data which, however, would be intractable to collect.","Deformable linear object, Model learning, Parameter identification, Model predictive control",Yuxuan Yang and Johannes A. Stork and Todor Stoyanov,https://www.sciencedirect.com/science/article/pii/S0921889022001518,https://doi.org/10.1016/j.robot.2022.104258,0921-8890,2022,104258,158,Robotics and Autonomous Systems,Learning differentiable dynamics models for shape control of deformable linear objects,article,YANG2022104258
"This article proposes a novel nonlinear state estimation framework for humanoid robots based on the dynamics of the center of mass (CoM) and dual-loop Kalman filter(DLKF). It effectively fuses the information from inertial measurement unit(IMU), joint encoders, and foot sensitive resistors (FSRs), and provides state estimates for various gait generation algorithms and dynamic balance controllers with CoM or divergence component of motion (DCM) feedback. Compared to the widely used linear models such as the linear inverted pendulum model (LIPM), the nonlinear dynamics of CoM effectively reduce the process error. However, the humanoid robot is a highly complex dynamic system with multiple links and joints, the dynamics of CoM are also a simplification of the whole body dynamics. As a result, it brings non-zero-mean, non-Gaussian, and correlated process error, which the conventional extend Kalman filter (EKF) cannot handle. To this end, the DLKF is adopted to compensate the process error, thus the estimator is robust to the modeling error caused by simplifications. Furthermore, the invariant extended Kalman filter (IEKF) is used for floating base kinematics estimation, and the force/torque (F/T) sensor which is difficult to integrate on smaller or cheaper robots due to the size and cost is not used in our framework. Finally, our nonlinear state estimation framework improves the accuracy of CoM and DCM estimation in a virtual environment simulation using our self-developed Defensor hydraulic humanoid robot.","Humanoid robot state estimation, Dynamics of the center of mass, Dual-loop Kalman filter, Invariant extended Kalman filter",Jingchao Li and Zhaohui Yuan and Sheng Dong and Jingqin Zhang and Jianrui Zhang,https://www.sciencedirect.com/science/article/pii/S0921889022000549,https://doi.org/10.1016/j.robot.2022.104100,0921-8890,2022,104100,153,Robotics and Autonomous Systems,A nonlinear state estimation framework for humanoid robots,article,LI2022104100
"Geometric errors directly affect the position of the end-effector of a Parallel Kinematic Manipulator (PKM), thus reducing its positioning accuracy. However, the tasks that are performed by PKMs, such as high-precision machining using a kinematic model with nominal values, are affected by machine errors that are not taken into account. Therefore, it is important to make an accurate determination of a machine?s error factors to obtain an accurate error model. Identifying the most crucial geometric errors and determining a method to control them is key in improving the accuracy of PKMs. To achieve this objective, a new method of sensitivity analysis, allowing the crucial geometric errors for parallel and serial manipulators to be identified, is proposed. A new dimensionless sensitivity index, based on the definition of a Local Sensitivity Index (LSI), is used to perform this analysis. The geometric error modeling is performed by deriving the position vector of the end-effector of the PKM. To test the efficiency of the proposed method, the main sources of PAR2 PKM errors are identified. The results show that 33.3% of the error components (main errors) from all error sources can be improved, to achieve a 51.8% improvement in the accuracy of the position error. These results indicate that the error sensitivity analysis method is quite effective, and can significantly contribute to improving the accuracy of a PKM.","Sensitivity analysis, New sensitivity index, PAR2 PKM, Position error modeling, Precision design",Allaoua Brahmia and Ridha Kelaiaia and Olivier Company and Ahmed Chemori,https://www.sciencedirect.com/science/article/pii/S092188902200001X,https://doi.org/10.1016/j.robot.2022.104021,0921-8890,2022,104021,150,Robotics and Autonomous Systems,Kinematic sensitivity analysis of manipulators using a novel dimensionless index,article,BRAHMIA2022104021
"Despite the relatively young age of Human?Robot Interaction (HRI) as a field, there is a large volume of research on advances in robot hardware, software and behavior. The goal of this article is to survey trends in social robot design, to provide an evidence-based approach and guidelines that can inform future social robot development. To this end, this article systematically reviews the evolution of social robots with a focus on their applications, technical features and design. In total 9920 articles from ACM Digital Library (n=4223) and IEEE Explore (n=5697) were reviewed. In order to make this review as inclusive as possible, a broad definition of social robots was used to make decisions about inclusion/exclusion of a given social robot during the review process. As a result, a total of 344 social robots were examined in the review with features being embodiment, mobility, total number of degrees of freedom, existence of a manipulator, size, weight, shell build, applications, target user group, commercial availability, social software capabilities, sensors, interaction modalities, face, software extension capability and initial release year. This resulted in a rich dataset with detailed information about the social robots used in the HRI field. We also provide design guidelines for social robots to inform future research. Findings of this review may help both researchers & practitioners to select, and/or design, the best social robot for their particular experiment or application scenario.","Assistive robots, Human?robot interaction, Robots in education, Companion robots, Domestic robots, Healthcare robots, Personal robots, Rehabilitation robots, Robot assistant, Therapy robots, Robot peers, Robot societies, Social robots, Toy robots, Evolution of social robots, History of social robots",Hamza Mahdi and Sami Alperen Akgun and Shahed Saleh and Kerstin Dautenhahn,https://www.sciencedirect.com/science/article/pii/S0921889022001117,https://doi.org/10.1016/j.robot.2022.104193,0921-8890,2022,104193,156,Robotics and Autonomous Systems,"A survey on the design and evolution of social robots ? Past, present and future",article,MAHDI2022104193
"Biped climbing robots can move and work in three-dimensional steel structures, but are extremely sensitive to the weight, size, and adsorption performance of the devices attached at both their ends. Herein, we propose a novel gripper for biped climbing robots comprising two layers of multiple fan-shaped permanent magnets, wherein the upper layer can coaxially rotate with respect to the lower layer. The novel magnetic gripper can switch between the release and adsorption states by rotating the upper layer of magnets to a particular angle, and it can approximately linearly control the adsorption force by varying this rotation angle. The structural parameters and layout of the magnets were studied and optimized, and the adsorption characteristics of the gripper were analyzed via simulations and verified via experiments. Additionally, the proposed magnetic gripper was applied in a biped climbing robot for verifying the effectiveness of the design based on three climbing tests. The results revealed that the proposed magnetic gripper outperformed the existing models in terms of adsorption force to mass ratio. The proposed gripper design offers the advantages of compact structure, simple control, and natural self-locking of the release and adsorption states.","Biped climbing robots, Switchable magnetic grippers, Simulation of adsorption characteristics, Steel structures",Haifei Zhu and Zidong Lin and Jingyu Yan and Pengcheng Ye and Weixin Zhang and Shixin Mao and Yisheng Guan,https://www.sciencedirect.com/science/article/pii/S0921889022000938,https://doi.org/10.1016/j.robot.2022.104164,0921-8890,2022,104164,155,Robotics and Autonomous Systems,Compact lightweight magnetic gripper designed for biped climbing robots based on coaxial rotation of multiple magnets,article,ZHU2022104164
"Predictive, inference-based occupancy mapping has been used successfully in many instances to create accurate and descriptive maps from sparse data, defining occupied space in a manner suitable to support autonomous navigation. However, one key drawback of inferring occupancy based largely on the proximity of range sensor observations is inaccuracy at the boundary between occupied and free space, where sparse coverage by the sensor data can be misinterpreted. To obtain a more accurate representation of the boundary between free and occupied space, we propose several modifications to a recently published occupancy mapping algorithm that uses Bayesian generalized kernel inference. In particular, our proposed algorithm distinguishes between unknown map cells with insufficient observations, and those which are uncertain due to disagreement among numerous observations, in a predictive, inference-based occupancy map. This distinction is key to our improved ability to capture ambiguities arising at the boundary between free and occupied space. We validate our approach using synthetic range data from a simulated environment and demonstrate real-time mapping performance using range data acquired by a ground robot operating in an underground mine.","Mapping, Range sensing, Mobile robotics",Erik Pearson and Kevin Doherty and Brendan Englot,https://www.sciencedirect.com/science/article/pii/S0921889022000380,https://doi.org/10.1016/j.robot.2022.104077,0921-8890,2022,104077,153,Robotics and Autonomous Systems,Improving obstacle boundary representations in predictive occupancy mapping,article,PEARSON2022104077
"This paper presents novel strategies for spawning and fusing submaps within an elastic dense 3D reconstruction system. The proposed system uses spatial understanding of the scanned environment to control memory usage growth by fusing overlapping submaps in different ways. This allows the number of submaps and memory consumption to scale with the size of the environment rather than the duration of exploration. By analysing spatial overlap and semantic information, our system segments distinct spaces on-the-fly during exploration, such as rooms, stairwells, and indoor?outdoor transitions. The proposed system associates semantically labelled submaps with poses of SLAM pose graph to enable global elasticity. A probabilistic model to merge the voxel labels of the different submaps is incorporated to ensure correct semantic submap fusion when SLAM loop closures occur. Additionally, we present a new mathematical formulation of relative uncertainty between poses to improve the global consistency of the reconstruction. Performance is demonstrated using experiments exploring multi-floor multi-room indoor environments, indoor?outdoor transitions and large-scale outdoor experiments. Relative to our baseline, the presented approach demonstrates improved scalability and accuracy.","LiDAR reconstruction, Pose-graph SLAM, Submaps, Semantic segmentation",Yiduo Wang and Milad Ramezani and Matias Mattamala and Sundara Tejaswi Digumarti and Maurice Fallon,https://www.sciencedirect.com/science/article/pii/S0921889022001075,https://doi.org/10.1016/j.robot.2022.104185,0921-8890,2022,104185,155,Robotics and Autonomous Systems,Strategies for large scale elastic and semantic LiDAR reconstruction,article,WANG2022104185
"In robotic microassembly and micromanipulation, robotic grasper plays a vital role in picking up and releasing the product. However, the design synthesis method for creating a new robotic grasper has not deeply considered yet. Therefore, this article presents an effective computation method for designing a new robotic grasper that can be used for microassembly and micromanipulation. Firstly, a new structural scheme of robotic grasper is made by using the topology procedure. The compliance is the objective with the stress constraint during the topology. Then, a new variant of the grasper is refined where compliant joints are needed to reach the better compliance and the elastic motions of grasping hands. In the second phase, the modeling establishment for predicting the behaviors of the grasper are built via using the intelligent computation, namely GENFIS#1-neuro-fuzzy inference system (ANFIS), GENFIS#2-ANFIS, and GENFIS#3-ANFIS. The numerical data of the grasper are collected via the design of experiment-based finite element method. The results indicated that the GENFIS#3-ANFIS type is the best solver for modeling the hand?s stroke, the resonant frequency, and the strain energy. Meanwhile, the GENFIS#2-ANFIS type was the best procedure for modeling the stress. Subsequently, the optimum geometrical dimensions of the grasper are searched by using the Bonobo optimizer to improve the four mentioned performances of the grasper. In the circumstance #1, the results found that the hand?s displacement is about 0.0922 mm, the resonant frequency is 67.6247 Hz, the elastic energy is 1.4550 mJ, and the stress is 6.7249 MPa. The circumstance #2 determined the resonant frequency of 67.6247 Hz, the hand?s displacement of 0.0883 mm, the elastic energy of 1.9914 mJ, and the stress of 6.7086 MPa. Finally, the circumstance #3 found the elastic energy of 2.0501 mJ, the hand?s displacement of 0.0884 mm, the resonant frequency of 80.0012 Hz, and the stress of 6.7046 MPa. Statistically compared with the other methods, the presented method is the simple and effective procedure for designing 3D printed robotic grasper.","Robotic grasper, Intelligent-based topology, Microassembly and micromanipulation, Bonobo optimizer, 3D printing",Ngoc Thoai Tran and Minh Phung Dang and Alokesh Pramanik and Animesh Basak and S. Shankar and Dharam Buddhi and Thanh-Phong Dao,https://www.sciencedirect.com/science/article/pii/S0921889022001191,https://doi.org/10.1016/j.robot.2022.104209,0921-8890,2022,104209,156,Robotics and Autonomous Systems,A computational design of robotic grasper by intelligence-based topology optimization for microassembly and micromanipulation,article,TRAN2022104209
"Reconfigurable modular robots have the potential to achieve a range of tasks by changing their physical configuration. To identify a suitable configuration, the use of libraries has been suggested. However, such libraries usually assume centralized control, and developing a hardware-dependent library for all assumed tasks may be impractical. In this article, we focus on slope and gap traversal tasks for single-legged reconfigurable modular robots. We propose an autonomous distributed system to traverse the environments without determining the desired configuration a priori. Each module locally monitors the failure risk of the environment traversal for the entire robot. When it detects the high failure risk, the entire robot changes its morphology by adding an additional module to the component of the robot at a connecting place determined by the failure experience. By repeating the procedure, the entire robot gradually adapts the morphology to the environment and finally traverses the environment. Through dynamic simulations and robot experiments, we validated that entire robots with several initial configurations succeeded in changing their morphologies and traversing several slope and gap environments.","Swarm robotics, Legged robot, Modular robot, Slope and gap traversal, Self-organization",Tomohiro Hayakawa and Fumitoshi Matsuno,https://www.sciencedirect.com/science/article/pii/S0921889022000872,https://doi.org/10.1016/j.robot.2022.104152,0921-8890,2022,104152,155,Robotics and Autonomous Systems,Autonomous distributed system for single-legged modular robots to traverse environments by adaptive reconfiguration,article,HAYAKAWA2022104152
"This paper introduces a wildfire monitoring system based on a fleet of Unmanned Aerial Vehicles (UAVs) to provide firefighters with precise and up-to-date information about a propagating wildfire, so that they can devise efficient suppression actions. We present an approach to plan trajectories for a fleet of fixed-wing UAVs to observe a wildfire evolving over time by tailoring the Variable Neighborhood Search metaheuristic to the problem characteristics. Realistic models of the terrain, of the fire propagation process, and of the UAVs are exploited, together with a model of the wind, to predict wildfire spread and plan accordingly the UAVs motions. Algorithms and models are integrated within a software architecture allowing tests with real and simulated UAVs flying over synthetic wildfires. Results of a mixed-reality test campaign show the ability of the proposed system to effectively map wildfire propagation.","UAV, Remote sensing, Wildfire monitoring, Multi-robot planning",Rafael Bailon-Ruiz and Arthur Bit-Monnot and Simon Lacroix,https://www.sciencedirect.com/science/article/pii/S0921889022000355,https://doi.org/10.1016/j.robot.2022.104071,0921-8890,2022,104071,152,Robotics and Autonomous Systems,Real-time wildfire monitoring with a fleet of UAVs,article,BAILONRUIZ2022104071
"Recent image-based robotic systems use predicted future state images to control robots. Therefore, the prediction accuracy of the future state image affects the performance of the robot. To predict images, most previous studies assume that the camera captures the entire scene and that the environment is static. However, in real robot applications, these assumptions do not always hold. For example, if a camera is attached to a mobile robot, its view changes from time to time. In this study, we analyzed the relationship between the performance of the image prediction model and the robot?s behavior, controlled by an image-based navigation algorithm. Through mobile robot navigation experiments using front-faced and omni-directional cameras, we discussed the capabilities of the image prediction models and demonstrated their performance when applied to the image-based navigation algorithm. Moreover, to adapt to the dynamic changes in the environment, we studied the effectiveness of directing the camera to the ceiling. We showed that robust navigation can be achieved without using images from cameras directed toward the front or the floor, because these views can be disturbed by moving objects in a dynamic environment.","Omni-directional camera, Action-conditioned image prediction, Mobile robot",Yu Ishihara and Masaki Takahashi,https://www.sciencedirect.com/science/article/pii/S0921889021002682,https://doi.org/10.1016/j.robot.2021.104018,0921-8890,2022,104018,150,Robotics and Autonomous Systems,Empirical study of future image prediction for image-based mobile robot navigation,article,ISHIHARA2022104018
"When designing social robots, it is crucial to understand the diverse expectations of different kinds of innovation adopters. Different factors influence early adopters of innovations and mass market representatives? perceptions of the usefulness of social robots. The first aim of the study was to test how applicable the technology acceptance model 3 (TAM3) is in the context of social robots. Participants? acceptance of social robotics in a workplace environment in the fuzzy front-end (FFE) innovation phase of a robot development project was examined. Based on the findings for the model, we developed a reduced version of the TAM3 that is more applicable for social robots. The second objective was to analyze how early adopters? and mass market representatives? acceptance of social robots differs. Quantitative research methods were used. For early adopters, result demonstrability has a significant influence on perceived usefulness of social robots, while for mass market representatives, perceived enjoyment has a more significant influence on perceived usefulness. The findings indicate that users? innovation adoption style influences the factors that users consider important in the usefulness of social robots. Robot developers should take these into account during the FFE innovation phase.","Robots, Technology acceptance model, Early adopter, Mass market representative, Diffusion of innovations, Workplace",Ulla A. Saari and Antero Tossavainen and Kirsikka Kaipainen and Saku J. Mäkinen,https://www.sciencedirect.com/science/article/pii/S0921889022000112,https://doi.org/10.1016/j.robot.2022.104033,0921-8890,2022,104033,151,Robotics and Autonomous Systems,Exploring factors influencing the acceptance of social robots among early adopters and mass market representatives,article,SAARI2022104033
"With the increasing requirements for vehicle adaptability and maneuverability in various road environments, four-wheel-steering four-wheel-drive (4WS4WD) vehicles have attracted wider attention. This paper presents a robust model predictive control-based strategy for the path tracking of 4WS4WD vehicles considering external disturbances. The strategy combines model predictive control (MPC) and control allocation under an upper?lower structure. The main objective of the present work is to improve the robustness and stability of path tracking by developing an MPC algorithm in the upper layer. The controller design considers general disturbances caused by allocation errors and sudden disturbances caused by an outer force in the offset model. Based on the offset model, a robust MPC control law is obtained by converting the robustness constraints into a linear matrix inequality. The control law is mathematically demonstrated to be stable in multidisturbed conditions via the Lyapunov stability theorem. Through comparison with a similar control algorithm of path tracking and applying it on different uneven ground conditions, the proposed robust algorithm is found to effectively overcome disturbances on the system.","Mobile robot, 4WS4WD vehicle, Path tracking, Model Predictive Control, Robustness",Qifan Tan and Cheng Qiu and Jing Huang and Yue Yin and Xinyu Zhang and Huaping Liu,https://www.sciencedirect.com/science/article/pii/S0921889022001567,https://doi.org/10.1016/j.robot.2022.104267,0921-8890,2022,104267,158,Robotics and Autonomous Systems,Path tracking control strategy for off-road 4WS4WD vehicle based on robust model predictive control,article,TAN2022104267
"In the last decades, Light Detection And Ranging (LiDAR) technology has been extensively explored as a robust alternative for self-localization and mapping. These approaches typically state ego-motion estimation as a non-linear optimization problem dependent on the correspondences established between the current point cloud and a map, whatever its scope, local or global. This paper proposes LiODOM, a novel LiDAR-only ODOmetry and Mapping approach for pose estimation and map-building, based on minimizing a loss function derived from a set of weighted point-to-line correspondences with a local map abstracted from the set of available point clouds. Furthermore, this work places a particular emphasis on map representation given its relevance for quick data association. To efficiently represent the environment, we propose a data structure that combined with a hashing scheme allows for fast access to any section of the map. LiODOM is validated by means of a set of experiments on public datasets, for which it compares favourably against other solutions. Its performance on-board an aerial platform is also reported.","LiDAR odometry, Mapping, Localization",Emilio Garcia-Fidalgo and Joan P. Company-Corcoles and Francisco Bonnin-Pascual and Alberto Ortiz,https://www.sciencedirect.com/science/article/pii/S0921889022001324,https://doi.org/10.1016/j.robot.2022.104226,0921-8890,2022,104226,156,Robotics and Autonomous Systems,LiODOM: Adaptive local mapping for robust LiDAR-only odometry,article,GARCIAFIDALGO2022104226
"Collision avoidance is one of the most important requirements for autonomous vehicles, particularly in complex and congested traffic scenarios where trajectories have little safety redundancy. However, simultaneously reaching the required accuracy and universal feasibility for different collision-avoidance behaviours is difficult due to the multi-state coupled motion of vehicles. To achieve the maximum traversability and ensure the safety of autonomous vehicles in any complex scenarios, we propose a quasi-critical collision-avoidance strategy based on a newly developed algorithm: the exclusive area-of-relative-velocity vector. This strategy first involves the construction of an exclusive area-of-velocity vector for each object vehicle to extract its position relative to the subject vehicle. In this procedure, to establish a subject-motion-decoupled scenario, projective transformation is applied to regularise the moving elliptical contour of the subject vehicle as a settled circle while retaining all positional relationships between the subject and object vehicles using the invariants. Subsequently, a group of escaping conditions for this exclusive area are established to express this quasi-critical collision-avoidance strategy explicitly and mathematically. The ultimate ability to escape from such an area is determined through theoretical derivations and experiments according to vehicle dynamics. In terms of real scenario data, a set of escaping equations is established to calculate the escaping conditions subject to the current state and the ultimate motion ability. Via scenario verifications, this strategy is shown to represent the safety boundary accurately and ensure quasi-critical collision-avoidance conditions under complex scenarios.","Autonomous vehicle, Collision-avoidance strategy, Relative velocity vector, Escaping equations",Zhaolin Liu and Jiqing Chen and Hongyang Xia and Fengchong Lan,https://www.sciencedirect.com/science/article/pii/S0921889022000197,https://doi.org/10.1016/j.robot.2022.104049,0921-8890,2022,104049,153,Robotics and Autonomous Systems,Quasi-critical collision-avoidance strategy for autonomous vehicles in complex traffic scenarios based on exclusive area of relative velocity vector algorithm,article,LIU2022104049
"We present an approach for safe motion planning under robot state and environment (obstacle and landmark location) uncertainties. To this end, we first develop an approach that accounts for the landmark uncertainties during robot localization. Existing planning approaches assume that the landmark locations are well known or are known with little uncertainty. However, this might not be true in practice. Noisy sensors and imperfect motions compound to the errors originating from the estimate of environment features. Moreover, possible occlusions and dynamic objects in the environment render imperfect landmark estimation. Consequently, not considering this uncertainty can wrongly localize the robot, leading to inefficient plans. Our approach thus incorporates the landmark uncertainty within the Bayes filter estimation framework. We also analyze the effect of considering this uncertainty and delineate the conditions under which it can be ignored. Second, we extend the state-of-the-art by computing an exact expression for the collision probability under Gaussian distributed robot motion, perception and obstacle location uncertainties. We formulate the collision probability process as a quadratic form in random variables. Under Gaussian distribution assumptions, an exact expression for collision probability is thus obtained which is computable in real-time. In contrast, existing approaches approximate the collision probability using upper-bounds that can lead to overly conservative estimate and thereby suboptimal plans. We demonstrate and evaluate our approach using a theoretical example and simulations. We also present a comparison of our approach to different state-of-the-art methods.","Localization, Collision probability, Obstacle avoidance",Antony Thomas and Fulvio Mastrogiovanni and Marco Baglietto,https://www.sciencedirect.com/science/article/pii/S0921889022001166,https://doi.org/10.1016/j.robot.2022.104203,0921-8890,2022,104203,156,Robotics and Autonomous Systems,Safe motion planning with environment uncertainty,article,THOMAS2022104203
"Human dancers can understand and judge the aesthetics of their own dance motions from their movement perception. Inspired by this, we propose a novel mechanism of automatic aesthetics assessment of robotic dance motions, which is based on ensemble learning aimed at developing the autonomous judgment ability of robots. In the proposed mechanism, key pose descriptors based higher-order clustering features are designed to characterize robotic dance motion. Then, an ensemble classifier is built to train a machine aesthetics model for the automatic aesthetics assessment on robotic dance motions. The proposed mechanism has been implemented on a simulated robot environment, and experimental results show its feasibility and good performance.","Machine aesthetics, Ensemble learning, Kinematic perception",Hua Peng and Jing Li and Huosheng Hu and Keli Hu and Liping Zhao and Chao Tang,https://www.sciencedirect.com/science/article/pii/S0921889022000914,https://doi.org/10.1016/j.robot.2022.104160,0921-8890,2022,104160,155,Robotics and Autonomous Systems,Automatic aesthetics assessment of robotic dance motions,article,PENG2022104160
"This work presents a field-hardened autonomous multimodal legged-aerial robotic system for subterranean exploration, extending a legged robot to be the carrier of an aerial platform capable of a rapid deployment in search-and-rescue scenarios. The driving force for developing such robotic configurations are the requirements for large-scale and long-term missions, where the payload capacity and long battery life of the legged robot is combined and integrated with the agile motion of the aerial agent. The multimodal robot is structured around the quadruped Boston Dynamics Spot, enhanced with a custom configured autonomy sensor payload as well as a UAV carrier platform, while the aerial agent is a custom built quadcopter. This work presents the novel design and hardware implementation as well as the onboard sensor suites. Moreover it establishes the overall autonomy architecture in a unified supervision approach while respecting each locomotion modality, including guidance, navigation, perception, state estimation, and control capabilities with a focus on rapid deployment and efficient exploration. The robotic system complete architecture is evaluated in real subterranean tunnel areas, in multiple fully autonomous search-and-rescue missions with the goal of identifying and locating objects of interest within the subterranean environment.","Field robotics, Search-and-rescue robotics, Unmanned aerial vehicles, Quadruped robots, Multimodality robots, Subterranean exploration",Björn Lindqvist and Samuel Karlsson and Anton Koval and Ilias Tevetzidis and Jakub Halu?ka and Christoforos Kanellakis and Ali-akbar Agha-mohammadi and George Nikolakopoulos,https://www.sciencedirect.com/science/article/pii/S0921889022000756,https://doi.org/10.1016/j.robot.2022.104134,0921-8890,2022,104134,154,Robotics and Autonomous Systems,Multimodality robotic systems: Integrated combined legged-aerial mobility for subterranean search-and-rescue,article,LINDQVIST2022104134
"Autonomous robots must have the ability to build an accurate map of an unknown environment by fully covering it in an exploration task. Several exploration approaches combine a Simultaneous Localization and Mapping (SLAM) technique with a strategy to move the robot through the environment actively looking for loops to be closed. When closing a loop, the robot revisits a previously mapped area, which allows it to reduce the uncertainty about its pose. In this paper, we present a concise environment representation named Loop-Aware Exploration Graph (LAEG). The LAEG?s nodes represent the essential information to the exploration process, such as the robot?s position and the frontiers of two different kinds, while the LAEG?s edges are the connections between these elements. Furthermore, the LAEG uses a specific type of edge to explicitly represent the predicted loops, facilitating the incorporation of this information into the exploration decision process. We also present an exploration approach that relies on the LAEG to make the decisions. Consequently, our approach maximizes the chances of closing a loop when choosing the next region to be explored, which is eased by the LAEG that represents the predicted loops as edges. The effectiveness of the proposed exploration approach was evaluated through experiments in five environments, comparing it with a greedy approach that only chases the most attractive unknown region and another one that makes the robot actively look for loop-closures.","Mobile robotics, Autonomous robots, Exploration strategy, Map abstraction",Diego Pittol and Mathias Mantelli and Renan Maffei and Mariana Kolberg and Edson Prestes,https://www.sciencedirect.com/science/article/pii/S092188902200104X,https://doi.org/10.1016/j.robot.2022.104179,0921-8890,2022,104179,155,Robotics and Autonomous Systems,Loop-Aware Exploration Graph: A concise representation of environments for exploration and active loop-closure,article,PITTOL2022104179
"The important thing about mobile robotics is that its use satisfies rapid movement without collisions. Several methods have been designed for this purpose, but not all of them give the results expected by the user. Our contribution in this article is to allow the mobile robot to take advantage of two methods by the hybridization effect. These methods, implemented are ANFIS ?Adaptive Neuro-Flou Inference System? and the PSO ?Particle Swarm Optimization?. Learning by the connectionist approach of the ANFIS controller is sufficient to allow the robot to reach its target but remains unsatisfactory. The contribution of the PSO algorithm allows the hybrid controller to optimize, the speed and therefore the positions of robot. The controller thus constituted gives better simulation results of the distances measured in pixels traveled by the hybrid method.","ANFIS, PSO, ROBOT, IA, Fuzzy logic",Malika Lazreg and Nacéra Benamrane,https://www.sciencedirect.com/science/article/pii/S0921889022000641,https://doi.org/10.1016/j.robot.2022.104114,0921-8890,2022,104114,153,Robotics and Autonomous Systems,Hybrid system for optimizing the robot mobile navigation using ANFIS and PSO,article,LAZREG2022104114
"Visual-inertial odometry (VIO) shows high localization accuracy in many environments. However, the inevitable estimation drift is constantly accumulating, which even leads to failures. Hence, an efficient loop closing (LC) is necessary for correcting drift. Unlike most existing methods rely on pre-trained model, we propose an incremental hierarchical forest (HF) based LC method (HF-LC), which online encodes frames for loop closing without any prior information, and it is suitable for arbitrary images. We thoroughly exploit the duality of binary descriptors, and propose a hierarchical forest based descriptor search method for loop frame retrieval, which is extremely fast with efficient descriptor clustering, binary search, and grid based loop closure selection modules. Moreover, we integrate HF-LC into a state-of-the-art keyframe based VIO, and develop a comprehensive hierarchical forest based visual-inertial SLAM (HFVIS) system. Furthermore, a lightweight geometric verification is designed for correctness checking and pose computing of loop keyframes. Finally, all keyframe poses are further optimized in global pose-graph optimization, which achieves better consistency. The efficacy of our method is validated on ground robot and aerial vehicle datasets. Extensive results confirm that the proposed HF-LC achieves better precision?recall performance, and our HFVIS system has higher localization accuracy and superior real-time performance.","Visual-inertial SLAM, Global consistent localization, Binary descriptor search, Loop closure detection",Hongle Xie and Weidong Chen and Jingchuan Wang,https://www.sciencedirect.com/science/article/pii/S0921889022000124,https://doi.org/10.1016/j.robot.2022.104035,0921-8890,2022,104035,151,Robotics and Autonomous Systems,Hierarchical forest based fast online loop closure for low-latency consistent visual-inertial SLAM,article,XIE2022104035
"Deep reinforcement learning (DRL) is one promising approach to teaching robots to perform complex tasks. Because methods that directly reuse the stored experience data cannot follow the change of the environment in robotic problems with a time-varying environment, online DRL is required. The eligibility traces method is well known as an online learning technique for improving sample efficiency in traditional reinforcement learning with linear regressors rather than DRL. The dependency between parameters of deep neural networks would destroy the eligibility traces, which is why they are not integrated with DRL. Although replacing the gradient with the most influential one rather than accumulating the gradients as the eligibility traces can alleviate this problem, the replacing operation reduces the number of reuses of previous experiences. To address these issues, this study proposes a new eligibility traces method that can be used even in DRL while maintaining high sample efficiency. When the accumulated gradients differ from those computed using the latest parameters, the proposed method takes into account the divergence between the past and latest parameters to adaptively decay the eligibility traces. Bregman divergences between outputs computed by the past and latest parameters are exploited due to the infeasible computational cost of the divergence between the past and latest parameters. In addition, a generalized method with multiple time-scale traces is designed for the first time. This design allows for the replacement of the most influential adaptively accumulated (decayed) eligibility traces. The proposed method outperformed conventional methods in terms of learning speed and task quality by the learned policy on benchmark tasks on a dynamic robotic simulator. A real-robot demonstration confirmed the significance of online DRL as well as the adaptability of the proposed method to a changing environment.","Deep reinforcement learning, Online learning, Eligibility traces",Taisuke Kobayashi,https://www.sciencedirect.com/science/article/pii/S0921889021002670,https://doi.org/10.1016/j.robot.2021.104019,0921-8890,2022,104019,151,Robotics and Autonomous Systems,Adaptive and multiple time-scale eligibility traces for online deep reinforcement learning,article,KOBAYASHI2022104019
"MapReduce is one of the essential programming models for parallel processing and distributed storage of enormous data sets. The default Hadoop implementation assumes that the executing nodes are homogeneous. Data Locality is an important feature that Hadoop introduced to improve the performance of the traditional MapReduce model. The key idea is to move the map task closer to the node where the actual data resides rather than transferring the vast data set near the computation. Data Locality helps in lowering the network congestion and improving performance. However, this practice fails when processing the data in a heterogeneous Hadoop cluster. In a heterogeneous setup, nodes with different computational capabilities pose a crucial challenge. Nodes with a faster processing capacity finish the job compared to the nodes with slower processing ability. This paper proposes a KNN based scheduler that focuses on speculative prefetching and clustering of the data. The process starts with speculative prefetching and then performing the KNN clustering on the intermediate map output before directing it to the reducer for final processing. The performance evaluation of scheduler performance is analysed by executing different workloads like WordCount, RandomText, RandomNum, and Sort. The results show that the proposed idea improves the performance of job execution","Hadoop, MapReduce, Scheduling, Speculative prefetching, And clustering",Khushboo Kalia and Saurav Dixit and Kaushal Kumar and Rajat Gera and Kirill Epifantsev and Vinod John and Natalia Taskaeva,https://www.sciencedirect.com/science/article/pii/S0921889022001336,https://doi.org/10.1016/j.robot.2022.104228,0921-8890,2022,104228,157,Robotics and Autonomous Systems,Improving MapReduce heterogeneous performance using KNN fair share scheduling,article,KALIA2022104228
"We propose a methodology for a robot to automatically generate felicitous co-speech gestures corresponding to robot utterances. First, the proposed method determines the part of a given robot utterance, where the robot makes a gesture by doing a morphemic analysis on the sentence of utterance. The part is herein called an expression unit. The method then predicts a gesture type to characterize the expression unit in the sense of conveying thoughts and feelings. The gesture type is selected from the four types of iconic, metaphoric, beat, and deictic categorized by McNeill by performing morphemic analysis on the sentence. A gesture proper to the gesture type is retrieved from a database of motion primitives that are built with predefined a limited number of words. For retrieving, Word2Vec is applied to estimate word similarity between the predefined words in the database and words in the expression unit such that the method can deal with an arbitrary sentence and generate an appropriate gesture for similar words in meaning. The proposed method showed 83% accuracy in determining expression units and gesture types for a set of sentences in Korean. Furthermore, a user study on feasibility has been performed with a humanoid, NAO, and received positive evaluations in terms of anthropomorphism for the robot.","Human?robot interaction, Co-speech gesture generation, Machine learning, Morphemic analysis, Word embedding",Yu-Jung Chae and Changjoo Nam and Daseul Yang and HunSeob Sin and ChangHwan Kim and Sung-Kee Park,https://www.sciencedirect.com/science/article/pii/S0921889022000884,https://doi.org/10.1016/j.robot.2022.104154,0921-8890,2022,104154,155,Robotics and Autonomous Systems,Generation of co-speech gestures of robot based on morphemic analysis,article,CHAE2022104154
"The restriction of feasible motions of a manipulator link constrained to move through an entry port is a common problem in minimally invasive surgery procedures. Additional spatial restrictions are required to ensure the safety of sensitive regions from unintentional damage. In this work, we design a target admittance model that is proved to enforce robot tool manipulation by a human through a remote center of motion and to guarantee that the tool will never enter or touch forbidden regions. The control scheme is proved passive under the exertion of a human force ensuring manipulation stability, and smooth natural motion in hands-on surgical procedures enhancing the user?s feeling of control over the task. Its performance is demonstrated by experiments with a setup mimicking a hands-on surgical procedure comprising a KUKA LWR4+ and a virtual intraoperative environment.","Physical Human?Robot Interaction, RCM manipulation, Active constraints, Surgical robots, Variable damping",Theodora Kastritsi and Zoe Doulgeri,https://www.sciencedirect.com/science/article/pii/S0921889022000367,https://doi.org/10.1016/j.robot.2022.104073,0921-8890,2022,104073,152,Robotics and Autonomous Systems,A passive admittance controller to enforce Remote Center of Motion and Tool Spatial constraints with application in hands-on surgical procedures,article,KASTRITSI2022104073
"Simultaneous Localization and Mapping (SLAM) is one of the fundamental problems in autonomous robotics. Over the years, many approaches to solve this problem for 6D poses and 3D maps based on LiDAR sensors or depth cameras have been proposed. One of the main drawbacks of the solutions found in the literature is the required computational power and corresponding energy consumption. In this paper, we present an approach for LiDAR-based SLAM that maintains a global truncated signed distance function (TSDF) to represent the map. It is implemented on a System-On-Chip (SoC) with an integrated FPGA accelerator. The proposed system is able to track the position of state-of-the-art LiDARs in real time, while maintaining a global TSDF map that can be used to create a polygonal map of the environment. We show that our implementation delivers competitive results compared to state-of-the-art algorithms while drastically reducing the power consumption compared to classical CPU or GPU-based methods.","SLAM, Hardware acceleration, FPGA programming, 3D mapping",Marc Eisoldt and Julian Gaal and Thomas Wiemann and Marcel Flottmann and Marc Rothmann and Marco Tassemeier and Mario Porrmann,https://www.sciencedirect.com/science/article/pii/S0921889022001178,https://doi.org/10.1016/j.robot.2022.104205,0921-8890,2022,104205,156,Robotics and Autonomous Systems,A fully integrated system for hardware-accelerated TSDF SLAM with LiDAR sensors (HATSDF SLAM),article,EISOLDT2022104205
"It is significantly challenging to develop biped robots, such as a humanoid robot, that can walk stably in complex environments, such as a rough terrain or slope. Additionally, various kinds of sensors are required. Force and torque (FT) and inertial measurement unit (IMU) sensors are necessary for a humanoid robot to achieve stable biped walking, and it is especially difficult to realize such locomotion without an IMU sensor in complex environments, such as a slope. Therefore, a new walking algorithm is needed so that a humanoid robot is able to walk well on a slope, even if the IMU sensor is damaged. This paper proposes a slope observer that can estimate the angle of the robot, angular velocity, and slope angle without an IMU sensor, as well as a controller for posture control and stabilization on a slope. The slope observer was developed based on a disturbance observer that can estimate the angle of the robot, angular velocity, and disturbance applied to the robot using only an FT sensor. The controller was designed as state feedback control based on the slope observer. Furthermore, the posture control was designed considering the slope angle such that the robot can always stand upright on the slope. The proposed slope observer and controller were verified with certain experiments performed in the lab, and the walking experiment of a real humanoid robot RoK-3 performed on the unknown slope. [https://youtu.be/x1PlzktlOpM]","Humanoid robots, Slope observer, Balance control, Slope walking, RoK-3",Yun-Ho Han and Baek-Kyu Cho,https://www.sciencedirect.com/science/article/pii/S0921889022000926,https://doi.org/10.1016/j.robot.2022.104163,0921-8890,2022,104163,155,Robotics and Autonomous Systems,Slope walking of humanoid robot without IMU sensor on an unknown slope,article,HAN2022104163
"While training an end-to-end navigation network in the real world is usually costly, simulation serves as a safe and low-cost tool in this training process. However, training neural network models in simulation brings up the problem of effectively transferring the model from simulation to the real world (sim-to-real). In this work, we regard the environment representation as a crucial element in this transfer process, and we propose a visual information pyramid (VIP) model to investigate a practical environment representation systematically. A novel representation composed of spatial and semantic information synthesis is established accordingly, where noise model embedding is particularly considered. To explore the effectiveness of the proposed representation, we compared its performance with other popularly used representations in the literature, such as RGB image, depth image, and semantic segmentation image, in both simulated and real-world scenarios. Results suggest that our environment representation stands out. Furthermore, an analysis on the feature map is implemented to investigate the effectiveness through hidden layer reaction, which could be irradiative for future researches on sim-to-real learning-based navigation.","Transfer learning, Visual navigation, Environment representation",Gang Chen and Hongzhe Yu and Wei Dong and Xinjun Sheng and Xiangyang Zhu and Han Ding,https://www.sciencedirect.com/science/article/pii/S0921889022000409,https://doi.org/10.1016/j.robot.2022.104081,0921-8890,2022,104081,153,Robotics and Autonomous Systems,What should be the input: Investigating the environment representations in sim-to-real transfer for navigation tasks,article,CHEN2022104081
"Legged robots can negotiate unstructured environments and have applications in education, environmental inspection, space exploration, and cargo transportation. As a powerful form of legged robots, jumping robots have attractive features due to their high efficiency, mobility, traverse obstacles, and low cost of transport. Although spring is the core component of the energy system, little related work explores the value selection of spring stiffness and the effect of different spring placements for jumping robots. In this article, we present a systematic method to select the stiffness of spring based on static analysis, jumping linkage configuration and multi-objective optimization for jumping robots. Also, to predict the motion behavior of jumping robots, we provide a comprehensive dynamic model of the robotic jumping in different phases according to the Lagrange method and the principle of virtual work, which considers the motion constraints and configuration constraints simultaneously. The proposed method and dynamic model can validate by designing a spring-linkage-based jumping robot as a showcase. The experimental results show performance improvements in jumping height in terms of both different springs? stiffness and arrangement, which is possible to appraise a maximal enhancement of 57.88%.","Jumping robots, Dynamic modeling, Hart linkage, Multiple springs, Legged robots",Xuanchun Yin and Jinchun Yan and Sheng Wen and Jiantao Zhang,https://www.sciencedirect.com/science/article/pii/S0921889022001579,https://doi.org/10.1016/j.robot.2022.104268,0921-8890,2022,104268,158,Robotics and Autonomous Systems,Spring-linkage integrated mechanism design for jumping robots,article,YIN2022104268
"Robust perception is an essential component to enable long-term operation of mobile robots. It depends on failure resilience through reliable sensor data and pre-processing, as well as failure awareness through introspection, for example the ability to self-assess localization performance. This paper presents CorAl: a principled, intuitive, and generalizable method to measure the quality of alignment between pairs of point clouds, which learns to detect alignment errors in a self-supervised manner. CorAl compares the differential entropy in the point clouds separately with the entropy in their union to account for entropy inherent to the scene. By making use of dual entropy measurements, we obtain a quality metric that is highly sensitive to small alignment errors and still generalizes well to unseen environments. In this work, we extend our previous work on lidar-only CorAl to radar data by proposing a two-step filtering technique that produces high-quality point clouds from noisy radar scans. Thus, we target robust perception in two ways: by introducing a method that introspectively assesses alignment quality, and by applying it to an inherently robust sensor modality. We show that our filtering technique combined with CorAl can be applied to the problem of alignment classification, and that it detects small alignment errors in urban settings with up to 98% accuracy, and with up to 96% if trained only in a different environment. Our lidar and radar experiments demonstrate that CorAl outperforms previous methods both on the ETH lidar benchmark, which includes several indoor and outdoor environments, and the large-scale Oxford and MulRan radar data sets for urban traffic scenarios. The results also demonstrate that CorAl generalizes very well across substantially different environments without the need of retraining.","Radar, Introspection, Localization",Daniel Adolfsson and Manuel Castellano-Quero and Martin Magnusson and Achim J. Lilienthal and Henrik Andreasson,https://www.sciencedirect.com/science/article/pii/S0921889022000768,https://doi.org/10.1016/j.robot.2022.104136,0921-8890,2022,104136,155,Robotics and Autonomous Systems,CorAl: Introspection for robust radar and lidar perception in diverse environments using differential entropy,article,ADOLFSSON2022104136
"Gesture can be used as an important way for human?robot interaction, since it is able to give accurate and intuitive instructions to the robots. Various sensors can be used to capture gestures. We apply three different sensors that can provide different modalities in recognizing human gestures. Such data also owns its own statistical properties for the purpose of transfer learning: they own the same labeled data, but both the source and the validation data-sets have their own statistical distributions. To tackle the transfer learning problem across different sensors with such kind of data-sets, we propose a weighting method to adjust the probability distributions of the data, which results in a more faster convergence result. We further apply this method in a broad learning system, which has proven to be efficient to learn with the incremental learning capability. The results show that although these three sensors measure different parts of the body using different technologies, transfer learning is able to find out the weighting correlation among the data-sets. It also suggests that using the proposed transfer learning is able to adjust the data which has different distributions which may be similar to the physical correlation between different parts of the body in the context of giving gestures.","Transfer learning, Gesture recognition, Multi-modal, EMG, Depth camera, Leap Motion",Junpei Zhong and Jie Li and Ahmad Lotfi and Peidong Liang and Chenguang Yang,https://www.sciencedirect.com/science/article/pii/S0921889022001051,https://doi.org/10.1016/j.robot.2022.104181,0921-8890,2022,104181,155,Robotics and Autonomous Systems,An incremental cross-modal transfer learning method for gesture interaction,article,ZHONG2022104181
"The autonomous multi-robot system is an emerging technology that has a wide range of potential applications, such as environmental monitoring, exploration of unknown area, battlefield surveillance, and search and rescue. One major challenge in such applications is how to deploy each robotic agent autonomously in a distributed manner. In this paper, we proposed a distributed coverage control strategy named multi-stage virtual force interaction scheme (VFIS), where the agents? deployment process is split into stages and each agent iteratively seeks its next position according to the interaction among agents and the interaction between agents and the perceived environment. The interactions are realized via virtual repulsive forces and virtual vortex forces, where the latter are newly proposed to enhance the exploration capability of agents. We also designed a group of benchmark testing problems for the mission of monitoring coverage of complex environments with unknown obstacles. Extensive simulation experiments were conducted based on the defined benchmark configurations and the results showed a favorable performance of the invented strategy. In addition, practical experiments were carried out using a group of mobile robots, which validated the effectiveness of the proposed method.","Monitoring coverage, Multi-robot system, Virtual force, Benchmark",Kang Ji and Qian Zhang and Zhi Yuan and Hui Cheng and Dingli Yu,https://www.sciencedirect.com/science/article/pii/S0921889021002384,https://doi.org/10.1016/j.robot.2021.103967,0921-8890,2022,103967,149,Robotics and Autonomous Systems,A virtual force interaction scheme for multi-robot environment monitoring,article,JI2022103967
"This paper proposes a modular framework to generate robust biped locomotion using a tight coupling between an analytical walking approach and deep reinforcement learning. This framework is composed of six main modules which are hierarchically connected to reduce the overall complexity and increase its flexibility. The core of this framework is a specific dynamics model which abstracts a humanoid?s dynamics model into two masses for modeling upper and lower body. This dynamics model is used to design an adaptive reference trajectories planner and an optimal controller which are fully parametric. Furthermore, a learning framework is developed based on Genetic Algorithm (GA) and Proximal Policy Optimization (PPO) to find the optimum parameters and to learn how to improve the stability of the robot by moving the arms and changing its center of mass height. A set of simulations are performed to validate the performance of the framework using the official RoboCup 3D League simulation environment. The results validate the performance of the framework, not only in creating a fast and stable gait but also in learning to improve the upper body efficiency.","Humanoid robots, Modular walk engine, Linear?Quadratic?Gaussian (LQG), Genetic Algorithm (GA), Proximal Policy Optimization (PPO), Deep Reinforcement Learning (DRL)",Mohammadreza Kasaei and Miguel Abreu and Nuno Lau and Artur Pereira and Luis Paulo Reis,https://www.sciencedirect.com/science/article/pii/S0921889021001858,https://doi.org/10.1016/j.robot.2021.103900,0921-8890,2021,103900,146,Robotics and Autonomous Systems,Robust biped locomotion using deep reinforcement learning on top of an analytical control approach,article,KASAEI2021103900
"Fault diagnosis is a key safety component in robotic assistive technologies. Although conventional model-based methods for sensor fault diagnosis in mobile robots have been well established, they face challenges due to model parameter changes and uncertainties. On the other hand, data-driven approaches becomes more appealing in order to take advantage from available historical data in the era of Big Data. To provide a new generic unsupervised solution to the fault detection and recovery, we explicitly include kinematic relations and temporal finite differences from measured sensor signals into training a multi-task deep neural network. To evaluate the proposed fault diagnosis and recovery framework, experiments have been conducted on a robotic rollator platform. Experiments under several conditions confirm that the proposed approach, which leverages machine learning-enhanced algorithms, exhibits reliable performance. Outperforming other baselines and state-of-the-art diagnosis algorithms, the framework presents a promising solution to sensor fault recovery challenges in assistive devices.","Fault detection and recovery, Robotic rollators, Deep learning, Assistive devices, Temporal finite differences",Yiwen Liao and Abdullah Yeaser and Bin Yang and James Tung and Ehsan Hashemi,https://www.sciencedirect.com/science/article/pii/S0921889021001615,https://doi.org/10.1016/j.robot.2021.103876,0921-8890,2021,103876,146,Robotics and Autonomous Systems,Unsupervised fault detection and recovery for intelligent robotic rollators,article,LIAO2021103876
"In this paper, we present an integrated robotic system capable of participating in and performing a wide range of educational and entertainment tasks collaborating with one or more children. The system, called ChildBot, features multimodal perception modules and multiple robotic agents that monitor the interaction environment and can robustly coordinate complex Child?Robot Interaction use-cases. In order to validate the effectiveness of the system and its integrated modules, we have conducted multiple experiments with a total of 52 children. Our results show improved perception capabilities in comparison to our earlier works that ChildBot was based on. In addition, we have conducted a preliminary user experience study, employing some educational/entertainment tasks, that yields encouraging results regarding the technical validity of our system and initial insights on the user experience with it.","Child?Robot Interaction, Multi-robot perception, Visual activity recognition, Distant speech recognition, Audio-visual active speaker localization, 6-DoF object tracking",Niki Efthymiou and Panagiotis P. Filntisis and Petros Koutras and Antigoni Tsiami and Jack Hadfield and Gerasimos Potamianos and Petros Maragos,https://www.sciencedirect.com/science/article/pii/S0921889021002426,https://doi.org/10.1016/j.robot.2021.103975,0921-8890,2022,103975,150,Robotics and Autonomous Systems,ChildBot: Multi-robot perception and interaction with children,article,EFTHYMIOU2022103975
"Even if pencil drawing is the basic method of human artistic expression, it remains at the forefront of scientific attention in the field of robotics, which focuses mainly on painting. Although various methods of artistic robotic drawing have been developed in the past, the results are not always satisfactory. The vast majority of existing systems focus only on sketches, and detailed pencil drawings are time-consuming. In this article, we present a novel general robotic system for creating realistic pencil drawings based on image evolution. We show that by procedural image generation approach using genetic algorithms, we can create realistic drawings with an element of machine creativity. Furthermore, we show that the image approximation using even simple line segments leads to aesthetic and fast drawings. Finally, we describe a hardware solution using an industrial robot, a software implementation, and preliminary experimental results.","Robotic pencil drawing, Image vectorization, Non-photorealistic rendering, Machine creativity",Michal Adamik and Jozef Goga and Jarmila Pavlovicova and Andrej Babinec and Ivan Sekaj,https://www.sciencedirect.com/science/article/pii/S0921889021001974,https://doi.org/10.1016/j.robot.2021.103912,0921-8890,2022,103912,148,Robotics and Autonomous Systems,Fast robotic pencil drawing based on image evolution by means of genetic algorithm,article,ADAMIK2022103912
"Continuum robots (CRs) have been the subject of intensive research in recent years due to their wide range of potential applications. Research on grasp taxonomy plays a key role in a number of task-based problems such as grasp synthesis, motion planning, and motion control. Additionally, grasp taxonomy has been shown to reduce the complexity of the design of robotic systems and human?computer interaction operations. The main goal of this research is to present a general CR-based grasp taxonomy. For this purpose, we first overview and summarize different types of CR-based grasp tasks. Then, we compare existing CR-based grasp configurations in the CR-related literature and classify the configurations into a comprehensive taxonomy. On the basis of this survey, nine major CR-based grasp families are introduced and arranged in subgroups for more detailed research. It should be noted that we studied grasps performed by different CR types and configurations without considering the object/CR size. Finally, the work includes different analyses of CR-based grasp taxonomy, including grasp frequency, grasp adaptability, taxonomy completeness, and properties of manipulated objects and tasks enabled by the proposed taxonomy.","Continuum robots, Grasp task, Grasp configuration, Grasp family, Grasp taxonomy, Taxonomy analysis",Ali Mehrkish and Farrokh Janabi-Sharifi,https://www.sciencedirect.com/science/article/pii/S0921889021001457,https://doi.org/10.1016/j.robot.2021.103860,0921-8890,2021,103860,145,Robotics and Autonomous Systems,A comprehensive grasp taxonomy of continuum robots,article,MEHRKISH2021103860
"In this paper, we introduce an adaptive robotic manipulation framework to respond to the flexibility needs of common industrial tasks such as box-filling and item sorting. The proposed framework consists of a vision module and a robot control module. The vision module is responsible for the detection and tracking of the environment (e.g., box and the items), which is also capable of creating an occupancy grid in real-time, to continuously update the robot trajectory planner with the occupied portions of the detected box and their coordinates. The robot control module includes a trajectory planner and a self-tuning Cartesian impedance controller, to implement an adaptive strategy for the picking, placement, and sorting of the items in the box. The item-sorting strategy is based on our preliminary observations on human motor behavior, implementing a trade-off between the task execution accuracy and environmental perception uncertainty. The efficacy of the framework in performing a flexible box-filling task using a robot, autonomously or in collaboration with a human, is evaluated through several experiments.","Intelligent and flexible manufacturing, Human?robot collaboration, Autonomous agents, Manipulation planning",Pietro Balatti and Mattia Leonori and Arash Ajoudani,https://www.sciencedirect.com/science/article/pii/S0921889021001731,https://doi.org/10.1016/j.robot.2021.103888,0921-8890,2021,103888,146,Robotics and Autonomous Systems,A flexible and collaborative approach to robotic box-filling and item sorting,article,BALATTI2021103888
"In this paper, disturbance reconstruction and robust trajectory tracking control of biped robots with hybrid dynamics in the port-Hamiltonian form is investigated. A new type of Hamiltonian function is introduced, which ensures the finite-time stability of the closed-loop system. The proposed control system consists of two loops: an inner and an outer loop. A fractional proportional?integral?derivative filter is used to achieve finite-time convergence for position tracking errors at the outer loop. A fractional-order sliding mode controller acts as a centralized controller at the inner-loop, ensuring the finite-time stability of the velocity tracking error. In this loop, the undesired effects of unknown external disturbance and parameter uncertainties are compensated using estimators. Two disturbance estimators are envisioned. The former is designed using fractional calculus. The latter is an adaptive estimator, and it is constructed using the general dynamic of biped robots. Stability analysis shows that the closed-loop system is finite-time stable in both contact-less and impact phases. Simulation studies on three types of biped robots (i.e., two-link walker, RABBIT biped robot, and flat-feet biped robot) demonstrate the proposed controller?s tracking performance and disturbance rejection capability.","Bipedal robots, Hybrid systems, Port-Hamiltonian dynamics, Fractional sliding surface, Finite-time control, Disturbance estimator",Yousef Farid and Fabio Ruggiero,https://www.sciencedirect.com/science/article/pii/S0921889021001214,https://doi.org/10.1016/j.robot.2021.103836,0921-8890,2021,103836,144,Robotics and Autonomous Systems,Finite-time disturbance reconstruction and robust fractional-order controller design for hybrid port-Hamiltonian dynamics of biped robots,article,FARID2021103836
"The coronavirus disease 2019 (COVID-19) outbreak has increased mortality and morbidity world-wide. Oropharyngeal swabbing is a well-known and commonly used sampling technique for COVID-19 diagnose around the world. We developed a robot to assist with COVID-19 oropharyngeal swabbing to prevent frontline clinical staff from being infected. The robot integrates a UR5 manipulator, rigid?flexible coupling (RFC) manipulator, force-sensing and control subsystem, visual subsystem and haptic device. The robot has strength in intrinsically safe and high repeat positioning accuracy. In addition, we also achieve one-dimensional constant force control in the automatic scheme (AS). Compared with the rigid sampling robot, the developed robot can perform the oropharyngeal swabbing procedure more safely and gently, reducing risk. Alternatively, a novel robot control schemes called collaborative manipulation scheme (CMS) which combines a automatic phase and teleoperation phase is proposed. At last, comparative experiments of three schemes were conducted, including CMS, AS, and teleoperation scheme (TS). The experimental results shows that CMS obtained the highest score according to the evaluation equation. CMS has the excellent performance in quality, experience and adaption. Therefore, the proposal of CMS is meaningful which is more suitable for robot-sampling.","Oropharyngeal swabbing robot, Rigid?flexible coupling manipulator, Micro-pneumatic actuator, Collaborative manipulation scheme, Evaluation metrics",Yongquan Chen and Qiwen Wang and Chuliang Chi and Chengjiang Wang and Qing Gao and Heng Zhang and Zheng Li and Zonggao Mu and Ruihuan Xu and Zhenglong Sun and Huihuan Qian,https://www.sciencedirect.com/science/article/pii/S0921889021002025,https://doi.org/10.1016/j.robot.2021.103917,0921-8890,2022,103917,148,Robotics and Autonomous Systems,A collaborative robot for COVID-19 oropharyngeal swabbing,article,CHEN2022103917
"Dynamic Movement Primitives (DMPs) is a framework for learning a point-to-point trajectory from a demonstration. Despite being widely used, DMPs still present some shortcomings that may limit their usage in real robotic applications. Firstly, at the state of the art, mainly Gaussian basis functions have been used to perform function approximation. Secondly, the adaptation of the trajectory generated by the DMP heavily depends on the choice of hyperparameters and the new desired goal position. Lastly, DMPs are a framework for ?one-shot learning?, meaning that they are constrained to learn from a unique demonstration. In this work, we present and motivate a new set of basis functions to be used in the learning process, showing their ability to accurately approximate functions while having both analytical and numerical advantages w.r.t. Gaussian basis functions. Then, we show how to use the invariance of DMPs w.r.t. affine transformations to make the generalization of the trajectory robust against both the choice of hyperparameters and new goal position, performing both synthetic tests and experiments with real robots to show this increased robustness. Finally, we propose an algorithm to extract a common behavior from multiple observations, validating it both on a synthetic dataset and on a dataset obtained by performing a task on a real robot.","Learning from demonstrations, Motion and path planning, Kinematics, Dynamic Movement Primitives",Michele Ginesi and Nicola Sansonetto and Paolo Fiorini,https://www.sciencedirect.com/science/article/pii/S0921889021001299,https://doi.org/10.1016/j.robot.2021.103844,0921-8890,2021,103844,144,Robotics and Autonomous Systems,Overcoming some drawbacks of Dynamic Movement Primitives,article,GINESI2021103844
"Transferring the grasping skills learned from simulated environments to the real world is favorable for many robotic applications, in which the collecting and labeling processes of real-world visual grasping datasets are often expensive or even impractical. However, the models purely trained on simulated data are often difficult to generalize well to the unseen real world due to the domain gap between the training and testing data. In this paper, we propose a novel domain adversarial transfer network to narrow the domain gap for cross-domain and task-constrained grasp pose detection. Generative adversarial training is exploited to constrain the generator to produce simulation-like data for extracting the shared features with the joint distribution. We also propose to improve the backbone by extracting task-constrained grasp candidates and constructing the grasp candidate evaluator with a lightweight structure and an embedded recalibration technique. To validate the effectiveness and superiority of our proposed method, grasping performance evaluation and task-oriented human?robot interaction experiments were investigated. The experiment results indicate that the proposed method achieves state-of-the-art performance in these experimental settings. An average task-constrained grasping success rate of 83.3% without using any real-world labels for the task-oriented human?robot interaction experiment was achieved especially.","Adversarial transfer learning, Domain adaptation, Grasp pose detection, Human?robot interaction",Xingshuo Jing and Kun Qian and Xin Xu and Jishen Bai and Bo Zhou,https://www.sciencedirect.com/science/article/pii/S0921889021001573,https://doi.org/10.1016/j.robot.2021.103872,0921-8890,2021,103872,145,Robotics and Autonomous Systems,Domain adversarial transfer for cross-domain and task-constrained grasp pose detection,article,JING2021103872
"In recent years Unmanned Aerial Vehicles (UAVs) have progressively been utilized for wildfire management, and are especially in prevalent in forest fire monitoring missions. To ensure the fast detection and accurate area estimation of forest fires, a two-step search and survey algorithm for multi-UAV system is proposed to address these fire scenarios. Initially, a grid-based partition method is applied to divide the area-of-interest into several search areas. Then, an archetype search pattern is used to provide timely UAV exploration within those sub-areas. Once the fire zones are detected, a novel survey strategy is employed for UAVs to discover the boundary points of the fire zones, so that the area of the fire zones can be estimated using the sampled boundary points. In addition, the effect of wind is accounted for improving fire zone boundary estimates. The proposed search-and-survey procedure is validated on multiple simulated scenarios using the U.S. Air Force?s mission-realistic Aerospace Multi-Agent Simulation Environment (AMASE) software. Simulation results showcase that the proposed search pattern can effectively discover the seeded fire zones within 40 min of the mission. This is relatively faster than the other two well-known search patterns. Moreover, the proposed survey technique provides a coverage estimate with at least 85% accuracy for the area of interest within 90 min of the mission.","UAV, Multi-agent autonomous system, AMASE, Search & survey, Collaborative operation, Robotics",Mrinmoy Sarkar and Xuyang Yan and Berat A. Erol and Ioannis Raptis and Abdollah Homaifar,https://www.sciencedirect.com/science/article/pii/S0921889021001330,https://doi.org/10.1016/j.robot.2021.103848,0921-8890,2021,103848,145,Robotics and Autonomous Systems,A novel search and survey technique for unmanned aerial systems in detecting and estimating the area for wildfires,article,SARKAR2021103848
"It is an essential task to guarantee satisfactory tracking performance for a warehouse mobile robot with a detachable load. To this end, a nonlinear extended state observer (ESO)-based tracking control is investigated via a double closed-loop framework in this paper. A kinematics controller is designed in an outer loop to generate desired velocities for the warehouse mobile robot. A nonlinear ESO with an improved error function is proposed in an inner loop to estimate load variations and internal unmodeled dynamics. Then a nonlinear error feedback controller based on estimation values is given to track the desired velocities from the outer loop. Simulation and experiment results illustrate the effectiveness and superiority of the proposed control strategy.","Warehouse mobile robot, Detachable load, Double closed-loop framework, Tracking control, Nonlinear extended state observer",Peng Li and Hongjiu Yang and Hongbo Li and Shiqing Liang,https://www.sciencedirect.com/science/article/pii/S0921889021002372,https://doi.org/10.1016/j.robot.2021.103965,0921-8890,2022,103965,149,Robotics and Autonomous Systems,Nonlinear ESO-based tracking control for warehouse mobile robots with detachable loads,article,LI2022103965
"Legged robots have potential advantages in mobility compared with wheeled robots. Hence, legged robots are widely utilized in outdoor unstructured environments. Human-following operation is one of important tasks for outdoor robots. However, most current human-following strategies requires large amount of computation resource hence difficult to be applied to legged robots. This paper proposes real-time low-computation cost human-following framework in outdoor environment for legged robots. Our method takes a full consideration of the differences between legged robots and wheeled robots. Firstly, an on-line extrinsic calibration method is proposed to calculate the camera coordinate and the world coordinate system. Then, a real-time low-computation cost human-following method utilizing RGBD cameras and 3D LIDAR is proposed. The robot motion considers tracking the leading person while avoiding obstacles. Furthermore, a dynamic alternating tripod trotting gait is developed to control the robot to follow the leading person. Finally, the method is implemented and tested on a hexapod robot Qingzhui with indoor and outdoor experiments. The framework proposed in this paper can be a valuable reference for other legged robots when operated in outdoor environments.","Human following, Person tracking, Hexapod robot, Legged robot, Obstacle avoidance, Gait generation",Yue Zhao and Yue Gao and Qiao Sun and Yuan Tian and Liheng Mao and Feng Gao,https://www.sciencedirect.com/science/article/pii/S0921889021001846,https://doi.org/10.1016/j.robot.2021.103899,0921-8890,2021,103899,146,Robotics and Autonomous Systems,A real-time low-computation cost human-following framework in outdoor environment for legged robots,article,ZHAO2021103899
"This paper proposes a novel method for six degrees of freedom pose estimation of objects for the application of robot arm pick and place. It is based on the use of a stereo vision system, which does not require calibration. Using both cameras, four corner points of the object are detected. A deep-neural-network (DNN) is trained for the prediction of the 6 DOF pose of the object from the four detected corner points? coordinates in each image of both cameras. The stereo vision used is a low-end vision system placed in a custom-made setup. Before the training phase of the DNN, the robot is set to auto collect data in a predefined workspace. This workspace is defined dependently on the spatial feasibility of the robot arm and the shared field of view of the stereo vision system. The collected data represent images of a 2D marker attached to the robot arm gripper. The 2D marker is used for data collection to ease the detection of the four corner points. The proposed method succeeds in estimating the six degrees of freedom pose of the object, without the need for the determination of neither the intrinsic nor the extrinsic parameters of the stereo vision system. The optimum design of the proposed DNN is obtained after comparing different activation functions and optimizers associated with the DNN. The proposed uncalibrated DNN-based method performance is compared to that of the traditional calibration-based method. In the calibration-based method, the rotational matrix relating the robot coordinates to the stereo vision coordinates is computed using two approaches. The first approach uses Singular Value Decomposition (SVD) while the second approach uses a novel proposed modification of particle swarm optimization (PSO) called Hyper particle Scouts optimization (HPSO). HPSO outperforms other metaheuristic optimization algorithms such as PSO and genetic algorithm (GA). Exhaustive tests are performed, and the proposed DNN-based method is shown to outperform all tested alternatives.","Deep learning, Pose estimation, Robot vision, Stereo vision, Optimization techniques, Levenberg?Marquardt algorithm",Mahmoud Abdelaal and Ramy M.A. Farag and Mohamed S. Saad and Ahmed Bahgat and Hassan M. Emara and Ayman El-Dessouki,https://www.sciencedirect.com/science/article/pii/S0921889021001329,https://doi.org/10.1016/j.robot.2021.103847,0921-8890,2021,103847,145,Robotics and Autonomous Systems,Uncalibrated stereo vision with deep learning for 6-DOF pose estimation for a robot arm system,article,ABDELAAL2021103847
"Programmable matter based on modular self-reconfigurable robots could stand as the ultimate form of display system, through which humans could not only see the virtual world in 3D, but manipulate it and interact with it through touch. These systems rely on self-reconfiguration processes to reshape themselves and update their representation, using methods that we argue, are currently too slow for such applications due to a lack of parallelism in the motion of the robotic modules. Therefore, we propose a novel approach to the problem, promising faster and more efficient self-reconfigurations in programmable matter display systems. We contend that this can be achieved by using a dedicated platform supporting self-reconfiguration named a sandbox, acting as a reserve of modules, and by engineering the representation of objects using an internal scaffolding covered by a coating. This paper introduces a complete view of our framework for realizing this approach on quasi-spherical modules arranged in a face-centered cubic lattice. After thoroughly discussing the model, motivations, and making a case for our method, we synthesize results from published research highlighting its benefits and engage in an honest and critical discussion of its current state of implementation and perspectives.","Programmable matter, Distributed algorithms, Modular robotics, Self-reconfiguration, Multi-agent systems",Pierre Thalamy and Benoît Piranda and Julien Bourgeois,https://www.sciencedirect.com/science/article/pii/S0921889021001603,https://doi.org/10.1016/j.robot.2021.103875,0921-8890,2021,103875,146,Robotics and Autonomous Systems,"Engineering efficient and massively parallel 3D self-reconfiguration using sandboxing, scaffolding and coating",article,THALAMY2021103875
"In this study, a novel hybrid force/position controller in workspace of robotic manipulator based on adaptive fuzzy control is developed to improve the controlling performance of force and position in contact with uncertain environments. The dynamic model of the robotic manipulator in joint space is converted to a dynamic model in workspace, which is consisted of the model of position-controlled subsystem and model of force-controlled subsystem. Furthermore, in the position-controlled subsystem, an adaptive fuzzy computed torque control is proposed by considering adaptive fuzzy control and conventional computed torque control (AFCTC), for compensating deviations caused by the presence of structured uncertainty and unstructured uncertainty. In the force-controlled subsystem, a fuzzy proportional integral control method (FPI) is proposed by fuzzy logic and conventional proportional integral method to improve the control performance. The asymptotic stability of the developed controller is proved by Lyapunov theorem. The simulation results show the preferable performance of the proposed controller (AFCTC-FPI) by comparison with adaptive fuzzy sliding mode control (AFSMC), adaptive network-based fuzzy inference system with proportion differential and integral (ANFIS-PD+I), computed torque control-proportion integral (CTC-PI), fuzzy proportional integral derivative (FPID), and proportional integral derivative (PID) in uncertain environments. Furthermore, in the experimental study, average position error with AFCTC-FPI is decreased by 87.14 % than that with PID, meanwhile, range of interaction force with AFCTC-FPI is reduced by 70.31% than that with PID. In summary, the experimental results also show the superior control accuracy of the proposed controller in real environment.","Hybrid force/position control, Workspace, Computed torque control, Adaptive fuzzy control, Fuzzy proportional integral",Ziling Wang and Lai Zou and Xiaojie Su and Guoyue Luo and Rui Li and Yun Huang,https://www.sciencedirect.com/science/article/pii/S092188902100155X,https://doi.org/10.1016/j.robot.2021.103870,0921-8890,2021,103870,145,Robotics and Autonomous Systems,Hybrid force/position control in workspace of robotic manipulator in uncertain environments based on adaptive fuzzy control,article,WANG2021103870
"In a world with rapidly growing levels of automation, robotics is playing an increasingly significant role in every aspect of human endeavour. In particular, many types of mobile robots are increasingly being utilised in places and for tasks that are difficult and dangerous for humans. Although the vision of fully autonomous mobile robotic platforms that can perform complex tasks without direct guidance from a human operator is compelling, the reality is that the current state of robotics technology is still a long way from being able to achieve this capability outside of very narrowly constrained contexts. Technology advancement for improved mobile robotic teleoperation and remote control is vital to enable robotic vehicles to operate with increasing autonomy levels while allowing for effective remote operation when task complexity is too great for the autonomous systems. Being motivated to bridge this gap, we present a review of existing teleoperation methods and enhancement techniques for control of mobile robots. After defining teleoperation, we provide a detailed review that analyses, categorises, and summarises existing mobile robot teleoperation methods. Next, we highlight existing enhancement techniques that have been applied to these teleoperation methods, along with their relative advantages and disadvantages. Finally, several promising future research directions are identified. The paper concludes with a discussion of research challenges and future research possibilities.","Robot, Teleoperation, Enhancement techniques, Future video prediction, Survey, Review",MD Moniruzzaman and Alexander Rassau and Douglas Chai and Syed Mohammed Shamsul Islam,https://www.sciencedirect.com/science/article/pii/S0921889021002414,https://doi.org/10.1016/j.robot.2021.103973,0921-8890,2022,103973,150,Robotics and Autonomous Systems,Teleoperation methods and enhancement techniques for mobile robots: A comprehensive survey,article,MONIRUZZAMAN2022103973
"We introduce a non-parametric hierarchical Bayesian approach for open-ended 3D object categorization, named the Local Hierarchical Dirichlet Process (Local-HDP). This method allows an agent to learn independent topics for each category incrementally and to adapt to the environment in time. Each topic is a distribution of the visual words over a predefined dictionary. Using an inference algorithm, these latent variables are inferred from the dataset. Subsequently, the category of an object is determined based on the likelihood of generating a 3D object from the model. Hierarchical Bayesian approaches like Latent Dirichlet Allocation (LDA) can transform low-level features to high-level conceptual topics for 3D object categorization. However, the efficiency and accuracy of LDA-based approaches depend on the number of topics that is chosen manually. Moreover, fixing the number of topics for all categories can lead to overfitting or underfitting of the model. In contrast, the proposed Local-HDP can autonomously determine the number of topics for each category. Furthermore, the online variational inference method has been adapted for fast posterior approximation in the Local-HDP model. Experiments show that the proposed Local-HDP method outperforms other state-of-the-art approaches in terms of accuracy, scalability, and memory efficiency by a large margin. Moreover, two robotic experiments have been conducted to show the applicability of the proposed approach in real-time applications.","Open-ended learning, Life-long learning, Class-incremental learning, 3D object category recognition, Local hierarchical Dirichlet process, Human?robot interaction",H. Ayoobi and H. Kasaei and M. Cao and R. Verbrugge and B. Verheij,https://www.sciencedirect.com/science/article/pii/S0921889021001962,https://doi.org/10.1016/j.robot.2021.103911,0921-8890,2022,103911,147,Robotics and Autonomous Systems,Local-HDP: Interactive open-ended 3D object category recognition in real-time robotic scenarios,article,AYOOBI2022103911
"We propose a multi-agent based computational framework for modeling decision-making and strategic interaction at micro level for smart vehicles in a smart world. The concepts of Markov game and best response dynamics are heavily leveraged. Our aim is to make the framework conceptually sound and computationally practical for a range of realistic applications, including micro path planning for autonomous vehicles. To this end, we first convert the would-be stochastic game problem into a closely related deterministic one by introducing risk premium in the utility function for each individual agent. We show how the sub-game perfect Nash equilibrium of the simplified deterministic game can be solved by an algorithm based on best response dynamics. In order to better model human driving behaviors with bounded rationality, we seek to further simplify the solution concept by replacing the Nash equilibrium condition with a heuristic and adaptive optimization with finite look-ahead anticipation. In addition, the algorithm corresponding to the new solution concept drastically improves the computational efficiency. To demonstrate how our approach can be applied to realistic traffic settings, we conduct a simulation experiment: to derive merging and yielding behaviors on a double-lane highway with an unexpected barrier. Despite assumption differences involved in the two solution concepts, the derived numerical solutions show that the endogenized driving behaviors are very similar. We also briefly comment on how the proposed framework can be further extended in a number of directions in our forthcoming work, such as behavioral calibration using real traffic video data, and computational mechanism design for traffic policy optimization.","Multi-agent decision-making, Coordinated path planning, Human driving behavior modeling",Qi Dai and Xunnong Xu and Wen Guo and Suzhou Huang and Dimitar Filev,https://www.sciencedirect.com/science/article/pii/S0921889021001445,https://doi.org/10.1016/j.robot.2021.103859,0921-8890,2021,103859,144,Robotics and Autonomous Systems,Towards a systematic computational framework for modeling multi-agent decision-making at micro level for smart vehicles in a smart world,article,DAI2021103859
"A persistent challenge in the cognitive development of autonomous robotics is the unsupervised and unstructured nature of skill transfer learning where the Self Organizing Map (SOM) has been used as the enabling technology. The Growing Self-Organizing Map (GSOM) algorithm is an unsupervised, structure-adapting machine learning algorithm conventionally used for data exploration, clustering, visualization, outlier detection and dimensionality reduction. In this paper, we present the design and development of a new distributed algorithm based on the GSOM for unsupervised skill transfer learning in autonomous robotics settings which overcomes the key limitations of the SOM in real-life scenarios. We posit this new algorithm will be directly applicable to skill transfer learning scenarios that require unsupervised, incremental and on-going self-learning of multi-tasks and knowledge transfer. The distributed and scalable properties of the proposed algorithm handle large volumes of data required for unsupervised skill transfer learning, based on data parallelization. It generates multiple maps representing diverse skill knowledge, which are then projected together to a single embedding. The new algorithm is positioned within an autonomous developmental robotics framework for knowledge acquisition and skill transfer learning. This framework was further adapted to three contemporary distributed computing platforms, Hadoop, Spark and Hama. Empirical evaluation of these three adaptations using several benchmark and real-life datasets demonstrates its practical value and computational efficiency for unsupervised skill transfer learning in autonomous robots.","Autonomous robots, Skill transfer learning, Distributed self-organizing map, Knowledge transfer, Growing Self-Organizing Map, MapReduce, Resilient Distributed Dataset, Bulk Synchronous Parallel, Developmental robotics, Unsupervised machine learning, Artificial intelligence",Madhura Jayaratne and Damminda Alahakoon and Daswin {de Silva},https://www.sciencedirect.com/science/article/pii/S0921889021001202,https://doi.org/10.1016/j.robot.2021.103835,0921-8890,2021,103835,144,Robotics and Autonomous Systems,Unsupervised skill transfer learning for autonomous robots using distributed Growing Self Organizing Maps,article,JAYARATNE2021103835
"The flexibility of gait and trajectory planning with heavy payload are the main challenges for legged stable walking of hexapod robots in unstructured terrain, especially in time-varying and local terrain mutation conditions. To guarantee adaptability in unstructured terrain environment, the factors, including the obstacle height, terrain depth, and secure foothold as well as stability state, should be considered in the gait and trajectory planning. In this article, a novel gait transition hierarchical control framework based on a flexible gait planner (FGP), and gait feedback regulator (GFR) with behavior rules is proposed for the developed hexapod wheel-legged robot (BIT-6NAZA). The core of this gait planner is to select the optimal footholds and change gait types according to secure foothold and stability margin and kinematic margin of legs, and the GFR is applied to modify the foot-end trajectory of the selected gait according to the terrain feedback information to adapt to unstructured terrain. Finally, taking BIT-6NAZA robot as an example, the simulation and experiment are carried out under the proposed control framework. The co-simulation and experimental results show that the robot can modify the foot-end trajectory in dynamic unstructured terrain and obtain elastic gait in obstacle avoidance.","Wheel-legged robot, Gait transition, Flexibly gait planner, Gait feedback regulator, Unstructured terrain",Zhihua Chen and Jiehao Li and Shoukun Wang and Junzheng Wang and Liling Ma,https://www.sciencedirect.com/science/article/pii/S0921889021002499,https://doi.org/10.1016/j.robot.2021.103989,0921-8890,2022,103989,150,Robotics and Autonomous Systems,Flexible gait transition for six wheel-legged robot with unstructured terrains,article,CHEN2022103989
"In mobile robot path planning, the ant colony algorithm has the problem that the historical paths explored by ants cannot be fully utilized. With this in mind, in this paper an enhanced ant colony algorithm with a communication mechanism is proposed. The communication mechanism is inspired by the contact of ant tentacles in nature, which can integrate historical paths to obtain a better composite path. To further improve the algorithm, an enlarged roulette method is presented to accelerate the convergence. Subsequently, an adaptive sigmoid attenuation function is designed to optimize the heuristic information at different stages. The various forms of the deadlock problem are analyzed and specific strategies formulated. Finally, parameter determination and comparison experiments are carried out. The experimental results demonstrate the efficiency of the proposed method and its considerable advantages in enhancing the performance of the ant colony algorithm.","Mobile robot, Path planning, Ant colony algorithm, Communication mechanism, Roulette method, Deadlock",Wenbin Hou and Zhihua Xiong and Changsheng Wang and Howard Chen,https://www.sciencedirect.com/science/article/pii/S0921889021002256,https://doi.org/10.1016/j.robot.2021.103949,0921-8890,2022,103949,148,Robotics and Autonomous Systems,Enhanced ant colony algorithm with communication mechanism for mobile robot path planning,article,HOU2022103949
"Multi-Agent Path Finding has been widely studied in the past few years due to its broad application in the field of robotics and AI. However, previous solvers rely on several simplifying assumptions. This limits their applicability in numerous real-world domains that adopt nonholonomic car-like agents rather than holonomic ones. In this paper, we give a mathematical formalization of the Multi-Agent Path Finding for Car-Like robots (CL-MAPF) problem. We propose a novel hierarchical search-based solver called Car-Like Conflict-Based Search to address this problem. It applies a body conflict tree to address collisions considering the shapes of the agents. We introduce a new algorithm called Spatiotemporal Hybrid-State A* as the single-agent planner to generate agents? paths satisfying both kinematic and spatiotemporal constraints. We also present a sequential planning version of our method, sacrificing a small amount of solution quality to achieve a significant reduction in runtime. We compare our method with two baseline algorithms on a dedicated benchmark and validate it in real-world scenarios. The experiment results show that the planning success rate of both baseline algorithms is below 50% for all six scenarios, while our algorithm maintains that of over 98%. It also gives clear evidence that our algorithm scales well to 100 agents in 300 m × 300 m scenario and is able to produce solutions that can be directly applied to Ackermann-steering robots in the real world. The benchmark and source code are released in https://github.com/APRIL-ZJU/CL-CBS. The video of the experiments can be found on YouTube.","Multi-agent systems, Path planning, Mobile robots",Licheng Wen and Yong Liu and Hongliang Li,https://www.sciencedirect.com/science/article/pii/S0921889021002530,https://doi.org/10.1016/j.robot.2021.103997,0921-8890,2022,103997,150,Robotics and Autonomous Systems,CL-MAPF: Multi-Agent Path Finding for Car-Like robots with kinematic and spatiotemporal constraints,article,WEN2022103997
"In the physical human?robot interaction (pHRi) system, the human and the robot are physically coupled, and it makes the human and the robot always influence each other. In engineering tasks, using a force sensor is the norm for control the robot through the interaction force between the human and the robot. However, the force measured from the force sensor contains the force intended by human motion and the natural force feedback generated by the robot movement and the human hand impedance due to the coupled dynamics. Therefore, it is necessary to characterize the human hand dynamics to improve transparency. However, it is difficult to estimate the human hand impedance, which is the primary source of natural force feedback in real-time. This paper proposes a real-time adaptive hand impedance compensator to enhance transparency in various pHRi conditions with human hand dynamics. The proposed algorithm regulates the impedance compensator?s parameters to find optimal values that minimize the energy-based cost function using Simultaneous Perturbation Stochastic Approximation (SPSA) and AMSGrad. SPSA is a useful method when the exact relationship between the parameters and the cost function is unknown. AMSGrad is a state-of-the-art technique widely used as an adaptive learning rate method in deep learning fields. The proposed real-time adaptive impedance compensator decreases the influence of natural force feedback by updating the parameter appropriately depending on the pHRi conditions, thus improving the transparency.","Physical human?robot interaction, Adaptive impedance compensator, SPSA",Kyeong Ha Lee and Seung Guk Baek and Hyuk Jin Lee and Seung Ho Lee and Ja Choon Koo,https://www.sciencedirect.com/science/article/pii/S0921889021002013,https://doi.org/10.1016/j.robot.2021.103916,0921-8890,2022,103916,147,Robotics and Autonomous Systems,Real-time adaptive impedance compensator using simultaneous perturbation stochastic approximation for enhanced physical human?robot interaction transparency,article,LEE2022103916
"Computational path planning approaches can enable development of autonomous rehabilitation and assistive exoskeletons. Using a human-like reference behavior for such wearable systems can ensure safe, effective, and intuitive human?robot interaction. This is of significant importance since the quality of interaction and ergonomic considerations have a substantial effect on technology usability and acceptance by the users. This paper proposes a novel framework for generating human-like paths for wearable exoskeletons in the shoulder-elbow level. The introduced method is a two-stage process where a human-like reference path is planned in the configuration space of the human arm, followed by an analytical transformation that directly maps the derived path to the configuration space of the exoskeleton. The analytical mapping presented is a function of the kinematic parameters of the system and can be adapted for other upper-limb exoskeletons. As a case study, the proposed method is used for generating human-like reference motions for a six-degree-of-freedom exoskeleton supporting scapulohumeral rhythm, glenohumeral rotations, and elbow flexion/extension. Firstly, it is shown that reaching motions associated with activities of daily living can be predicted with high accuracy in the human joint space. This is demonstrated by analyzing the experimental data collected from healthy subjects. Subsequently, it is verified through kinematic analysis that the transformation of generated paths to the exoskeleton configuration space does not alter their spatial profile in the task space.","Computational models, Human-like motion, Path planning, Upper-limb exoskeletons, Scapulohumeral rhythm",Rana {Soltani Zarrin} and Amin Zeiaee and Reza Langari and John J. Buchanan and Nina Robson,https://www.sciencedirect.com/science/article/pii/S0921889021001287,https://doi.org/10.1016/j.robot.2021.103843,0921-8890,2021,103843,145,Robotics and Autonomous Systems,Towards autonomous ergonomic upper-limb exoskeletons: A computational approach for planning a human-like path,article,SOLTANIZARRIN2021103843
"We focus on the Multi-Robot pickup and delivery problem for logistic scenarios that recently received significant attention from the research community. In particular we consider an innovative variant of the pickup and delivery problem where robots can deliver, in a single travel, multiple items. We propose a decentralized coordination algorithm based on a token passing approach. Our algorithm allocates delivery tasks (i.e., an aggregation of items to be delivered by a single robot) to the Multi-Robot System avoiding conflicts among the robots. In more detail, we show that our approach generates conflict-free paths for the Multi-Robot system requiring weaker assumptions on the operational area compared to previous approaches. We empirically evaluate the proposed method on three different scenarios, including the production line of a smart factory, comparing the performance of our decentralized method against two centralized approaches. Results show that our approach finds solutions of similar quality (in terms of makespan and travel distance) reducing the associated computational effort.","Multi-Robot systems, Multi-Agent Path Planning, Task allocation, Logistic applications",Antonello Contini and Alessandro Farinelli,https://www.sciencedirect.com/science/article/pii/S0921889021001561,https://doi.org/10.1016/j.robot.2021.103871,0921-8890,2021,103871,146,Robotics and Autonomous Systems,Coordination approaches for multi-item pickup and delivery in logistic scenarios,article,CONTINI2021103871
"The automatic parking system can replace people to complete the parking task and reduce the burden of driving. The size of the parking space affects the number of parking operations and the time for parking planning to be completed. Parking planning in narrow space is a challenging problem, especially in crowded urban environments. This paper presents a parking path planning method in a narrow vertical parking space. First, the parking path planning method can be used in narrow corridor spaces and narrow spots. According to the size of the corridor space and the parking space obtained by the environment perception, this method can determine the number of parking maneuvers and the start parking position. Second, to allow the vehicle to generate a parking path at any position to reach the parking starting point, the system generates a target line set that considers control error factors. It will also select the optimal target line based on the current position. Third, the vehicle cannot complete the parking while traveling along the original parking path when the factual error is greater than the reserved error. Therefore, a re-planning method based on geometric planning is proposed to improve the robustness of the system. Finally, through the establishment of longitudinal and lateral driver models, the effectiveness of the path planning method is verified, and compared with other path planning methods, it proves that the method proposed in this paper performs well in the number of maneuvers and planning time in a small space.","Autonomous parking, Motion planning, Path planning, Driver model",Lei Cai and Hsin Guan and Hao Lun Zhang and Xin Jia and Jun Zhan,https://www.sciencedirect.com/science/article/pii/S0921889021002360,https://doi.org/10.1016/j.robot.2021.103964,0921-8890,2022,103964,149,Robotics and Autonomous Systems,Multi-maneuver vertical parking path planning and control in a narrow space,article,CAI2022103964
"With the increasing complexity of robot tasks in the industrial field, sometimes the manipulator needs to change the payload or replace end-effectors frequently in a period of time, which will cause the change of gravity model. This paper presents a fast gravity compensation updating method based on sparse selection and reconstruction. Instead of using the classic model, feature sets in the formulation of dynamic motion are exploited and the gravity model learning is transformed into a sparse problem. Then, the Alternating Direction Multiplier Method (ADMM) is used to accelerate the process of solving the sparse optimization problem and reconstructing the effective features of the gravity model from the original signal. The merits of our method are that it does not depend on any kinematic and dynamic parameters, and there is no need to redesign the specific excitation trajectory in the gravity model updating. Thus, the updating process avoids heavy work of calibration and simplifies the labor complexity considerably from the conventional analytical methods. The results of various payload experiments on a real 7-DOF manipulator show that the proposed method can update the gravity compensation model efficiently and accurately.","Industrial robot arm, Gravity compensation, Feature selection, Model reconstruction, ADMM",Chenglong Yu and Zhiqi Li and Dapeng Yang and Hong Liu,https://www.sciencedirect.com/science/article/pii/S0921889021002402,https://doi.org/10.1016/j.robot.2021.103971,0921-8890,2022,103971,149,Robotics and Autonomous Systems,A fast robotic arm gravity compensation updating approach for industrial application using sparse selection and reconstruction,article,YU2022103971
"This work presents a novel software architecture to autonomously identify and evaluate the gymnastic activity that people are carrying out. It is composed of three different interconnected layers. The first corresponds to a Multilayer Perceptron (MLP) trained from a set of angular magnitudes derived from the information provided by the OpenPose library. This library works frame by frame, so some postures may be incorrectly detected due to eventual occlusions. The MLP layer makes it possible to accurately identify the posture a person is performing. A second layer, based on a Hidden Markov Model (HMM) and the Viterbi algorithm, filters the incorrect spurious postures. Thus, the accuracy of the algorithm is improved, leading to a precise sequence of postures. A third layer identifies the current exercise and evaluates whether the person is doing it at a correct speed. This layer uses an innovative Modified Levenshtein Distance (MLD), which considers not only the number of operations to transform a given sequence, but also the nature of the elements participating in the comparison. The system works in real time with little delay, thus recognizing sequences of arbitrary length and providing continuous feedback on the exercises being performed. An experiment carried out consisted in reproducing the output of the second layer on an autonomous Pepper robot that can be used in environments where physical exercise is performed, such as a residence for the elderly or others. It has reproduced different exercises previously executed by an instructor so that people can copy the robot. The article analyzes the current situation of the automated gymnastic activities recognition, presents the architecture, the different experiments carried out and the results obtained. The integration of the three components (MLP, HMM and MLD) results in a robust system that has allowed us to improve the results of previous works.","Automated gymnastic activity recognition, Autonomous robot, Social robotics, Multilayer perceptron, MLP, Hidden Markov model, HMM, Viterbi, Modified Levenshtein distance, MLD, OpenPose",Jaime Duque Domingo and Jaime Gómez-García-Bermejo and Eduardo Zalama,https://www.sciencedirect.com/science/article/pii/S0921889021001159,https://doi.org/10.1016/j.robot.2021.103830,0921-8890,2021,103830,143,Robotics and Autonomous Systems,Visual recognition of gymnastic exercise sequences. Application to supervision and robot learning by demonstration,article,DOMINGO2021103830
"Manipulators coupled with an Unmanned Aerial Vehicle (UAV) have made it possible to perform aerial handling, transport, and picking maneuvers. One of the techniques used to control these systems is a backstepping controller that has shown high performance compared to a PID in the face of uncertainties and parametric disturbances. This paper presents the study of a backstepping controller for a mobile manipulator (MM?UAV) system tuned with the Cuckoo Search algorithm (CS) for trajectory tracking. Unlike other research, this study focuses on optimization using this metaheuristic algorithm that has never been applied in an MM?UAV. The system is divided in a novel way to implement the CS, considering the dependence of each rotation axis with the correspondence translation axis. Additionally, the tuning focuses on two critical points of the dynamic response, the overshoot and settling time. The results at the simulation and experimental level show that for all cases, a settling time of fewer than 0.8 s and overshoot is minor than 2%. This allows a balanced response of the system, which directly impacts energy consumption. The results are compared with a PID controller to verify the proposed work efficiency, showing a reduction of up to 8% of overshoots without exceeding in any experiment the maximum settling time of 0.8 s imposed to the system.","Cuckoo Search algorithm, Backstepping control, Unmanned aerial vehicle, Manipulator, Optimal control",Omar Rodríguez-Abreo and Francisco-Javier Ornelas-Rodríguez and Alfonso Ramírez-Pedraza and Juan B. Hurtado-Ramos and José-Joel González-Barbosa,https://www.sciencedirect.com/science/article/pii/S0921889021001950,https://doi.org/10.1016/j.robot.2021.103910,0921-8890,2022,103910,147,Robotics and Autonomous Systems,Backstepping control for a UAV-manipulator tuned by Cuckoo Search algorithm,article,RODRIGUEZABREO2022103910
"Unmanned aerial vehicles (UAVs) are reaching offshore. In this work, we formulate the novel problem of a marine locomotive quadrotor UAV, which manipulates the surge velocity of a floating buoy by means of a cable. The proposed robotic system can have a variety of novel applications for UAVs where their high speed and maneuverability, as well as their ease of deployment and wide field of vision, give them a superior advantage. In addition, the major limitation of limited flight time of quadrotor UAVs is typically addressed through an umbilical power cable, which naturally integrates with the proposed system. A detailed high-fidelity dynamic model is presented for the buoy, UAV, and water environment. In addition, a stable control system design is proposed to manipulate the surge velocity of the buoy within certain constraints that keep the buoy in contact with the water surface. Polar coordinates are used in the controller design process since they outperform traditional Cartesian-based velocity controllers when it comes to ensuring correlated effects on the tracking performance, where each control channel independently affects one control parameter. The system model and controller design are validated in numerical simulation under different settings, configurations, and wave scenarios.","Tethered UAV, Marine robotics, Motion control, Locomotive UAV, Floating buoy manipulation",Ahmad Kourani and Naseem Daher,https://www.sciencedirect.com/science/article/pii/S0921889021001433,https://doi.org/10.1016/j.robot.2021.103858,0921-8890,2021,103858,145,Robotics and Autonomous Systems,Marine locomotion: A tethered UAV-Buoy system with surge velocity control,article,KOURANI2021103858
"The paper presents a model-based approach to developing robotic system controllers. Central to this approach is a parameterised meta-model that describes the generic robotic system from two points of view: structure and activity. By appropriate parameterisation of the meta-model one can obtain a particular model of a robotic system performing desired tasks. The meta-model is expressed using the Robotic System Hierarchical Petri Net (RSHPN), a 6-layer Petri net tailored for robotics. Each layer describes the activity of the robotic system at a completely different level of abstraction. This guarantees the separation of concerns. The required model emerges from the meta-model by appropriate parameterisation of the layers of the RSHPN. Introduction of parameterisation enables the robot designer to focus only on the concepts derived from the domain. It greatly facilitates the robotic system development process as it gives the designer clear guidance on what needs to be defined and what is imposed by the design pattern. The resulting single RSHPN model is used both to verify some properties of the system, e.g. lack of deadlocks, but also to automatically generate controller code. The presented approach is illustrated by examples of the creation of two different robotic systems.","Embodied agent approach, Model Driven Engineering, Robotic System Hierarchical Petri Net, Meta-model parameterisation",Maksym Figat and Cezary Zieli?ski,https://www.sciencedirect.com/science/article/pii/S0921889021002487,https://doi.org/10.1016/j.robot.2021.103987,0921-8890,2022,103987,150,Robotics and Autonomous Systems,Parameterised robotic system meta-model expressed by Hierarchical Petri nets,article,FIGAT2022103987
"In order for a mobile robot to be able to effectively operate in complex, dynamic environments it must be capable of understanding both where and what the objects around them are. In this paper we introduce the semantic probability hypothesis density (SPHD) filter, which allows robots to simultaneously track multiple classes of targets despite measurement uncertainty, including false positive detections, false negative detections, measurement noise, and target misclassification. The SPHD filter is capable of incorporating a different motion model for each type of target and of functioning in situations where the number of targets is unknown and time-varying. To demonstrate the efficacy of the SPHD filter, we conduct both simulated and hardware tests with multiple target types containing both static and dynamic targets. We show that the SPHD filter allows effective tracking of multiple classes of targets even with detection error to some level, and performs better than a collection of PHD filters running in parallel, one for each target class. We also provide a detailed methodology that practitioners can use to fit the probabilistic sensor models necessary to run the SPHD filter.","Multiple target tracking, Semantic tracking, PHD filter, Robot learning",Jun Chen and Zhanteng Xie and Philip Dames,https://www.sciencedirect.com/science/article/pii/S0921889021002244,https://doi.org/10.1016/j.robot.2021.103947,0921-8890,2022,103947,149,Robotics and Autonomous Systems,The semantic PHD filter for multi-class target tracking: From theory to practice,article,CHEN2022103947
"This paper conducts a comparison of the performance and cognitive workload between three UAV control interfaces on an nCA (navigation control autonomy) Tier 1-III flight navigation task. The first interface is the standard RC Joystick (RCJ) controller, the second interface is the multimodal speech and visual gesture (mSVG) interface, and the third interface is the modified version of the RCJ interface with altitude, attitude, and position (AAP) assist. The modified RCJ interface was achieved with the aid of the Keyboard (KBD). A model of the mSVG interface previously designed and tested was used in this comparison. An experiment study was designed to measure the completion time and navigation accuracy of participants using each of the three interfaces, on a developed path_v02 test flight path. Thirty-seven (37) participants volunteered. The NASA task load index (TLX) survey questionnaire was administered at the end of each interface experiment to access the participants experience and to estimate the interface cognitive workload. A commercial software, the RealFlight Drone Simulator (RFDS) was used to estimate the RCJ skill level of the participants. From the results of the experiment, it was shown that the flying hours, the number of months flying, and the RFDS Level 4 challenge performance was a good estimator for participants RCJ flying skill level. A two-way result was obtained in the comparison of the RCJ and mSVG interfaces. It was concluded that, although the mSVG was better than the standard RCJ interface, the AAP-assisted RCJ was found to be as effective as (in some cases better than) the mSVG interface. It was also shown, from the speech gesture ratio result, that the participants had a preference for gesture over speech when using the mSVG interface. Some further works such as an outdoor field test and a performance comparison at higher nCA levels were suggested.","Aerobot, mSVG (multimodal speech and visual gesture), nCA (navigation control autonomy), RFDS (RealFlight Drone Simulator), Speech, Visual gesture",Ayodeji Opeyemi Abioye and Stephen D. Prior and Peter Saddington and Sarvapali D. Ramchurn,https://www.sciencedirect.com/science/article/pii/S0921889021002001,https://doi.org/10.1016/j.robot.2021.103915,0921-8890,2022,103915,147,Robotics and Autonomous Systems,The performance and cognitive workload analysis of a multimodal speech and visual gesture (mSVG) UAV control interface,article,ABIOYE2022103915
"Phase-variable-based approaches are emerging in the control of lower-limb wearable robots, such as exoskeletons and prosthetic legs. However, real-time smooth estimation of the gait phase within each gait cycle remains an open problem. This paper presents a novel method for real-time continuous gait phase estimation during walking. The proposed framework consists of three subsystems: real-time kinematic data collection, gait phase variable estimation, and online adaptation of individual kinematics through backward data segmentation of completed gait strides. It is worth noting that we introduce an online learning mechanism for extracting and learning gait features from previous strides, in contrast with offline parameter tuning. The proposed basic gait model is initialized by human average data and is incrementally refined as a function of the individual gait features over different walking speeds. This provides a framework for long-term personalized control. Furthermore, the phase variable is constructed through the thigh angle measured by an inertial measurement unit. The resulting simple sensor system improves the usability of the proposed technique in wearable robotics. Validation experiments with seven healthy subjects, including treadmill walking and free level-ground walking, were conducted to evaluate the performance of the proposed method. In treadmill validation, the root-mean-square error (RMSE) of the phase estimator was 4.14 ± 1.68% for steady speeds, while it was 6.77 ± 2.29% for unsteady-speed walking. In level-ground validation, the average RMSE of the phase estimator was 4.59 ± 1.76%. Preliminary experiments were also conducted using a single-joint hip exoskeleton to demonstrate the usability of our method in lower-limb wearable robots.","Gait phase estimation, Trajectory correlation, Gait kinematics, Wearable robotics",Binquan Zhang and Sun?an Wang and Min Zhou and Wanlu Xu,https://www.sciencedirect.com/science/article/pii/S0921889021001275,https://doi.org/10.1016/j.robot.2021.103842,0921-8890,2021,103842,143,Robotics and Autonomous Systems,An adaptive framework of real-time continuous gait phase variable estimation for lower-limb wearable robots,article,ZHANG2021103842
"In this work, the dynamics of ?n? legged modular miniature robots with a soft body is modeled. The dynamic formulation is obtained using Newton?Euler formulation that depends on the contact parameters and the feet closed-chain kinematic analysis. The dynamic model determines the locomotion parameters of each module as an individual system as well as the dynamics of the whole robot in a 3D space; i.e., the robot is modeled as one system, and modules are considered to be sets of flexible links connected within this system. Kinematic constraints among these modules are obtained by considering the type of backbone integrated into the modular robot. Various types of backbones are used that are classified into three groups: rigid, only torsional, and soft. The model is verified using SMoLBot, an origami-inspired miniature robot made of multiple modules and soft/rigid backbones. Additional to the dynamic model, the effect of different sets of design parameters on the locomotion of the legged soft-bodied modular miniature robots is studied. Analyses comparing the velocity of SMoLBot with a different number of modules and various types of backbones are presented using the proposed dynamic model. Our results show the existence of an optimum backbone torsional stiffness for legged miniature modular robots and an optimum number of legs for a given backbone stiffness that maximizes the robot?s velocity. In this research, presented results and locomotion study show that the robot?s design should be iteratively improved based on specific optimum goals for exclusively defined task to satisfy the operational needs.","Robot dynamics, Legged robots, Miniature robots, Modular robots, Soft mobile robots, Origami-inspired robots",Nima Mahkam and Onur Özcan,https://www.sciencedirect.com/science/article/pii/S0921889021001263,https://doi.org/10.1016/j.robot.2021.103841,0921-8890,2021,103841,144,Robotics and Autonomous Systems,A framework for dynamic modeling of legged modular miniature robots with soft backbones,article,MAHKAM2021103841
"This article analyses data collected from press reports, social media, and the scientific literature on 338 instances of robots used explicitly in response to COVID-19 from 24 Jan, 2020, to 23 Jan, 2021, in 48 countries. The analysis was guided by four overarching questions: (1) What were robots used for in the COVID-19 response? (2) When were they used? (3) How did different countries innovate? and 4) Did having a national policy on robotics influence a country?s innovation and insertion of robotics for COVID-19? The findings indicate that robots were used for six different sociotechnical work domains and 29 discrete use cases. When robots were used varied greatly on the country; although many countries did report an increase at the beginning of their first surge. To understand the findings of how innovation occurred, the data was examined through the lens of the technology?s maturity according to NASA?s Technical Readiness Assessment metrics. Through this lens, findings note that existing robots were used for more than 78% of the instances; slightly modified robots made up 10%; and truly novel robots or novel use cases constituted 12% of the instances. The findings clearly indicate that countries with a national robotics initiative were more likely to use robotics more often and for broader purposes. Finally, the dataset and analysis produces a broad set of implications that warrant further study and investigation. The results from this analysis are expected to be of value to the robotics and robotics policy community in preparing robots for rapid insertion into future disasters.","Robotics and society, Field robotics, Disaster robotics, Medical robotics, Unmanned systems",Robin R. Murphy and Vignesh B.M. Gandudi and Trisha Amin and Angela Clendenin and Jason Moats,https://www.sciencedirect.com/science/article/pii/S0921889021002074,https://doi.org/10.1016/j.robot.2021.103922,0921-8890,2022,103922,148,Robotics and Autonomous Systems,An analysis of international use of robots for COVID-19,article,MURPHY2022103922
"In this article, a new formation for swarm robotic systems is introduced. This formation, which is made up of a portion of swarm members and encircles the whole swarm, is called the shell formation. In this regard, an effective algorithm for developing the shell formation in swarm robotic systems is established. The interaction mechanism among swarm agents is based on the method of artificial potential fields and the local rule of the nearest neighbor. Subsequently, inspired by the thermodynamic science and based on the introduced shell formation, the thermodynamic concept of pressure is generalized to swarm robotic systems. Finally, the efficacy of the introduced shell formation in solving the problem of passing through a narrow passage is studied via numerical simulations.","Swarm robotics, Shell formation, Thermodynamic viewpoint, Swarm pressure, Passing through a narrow passage",Ahmad Mahdian Parrany and Aria Alasty,https://www.sciencedirect.com/science/article/pii/S0921889021002190,https://doi.org/10.1016/j.robot.2021.103939,0921-8890,2022,103939,148,Robotics and Autonomous Systems,Introducing shell formation and a thermodynamics-inspired concept for swarm robotic systems,article,PARRANY2022103939
"Due to their compliance, continuum robots (CRs) hold great potential for many applications. However, despite intensive recent research, their control poses significant challenges. The nonlinear kinematic behavior, limited actuation channels, and physical and environmental constraints typically associated with CRs hinder the development of effective control strategies. In this paper, a visual predictive position control method for tendon-driven continuum robots is proposed. The developed control approach integrates the advantages of image-based visual servoing and model predictive control techniques to enable direct end-point control in the presence of constraints and improve the control robustness to system uncertainties, sensing noise, and modeling errors. Both simulation and experimental results demonstrate the effectiveness of the method.","Continuum robot, Tendon driven, Visual servoing, Predictive control, Robustness, Steerable catheter",Somayeh Norouzi-Ghazbi and Ali Mehrkish and Mostafa {M.H. Fallah} and Farrokh Janabi-Sharifi,https://www.sciencedirect.com/science/article/pii/S092188902100141X,https://doi.org/10.1016/j.robot.2021.103856,0921-8890,2021,103856,145,Robotics and Autonomous Systems,Constrained visual predictive control of tendon-driven continuum robots,article,NOROUZIGHAZBI2021103856
"Background: The integration of mobile robotic platforms in human gait analysis offers the potential to develop multiple medical applications and achieve new discoveries. The aim of this paper is to present a first design and validation of a ROS-based mobile robotic platform for human gait analysis. Methods: During the design stage, the model identification and the configuration of the control law were performed. The design of the control law required the integration of a lead compensator and a Filtered Smith Predictor (FSP). During the validation procedure, the accuracy of the system to retrieve kinematic gait data and the main descriptors of gait disorders was calculated with respect to the ground truth of a Vicon system. For this purpose, one hundred gait recordings were processed thanks to the collaboration of twenty participants. The participants walked in a one-way straight line gait. Results: Results showed high correlation and low error rates mainly in joint excursions from sagittal and transverse planes. Conclusion: This gait analysis system demonstrated several advantages compared with the current approaches. The use of a mobile robotic platform allowed gait analysis in long tracking ranges and without space limitations. Furthermore, the design of a suitable control law allowed a smooth tracking of the person. This led to optimal results when assessing joint excursions. Significance: This system represents a cost-effective and non-invasive alternative that could be used for human gait analysis applications.","Mobile robot, Gait analysis, Depth sensors",Diego Guffanti and Alberto Brunete and Miguel Hernando,https://www.sciencedirect.com/science/article/pii/S0921889021001548,https://doi.org/10.1016/j.robot.2021.103869,0921-8890,2021,103869,145,Robotics and Autonomous Systems,Development and validation of a ROS-based mobile robotic platform for human gait analysis applications,article,GUFFANTI2021103869
"Just as end-user programming has helped make computer programming accessible for a variety of users and settings, end-user robot programming has helped empower end-users without specialized knowledge or technical skills to customize robotic assistance that meets diverse environmental constraints and task requirements. While end-user robot programming methods such as kinesthetic teaching have introduced direct approaches to task demonstration that allow users to avoid working with traditional programming constructs, our formative study revealed that everyday people still have difficulties in specifying effective robot programs using these methods due to challenges in understanding robot kinematics and programming without situated context and assistive system feedback. These findings informed our development of Demoshop, an interactive robot programming tool that includes user-centric programming aids to help end-users author and edit task demonstrations. To evaluate the effectiveness of Demoshop, we conducted a user study comparing task performance and user experience associated with using Demoshop relative to a widely used commercial baseline interface. Results of our study indicate that users have greater task efficiency while authoring robot programs and maintain stronger mental models of the system when using Demoshop compared to the baseline interface. Our system implementation and study have implications for the further development of assistance in end-user robot programming.","Human?robot interaction, End?user development, End?user robot programming",Gopika Ajaykumar and Maia Stiber and Chien-Ming Huang,https://www.sciencedirect.com/science/article/pii/S0921889021001305,https://doi.org/10.1016/j.robot.2021.103845,0921-8890,2021,103845,145,Robotics and Autonomous Systems,Designing user-centric programming aids for kinesthetic teaching of collaborative robots,article,AJAYKUMAR2021103845
"As a novel class of robots, soft robots have demonstrated many desirable mechanical properties than traditional rigid robots due to their nature of being compliant, flexible and hyper-redundant, such as great adaptability to unknown environments, safe human robot interaction (HRI), energy-saving actuation and the maneuverability to display diverse mechanical properties. However, its inherent high-DoF nature would result in some complex nonlinear behaviors, and their kinematic or dynamic models are therefore harder to deduce than the ones of conventional rigid robots. In this paper, we propose a trajectory tracking control strategy for a soft trunk robot based on Finite Element Method (FEM). We first plan a feasible trajectory for the studied robot in SOFA (a FEM-based simulator) by solving a model-prediction-control (MPC)-based optimization problem. The second step is to conduct linearization around the pre-designed trajectory, based on which an associated controller can be then developed. The detailed derivation of the mentioned work is explained accordingly. In the end, the results of experimental validation is presented to prove the feasibility of the proposed method.","Soft robotics, Finite Element Method, Trajectory planning, Trajectory tracking control",Ke Wu and Gang Zheng and Junfeng Zhang,https://www.sciencedirect.com/science/article/pii/S0921889021002359,https://doi.org/10.1016/j.robot.2021.103961,0921-8890,2022,103961,150,Robotics and Autonomous Systems,FEM-based trajectory tracking control of a soft trunk robot,article,WU2022103961
"In-vehicle human?machine interface (HMI) mainly refers to the T-shaped panel system with instruments, centre console, gear lever and other components installed. For intelligent vehicles, the high level of intelligent interconnection may to some extent make drivers lack situational safety awareness and reduce the usability of the system. Thus, this study attempted to establish a relationship between design features and system usability of the in-vehicle panels. From the perspective of visual ergonomics, the panels were deconstructed into design features to determine 36 samples to be studied. After dividing each sample into four areas of interest (AOI), eye movement and subjective preference data were collected to quantify the user experience. Artificial neural network (ANN) and support vector machine (SVM) were used in the study. Nevertheless, conventional learning algorithms often underwent deficiencies in accuracy and robustness in the detection of multifarious kinds of panels. Therefore, the parameters of the two models were tuned to deal with the noise common in user experience data. The determinant coefficients, mean-square errors and mean relative errors of the two models showed that the SVM model had a higher accuracy, smaller error and was more stable in the learning of user experience of HMI design features, which could provide a method for the layout design and evaluation of T-shaped instrument panel.","Instrument panel, Design features, Eye movement, System usability, BP neural network, SVM",Hao Yang and Jitao Zhang and Yueran Wang and Ruoyu Jia,https://www.sciencedirect.com/science/article/pii/S0921889021001147,https://doi.org/10.1016/j.robot.2021.103829,0921-8890,2021,103829,143,Robotics and Autonomous Systems,Exploring relationships between design features and system usability of intelligent car human?machine interface,article,YANG2021103829
"The ability to distinguish between the self and the background is of paramount importance for robotic tasks. The particular case of hands, as the end effectors of a robotic system that more often enter into contact with other elements of the environment, must be perceived and tracked with precision to execute the intended tasks with dexterity and without colliding with obstacles. They are fundamental for several applications, from Human?Robot Interaction tasks to object manipulation. Modern humanoid robots are characterized by high number of degrees of freedom which makes their forward kinematics models very sensitive to uncertainty. Thus, resorting to vision sensing can be the only solution to endow these robots with a good perception of the self, being able to localize their body parts with precision. In this paper, we propose the use of a Convolution Neural Network (CNN) to segment the robot hand from an image in an egocentric view. It is known that CNNs require a huge amount of data to be trained. To overcome the challenge of labeling real-world images, we propose the use of simulated datasets exploiting domain randomization techniques. We fine-tuned the Mask-RCNN network for the specific task of segmenting the hand of the humanoid robot Vizzy. We focus our attention on developing a methodology that requires low amounts of data to achieve reasonable performance while giving detailed insight on how to properly generate variability in the training dataset. Moreover, we analyze the fine-tuning process within the complex model of Mask-RCNN, understanding which weights should be transferred to the new task of segmenting robot hands. Our final model was trained solely on synthetic images and achieves an average IoU of 82% on synthetic validation data and 56.3% on real test data. These results were achieved with only 1000 training images and 3 h of training time using a single GPU.","Robotic hand, Visual segmentation, Deep learning, Domain randomization, Self-recognition",Alexandre Almeida and Pedro Vicente and Alexandre Bernardino,https://www.sciencedirect.com/science/article/pii/S0921889021001421,https://doi.org/10.1016/j.robot.2021.103857,0921-8890,2021,103857,145,Robotics and Autonomous Systems,Where is my hand? Deep hand segmentation for visual self-recognition in humanoid robots,article,ALMEIDA2021103857
"Most of the existing path planning algorithms require a prior global map. Although there have been some algorithms proposed for unknown environments, they can only deal with those which just have several hidden obstacles in a roughly known global map. In order to improve the efficiency of robot?s path planning without prior global maps, this paper proposes a Convolutionally Evaluated Gradient First Search (CE-GFS) path planning algorithm. It allows the robot to collect environmental information and complete path planning simultaneously. Firstly, the Gradient First Search (GFS) algorithm is proposed based on the gradient score parameter, with which the conventional cost function is replaced. The GFS can adapt to any moving direction through the environmental information surrounding the mobile robot and computing the gradient score parameter. Secondly, CE-GFS path planning algorithm is proposed based on GFS and convolutional evaluation method. The CE-GFS helps the robots to evaluate the efficiency of the global path and get global perception ability, so that they are prevented from going astray, which can significantly improve the efficiency of path planning. Finally, several simulation tests and field tests have been carried out. The test results show that convolutional evaluation improves the efficiency of CE-GFS by 86.94% on average compared with GFS at the price of 0.18% decrease in path planning success rate. Moreover, the time cost of the proposed CE-GFS algorithm is 42.18% less than that of FAR-Planner in some special cases.","Path planning, Mobile robot, Gradient descent, Unknown environments",Yizhi Wu and Fei Xie and Lei Huang and Rui Sun and Jiquan Yang and Qiang Yu,https://www.sciencedirect.com/science/article/pii/S0921889021002475,https://doi.org/10.1016/j.robot.2021.103985,0921-8890,2022,103985,150,Robotics and Autonomous Systems,Convolutionally evaluated gradient first search path planning algorithm without prior global maps,article,WU2022103985
"Minimally invasive surgical instrument visual detection and tracking is one of the core algorithms of minimally invasive surgical robots. With the development of machine vision and robotics, related technologies such as virtual reality, three-dimensional reconstruction, path planning, and human?machine collaboration can be applied to surgical operations to assist clinicians or use surgical robots to complete clinical operations. The minimally invasive surgical instrument vision detection and tracking algorithm analyzes the image transmitted by the surgical robot endoscope, extracting the position of the surgical instrument tip in the image, so as to provide the surgical navigation. This technology can greatly improve the accuracy and success rate of surgical operations. The purpose of this paper is to further study the visual detection and tracking technology of minimally invasive surgical instruments, summarize the existing research results, and apply it to the surgical robot project. By reading the literature, the author summarized the theoretical basis and related algorithms of this technology in recent years. Finally, the author compares the accuracy, speed and application scenario of each algorithm, and analyzes the advantages and disadvantages of each algorithm. The papers included in the review were selected through Web of Science, Google Scholar, PubMed and CNKI searches using the keywords: ?object detection?, ?object tracking?, ?surgical tool detection?, ?surgical tool tracking?, ?surgical instrument detection? and ?surgical instrument tracking? limiting results to the year range 1985?2021. Our study shows that this technology will have a great development prospect in the aspects of accuracy and real-time improvement in the future.","Surgical robots, Machine vision, Detection and tracking of surgical instruments, Deep learning, Feature extraction",Yan Wang and Qiyuan Sun and Zhenzhong Liu and Lin Gu,https://www.sciencedirect.com/science/article/pii/S0921889021002232,https://doi.org/10.1016/j.robot.2021.103945,0921-8890,2022,103945,149,Robotics and Autonomous Systems,Visual detection and tracking algorithms for minimally invasive surgical instruments: A comprehensive review of the state-of-the-art,article,WANG2022103945
"The paper presents ISO standardization work carried out to formulate guidelines for service robot modularity for assisting the development of open plug-n-play modules that can be easily assembled to create application specific robots and robot systems. Although robot modularity has been an active research field for many years, the developments have had little impact on advancing robot markets due to their individualist nature and the results not having sufficiently wide relevance or appeal. The paper initially provides an overview of the new ISO 22166-1 service robot modularity standard and aims to illustrate how to implement it with several use cases. Specific innovations produced in realizing robot modules under the guidance of ISO are introduced and two simple approaches based on block diagram approaches (the line and circle diagrams) are proposed for implementing and designing modular robots. Finally, the paper presents several use cases as examples where the new ISO robot modular approach can be used to good effect.","Modularity, Service robots, ISO standardization, Use cases",Yibo Zou and Donghan Kim and Philip Norman and Jose Espinosa and Jen-Chieh Wang and Gurvinder S. Virk,https://www.sciencedirect.com/science/article/pii/S0921889021002220,https://doi.org/10.1016/j.robot.2021.103943,0921-8890,2022,103943,148,Robotics and Autonomous Systems,Towards robot modularity ? A review of international modularity standardization for service robots,article,ZOU2022103943
"Task Parametrised Gaussian Mixture Modelling and Regression (TP-GMM/R) is an eminent algorithm to enable collaborative robots (cobots) to adapt to new environments intuitively by learning robotic paths demonstrated by humans. Task parameters in the TP-GMM/R algorithm, i.e., frames associated with demonstration paths, are considered to have orientations by default. This requirement, however, limits the range of applications that TP-GMM/R can support. To address the issue, in this paper, a novel ring Gaussian (rGaussian) is defined to cater for orientation-less frames, and an improved TP-GMM/R algorithm based on rGaussians is developed to improve the adaptability and robustness of the algorithm. In the improved algorithm, firstly, kernels are incorporated to enable Gaussians encoding points from all demonstrations, and criteria are devised to judge a frame to be oriented or orientation-less. Then, improved Gaussian mixture regression that caters for rGaussians and orientation-less frames is developed to generate regression paths adaptable to complex environments. Finally, a series of case studies are used to benchmark the improved TP-GMM/R algorithm with the conventional TP-GMM/R algorithm under different conditions. Quantitative analyses are conducted in terms of smoothness, efficiency and reachability. Results show that the improved algorithm outperformed the conventional algorithm on all the cases.","Learning from demonstration, Gaussian Mixture Model, Gaussian Mixture Regression, Collaborative robots (cobots)",Shirine {El Zaatari} and Weidong Li and Zahid Usman,https://www.sciencedirect.com/science/article/pii/S0921889021001494,https://doi.org/10.1016/j.robot.2021.103864,0921-8890,2021,103864,145,Robotics and Autonomous Systems,Ring Gaussian Mixture Modelling and Regression for collaborative robots,article,ELZAATARI2021103864
"The area of swarm robotics has grown widely in recent years, precisely because its formulation is based on the use of various techniques, ranging from computer networks to controllers. We can employ different types of techniques to carry out the control of a robots team. In this work we will focus on creating techniques based on bio-inspired computing. Within this theme, we will be focused on using cellular automata with synchronous and asynchronous rules and ant colonies optimization. Additionally, we will consider greedy approaches to select the next robot?s state cell and a local Tabu search with a queue of robot movement restrictions. Thus, we have a surrogate model capable of providing the team robot navigation in the surveillance task. We developed two different controllers, a simpler first, based on a precursor model and a second optimized model, based on the previous controller refinement. At the end, we used a genetic algorithm, which received the surrogate model as input for the improvement of our proposed models parameters. In addition, a survey with the evolution of surveillance models using cellular automata in a systematic review of literature will be shown. Experiments were performed to demonstrate the degree of robot team coverage by different environments. We accomplished statistical analysis with the intention of presenting different sizes of robot teams and amounts of pheromone deposited into the environment. In the end, we fulfilled experiments using the empirical simulation methodology of a robots team using the Webots simulator with e-Puck architecture. The results were promising, the robot team performed this task efficiently and the system is highly scalable.","Cellular automata, Swarm robotics, Bio-inspired controller, Ant colony optimization, Genetic algorithms, Surveillance task, Tabu search",Hamilton J.M. Lopes and Danielli A. Lima,https://www.sciencedirect.com/science/article/pii/S0921889021001251,https://doi.org/10.1016/j.robot.2021.103840,0921-8890,2021,103840,144,Robotics and Autonomous Systems,Evolutionary Tabu Inverted Ant Cellular Automata with Elitist Inertia for swarm robotics as surrogate method in surveillance task using e-Puck architecture,article,LOPES2021103840
"This article proposes a dynamic model based on distance and orientation between an omnidirectional mobile robot and a quadrotor Unmanned Aerial Vehicle (UAV), both under the leader?follower scheme. It is assumed that the omnidirectional robot is already controlled in order to follow a desired trajectory. On the other hand, a backstepping with a Continuous Sliding-Mode Control (C-SMC) are designed for the quadrotor with the objective of keeping a distance and formation angle with respect to the omnidirectional robot. Numerical simulations and real-time experiments show the performance of the proposed control strategy.","Backstepping, Omnidirectional robot, Quadrotor UAV, Sliding-mode control",Jaime González-Sierra and Alejandro Dzul and Edgar Martínez,https://www.sciencedirect.com/science/article/pii/S0921889021002062,https://doi.org/10.1016/j.robot.2021.103921,0921-8890,2022,103921,147,Robotics and Autonomous Systems,Formation control of distance and orientation based-model of an omnidirectional robot and a quadrotor UAV,article,GONZALEZSIERRA2022103921
"Motion primitive planning under parametric uncertainty may be modeled as a chance-constrained Markov Decision Process (CCMDP). Single-query solutions to CCMDPs can be obtained by searching the And/Or graph representing the state?action space of the system. The Risk-bounded AO* (RAO*) algorithm has been proposed as a solution method for this problem, but it scales poorly to MDPs resulting from a motion primitive discretization because it has no mechanism to prioritize expansion of AND nodes. This paper describes an induced heuristic for state?action pairs that can be rapidly computed by leveraging the properties of motion primitives; its value can be used to prioritize AND nodes for more efficient search. Search is further accelerated by leveraging shared symmetry in constraints and dynamics to move almost all computation necessary to enforce convex polytope constraints offline. The performance improvements are demonstrated with path planning problems involving a Dubins Car and a nonlinear aircraft model.","Motion primitives, Trajectory planning, MDP, Graph search, And/Or graphs, Parametric uncertainty, Chance constraints, Collision avoidance, Informed search",Geordan Gutow and Jonathan D. Rogers,https://www.sciencedirect.com/science/article/pii/S0921889021002505,https://doi.org/10.1016/j.robot.2021.103991,0921-8890,2022,103991,149,Robotics and Autonomous Systems,AND/OR search techniques for chance constrained motion primitive path planning,article,GUTOW2022103991
"In this paper, a new hand?eye calibration method based on spatial distance and epipolar constraints is proposed to obtain the transformation X between the end effector (hand) of the robotic arm and the camera (eye) fixed on the end effector. Most of the current effective hand?eye calibration methods utilize the classical identity, AX=XB, to obtain the analytical solution of X, and then apply various constraints to iteratively optimize the initial X, but these constraints are often at the 2D level. However, the result of hand?eye? calibration needs to ensure the accuracy of the vision-guided robot arm system operating in 3D space, which leads to inconsistency between optimization goals and the actual requirements. Therefore, the proposed method introduces 3D constraints into the iterative optimization of X and takes 3D error as an evaluation indicator of the calibration quality. There are two main steps in the proposed method. Firstly, the initial value of hand?eye transformation matrix is calculated by utilizing Kronecker product, which avoids the error propagation from rotation parameters to translation parameters. Then, the inherent epipolar constraints and the spatial distance constraints between feature points are combined to optimize hand?eye calibration parameters iteratively. To evaluate the precision and robustness of the proposed method, both simulation experiment and real experiment are carried out. The experimental results show that compared with conventional methods, the proposed method has higher accuracy and stronger robustness.","Hand-eye calibration, Kronecker product, Nonlinear optimization, 3D constraints",Zhenyu Liu and Xia Liu and Guifang Duan and Jianrong Tan,https://www.sciencedirect.com/science/article/pii/S0921889021001536,https://doi.org/10.1016/j.robot.2021.103868,0921-8890,2021,103868,145,Robotics and Autonomous Systems,Precise hand?eye calibration method based on spatial distance and epipolar constraints,article,LIU2021103868
"Research in multi-robot systems is a rich field that has attracted much attention in recent decades. However, robot coordination and task allocation to a correct mission accomplishment are still challenging even with technological advances. Despite many proposals presented in the literature, the applications and theories about the task allocation problem are not yet exhausted. Thus, this work proposes an axiomatic framework based on Social Choice Theory to analyze the task allocation problem in intentional cooperation multi-robot systems. It uses Kenneth J. Arrow?s framework of his famous Impossibility Theorem. The conditions imposed by Arrow aim to create an ideal for preference aggregation mechanisms through axiomatic analysis. This paper aims to transport this analysis to the multi-robot domain. A behavior-based Multi-robot Task Allocation architecture is used to present simulation results and discuss two cases in the ordinal preference domain. The analysis results show that using the proposed framework to analyze, under the Arrovian perspective, implemented MRTA architectures is feasible.","Multi-robot system, Task allocation, Social choice, Arrow?s theorem, Preference aggregation",Wallace Pereira Neves {dos Reis} and Gustavo Leite Lopes and Guilherme Sousa Bastos,https://www.sciencedirect.com/science/article/pii/S092188902100124X,https://doi.org/10.1016/j.robot.2021.103839,0921-8890,2021,103839,144,Robotics and Autonomous Systems,An arrovian analysis on the multi-robot task allocation problem: Analyzing a behavior-based architecture,article,DOSREIS2021103839
"High-precision measurement is a common task in many engineering applications. In these cases, sensor fusion algorithms represented by Kalman filter and its variants are effective and practical. It is introduced in the article, how to use this sensor fusion algorithm in a high-precision tracking task, where only one sensor (tacheometer) is used in the project. It is also discussed in the article how to build estimation models, including measurement model and motion model, for specific robot positioning problems. A variety of related models are compared in this article. The best model that utilize the prior knowledge of robot motion is proposed, which can not only meet the high precision requirements, but also have robustness to the robot operating environment.","Kalman filter, Sensor fusion, Tracking",Christoph Naab and Zhuoxun Zheng,https://www.sciencedirect.com/science/article/pii/S0921889021001895,https://doi.org/10.1016/j.robot.2021.103904,0921-8890,2022,103904,147,Robotics and Autonomous Systems,Application of the unscented Kalman filter in position estimation a case study on a robot for precise positioning,article,NAAB2022103904
"Object handover is a fundamental skill needed in many human?robot collaboration tasks ranging from industrial manipulation to daily service. It remains challenging for robots to perform a handover as flexibly and fluently as a human. This article proposes a framework based on Dynamic Movement Primitives (DMP) that enables robot to learn from human demonstrations and transfer the skill into human?robot handovers. In particular, we focus on the problem of dealing with time varying handover locations. Compared to the conventional DMP formalism, the proposed method contains the following extensions: (1) uncertainty-aware learning with Gaussian Process, (2) a weighting function to control the transition of the shape and goal attraction terms, (3) an orientation-based spatial scaling, (4) online parameter adaption with human feedback. Moreover, inspired by the principle of cooperative DMPs, we present an equivalent model to study the interactive dynamics in human?robot handovers. The proposed framework has been validated in experiments and evaluated by both subjective and objective metrics. Results show an enhancement of success rate, fluency and human comfort.","Dynamic movement primitives, Human?robot handovers, Adaptive control, Interaction model",Min Wu and Bertram Taetz and Yanhao He and Gabriele Bleser and Steven Liu,https://www.sciencedirect.com/science/article/pii/S0921889021002189,https://doi.org/10.1016/j.robot.2021.103935,0921-8890,2022,103935,148,Robotics and Autonomous Systems,An adaptive learning and control framework based on dynamic movement primitives with application to human?robot handovers,article,WU2022103935
"The range of motion and force output of soft actuators are important characteristics that determine the capacities of soft robots. Pouch motors are a family of soft fluidic actuators featuring a simple mechanical structure and easy fabrication process, but their relatively small contraction ratio constrains their potential applications. Inspired by the origami membrane in the lobster leg joint, we propose two types of origamic pouch motors in which origami structures are integrated into the longitudinal edges of traditional pouches. As a uniform and large degree of transverse expansion can be facilitated by unfolding the origami structures, a significantly larger contraction ratio and enhanced force output can be achieved. The complete workflow of origamic pouch motors is presented including the design principles, fabrication process, theoretical modeling, and experimental characterization, and multiple pouches can be conveniently assembled to realize different motion profiles with a larger range of motion as well. For application demonstrations, we develop different grippers based on origamic pouch motors for safe and forceful grasping. The results of this study can provide guidance for the development of robotic systems featuring easy fabrication, safe actuation, lightweight, a large motion range, and high force output.","Soft actuators, Hydraulic/pneumatic actuators, Soft robotics, Large motion range",Shanjun Li and Jiahao Lin and Hanwen Kang and Yunjiang Cheng and Yaohui Chen,https://www.sciencedirect.com/science/article/pii/S0921889021002463,https://doi.org/10.1016/j.robot.2021.103983,0921-8890,2022,103983,149,Robotics and Autonomous Systems,Bio-inspired origamic pouch motors with a high contraction ratio and enhanced force output,article,LI2022103983
"Despite the increasing popularity of the cloud robotics paradigm, the literature on the field still lacks comprehensive analysis on several aspects of the technology. Therefore, the adoption of common standards and frameworks is fundamental for developing the field and allowing practical works to be reproduced and compared. This work presents a ROS-based open framework for robot-cloud communication, easing the integration of robotics and remote cloud platforms, and discusses the implementation of the overall cloud robotics stack over open source software and commercial off-the-shelf devices. Additionally, we present two practical implementations in which most of the computation is carried out remotely and perform a series of experiments to demonstrate our technique. Our results indicate that task times can be reduced up to 15% when using remote cloud platforms even under 150 ms average communication latency over the public Internet while observing figures as low as 2% on throughput loss in sensor data transmission. In general, such results point to the feasibility of the presented approach in different classes of applications, even under non-ideal network and cloud settings.","Cloud robotics, ROS, Human?robot interaction, Navigation, Mobile robots",Ricardo C. Mello and Sergio D. {Sierra M.} and Wandercleyson M. Scheidegger and Marcela C. Múnera and Carlos A. Cifuentes and Moises R.N. Ribeiro and Anselmo Frizera-Neto,https://www.sciencedirect.com/science/article/pii/S0921889021002451,https://doi.org/10.1016/j.robot.2021.103981,0921-8890,2022,103981,150,Robotics and Autonomous Systems,The PoundCloud framework for ROS-based cloud robotics: Case studies on autonomous navigation and human?robot interaction,article,MELLO2022103981
"Complex manipulation tasks require careful integration of symbolic reasoning and motion planning. This problem, commonly referred to as Task and Motion Planning (TAMP), is even more challenging if the workspace is non-static, e.g. due to human interventions and perceived with noisy non-ideal sensors. This work proposes an online approximated TAMP method that combines a geometric reasoning module and a motion planner with a standard task planner in a receding horizon fashion. Our approach iteratively solves a reduced planning problem over a receding window of a limited number of future actions during the implementation of the actions. Thus, only the first action of the horizon is actually scheduled at each iteration, then the window is moved forward, and the problem is solved again. This procedure allows to naturally take into account potential changes in the scene while ensuring good runtime performance. We validate our approach within extensive experiments in a simulated environment. We showed that our approach is able to deal with unexpected changes in the environment while ensuring comparable performance with respect to other recent TAMP approaches in solving traditional static benchmarks. We release with this paper the open-source implementation of our method.","Task and Motion Planning, Robot manipulation, Non-static Environments",Nicola Castaman and Enrico Pagello and Emanuele Menegatti and Alberto Pretto,https://www.sciencedirect.com/science/article/pii/S0921889021001482,https://doi.org/10.1016/j.robot.2021.103863,0921-8890,2021,103863,145,Robotics and Autonomous Systems,Receding Horizon Task and Motion Planning in Changing Environments,article,CASTAMAN2021103863
"The use of robots has significantly increased to fight highly contagious diseases like SARS-COV-2, Ebola, MERS, and others. One of the important applications of robots to fight such infectious diseases is disinfection. Manual disinfection can be a time-consuming, risky, labor-intensive, and mundane, and humans may fail to disinfect critical areas due to the resulting fatigue. Autonomous or semi-autonomous mobile manipulators mounted with a spray nozzle at the end-effector can be very effective in spraying disinfectant liquid for deep disinfection of objects and surfaces. In this paper, we present an area-coverage planning algorithm to compute a path that the nozzle follows to disinfect surfaces represented by their point clouds. We project the point cloud on a plane and produce a polygon on which we generate multiple spray paths using our branch and bound-based tree search area-coverage algorithm such that the spray paths cover the entire area of the polygon. An appropriate spray path is chosen using a robot capability map-based selection criterion. We generate mobile manipulator trajectories using successive refinement-based parametric optimization so that the paths for the nozzle are followed accurately. Thereafter, we need to make sure that the joint velocities of the mobile manipulator are regulated appropriately such that each point on the surface receives enough disinfectant spray. To this end, we compute the time intervals between the robot path waypoints such that enough disinfectant liquid is sprayed on all points of the point cloud that results in thorough disinfection of the surface, and the particular robot path is executed in the minimum possible time. We have implemented the area-coverage planning and mobile manipulator motion planning on five test scenarios in simulation using our ADAMMS-SD (Agile Dexterous Autonomous Mobile Manipulation System for Surface Disinfection) robot. We benchmark our spray path generation algorithm with three competing methods by showing that the generated paths are significantly more efficient in terms of area coverage and reducing disinfectant wastage. We also show the time interval computation between successive waypoints results in thorough disinfection of surfaces.",,Shantanu Thakar and Rishi K. Malhan and Prahar M. Bhatt and Satyandra K. Gupta,https://www.sciencedirect.com/science/article/pii/S0921889021002050,https://doi.org/10.1016/j.robot.2021.103920,0921-8890,2022,103920,147,Robotics and Autonomous Systems,Area-Coverage Planning for Spray-based Surface Disinfection with a Mobile Manipulator,article,THAKAR2022103920
"This paper deals with multi-agent scenarios where individual agents must coordinate their plans in order to efficiently complete a set of tasks. Our strategy formulates the task planning problem as a potential game and uses decentralized stochastic sampling policies to reach a consensus on which sequences of actions agents should take. We execute this over a receding finite time horizon and take special care to discourage agents from breaking promises in the near future, which may cause other agents to unsuccessfully attempt a joint action. At the same time, we allow agents to change plans in the distant future, as this gives time for other agents to adapt their plans, allowing the team to escape locally optimal solutions. To do this we introduce two sampling schemes for new actions: a geometric-based scheme, where the probability of sampling a new action increases geometrically in time, and an inference-based sampling scheme, where a convolutional neural network provides recommendations for joint actions. We test the proposed schemes in a cooperative orienteering environment to illustrate their performance and validate the intuition behind their design.","Multi-agent planning, Potential games, Reinforcement learning, Simulated annealing",Aaron Ma and Mike Ouimet and Jorge Cortés,https://www.sciencedirect.com/science/article/pii/S0921889021001081,https://doi.org/10.1016/j.robot.2021.103823,0921-8890,2021,103823,143,Robotics and Autonomous Systems,Temporal sampling annealing schemes for receding horizon multi-agent planning,article,MA2021103823
"There are two challenges for wall-climbing robots in the maintenance and inspection of large vertical ferromagnetic structures: the requirement of high load capacity and the curved appearance of the wall. An improved magnetic crawler wall-climbing robot is presented in this paper. Without increasing the adhesion force, a load dispersion mechanism (LDM) is proposed to enhance the payload capacity of the crawler wall-climbing robot, through making full use of the magnetic adhesion force for resisting the overturning moment. Based on the passive independent suspension, a flexible connection scheme of the robot skeleton is proposed, that renders the wall-climbing robot move on the convex surface. Experiment results show that the magnetic crawler wall-climbing robot can move on the cylindrical wall whose curvature radius is 3000 mm. In motion, the robot can carry 75 kg payload. In the static state, the robot can afford 150 kg payload.","Wall-climbing robot, Magnetic crawler, High payload, Curved surface adaptivity",Junyu Hu and Xu Han and Yourui Tao and Shizhe Feng,https://www.sciencedirect.com/science/article/pii/S0921889021001925,https://doi.org/10.1016/j.robot.2021.103907,0921-8890,2022,103907,148,Robotics and Autonomous Systems,A magnetic crawler wall-climbing robot with capacity of high payload on the convex surface,article,HU2022103907
"This paper reports a feedback-based manoeuvre planning approach for automated nonprehensile selective micromanipulation of large, microscopic biological objects (?100?m). We employ ferromagnetic micro-particles as microrobots actuated via a global magnetic field produced by electromagnetic coils placed in quadrupole configuration. The microrobot motion is programmed to push the target object to the goal location. We employ a three-step approach comprising: (a) generate a collision-free optimal path between the initial and the commanded goal location, (b) generate a manoeuvre planning algorithm that invokes one of the three motion manoeuvres, namely, ?approach?, ?push?, and ?align? depending upon the instantaneous locations of the microrobot, target object, and the desired waypoint, and (c) deploy a simple proportional controller that determines the currents required in the electromagnetic coils that can produce a suitable magnetic field for executing the manoeuvre invoked by the manoeuvre planner. This paper reports a number of validation experiments conducted on both zebrafish, i.e., Danio rerio embryos and silica beads as target objects. We envisage that the developed inexpensive approach can be useful in robotic manipulation of biological objects with sizes in hundreds of microns including large biological cells, polyploid giant cancer cells (PGCC), multicellular spheroids, Dictyostelium slug, human oocytes, and autophagy candidates. We also believe that functionalizing the microrobots with living cells or suitable chemicals will make it possible to perform on-chip biological experiments in future.","Nonprehensile manipulation, Micromanipulation, Magnetic manipulation, Feedback planner, Path planner, Cell manipulation",Dharmveer Agarwal and Ajay D. Thakur and Atul Thakur,https://www.sciencedirect.com/science/article/pii/S0921889021002219,https://doi.org/10.1016/j.robot.2021.103941,0921-8890,2022,103941,148,Robotics and Autonomous Systems,A feedback-based manoeuvre planner for nonprehensile magnetic micromanipulation of large microscopic biological objects,article,AGARWAL2022103941
"Recovering after an abrupt push is essential for bipedal robots in real-world applications within environments where humans must collaborate closely with robots. There are several balancing algorithms for bipedal robots in the literature, however most of them either rely on hard coding or power-hungry algorithms. We propose a hybrid autonomous controller that hierarchically combines two separate, efficient systems, to address this problem. The lower-level system is a reliable, high-speed, full state controller that was hardcoded on a microcontroller to be power efficient. The higher-level system is a low-speed reinforcement learning controller implemented on a low-power onboard computer. While one controller offers speed, the other provides trainability and adaptability. An efficient control is then formed without sacrificing adaptability to new dynamic environments. Additionally, as the higher-level system is trained via deep reinforcement learning, the robot could learn after deployment, which is ideal for real-world applications. The system?s performance is validated with a real robot recovering after a random push in less than 5 s, with minimal steps from its initial positions. The training was conducted using simulated data.","Bipedal robot, Pattern generator, Reinforcement learning, Hybrid controller",Christos Kouppas and Mohamad Saada and Qinggang Meng and Mark King and Dennis Majoe,https://www.sciencedirect.com/science/article/pii/S0921889021001767,https://doi.org/10.1016/j.robot.2021.103891,0921-8890,2021,103891,146,Robotics and Autonomous Systems,Hybrid autonomous controller for bipedal robot balance with deep reinforcement learning and pattern generators,article,KOUPPAS2021103891
"The paper addresses the problem of multi-robot navigation in human shared spaces. We propose a hierarchical framework that combines global path planning, local path planning and reactive strategies, ensuring a safe and socially-aware navigation. We show through several tests and extensive experiments with a real robotic implementation that our combination of solutions delivers excellent results in terms of robustness and performance even in challenging natural scenarios.","Multi-robot navigation, Socially-aware navigation, Distributed systems",Manuel Boldrer and Alessandro Antonucci and Paolo Bevilacqua and Luigi Palopoli and Daniele Fontanelli,https://www.sciencedirect.com/science/article/pii/S092188902100244X,https://doi.org/10.1016/j.robot.2021.103979,0921-8890,2022,103979,149,Robotics and Autonomous Systems,Multi-agent navigation in human-shared environments: A safe and socially-aware approach,article,BOLDRER2022103979
"The paper proposes a heuristic-based prospective method to discover possible conflicts of shared control between humans and autonomous systems. This method adapts the triplet Competence-Availability-Possibility-to-act (CAP) that represents the autonomy characteristics of decision-makers such as humans or autonomous systems. The CAP-based autonomy is decomposed into several scenarios of shared control in a workspace or between workspaces. Conflicting decisions between humans and autonomous systems are conflicts of autonomy relating to competence, availability, or possibility to act and are determined by applying heuristics adapted from deductive, inductive, abductive, and counterfactual reasoning principles. This heuristic-based method comprises four main steps: verification of shared control, identification of discovery parameters, discovery of possible conflicting decisions, and validation of these conflicts. It was applied to a driving automation case study involving two autonomous systems: Lane Keeping Assist (LKA) and Automated Cruise Control (ACC). The conflicts of autonomy identified determine possible confusions between the reasoning of a driver and that of an autonomous system, sometimes resulting in dangerous situations. These were validated and analyzed in two ways by drivers with at least two years of driving experience: during an investigation to obtain qualitative feedback from 43 drivers and during a tutorial on human reliability assessment involving 17 people. The results demonstrate the advantage of the heuristic-based method to detect possible conflicting decisions or sources of conflicts between humans and machines. The approach proposed will consequently be of assistance in the design of shared control processes between humans and autonomous systems through the implementation of technical learning or pedagogical abilities, the improvement of alarm systems to control human attention or avoid confusion between the intentions of humans and machines, or the development of training programs or driving lessons to increase user awareness of such conflicts.","Shared control, Level of autonomy, Conflicting decision, Autonomous system, Car driving, Heuristics",Frédéric Vanderhaegen,https://www.sciencedirect.com/science/article/pii/S0921889021001524,https://doi.org/10.1016/j.robot.2021.103867,0921-8890,2021,103867,146,Robotics and Autonomous Systems,Heuristic-based method for conflict discovery of shared control between humans and autonomous systems - A driving automation case study,article,VANDERHAEGEN2021103867
"This paper is concerned with the presentation of a parallel compliance adaptation method for systems equipped with rotary motion mechanisms towards obtaining energy efficiency in cyclic tasks over a reasonable range of task frequency variations. In this work, we first introduce a variable parallel elastic actuator (VPEA) design for implementation on uni-directional joints that can respond in line with the torque requirements caused by frequency variations in rotary mechanisms. Then, in the next step, we propose two design approaches namely ?general method? and ?frequency-based method? for the VPEA along with the stiffness adjustment approaches both in offline and online manners. The optimality and convergence of the adaptation method for the proposed rotary VPEA are also analytically proved in general to be globally exponentially stable in the sense of Lyapunov. Finally, to demonstrate the applicability and efficiency of our VPEA, we deployed it in a robotic leg model as the case study. The simulation results demonstrate the stability and convergence of our adaptation rule and highlight the performance of the proposed VPEA in increasing energy efficiency over a wide range of task frequency variations.","Compliant actuation, Variable elastic actuator, Adaptation, Energy efficiency, Legged locomotion",Omid Mohseni and Majid Abedinzadeh Shahri and Ayoob Davoodi and Majid Nili Ahmadabadi,https://www.sciencedirect.com/science/article/pii/S0921889021001007,https://doi.org/10.1016/j.robot.2021.103815,0921-8890,2021,103815,143,Robotics and Autonomous Systems,Adaptation in a variable parallel elastic actuator for rotary mechanisms towards energy efficiency,article,MOHSENI2021103815
"Trajectory tracking of an unmanned ground vehicle (UGV) is essential due to its extensive construction, agriculture, and military applications. In this paper, we propose an efficient, robust model predictive control (RMPC) for the trajectory tracking of a small-scale autonomous bulldozer in the presence of perturbations by unknown but bounded disturbances. The proposed RMPC is designed by considering a linearised tracking error-based model combined with a feed-forward and optimal control action to achieve the proposed trajectory. The presence of a corrective feedback controller as a time-varying finite-time linear quadratic regulator (LQR) suppresses the uncertainties acting on the real system by regulating around the nominal system. Pose estimation, required for control feedback, is based on sensor data fusion performed by an extended Kalman filter (EKF) map-based localiser, which processes inertial measurement unit (IMU) and light detection and ranging (LiDAR) measurements. Experiments are performed using a real robot (Husky A200) to validate the proposed control scheme?s performance. The experimental results show that the proposed controller can safely track target trajectories with low processing time, small tracking errors, and smooth control actions. Finally, the proposed control scheme is compared with related techniques and outperforms them in tracking accuracy.","Small-scale autonomous bulldozer, Optimal control, Model predictive control, Trajectory tracking, Unmanned ground vehicle",Subhan Khan and Jose Guivant and Xuesong Li,https://www.sciencedirect.com/science/article/pii/S0921889021001883,https://doi.org/10.1016/j.robot.2021.103903,0921-8890,2022,103903,147,Robotics and Autonomous Systems,Design and experimental validation of a robust model predictive control for the optimal trajectory tracking of a small-scale autonomous bulldozer,article,KHAN2022103903
"This paper presents a collision avoidance algorithm for stabilized gun turrets and its real-time implementation. With the help of new collision avoidance algorithm, all types of turrets can be driven more efficiently and safely according to the specified speed, acceleration and jerk limits. Even in situations such as avoiding obstacles, deceleration/acceleration, if the user issues new commands which does not cause a collision, the algorithm starts to apply the new commands providing flexibility to the user. Since all possible worst scenarios are examined one by one, it is guaranteed that the algorithm provides collision free motion in both simulations and real-time tests. A configuration space where worst scenarios can occur is created for the performance measurement of the algorithm, and the same space is used in all tests. By giving different speed commands in the specified configuration space, the performance of the algorithm at different speeds is observed on the stabilized gun turret. For the measurement of the performance under the noisy speed commands, a custom noisy speed command of about 1000 s is created and both simulation and real-time tests are performed. As a result of these tests, it is shown that there is no collision. Finally, by adding cascade position control loop, the departure from the starting point to the desired target point is achieved without any collision. The most important feature that distinguishes this algorithm from others is both speed and position can be controlled and during transition phase, the target point can be changed instantly. In addition, no target position is required for the system to move collision-free, only axis speed commands are sufficient. Since the algorithm does not intervene in the speed and torque loops in contrast to potential field-based methods, it can be added to ready-to-use systems by manipulating only the speed references.","Collision avoidance, End control damping algorithm, Path planning, Stabilized gun turrets, Autonomous turrets, C-space",Ümit Yerlikaya and R. Tuna Balkan,https://www.sciencedirect.com/science/article/pii/S0921889021001123,https://doi.org/10.1016/j.robot.2021.103827,0921-8890,2021,103827,143,Robotics and Autonomous Systems,End control damping algorithm for a stabilized gun turret system for the satisfaction of the collision avoidance requirement,article,YERLIKAYA2021103827
"Active exoskeletons can help adults with muscular dystrophy regain independence and self-esteem, which have been limited due to their severe and progressive muscular weakness. A four degrees-of-freedom fully actuated upper limb exoskeleton, equipped with a spring-based anti-gravity system, has been designed, prototyped, and tested on end-users. While wearing the exoskeleton, the user directly controls the system by actively driving the end-effector position (i.e., the hand) using a joystick or vocal control. The exoskeleton?s kinematic model has been determined so that, given a desired user?s position in the task-space, a differential inverse kinematics algorithm computes the desired joint-space motion trajectories. The dynamic model was investigated in the vertical plane, demonstrating that gravity torques were considerably higher than velocity-induced and inertia torques, which have been therefore neglected. A pilot study on 14 Muscular Dystrophy patients was conducted. Outcome measures included: (i) externally-assessed functional benefit evaluated through the Performance of Upper Limbs module, (ii) self-perceived functional benefit assessed through the ABILHAND questionnaire, and (iii) usability of the system assessed through the System Usability Scale. All participants strongly increased their range of motion, and they were able to perform activities that were not possible without the exoskeleton, such as feeding. The externally-assessed and self-perceived functional improvements were statistically improved when wearing the exoskeleton (PUL p-value=0.001, ABILHAND p-value=0.005). System usability was evaluated to be excellent. Patients? feedbacks were encouraging and outlined future development steps.","Exoskeleton, Assistive devices, Robotics, Biomechatronics, Multi-modal interfaces, Joystick, Upper limbs, Muscular dystrophy, Neuromuscular disease",Marta Gandolla and Stefano Dalla Gasperina and Valeria Longatelli and Alessandro Manti and Lorenzo Aquilante and Maria Grazia D?Angelo and Emilia Biffi and Eleonora Diella and Franco Molteni and Mauro Rossini and Margit Gföhler and Markus Puchinger and Marco Bocciolone and Francesco Braghin and Alessandra Pedrocchi,https://www.sciencedirect.com/science/article/pii/S092188902100107X,https://doi.org/10.1016/j.robot.2021.103822,0921-8890,2021,103822,143,Robotics and Autonomous Systems,An assistive upper-limb exoskeleton controlled by multi-modal interfaces for severely impaired patients: development and experimental assessment,article,GANDOLLA2021103822
"Building on the maturity of single-robot SLAM algorithms, collaborative SLAM has brought significant gains in terms of efficiency and robustness, but has also raised new challenges to cope with like informational, network and resource constraints. Several multi-robot frameworks have been coined for visual SLAM, ranging from highly-integrated and fully-centralized architectures to fully distributed and decentralized methods. However, many proposed architectures compromise the autonomy of the robots in fusing the data processed by the other agents to enhance their own estimation accuracy. In this paper, we propose three methods to share visual-inertial information, based on rigid, condensed and pruned visual-inertial packets. We also propose a common collaborative SLAM architecture to organize the computation, exchange and integration of such packets. We evaluated those methods on the EuRoC (Burri et al. 2016) dataset and on our custom dataset AirMuseum (Dubois et al. 2020). Experiments showed that the proposed methods allow the agents to build, exchange and integrate consistent visual-inertial packets, and improve their trajectory estimation accuracy up to several centimeters.","Robotics, Visual-inertial collaborative SLAM",Rodolphe Dubois and Alexandre Eudes and Vincent Frémont,https://www.sciencedirect.com/science/article/pii/S0921889021002177,https://doi.org/10.1016/j.robot.2021.103933,0921-8890,2022,103933,148,Robotics and Autonomous Systems,Sharing visual-inertial data for collaborative decentralized simultaneous localization and mapping,article,DUBOIS2022103933
"With the rapid development of intelligent systems, such as self-driving vehicles, service robots and surveillance systems, pedestrian trajectory prediction has become a very challenging problem. How to perceive, understand and predict the motion patterns of pedestrians in a highly crowded and chaotic environment in order to prevent future collisions becomes a top priority. The motion of pedestrians is not only affected by their own factors, but also by surrounding neighbors. To solve the above problems, we propose a model named PTPGC based on graph attention and convolutional long short-term memory (ConvLSTM) network to predict multiple reasonable pedestrian trajectories. Firstly, the pedestrians are represented in a dynamic graph by setting a Euclidean distance threshold. Then, a graph attention network is used to learn the spatial interaction relationship of all pedestrians in each time step, and a temporal convolutional network (TCN) is used to encode the pedestrians? own factors. Finally, we use the ConvLSTM to iteratively predict the multiple reasonable and feasible future trajectories of pedestrians. Experiments show that our model has a higher prediction accuracy on two public pedestrian data sets (ETH and UCY) compared with the existing baselines for pedestrian trajectory prediction, and the generated trajectories are more in line with social rationality and physical constraints.","Trajectory prediction, Graph attention, ConvLSTM, Multimodal",Juan Yang and Xu Sun and Rong Gui Wang and Li Xia Xue,https://www.sciencedirect.com/science/article/pii/S0921889021002165,https://doi.org/10.1016/j.robot.2021.103931,0921-8890,2022,103931,148,Robotics and Autonomous Systems,PTPGC: Pedestrian trajectory prediction by graph attention network with ConvLSTM,article,YANG2022103931
"We conducted a literature review on sensor heads for humanoid robots. A strong case is made on topics involved in human?robot interaction. Having found that vision is the most abundant perception system among sensor heads for humanoid robots, we included a review of control techniques for humanoid active vision. We provide historical insight and inform on current robotic head design and applications. Information is chronologically organized whenever possible and exposes trends in control techniques, mechanical design, periodical advances and overall philosophy. We found that there are two main types of humanoid robot heads which we propose to classify as either non-expressive face robot heads or expressive face robot heads. We expose their respective characteristics and provide some ideas on design and vision control considerations for humanoid robot heads involved in human?robot interactions.","Humanoid robot heads, Human?robot interaction, Review, Control of robotic systems, Active vision",J.A. Rojas-Quintero and M.C. Rodríguez-Liñán,https://www.sciencedirect.com/science/article/pii/S0921889021001196,https://doi.org/10.1016/j.robot.2021.103834,0921-8890,2021,103834,143,Robotics and Autonomous Systems,A literature review of sensor heads for humanoid robots,article,ROJASQUINTERO2021103834
"Semantic segmentation is a crucial task in emerging robotic applications like autonomous driving and social robotics. State-of-the-art methods in this field rely on deep learning, with several works in the literature following the trend of using larger networks to achieve higher performance. However, this leads to greater model complexity and higher computational costs, which make it difficult to integrate such models on mobile robots. In this work we investigate how it is possible to obtain lighter performing deep models introducing additional data at a very low computational cost, instead of increasing the network complexity. We consider the features used in the 3D Entangled Forests algorithm, proposing different strategies to integrate such additional information into different deep networks. The new features allow to obtain lighter and performing segmentation models, either by shrinking the network size or improving existing networks proposed for real-time segmentation. Such result represents an interesting alternative in mobile robotics application, where computational power and energy are limited.","Semantic segmentation, Scene understanding, Deep learning",Matteo Terreran and Stefano Ghidoni,https://www.sciencedirect.com/science/article/pii/S0921889021001470,https://doi.org/10.1016/j.robot.2021.103862,0921-8890,2021,103862,146,Robotics and Autonomous Systems,Light deep learning models enriched with Entangled features for RGB-D semantic segmentation,article,TERRERAN2021103862
"In this study, a bioinspired multi-finger robot system (MFRS) is designed based on the characteristics of eagle claws. The MFRS is attached to a rotary-wing unmanned aerial vehicle (RUAV), which can be enabled to land on uneven terrain. In addition, the robot can also grab target objects or perch on a cylinder. The finger of the robot can simultaneously rotate three revolute joints only relying on one motor, to achieve an action similar to the grip of the eagle claw. The hardware structure and control system architecture of the MFRS are established. Based on depth vision, an adaptive landing algorithm that can achieve real-time optimal landing point selection is proposed. The outdoor experiments show that the robot can effectively land the RUAV on the slopes, steps, and unstructured terrains.","Multi-finger robot system, Bioinspired design, Rotary-wing UAV, Adaptive landing",Jian Liu and Dan Zhang and Chenwei Wu and Hongyan Tang and Chunxu Tian,https://www.sciencedirect.com/science/article/pii/S0921889021001639,https://doi.org/10.1016/j.robot.2021.103878,0921-8890,2021,103878,146,Robotics and Autonomous Systems,A multi-finger robot system for adaptive landing gear and aerial manipulation,article,LIU2021103878
"Natural rubber latex is an important energy material. However, the harvest of latex is still manual, and there are few researches on automatic work. This paper proposed a method for robot to harvest from each rubber tree without stopping. The robot toggled the collection cup through the flexible actuator, the cup poured out the latex and rotated to the next collection position. In this way, it not only completed the harvest work, but also prepared for the next collection. Aiming at the problem of latex splashing during rapid toggle, the structural parameters of the collection cup and the flexible actuator were modeled and studied. This method made the rotation speed of the collection cup smoother and avoids splashing. To enable the robot to accurately complete the harvesting work, this paper used two-dimensional Light Detection and Ranging (LiDAR) and ranging sensor to locate the space position of the collection cup. The results show that when the toggle speed is 0.5 m/s and the latex volume is 300 ml, the average shaking height is 3.58 mm. In the field test, the lateral error of positioning is less than 8.86 mm, and the height error is less than 0.72 mm; the average harvest rate is 98.18%. The robot has high efficiency and good stability, and can be applied to the rubber plantation to harvest automatically.","Agricultural robotics, Natural rubber, Spillage-free harvesting, Latex harvesting, Dynamic model",Song Wang and Hang Zhou and Chunlong Zhang and Luzhen Ge and Wei Li and Ting Yuan and Wenqiang Zhang and Junxiong Zhang,https://www.sciencedirect.com/science/article/pii/S0921889021001913,https://doi.org/10.1016/j.robot.2021.103906,0921-8890,2022,103906,147,Robotics and Autonomous Systems,"Design, development and evaluation of latex harvesting robot based on flexible Toggle",article,WANG2022103906
"Robotic picking of diverse range of novel objects is a great challenge in dense clutter, in which objects are stacked together tightly. However, collecting large-scale dataset with dense grasp labels is extremely time-consuming, and there is a huge gap between synthetic and real images. In this paper, we explore suction based grasping from synthetic multi object rendering. To avoid tedious human labeling, we present a pipeline to model stacked objects in simulation and generate photorealistic rendering RGB-D images with dense suction point labels. To reduce simulation-to-reality gap from synthetic images to low-quality RGB-D camera, we propose a novel domain-invariant Suction Quality Neural Network (diSQNN) by training on labeled synthetic dataset with unlabeled real dataset. Specifically, diSQNN fuses photorealistic color feature and adversarial depth feature, and uses a domain discriminator on depth extractor to align depth feature distribution from synthetic and real images. We evaluate our proposed method by comparing with other baseline and suction detection method. The results demonstrate the effectiveness of our synthetic dense cluttered rendering. And through feature alignment, our domain invariant learning method can learn grasp related features, while ignoring domain related disturbing features, which maintains a high transfer performance on real RGB-D images. On a physical robot with vacuum-based gripper, the proposed method achieves average picking success rate of 91% and 88% for known objects and novel objects in a tote without using any manual labels.","Robotic picking, Sim2real, Dense clutter, Domain invariant, Deep learning",Wenhai Liu and Weiming Wang and Yang You and Teng Xue and Zhenyu Pan and Jin Qi and Jie Hu,https://www.sciencedirect.com/science/article/pii/S092188902100186X,https://doi.org/10.1016/j.robot.2021.103901,0921-8890,2022,103901,147,Robotics and Autonomous Systems,Robotic picking in dense clutter via domain invariant learning from synthetic dense cluttered rendering,article,LIU2022103901
"This article describes a novel approach to expand in run-time the knowledge base of an Artificial Conversational Agent. A technique for automatic knowledge extraction from the user?s sentence and four methods to insert the new acquired concepts in the knowledge base have been developed and integrated into a system that has already been tested for knowledge-based conversation between a social humanoid robot and residents of care homes. The run-time addition of new knowledge allows overcoming some limitations that affect most robots and chatbots: the incapability of engaging the user for a long time due to the restricted number of conversation topics. The insertion in the knowledge base of new concepts recognized in the user?s sentence is expected to result in a wider range of topics that can be covered during an interaction, making the conversation less repetitive. Two experiments are presented to assess the performance of the knowledge extraction technique, and the efficiency of the developed insertion methods when adding several concepts in the Ontology.","Social robotics, Human?robot interaction, Knowledge-grounded conversation, Knowledge extraction",Lucrezia Grassi and Carmine Tommaso Recchiuto and Antonio Sgorbissa,https://www.sciencedirect.com/science/article/pii/S0921889021002207,https://doi.org/10.1016/j.robot.2021.103938,0921-8890,2022,103938,148,Robotics and Autonomous Systems,"Knowledge triggering, extraction and storage via human?robot verbal interaction",article,GRASSI2022103938
"Robotic odor source localization (OSL) has been viewed as a challenging task due to the turbulent nature of airflows and the resulting odor plume characteristics. The key to solving an OSL problem is designing an effective olfactory-based navigation algorithm, which guides a plume-tracing robot to find the odor source via tracing emitted plumes. Inspired by the mate-seeking behaviors of male moths, this article presents a behavior-based navigation algorithm for using on a mobile robot to locate an odor source in an unknown environment. Unlike traditional bio-inspired algorithms, which use fixed parameters to formulate robot search trajectories, we design a fuzzy controller to perceive the environment and adjust trajectory parameters based on the current search situation. Therefore, the robot can automatically adapt the scale of search trajectories to fit environmental changes and balance the exploration and exploitation of the search. Simulation and on-vehicle results show that compared to two classical olfactory-based navigation algorithms, the proposed algorithm is more efficient and outperforms them in terms of the averaged search time and success rate.","Odor source localization, Behavior-based navigation methods, Fuzzy-inference theories",Lingxiao Wang and Shuo Pang,https://www.sciencedirect.com/science/article/pii/S0921889021001998,https://doi.org/10.1016/j.robot.2021.103914,0921-8890,2022,103914,147,Robotics and Autonomous Systems,Robotic odor source localization via adaptive bio-inspired navigation using fuzzy inference methods,article,WANG2022103914
"Telepresence robots empower human operators to navigate remote environments. However, operating and navigating the robot in an unknown environment is challenging due to delay in the communication network (e.g., distance, bandwidth, communication drop-outs etc.), processing delays and slow dynamics of the mobile robots resulting in time-lagged in the system. Also, erroneous sensor data measurement which is important to estimate the robot?s true state (positional information) in the remote environment, often create complications and make it harder for the system to control the robot. In this paper, we propose a new approach for state estimation assuming uncertain delayed sensor measurements of a Telepresence robot during navigation. A new real world experimental model, based on Augmented State Extended Kalman Filter (AS-EKF), is proposed to estimate the true position of the Telepresence robot. The uncertainty of the delayed sensor measurements have been modelled using probabilistic density functions (PDF). The proposed model was successfully verified in our proposed experimental framework which consists of a state-of-the-art differential-drive Telepresence robot and a motion tracking multi-camera system. The results show significant improvements compared to the traditional EKF that does not consider uncertain delays in sensor measurements. The proposed model will be beneficial to build a real time predictive display by reducing the effect of visual delay to navigate the robot under the operator?s control command, without waiting for delayed sensor measurements.","State estimation, Delay compensation, Telepresence, Robot navigation, AS-EKF",Barnali Das and Gordon Dobie,https://www.sciencedirect.com/science/article/pii/S0921889021001755,https://doi.org/10.1016/j.robot.2021.103890,0921-8890,2021,103890,146,Robotics and Autonomous Systems,Delay compensated state estimation for Telepresence robot navigation,article,DAS2021103890
"The mirror test is a well-known task in Robotics. The existing strategies are based on kinesthetic-visual matching techniques and manipulate perceptual and motion data. The proposed work attempts to demonstrate that it is possible to implement a robust robotic self-recognition method by the inner speech, i.e. the self-dialogue that enables reasoning on symbolic information. The robot self-talks and conceptually reasons on the symbolic forms of signals, and infers if the robot it sees in the mirror is itself or not. The idea is supported by the existing literature in psychology, where the importance of inner speech in self-reflection and self-concept emergence for solving the mirror test was empirically demonstrated.","Inner speech, Cognitive architecture, Robot mirror test, Conceptual reasoning",Arianna Pipitone and Antonio Chella,https://www.sciencedirect.com/science/article/pii/S0921889021001238,https://doi.org/10.1016/j.robot.2021.103838,0921-8890,2021,103838,144,Robotics and Autonomous Systems,Robot passes the mirror test by inner speech,article,PIPITONE2021103838
"Efficiently coordinating different types of robots is an important enabler for many commercial and industrial automation tasks. Here, we present a distributed framework that enables a team of heterogeneous robots to dynamically generate actions from a common, user-defined goal specification. In particular, we discuss the integration of various robotic capabilities into a common task allocation and planning formalism, as well as the specification of expressive, temporally-extended goals by non-expert users. Models for task allocation and execution both consider non-deterministic outcomes of actions and thus, are suitable for a wide range of real-world tasks including formally specified reactions to online observations. One main focus of our paper is to evaluate the framework and its integration of software modules through a number of experiments. These experiments comprise industry-inspired scenarios as motivated by future real-world applications. Finally, we discuss the results and learnings for motivating practically relevant, future research questions.","Robotics, Multi-robot, Temporal logic, HRI, Heterogeneous robots, Task decomposition, Task allocation, Abstraction",Philipp Schillinger and Sergio García and Alexandros Makris and Konstantinos Roditakis and Michalis Logothetis and Konstantinos Alevizos and Wei Ren and Pouria Tajvar and Patrizio Pelliccione and Antonis Argyros and Kostas J. Kyriakopoulos and Dimos V. Dimarogonas,https://www.sciencedirect.com/science/article/pii/S0921889021001512,https://doi.org/10.1016/j.robot.2021.103866,0921-8890,2021,103866,145,Robotics and Autonomous Systems,Adaptive heterogeneous multi-robot collaboration from formal task specifications,article,SCHILLINGER2021103866
"Coexisting with the current COVID-19 pandemic is a global reality that comes with unique challenges impacting daily interactions, business, and facility maintenance. A monumental challenge accompanied is continuous and effective disinfection of shared spaces, such as office/school buildings, elevators, classrooms, and cafeterias. Although ultraviolet light and chemical sprays are routines for indoor disinfection, they irritate humans, hence can only be used when the facility is unoccupied. Stationary air filtration systems, while being irritation-free and commonly available, fail to protect all occupants due to limitations in air circulation and diffusion. Hence, we present a novel collaborative robot (cobot) disinfection system equipped with a Bernoulli Air Filtration Module, with a design that minimizes disturbance to the surrounding airflow and maneuverability among occupants for maximum coverage. The influence of robotic air filtration on dosage at neighbors of a coughing source is analyzed with derivations from a Computational Fluid Dynamics (CFD) simulation. Based on the analysis, the novel occupant-centric online rerouting algorithm decides the path of the robot. The rerouting ensures effective air filtration that minimizes the risk of occupants under their detected layout. The proposed system was tested on a 2 × 3 seating grid (empty seats allowed) in a classroom, and the worst-case dosage for all occupants was chosen as the metric. The system reduced the worst-case dosage among all occupants by 26% and 19% compared to a stationary air filtration system with the same flow rate, and a robotic air filtration system that traverses all the seats but without occupant-centric planning of its path, respectively. Hence, we validated the effectiveness of the proposed robotic air filtration system.","Robotic air filtration, Socially-distanced classrooms, Approximation of computational fluid dynamics, Trajectory and speed optimization",Haoguang Yang and Mythra V. Balakuntala and Jhon J. Quiñones and Upinder Kaur and Abigayle E. Moser and Ali Doosttalab and Antonio Esquivel-Puentes and Tanya Purwar and Luciano Castillo and Xin Ma and Lucy T. Zhang and Richard M. Voyles,https://www.sciencedirect.com/science/article/pii/S0921889021002049,https://doi.org/10.1016/j.robot.2021.103919,0921-8890,2022,103919,147,Robotics and Autonomous Systems,Occupant-centric robotic air filtration and planning for classrooms for Safer school reopening amid respiratory pandemics,article,YANG2022103919
"The objective of this study is improving the location estimate of a mobile robot capable of motion on a plane and mounted with a conventional 2D LIDAR sensor, given an initial guess for its location on a 2D map of its surroundings. Documented herein is the theoretical reasoning behind solving a matching problem between two homoriented 2D scans, one derived from the robot?s physical sensor and one derived by simulating its operation within the map, in a manner that does not require the establishing of correspondences between their constituting rays. Two results are proved and subsequently shown through experiments. The first is that the true position of the sensor can be recovered with arbitrary precision when the physical sensor reports faultless measurements and there is no discrepancy between the environment the robot operates in and its perception of it by the robot. The second is that when either is affected by disturbance, the location estimate is bound in a neighbourhood of the true location whose radius is proportional to the affecting disturbance.","Robot localisation, Scan-to-map-scan matching",Alexandros Filotheou,https://www.sciencedirect.com/science/article/pii/S0921889021002323,https://doi.org/10.1016/j.robot.2021.103957,0921-8890,2022,103957,149,Robotics and Autonomous Systems,Correspondenceless scan-to-map-scan matching of homoriented 2D scans for mobile robot localisation,article,FILOTHEOU2022103957
"Since the dynamic nature of human?robot interaction becomes increasingly prevalent in our daily life, there is a great demand for enabling the robot to better understand human personality traits and inspiring humans to be more engaged in the interaction with the robot. Therefore, in this work, as we design the paradigm of human?robot interaction as close to the real situation as possible, the following three main problems are addressed: (1) fusion of visual and audio features of human interaction modalities, (2) integration of variable length feature vectors, and (3) compensation of shaky camera motion caused by movements of the robot?s communicative gesture. Specifically, the three most important visual features of humans including head motion, gaze, and body motion were extracted from a camera mounted on the robot performing verbal and body gestures during the interaction. Then, our system was geared to fuse the aforementioned visual features and different types of vocal features, such as voice pitch, voice energy, and Mel-Frequency Cepstral Coefficient, dealing with variable length multiple feature vectors. Lastly, considering unknown patterns and sequential characteristics of human communicative behavior, we proposed a multi-layer Hidden Markov Model that improved the classification accuracy of personality traits and offered notable advantages of fusing the multiple features. The results were thoroughly analyzed and supported by psychological studies. The proposed multi-modal fusion approach is expected to deepen the communicative competence of social robots interacting with humans from different cultures and backgrounds.","Human?robot interaction, Human personality traits, Multi-modal feature fusion, Machine learning",Zhihao Shen and Armagan Elibol and Nak Young Chong,https://www.sciencedirect.com/science/article/pii/S0921889021001597,https://doi.org/10.1016/j.robot.2021.103874,0921-8890,2021,103874,146,Robotics and Autonomous Systems,Multi-modal feature fusion for better understanding of human personality traits in social human?robot interaction,article,SHEN2021103874
"This work considers the problem of chaotic path planning, using an improved memory technique to boost performance. In this application, the dynamics of two simple chaotic maps are first used to generate a pseudo-random bit generator. Using this as a source, a series of navigation commands are generated and used by an autonomous robot to explore an area, while maintaining a random and unpredictable motion. This navigation strategy can bring overall area coverage, but also yields numerous revisits to previous cells. Here, a memory technique is applied to limit the chaotic motion of the robot to adjacent cells with the least number of visits, leading to overall improvement in performance. Numerical simulations are performed to evaluate the path planning strategy. The simulation results showcase a major improvement in coverage performance compared to the memory-free technique and also compared to an inverse pheromone technique previously developed by the authors. Also, the number of multiple visits to previous cells is significantly reduced with the proposed technique.","Autonomous mobile robot, Path planning, Terrain coverage, Chaos, PRBG, Memory, Optimization",Eleftherios Petavratzis and Lazaros Moysis and Christos Volos and Ioannis Stouboulos and Hector Nistazakis and Kimon Valavanis,https://www.sciencedirect.com/science/article/pii/S0921889021001111,https://doi.org/10.1016/j.robot.2021.103826,0921-8890,2021,103826,143,Robotics and Autonomous Systems,A chaotic path planning generator enhanced by a memory technique,article,PETAVRATZIS2021103826
"In this paper, a novel approach for autonomously catching fast flying objects is presented, as inspired by the Mohamed Bin Zayed International Robotics Challenge (MBZIRC) 2020. In this competition, an autonomous Unmanned Aerial Vehicle (UAV) was used to intercept a ball carried by a fast flying drone. The presented solution utilizes a 3D LiDAR sensor for quick and robust target detection. The trajectory of the target is estimated and predicted to select a suitable interception position. The interceptor UAV is navigated into the interception position to safely approach the target. The interception position is frequently being adjusted based on the updated estimation and prediction of the target?s motion to ensure that the ball is caught in the dedicated onboard net. After a successful interception is detected, the UAV lands in a designated landing area. The proposed concept was intensively tested and refined in demanding outdoor conditions with strong winds and varying perception conditions to achieve the robustness required by both the demanding application and the competition. In the MBZIRC 2020 competition, our solution scored second place in Challenge 1 and first place in a combined Grand Challenge. This manuscript will provide a detailed description of the applied methods and an evaluation of our approach with data collected from real-world experiments. In addition, we present achievements of our R&D towards the transition from the MBZIRC competition to an autonomous drone interceptor, which was the main motivation of this challenge.","Unmanned aerial systems, Machine perception, Mobile robotics, Aerial safety",Matou? Vrba and Yurii Stasinchuk and Tomá? Bá?a and Vojt?ch Spurný and Mat?j Petrlík and Daniel He?t and David ?aitlík and Martin Saska,https://www.sciencedirect.com/science/article/pii/S0921889021002396,https://doi.org/10.1016/j.robot.2021.103970,0921-8890,2022,103970,149,Robotics and Autonomous Systems,Autonomous capture of agile flying objects using UAVs: The MBZIRC 2020 challenge,article,VRBA2022103970
"In this paper, we present a reconfiguration algorithm for shape-shifting modular robots with a triangular structure. The algorithm is derived from a novel description of the configuration space based on extended binary trees. Extended binary trees representing the same configuration are grouped into equivalence classes, which allows for a one-to-one correspondence between a configuration and its mathematical representation. Reconfiguration is then accomplished by a successive construction of the goal configuration, realized by moving individual modules along the surface of the robot and building up the binary tree of the goal configuration by populating unoccupied binary tree indices in ascending order with new modules. The algorithm is capable of solving the self-reconfiguration problem for modular robots with a triangular structure in O(n2) reconfiguration steps and is demonstrated on two reconfiguration examples. We then discuss the limits of the proposed methods, regarding constraints on the implementation and the lack of efficient collision avoidance, and outline possible resolutions.","Extended binary trees, Self-reconfiguration, Modular robots, Triangular modules",Michael Gerbl and Johannes Gerstmayr,https://www.sciencedirect.com/science/article/pii/S0921889021002153,https://doi.org/10.1016/j.robot.2021.103930,0921-8890,2022,103930,147,Robotics and Autonomous Systems,Self-reconfiguration of shape-shifting modular robots with triangular structure,article,GERBL2022103930
"The World Health Organization (WHO) reported that more than 1 billion people live with some form of disability. Moreover, the number of elderly is increasing in recent years. According to the United Nations (UN), in 2050, there will be 2.1 billion people above 60 years of age worldwide. Many of these people live alone in their homes or clinics and rely on some kind of help to fulfill their specific needs. In this context, emerging opportunities for the application of robotics to support ubiquitous healthcare may reflect in reducing medical costs and increasing the convenience of patients and people in general. This paper presents a systematic mapping study to identify the application of service robots in the assistance of human care, focusing on the employment of computational technologies and unexplored research gaps in the literature. The study conducted searches in eight scientific repositories in the area of service robots through a systematic filtering process to remove bias. Afterward, the filtering process allowed to reduce from an initial sample of 9372 to 69 studies. As a result, these studies were reviewed entirely, analyzed, and categorized to answer six research questions. In addition, the study proposed four taxonomies illustrating the state-of-the-art of robotics in human care. The results highlight therapy and entertainment as the most common categories of the usage of robotics in human care. The most widely-used technologies to integrate with smart environments are smartphone sensors, smart device integration, wearables, and cloud services. The most frequently used mean of human?robot interaction is verbal communication, which is useful to help the elderly, children, and people with a mental health disorder. The most commonly cited diseases were cognition impairment, autism spectrum disorder, and motor impairment. Finally, we observed a trend in the growth of the use of service robots to improve the intelligence of the environment supporting human care. The scientific contribution of this article are four taxonomies that classify and group caregiver robots according to the application, integration with a smart environment, human?robot interaction, and target audience. This study also allowed the learning of 11 lessons on methodological and technological aspects based on the profound research performed.","Caregiver robot, Human caregiver, Assistive robot, Service robot, Cognitive impairment, Systematic mapping study",Nícolas B. Santos and Rodrigo S. Bavaresco and João E.R. Tavares and Gabriel de O. Ramos and Jorge L.V. Barbosa,https://www.sciencedirect.com/science/article/pii/S0921889021001184,https://doi.org/10.1016/j.robot.2021.103833,0921-8890,2021,103833,144,Robotics and Autonomous Systems,A systematic mapping study of robotics in human care,article,SANTOS2021103833
"The brightness constancy assumption is the cornerstone of direct or semi-direct visual odometry (VO) and visual simultaneous localization and mapping (SLAM). However, due to the existence of automatic exposure time, nonlinear camera response function, and vignetting, this assumption is difficult to hold in practical applications. Therefore, the corresponding algorithm performs poorly on arbitrary video sequences and uncalibrated cameras. Hence, we propose a novel constant intensity semi-direct visual-inertial odometry (VIO) integrated with online photometric calibration, which combines the exactness of the feature-based method and the quickness of the direct method. We combine gain-adaptive direct image alignment and gain-adaptive Kanade?Lucas?Tomasi (KLT) optical flow tracking to complete the feature matching and use it as the input for the back-end optimization and online photometric calibration. Our photometric calibration module can complete the estimation of all photometric parameters without any prior knowledge and cooperate with the front-end to complete the real-time photometric calibration of the latest frame. Experiments on the TUM Mono VO dataset, EuRoC dataset, and real environments prove that the algorithm can reliably calibrate the photometric parameters of an arbitrary video sequence. The semi-direct VIO algorithm integrated with the photometric calibration algorithm achieves a good balance between speed, accuracy, and robustness.","The brightness constancy assumption, Semi-direct VIO, Online photometric calibration",Quanpan Liu and Zhengjie Wang and Huan Wang,https://www.sciencedirect.com/science/article/pii/S0921889021001627,https://doi.org/10.1016/j.robot.2021.103877,0921-8890,2021,103877,146,Robotics and Autonomous Systems,PC-SD-VIO: A constant intensity semi-direct monocular visual-inertial odometry with online photometric calibration,article,LIU2021103877
"This paper tackles a class of multi-robot task allocation (MRTA) problems called ?Single-Task Robots and Single-Robot Tasks? or SR?ST problems, subject to the following additional characteristics: tasks with deadlines, tasks that are generated during the mission, and robots with range and payload constraints (thus requiring multiple tours per robot). While these characteristics are typical of various disaster response and commercial applications, there is a lack of online MRTA solutions to address them. To solve this class of complex MRTA problems, an efficient online method (which is also suitable for decentralized deployment) is developed based on the construction and weighted matching of bipartite graphs. An exact integer linear programming (ILP) formulation of this class of MRTA problems is also developed, the solution of which serves both as an offline MRTA approach and as a provably optimal benchmark against which the online method is compared. The new methods are applied to a flood response problem where multiple unmanned aerial vehicles must respond to victims spread out over a large area. The results show that the new online algorithm closely trails the offline ILP method in terms of task completion performance, while being >103 times more computationally efficient compared to the ILP method. Dedicated case studies provide further insights into the favorable scalability of the online method with an increasing number of UAVs ? offering up to 46% higher task completion compared to a random walk baseline in huge 1000-task problems. Lastly, application to a slightly different class of SR?ST problems and comparison of the ensuing results with that of corresponding state-of-the-art methods demonstrate the potential wider applicability of the proposed online MRTA method.","Bipartite graph, Integer linear programming, Multi-UAV flood response, Multi-robot task allocation, Unmanned aerial vehicles",Payam Ghassemi and Souma Chowdhury,https://www.sciencedirect.com/science/article/pii/S0921889021001901,https://doi.org/10.1016/j.robot.2021.103905,0921-8890,2022,103905,147,Robotics and Autonomous Systems,Multi-robot task allocation in disaster response: Addressing dynamic tasks with deadlines and robots with range and payload constraints,article,GHASSEMI2022103905
"In this paper, experimental investigation of the flight performance of the proposed universal Unmanned Aerial Vehicle (UAV) in case of rotor failures is presented. In the experimental flight tests, proposed universal UAV that can be converted to many different configurations due to its non-standard multi-layer structure was used in two different configurations as a standard octorotor and a multi-layer dodecarotor. Multiple outdoor experiments are conducted to show flight safety and reliability of the proposed UAV in terms of rotor failure tolerance. In order to evaluate flight safety and reliability of the proposed UAV, take-off, hovering and landing flight performance analyzes were performed in cases where one or two motors/propellers were completely lost. As performance criteria, errors in the UAV?s roll, pitch and yaw angles, altitude error and vibration in three axes were determined. The flight test results are presented both numerically and graphically. According to the results, multi-layer dodecarotor type has shown a more stable flight performance in terms of angular position errors. In addition, in both types of UAVs, in the case of failure of two rotors rotating in the opposite direction, it has been observed that the error in yaw angle is less than a rotor failure, as expected. Likewise, in the case of failure of two rotors rotating in the same direction, performance loss was observed in the control of yaw angle.","Actuator redundancy, Fault-tolerance, Flight safety, Multi-layer UAV, Universal UAV",Veli Bak?rc?o?lu and Nihat Çabuk and ?ahin Y?ld?r?m,https://www.sciencedirect.com/science/article/pii/S0921889021002438,https://doi.org/10.1016/j.robot.2021.103977,0921-8890,2022,103977,149,Robotics and Autonomous Systems,Experimental comparison of the effect of the number of redundant rotors on the fault tolerance performance for the proposed multilayer UAV,article,BAKIRCIOGLU2022103977
"Simulation is one of the most important tools for robotics research, as it serves several crucial purposes such as prototyping, learning, avoiding dispensable hardware costs, or studying future systems that cannot be fabricated yet. Large scale self-reconfiguring modular robotic systems are an instance of such systems. Yet, current modular robotic simulators are overwhelmingly physics-based, which are good for real-world simulation but can be superfluous and sacrifice scalability when studying such systems through a behavioral lens. This paper introduces VisibleSim, an open-source behavioral simulator for lattice-based modular robots that uses discrete-event simulation. We describe the principles behind the simulator and introduce its features and usage from a user standpoint. VisibleSim has unique features like extensibility, versatility, and flexibility, it can also be used as a powerful visualization tool and has already a proven track record with several modular robotic architectures. We present a stress test composed of, ultimately, 32 million simulated robots, a new record in the field of modular robotic simulation.","Discrete-event simulator, Modular robotic systems, Programmable matter, Distributed algorithms, Robotic simulation",Pierre Thalamy and Benoît Piranda and André Naz and Julien Bourgeois,https://www.sciencedirect.com/science/article/pii/S0921889021001986,https://doi.org/10.1016/j.robot.2021.103913,0921-8890,2022,103913,147,Robotics and Autonomous Systems,VisibleSim: A behavioral simulation framework for lattice modular robots,article,THALAMY2022103913
"An effective perception system is a fundamental component for farming robots, as it enables them to properly perceive the surrounding environment and to carry out targeted operations. The most recent methods make use of state-of-the-art machine learning techniques to learn a valid model for the target task. However, those techniques need a large amount of labeled data for training. A recent approach to deal with this issue is data augmentation through Generative Adversarial Networks (GANs), where entire synthetic scenes are added to the training data, thus enlarging and diversifying their informative content. In this work, we propose an alternative solution with respect to the common data augmentation methods, applying it to the fundamental problem of crop/weed segmentation in precision farming. Starting from real images, we create semi-artificial samples by replacing the most relevant object classes (i.e., crop and weeds) with their synthesized counterparts. To do that, we employ a conditional GAN (cGAN), where the generative model is trained by conditioning the shape of the generated object. Moreover, in addition to RGB data, we take into account also near-infrared (NIR) information, generating four channel multi-spectral synthetic images. Quantitative experiments, carried out on three publicly available datasets, show that (i) our model is capable of generating realistic multi-spectral images of plants and (ii) the usage of such synthetic images in the training process improves the segmentation performance of state-of-the-art semantic segmentation convolutional networks.","Agricultural robotics, Crop/weed detection, cGANs, Semantic segmentation",Mulham Fawakherji and Ciro Potena and Alberto Pretto and Domenico D. Bloisi and Daniele Nardi,https://www.sciencedirect.com/science/article/pii/S0921889021001469,https://doi.org/10.1016/j.robot.2021.103861,0921-8890,2021,103861,146,Robotics and Autonomous Systems,Multi-Spectral Image Synthesis for Crop/Weed Segmentation in Precision Farming,article,FAWAKHERJI2021103861
"This article introduces distributed herding controllers to make multiple robots (agents) follow a leader in environments with many unknown obstacles. The proposed herding controllers are developed considering agents which can only measure the bearing of a nearby agent using bearing sensors, such as camera. In addition, an agent uses Received Signal Strength Indicator (RSSI) sensors to detect the moment when it meets another agent. Every agent, except for the leader, is not equipped with sensors to localize itself. Every agent can only detect nearby agents and moves utilizing local sensing measurements. Since every agent moves in an unknown cluttered environment, communication or sensing between agents may be lost blocked by obstacles. Therefore, this article presents distributed herding controllers so that multiple agents follow a leader while maintaining network connectivity in unknown cluttered environments. The leader changes its velocity adaptively so that it can reach the goal while maintaining network connectivity with its followers. The proposed herding controllers are developed to overcome a network faulty situation. As far as we know, this paper is novel in presenting distributed herding controls of multiple agents, such that the network connectivity is maintained while agents move in cluttered environments. Under MATLAB simulations, we verify the effectiveness of the proposed herding approach in cluttered environments.","Networked system, Bearing measurements, Distributed herding, Network connectivity, Cluttered environments",Jonghoek Kim,https://www.sciencedirect.com/science/article/pii/S0921889021001743,https://doi.org/10.1016/j.robot.2021.103889,0921-8890,2021,103889,146,Robotics and Autonomous Systems,Distributed herding of multiple robots in cluttered environments,article,KIM2021103889
"Intelligent systems are increasingly part of our everyday lives and have been integrated seamlessly to the point where it is difficult to imagine a world without them. Physical manifestations of those systems on the other hand, in the form of embodied agents or robots, have so far been used only for specific applications and are often limited to functional roles (e.g. in the industry, entertainment and military fields). Given the current growth and innovation in the research communities concerned with the topics of robot navigation, human?robot-interaction and human activity recognition, it seems like this might soon change. Robots are increasingly easy to obtain and use and the acceptance of them in general is growing. However, the design of a socially compliant robot that can function as a companion needs to take various areas of research into account. This paper is concerned with the navigation aspect of a socially-compliant robot and provides a survey of existing solutions for the relevant areas of research as well as an outlook on possible future directions.","Robot navigation, Human robot interaction, Active vision, Activity recognition",Ronja Möller and Antonino Furnari and Sebastiano Battiato and Aki Härmä and Giovanni Maria Farinella,https://www.sciencedirect.com/science/article/pii/S0921889021001226,https://doi.org/10.1016/j.robot.2021.103837,0921-8890,2021,103837,145,Robotics and Autonomous Systems,A survey on human-aware robot navigation,article,MOLLER2021103837
"Articulated robots such as manipulators increasingly must operate in uncertain and dynamic environments where interaction (with human coworkers, for example) is necessary. In these situations, the capacity to quickly adapt to unexpected changes in operational space constraints is essential. At certain points in a manipulator?s configuration space, termed singularities, the robot loses one or more degrees of freedom (DoF) and is unable to move in specific operational space directions. The inability to move in arbitrary directions in operational space compromises adaptivity and, potentially, safety. We introduce a geometry-aware singularity index, defined using a Riemannian metric on the manifold of symmetric positive definite matrices, to provide a measure of proximity to singular configurations. We demonstrate that our index avoids some of the failure modes and difficulties inherent to other common indices. Further, we show that our index can be differentiated easily, making it compatible with local optimization approaches used for operational space control. Our experimental results establish that, for reaching and path following tasks, optimization based on our index outperforms a common manipulability maximization technique and ensures singularity-robust motions.","Manipulation, Manipulability ellipsoid, Kinematics, Differential geometry",Filip Mari? and Luka Petrovi? and Marko Guberina and Jonathan Kelly and Ivan Petrovi?,https://www.sciencedirect.com/science/article/pii/S0921889021001500,https://doi.org/10.1016/j.robot.2021.103865,0921-8890,2021,103865,145,Robotics and Autonomous Systems,A Riemannian metric for geometry-aware singularity avoidance by articulated robots,article,MARIC2021103865
"The paper develops a robotic manipulation system to meet the pressing needs for handling a large number of test tubes in clinical examination and replace or reduce human labor. It presents the technical details of the system, which separates and arranges test tubes in racks with the help of 3D vision and artificial intelligence (AI) planning. The developed system only requires a person to put a rack with mixed and non-arranged tubes in front of a robot. The robot autonomously performs recognition, reasoning, planning, manipulation, etc., and returns a rack with separated and arranged tubes. The system is simple-to-use, and there are no requests for expert knowledge in robotics. We expect such a system to play an important role in helping managing bulky examination samples. We also hope similar systems could be extended to other clinical manipulation like handling mixers and pipettes in the future.","Grasping, Manipulation, Motion planning, Lab automation",Weiwei Wan and Takeyuki Kotaka and Kensuke Harada,https://www.sciencedirect.com/science/article/pii/S0921889021002037,https://doi.org/10.1016/j.robot.2021.103918,0921-8890,2022,103918,147,Robotics and Autonomous Systems,Arranging test tubes in racks using combined task and motion planning,article,WAN2022103918
"One of the most critical problems to be addressed by future generation socially-assistive robots working in semi-organized social environments, such as shopping centers, nursing homes, airports, hospitals, or assisted living centers, is the capability of human-aware navigation. Autonomous navigation in a complex environment with people, staff with different roles, timetables, and restrictions to access, among others, requires adapting to socially accepted rules. Consequently, the path-planner must consider concepts related to proxemics and personal spaces of interaction that include human?human, human?robot, or human?object combinations. Likewise, the speed of approaching people, both to initiate communication or to navigate nearby, must be adapted to social conventions. Some of these situations have already been studied in the literature with varying degrees of success. However, the concept of time dependency or chronemics in the robot social navigation has been poorly explored. Current algorithms do not take into account the social complexity of real environments and their relationship with the time of day or the activities performed in these scenarios. This article presents a new framework for robot social navigation in human environments, introducing the concept of time-dependent social mapping. The main novelty is that the social route planned by the robot considers variables that depend on the time and the scheduled center activities. The article describes how the areas of interaction vary over time and how they affect human-aware navigation. To this end, the proposed navigation stack defines a new function for time-dependent social interaction space that takes continuous values and is configurable by the center?s staff. The global path-planner uses this function to choose dynamically a socially accepted path to the target. Then, the framework uses an elastic band path optimizer as a local planner, adapting the robot?s navigation to possible changes during the trajectory. Several use cases in simulated caregiving centers have been explored to validate the robot?s social navigation improvements using these temporal variables.","Social robot navigation, Human-aware navigation, Social mapping",L.V. Calderita and A. Vega and P. Bustos and P. Núñez,https://www.sciencedirect.com/science/article/pii/S0921889021001585,https://doi.org/10.1016/j.robot.2021.103873,0921-8890,2021,103873,145,Robotics and Autonomous Systems,A new human-aware robot navigation framework based on time-dependent social interaction spaces: An application to assistive robots in caregiving centers,article,CALDERITA2021103873
"In this work, we address the design of tightly integrated control, estimation, and allocation algorithms allowing a group of robots to move collectively. For doing so, we leverage a modular framework that allows us to define precisely the needed functional components and thus consider and compare multiple algorithmic solutions for the same module. We demonstrate the effectiveness of such a framework through multiple spatial coordination challenges carried out both in simulation and reality and leveraging different distributed control laws (graph-based and behavior-based controllers). Moreover, we investigate the impact of different localization and communication constraints as well as that of real-time switching of control laws on selected coordination metrics. Finally, we also introduce additional algorithmic components for demonstrating further the modularity of the framework. We find that defining the modularity based on functionality is a very effective way to enable algorithm benchmarking and discover possible improvements of the overall software stack while at the same time being agnostic to the underlying hardware and middleware resources. This is an especially welcome feature in case of severely resource-constrained multi-robot systems. Moreover, an important benefit of such design process is that the resulting distributed control algorithms are very robust to the considered noise sources and amplitudes as well as to the diverse types of challenges considered.","Distributed control algorithms, Multi-robot systems, Benchmarking, Performance evaluation, Control software design",Cyrill Baumann and Alcherio Martinoli,https://www.sciencedirect.com/science/article/pii/S0921889021001342,https://doi.org/10.1016/j.robot.2021.103849,0921-8890,2021,103849,144,Robotics and Autonomous Systems,A modular functional framework for the design and evaluation of multi-robot navigation,article,BAUMANN2021103849
"This paper deals with an innovative autonomous bus navigation and parking system in a bus depot, in order to optimize their movements in a confined area. The kinematic model of the vehicle is defined. Considering its dimensions and weight as well as the centimetric accuracy required, a predictive controller is designed, based on its model linearized around the changing path curvature value, to perform accurate curved paths tracking with a limited tracking error guaranteed by the consideration of a constraint. This controller and additional sliding observers are designed according to the distance traveled, allowing maneuvers to be performed at any forward or backward speed with constant accuracy. In addition, these observers are not affected by path tracking errors. The implementation on an industrial vehicle, operated under realistic conditions, demonstrates the performance and robustness of this navigation system.","Heavy car-like mobile robot, Linear constrained predictive regulator, Curvilinear abscissa dependent sliding estimator, Bus center autonomous storage",Eric Lucet and Alain Micaelli and François-Xavier Russotto,https://www.sciencedirect.com/science/article/pii/S0921889020305467,https://doi.org/10.1016/j.robot.2020.103706,0921-8890,2021,103706,136,Robotics and Autonomous Systems,Accurate autonomous navigation strategy dedicated to the storage of buses in a bus center,article,LUCET2021103706
"One of the problems that service robotics deals with is to bring mobile manipulators to work in semi-structured human scenarios, which requires an efficient and flexible way to execute every-day tasks, like serve a cup in a cluttered environment. Usually, for those tasks, the combination of symbolic and geometric levels of planning is necessary, as well as the integration of perception models with knowledge to guide both planning levels, resulting in a sequence of actions or skills which, according to the current knowledge of the world, may be executed. This paper proposes a planning and execution framework, called SkillMaN, for robotic manipulation tasks, which is equipped with a module with experiential knowledge (learned from its experience or given by the user) on how to execute a set of skills, like pick-up, put-down or open a drawer, using workflows as well as robot trajectories. The framework also contains an execution assistant with geometric tools and reasoning capabilities to manage how to actually execute the sequence of motions to perform a manipulation task (which are forwarded to the executor module), as well as the capacity to store the relevant information to the experiential knowledge for further usage, and the capacity to interpret the actual perceived situation (in case the preconditions of an action do not hold) and to feed back the updated state to the planner to resume from there, allowing the robot to adapt to non-expected situations. To evaluate the viability of the proposed framework, an experiment has been proposed involving different skills performed with various types of objects in different scene contexts.","Manipulation planning, Semantic Skill, Navigation, Every-day tasks, Adaptation, Knowledge-based Reasoning",Mohammed Diab and Mihai Pomarlan and Daniel Beßler and Aliakbar Akbari and Jan Rosell and John Bateman and Michael Beetz,https://www.sciencedirect.com/science/article/pii/S0921889020304930,https://doi.org/10.1016/j.robot.2020.103653,0921-8890,2020,103653,134,Robotics and Autonomous Systems,SkillMaN ? A skill-based robotic manipulation framework based on perception and reasoning,article,DIAB2020103653
"In order to possess a significant degree of autonomy, a robot must be able to perceive its environment and store a representation of that environment for use in tasks such as localisation, navigation, collision avoidance, and higher decision making. It must do this subject to constraints on memory and processing power typical of the embedded computer systems commonly found on small robotic devices. These constraints are particularly important for flying robots (i.e. unmanned aerial vehicles), for which weight must be minimised. The challenge of storing a detailed map of a large area on a small embedded computer has led to the development of many algorithms that exploit the sparsity of typical maps to create a more memory-efficient representation. In this paper, we demonstrate that the verticality of both natural and man-made structures can be exploited to create a framework that can store occupancy grid maps efficiently, without causing additional computational burden. The new framework achieves an order-of-magnitude reduction in memory footprint relative to widely-used occupancy grid mapping software, while also achieving a slight speed-up in map insertion and access times. We also make available LIDAR scans taken from a hexacopter of an indoor flight arena that can be used to assist in evaluating future mapping and SLAM developments.","Mapping, Occupancy grid, Bayesian estimation, Robotics",Alex Fisher and Ricardo Cannizzaro and Madeleine Cochrane and Chatura Nagahawatte and Jennifer L. Palmer,https://www.sciencedirect.com/science/article/pii/S0921889021000403,https://doi.org/10.1016/j.robot.2021.103755,0921-8890,2021,103755,142,Robotics and Autonomous Systems,ColMap: A memory-efficient occupancy grid mapping framework,article,FISHER2021103755
"Constraint-based control approaches offer a flexible way to specify robotic manipulation tasks and execute them on robots with many degrees of freedom. However, the specification of task constraints and their associated priorities usually requires a human-expert and often leads to tailor-made solutions for specific situations. This paper presents our recent efforts to automatically derive task constraints for a constraint-based robot controller from data and adapt them with respect to previously unseen situations (contexts). We use a programming-by-demonstration approach to generate training data in multiple variations (context changes) of a given task. From this data we learn a probabilistic model that maps context variables to task constraints and their respective soft task priorities. We evaluate our approach with 3 different dual-arm manipulation tasks on an industrial robot and show that it performs better than comparable approaches with respect to reproduction accuracy in previously unseen contexts.","Context-adaptive control, Constraint-based robot control, Programming-by-demonstration, Gaussian mixture regression, Dual-arm manipulation",Dennis Mronga and Frank Kirchner,https://www.sciencedirect.com/science/article/pii/S0921889021000646,https://doi.org/10.1016/j.robot.2021.103779,0921-8890,2021,103779,141,Robotics and Autonomous Systems,Learning context-adaptive task constraints for robotic manipulation,article,MRONGA2021103779
"Dexterous grasping is one of the most fundamental abilities of robots to implement various manipulation tasks. Robots should have the same ability as humans to plan various grasp types for dexterous grasping. This paper addresses the problem of the adaptability of grasp planning. A novel adaptive grasp planning framework is designed to adapt to various grasp types rather than a single one. In this framework, six commonly used grasp types are considered. The information of grasp type is extracted from visual data. Then, inspired by the opposition concept, a novel concept of pregrasping opposition is introduced as the pregrasping configuration to encode the information of the grasp type. After that, a two-stage adaptive grasp planning method is proposed, which determines the pregrasping opposition in Stage One and finds a feasible grasp configuration for object grasping in Stage Two. The pregrasping opposition is used as a waypoint for the formation of complex grasps. The effectiveness of the proposed framework was evaluated in simulation and real-world experiments. The experimental results demonstrated that the proposed framework can plan various grasp types for dexterous robotic grasping. Additionally, the use of grasp types helps to reduce the complexity of grasp planning and improve the grasp dexterity of robotic hands.","Dexterous grasping, Grasp planning, Grasp type, Grasp quality measure, Grasp optimization",Zhen Deng and Bin Fang and Bingwei He and Jianwei Zhang,https://www.sciencedirect.com/science/article/pii/S0921889021000129,https://doi.org/10.1016/j.robot.2021.103727,0921-8890,2021,103727,140,Robotics and Autonomous Systems,An adaptive planning framework for dexterous robotic grasping with grasp type detection,article,DENG2021103727
"This report describes an automatic control system that allows an assistive robot pushing a wheelchair to climb steps. The robot is equipped with a wheeled mechanism and dual manipulators. The wheelchair is a commercially available model that has been equipped with sensors, circuits, and batteries. The robot and wheelchair are connected when the vehicles climb a step. In that operation, the front wheels of the wheelchair are lifted and placed on the step using the velocity differences between the wheelchair and the robot. Next, when the rear wheels of the wheelchair ascend the step, the robot imitates the upper arm motions of a human pushing against his/her chest that commonly occurs when maneuvering a wheelchair up a step. Similarly, the front wheels of the robot are lifted and placed on the step using the velocity differences between the vehicles and the robot?s front wheels. After that, with the assistance of the wheelchair, the other wheels of the robot climb onto the step. In an effort to ensure safety, we also performed a theoretical analysis to determine the most suitable distance for lifting the front wheels of the robot when approaching and climbing a step. Our newly developed cooperative step-climbing system makes it possible to eliminate the complicated operations that were required by previous methods and can also prevent collisions between the wheelchair?s front wheels and the step, thus drastically improving the convenience of the operation. The test subject riding the wheelchair was an able-bodied male, and the experiment conducted to evaluate our system was performed on a 120 mm step height that had a friction coefficient of 0.72. This setup was sufficient for demonstrating the overall effectiveness of our system.","Step climbing, Wheelchair, Architectural accessibility, Assistive technology",Hidetoshi Ikeda and Takafumi Toyama and Daisuke Maki and Keisuke Sato and Eiji Nakano,https://www.sciencedirect.com/science/article/pii/S0921889020305108,https://doi.org/10.1016/j.robot.2020.103670,0921-8890,2021,103670,135,Robotics and Autonomous Systems,Cooperative step-climbing strategy using an autonomous wheelchair and a robot,article,IKEDA2021103670
"Building 3D maps of various terrains is a necessary approach to gain environmental information for mobile robots when they are exploring in unknown territories. In this paper, we propose a method to construct a point cloud map with laser-measured data as the robot moves around. A terrain-adaptive density mapping technique is used to balance the demands of small data size and high terrain accuracy by utilizing the local curvatures as the simplification criteria. The adaptive density mapping technique is further integrated within the map merging framework to improve the matching speed and accuracy. Indoor and outdoor experiments are proceeded, which verifies the effects of using terrain-adaptive density point cloud on controlling the map size and decreasing the map alignment error.","Map merging, ICP algorithm, Point cloud simplification, Terrain-adaptive mapping",Yangmin Xie and Yujie Tang and Rui Zhou and Yukun Guo and Hang Shi,https://www.sciencedirect.com/science/article/pii/S0921889020304899,https://doi.org/10.1016/j.robot.2020.103649,0921-8890,2020,103649,134,Robotics and Autonomous Systems,Map merging with terrain-adaptive density using mobile 3D laser scanner,article,XIE2020103649
"This paper describes a system for service robots that combines ontological knowledge reasoning and human?robot interaction to interpret natural language commands and successfully perform household chores, such as finding and delivering objects. Knowledge and context reasoning is essential for providing more efficient service robots, given their diverse and continuously changing environments. Moreover, since they are in contact with humans, robots require such skills as interaction and language. Therefore, we developed a system with specific modules to manage robots? knowledge and reasoning, command analysis, decision-making, and talking interaction. The system relies on inference methods and verbal interaction to understand commands and clarify uncertain information. We tested our system inside a simulated environment where the robot receives commands with missing or unclear information. The system?s performance was compared with the average performance of human subjects who completed the same commands in the simulation.","Knowledge management, Ontology-based, Service robots, Human?robot interaction",L. {Villamar Gómez} and J. Miura,https://www.sciencedirect.com/science/article/pii/S0921889021000488,https://doi.org/10.1016/j.robot.2021.103763,0921-8890,2021,103763,140,Robotics and Autonomous Systems,Ontology-based knowledge management with verbal interaction for command interpretation and execution by home service robots,article,VILLAMARGOMEZ2021103763
"Programming a robot to deal with open-ended tasks remains a challenge, in particular if the robot has to manipulate objects. Launching, grasping, pushing or any other object interaction can be simulated but the corresponding models are not reversible and the robot behavior thus cannot be directly deduced. These behaviors are hard to learn without a demonstration as the search space is large and the reward sparse. We propose a method to autonomously generate a diverse repertoire of simple object interaction behaviors in simulation. Our goal is to bootstrap a robot learning and development process with limited information about what the robot has to achieve and how. This repertoire can be exploited to solve different tasks in reality thanks to a proposed adaptation method or could be used as a training set for data-hungry algorithms. The proposed approach relies on the definition of a goal space and generates a repertoire of trajectories to reach attainable goals, thus allowing the robot to control this goal space. The repertoire is built with an off-the-shelf simulation thanks to a quality?diversity algorithm. The result is a set of solutions tested in simulation only. It may result in two different problems: (1) as the repertoire is discrete and finite, it may not contain the trajectory to deal with a given situation or (2) some trajectories may lead to a behavior in reality that differs from simulation because of a reality gap. We propose an approach to deal with both issues by using a local linearization of the mapping between the motion parameters and the observed effects. Furthermore, we present an approach to update the existing solutions repertoire with the tests done on the real robot. The approach has been validated on two different experiments on the Baxter robot: a ball launching and a joystick manipulation tasks.","Quality?diversity search, Evolutionary algorithm, Long-life learning, Robotics, Developmental robotics, Behavior repertoire",Seungsu Kim and Alexandre Coninx and Stephane Doncieux,https://www.sciencedirect.com/science/article/pii/S0921889020305509,https://doi.org/10.1016/j.robot.2020.103710,0921-8890,2021,103710,136,Robotics and Autonomous Systems,From exploration to control: Learning object manipulation skills through novelty search and local adaptation,article,KIM2021103710
"In this paper, we present an online nonlinear Model Predictive Control (MPC) method for collision-free, deadlock-free navigation by multiple autonomous nonholonomic Wheeled Mobile Robots (WMRs). Our proposed method solves a nonlinear constrained optimization problem at each time step over a specified horizon to compute a sequence of optimal control inputs that drive the robots to target poses along collision-free trajectories, where the robots? future states are predicted according to a unicycle kinematic model. To reduce the computational complexity of the optimization problem, we formulate it without stabilizing terminal constraints or terminal costs. We describe a computationally efficient approach to programming and solving the optimization problem, using open-source software tools for fast nonlinear optimization and applying the multiple-shooting method. We also provide rigorous proofs of the feasibility of the optimization problem and the stability of the proposed method. To validate the performance of our MPC method, we implement it in both 3D robot simulations and experiments with real nonholonomic WMRs for different multi-robot navigation scenarios with up to six robots. In all scenarios, the robots successfully navigate to their goal poses without colliding with one another or becoming trapped in a deadlock.","Nonlinear model predictive control, Multi-robot systems, Wheeled mobile robots, Nonholonomic constraints, Collision avoidance, Deadlock avoidance",Amir {Salimi Lafmejani} and Spring Berman,https://www.sciencedirect.com/science/article/pii/S0921889021000592,https://doi.org/10.1016/j.robot.2021.103774,0921-8890,2021,103774,141,Robotics and Autonomous Systems,Nonlinear MPC for collision-free and deadlock-free navigation of multiple nonholonomic mobile robots,article,SALIMILAFMEJANI2021103774
"This paper deals with the formation flying control problem for a team of nonlinear uncertain quadrotors in presence of noisy measurements and environmental disturbances. A novel distributed output-feedback nonlinear robust algorithm is proposed to solve the problem. The algorithm leads to a series of combined estimation-control local policies with minimum communicated information by decomposing the global network to local star networks. An analytical study establishes the stability of the closed-loop system and the Monte-Carlo simulation demonstrates the robust performance and boundedness of the outputs numerically. The Software In the Loop (SIL) testing is performed utilizing Pixhawk open source flight management unit, Raspberry-pi 3 and GAZEBO simulation environment to reveal the effectiveness of the proposed distributed control-estimation algorithm for practical implementation.","Multi-agent system, Monte-Carlo simulation, SIL test, Pixhawk FMU, Raspberry-Pi 3, MAVROS",Fatemeh Rekabi and Farzad A. Shirazi and Mohammad Jafar Sadigh and Mahmood Saadat,https://www.sciencedirect.com/science/article/pii/S0921889020305297,https://doi.org/10.1016/j.robot.2020.103689,0921-8890,2021,103689,136,Robotics and Autonomous Systems,Distributed output feedback nonlinear H? formation control algorithm for heterogeneous aerial robotic teams,article,REKABI2021103689
"This paper presents a trajectory generation algorithm with which a three-dimensional (3D) biped robot can perform aperiodic gaits by modifying only a small set of gait parameters. In addition to the double support phase (DSP), the gait can transit smoothly from one single support phase (SSP) to another. We decouple the sagittal and coronal dynamics, firstly. In the sagittal plane, the linear inverted pendulum model (LIPM) is used to generate the walking reference trajectory during the SSP. An extra template model, linear pendulum model (LPM), is added to describe the motion in the DSP. For the coronal plane, we only utilize the LPM for trajectory generation. Thanks to linearity properties, the proposed method can obtain the biped locomotion computationally fast without the need for numerical time-integration. Herein, we also introduce the trajectory generation algorithm for different aperiodic gaits including from standing to walking, stopping walking, as well as speed switch. A full-dynamics 3D humanoid robot is used for the tests of the developed reference trajectory through simulation. The results are promising for implementations.","3D biped robot, Double support phase, LIPM, LPM, Aperiodic gaits",Zhongqu Xie and Long Li and Xiang Luo,https://www.sciencedirect.com/science/article/pii/S0921889021001160,https://doi.org/10.1016/j.robot.2021.103831,0921-8890,2021,103831,143,Robotics and Autonomous Systems,Three-dimensional aperiodic biped walking including the double support phase using LIPM and LPM,article,XIE2021103831
"Point clouds registration is a fundamental step of many point clouds processing pipelines; however, most algorithms are tested on data that are collected ad-hoc and not shared with the research community. These data often cover only a very limited set of use cases; therefore, the results cannot be generalized. Public datasets proposed until now, taken individually, cover only a few kinds of environment and mostly a single sensor. For these reasons, we developed a benchmark, for localization and mapping applications, using multiple publicly available datasets. In this way, we are able to cover many kinds of environment and many kinds of sensor that can produce point clouds. Furthermore, the ground truth has been thoroughly inspected and evaluated to ensure its quality. For some of the datasets, the accuracy of the ground truth measuring system was not reported by the original authors, therefore we estimated it with our own novel method, based on an iterative registration algorithm. Along with the data, we provide a broad set of registration problems, chosen to cover different types of initial misalignment, various degrees of overlap, and different kinds of registration problems. Lastly, we propose a metric to measure the performances of registration algorithms: it combines the commonly used rotation and translation errors together, to allow an objective comparison of the alignments. This work aims at encouraging authors to use a public and shared benchmark, instead of data collected ad-hoc, to ensure objectivity and repeatability, two fundamental characteristics in any scientific field.","Benchmark, Point clouds registration, Datasets",Simone Fontana and Daniele Cattaneo and Augusto L. Ballardini and Matteo Vaghi and Domenico G. Sorrenti,https://www.sciencedirect.com/science/article/pii/S0921889021000191,https://doi.org/10.1016/j.robot.2021.103734,0921-8890,2021,103734,140,Robotics and Autonomous Systems,A benchmark for point clouds registration algorithms,article,FONTANA2021103734
"A great amount of effort has been devoted to the study on self-separation assurance approach for civil aviation in the airspace with increasing density. In this article, the Optimal Reciprocal Collision Avoidance (ORCA) algorithm is modified to make it work for autonomous and decentralized collision avoidance for civil aircraft. Without considering the direction selectivity of collision-free maneuver, aircraft may select the relative parallel trajectories by deploying the ORCA algorithm in both decentralized and centralized way. As a result, the collision tends to be postponed to the next time horizon because civil aircraft need to return to original trajectories. Simultaneously, the unified rules can hardly be integrated into the approach due to the lack of direction selectivity for collision-free navigation. The process of separation assurance will be disorderly when multiple aircraft are involved. To solve the problem mentioned above, a new algorithm called Directional Optimal Reciprocal Collision Avoidance (DORCA) is proposed. The DORCA algorithm employs a vector rotation mode to construct the forbidden Velocity Obstacle (VO) set in order to improve the computation efficiency. In addition, the direction selectivity of maneuver is achieved through constructing the direction-constrained VO set according to the direction of relative motion in velocity space. Direction selectivity of the algorithm enables the process of collision avoidance to comply with the unified rules. A number of encounter scenarios are conducted to confirm the validity and feasibility of the proposed DORCA algorithm. In all scenarios tested, the direction selectivity of collision-free maneuver can be successfully integrated into the DORCA algorithm, and the algorithm is more efficient than the ORCA algorithm for collision avoidance in decentralized way.","Self-separation assurance, Civil aircraft, DORCA, Decentralized collision avoidance, The unified rules, Direction selectivity",Haotian Niu and Cunbao Ma and Pei Han,https://www.sciencedirect.com/science/article/pii/S0921889020305455,https://doi.org/10.1016/j.robot.2020.103705,0921-8890,2021,103705,136,Robotics and Autonomous Systems,Directional optimal reciprocal collision avoidance,article,NIU2021103705
"Robustly estimating the orientations of people is a crucial precondition for a wide range of applications. Especially for autonomous systems operating in populated environments, the orientation of a person can give valuable information to increase their acceptance. Given people?s orientations, mobile systems can apply navigation strategies which take people?s proxemics into account or approach them in a human like manner to perform human robot interaction (HRI) tasks. In this paper, we present an approach for person orientation estimation based on computationally efficient features extracted from colored point clouds, formerly used for a two-class person attribute classification. The classification approach has been extended to the continuous domain while treating the problem of orientation estimation in real time. Furthermore, we present an approach for tracking estimated orientations over time using a Bayesian filter. We will show that tracking can increase the accuracy of orientations by up to 3.69° on a dataset recorded with a mobile robot. Best results on this highly challenging dataset are achieved with a regression approach for orientation estimation in combination with tracking. The mean angular error of just 16.49° proofs the applicability in real-world scenarios.","Person orientation estimation, Person perception, Mobile robotics, Real time",Tim Wengefeld and Benjamin Lewandowski and Daniel Seichter and Lennard Pfennig and Steffen Müller and Horst-Michael Gross,https://www.sciencedirect.com/science/article/pii/S0921889020305054,https://doi.org/10.1016/j.robot.2020.103665,0921-8890,2021,103665,135,Robotics and Autonomous Systems,Real-time person orientation estimation and tracking using colored point clouds,article,WENGEFELD2021103665
"The evolution of Intelligent Transportation Systems in recent times necessitates the development of self-awareness in agents. Before the intensive use of Machine Learning, the detection of abnormalities was manually programmed by checking every variable and creating huge nested conditions that are very difficult to track. This paper aims to introduce a novel method to develop self-awareness in autonomous vehicles that mainly focuses on detecting abnormal situations around the considered agents. Multi-sensory time-series data from the vehicles are used to develop the data-driven Dynamic Bayesian Network (DBN) models used for future state prediction and the detection of dynamic abnormalities. Moreover, an initial level collective awareness model that can perform joint anomaly detection in co-operative tasks is proposed. The GNG algorithm learns the DBN models? discrete node variables; probabilistic transition links connect the node variables. A Markov Jump Particle Filter (MJPF) is applied to predict future states and detect when the vehicle is potentially misbehaving using learned DBNs as filter parameters. In this paper, datasets from real experiments of autonomous vehicles performing various tasks used to learn and test a set of switching DBN models.","Intelligent Transportation System (ITS), Autonomous vehicles, Dynamic Bayesian Network (DBN), Hellinger distance, Abnormality detection",Divya Thekke Kanapram and Pablo Marin-Plaza and Lucio Marcenaro and David Martin and Arturo {de la Escalera} and Carlo Regazzoni,https://www.sciencedirect.com/science/article/pii/S0921889020304929,https://doi.org/10.1016/j.robot.2020.103652,0921-8890,2020,103652,134,Robotics and Autonomous Systems,Self-awareness in intelligent vehicles: Feature based dynamic Bayesian models for abnormality detection,article,KANAPRAM2020103652
"This paper presents a method for planning optimal trajectories with a team of Unmanned Aerial Vehicles (UAVs) performing autonomous cinematography. The method is able to plan trajectories online and in a distributed manner, providing coordination between the UAVs. We propose a novel non-linear formulation for this challenging problem of computing multi-UAV optimal trajectories for cinematography; integrating UAVs dynamics and collision avoidance constraints, together with cinematographic aspects like smoothness, gimbal mechanical limits and mutual camera visibility. We integrate our method within a hardware and software architecture for UAV cinematography that was previously developed within the framework of the MultiDrone project; and demonstrate its use with different types of shots filming a moving target outdoors. We provide extensive experimental results both in simulation and field experiments. We analyze the performance of the method and prove that it is able to compute online smooth trajectories, reducing jerky movements and complying with cinematography constraints.","Optimal trajectory planning, UAV cinematography, Multi-UAV coordination",Alfonso Alcántara and Jesús Capitán and Rita Cunha and Aníbal Ollero,https://www.sciencedirect.com/science/article/pii/S0921889021000634,https://doi.org/10.1016/j.robot.2021.103778,0921-8890,2021,103778,140,Robotics and Autonomous Systems,Optimal trajectory planning for cinematography with multiple Unmanned Aerial Vehicles,article,ALCANTARA2021103778
"This paper presents an approach to planning under uncertainty in resource-constrained environments. We describe our novel method for online plan modification and execution monitoring, which augments an existing plan with pre-computed plan fragments in response to observed resource availability. Our plan merging algorithm uses causal structure to interleave actions, creating solutions online using observations of the true state without introducing significant computational cost. Our system monitors resource availability, reasoning about the probability of successfully completing the goals. We show that when the probability of completing a plan decreases, by removing low-priority goals our system reduces the risk of plan failure, increasing mission success rate. Conversely, when resource availability allows, by including additional goals our system increases reward without adversely affecting success rate. We evaluate our approach using the example domain of long-range autonomous underwater vehicle (AUV) missions, in which a vehicle spends months at sea with little or no opportunity for intervention. We compare the performance to a state-of-the-art oversubscription planner. Planning within such domains is challenging because significant resource usage uncertainty means it is computationally infeasible to calculate the optimal strategy in advance. We also evaluate the applicability of our plan merging algorithm to existing IPC domains, presenting a discussion of the domain characteristics which favour the use of our approach.","Automated planning, Decision making, Resource uncertainty, Contingency planning, Plan repair, Online planning",Catherine A. Harris and Nick Hawes and Richard Dearden,https://www.sciencedirect.com/science/article/pii/S0921889021000117,https://doi.org/10.1016/j.robot.2021.103726,0921-8890,2021,103726,140,Robotics and Autonomous Systems,Online plan modification in uncertain resource-constrained environments,article,HARRIS2021103726
"Efficient robotic behaviors require robustness and adaptation to dynamic changes of the environment, whose characteristics rapidly vary during robot operation. To generate effective robot action policies, planning and learning techniques have shown the most promising results. However, if considered individually, they present different limitations. Planning techniques lack generalization among similar states and require experts to define behavioral routines at different levels of abstraction. Conversely, learning methods usually require a considerable number of training samples and iterations of the algorithm. To overcome these issues, and to efficiently generate robot behaviors, we introduce LoOP, an iterative learning algorithm for optimistic planning that combines state-of-the-art planning and learning techniques to generate action policies. The main contribution of LoOP is the combination of Monte-Carlo Search Planning and Q-learning, which enables focused exploration during policy refinement in different robotic applications. We demonstrate the robustness and flexibility of LoOP in various domains and multiple robotic platforms, by validating the proposed approach with an extensive experimental evaluation.","Autonomous planning and learning, Monte-Carlo planning, Q-learning, Deep robot reinforcement learning",Francesco Riccio and Roberto Capobianco and Daniele Nardi,https://www.sciencedirect.com/science/article/pii/S0921889020305339,https://doi.org/10.1016/j.robot.2020.103693,0921-8890,2021,103693,136,Robotics and Autonomous Systems,LoOP: Iterative learning for optimistic planning on robots,article,RICCIO2021103693
"This study proposes a new shared mixed reality (MR)-bilateral telerobotic system. The main contribution of this study is to combine MR teleoperation and bilateral teleoperation, which takes advantage of the two types of teleoperation and compensates for each other?s drawbacks. With this combination, the proposed system can address the asymmetry issues in bilateral teleoperation, such as kinematic redundancy and workspace inequality, and provide force feedback, which is lacking in MR teleoperation. In addition, this system effectively supports long-distance movements and fine movements. In this system, a new MR interface is developed to provide the operator with an immersive visual feedback of the workspace, in which a useful virtual controller known as an interaction proxy?is designed. Compared with previous virtual reality-based teleoperation systems, this interaction proxy can freely decouple the operator from the control loop, such that the operational burden can be substantially alleviated. Additionally, the force feedback provided by the bilateral teleoperation gives the operator an advanced perception about the remote workspace and can improve task performance. Experiments on multiple pick-and-place tasks are provided to demonstrate the feasibility and effectiveness of the proposed system.","Virtual reality, Bilateral teleoperation, Shared control",Da Sun and Qianfang Liao and Andrey Kiselev and Todor Stoyanov and Amy Loutfi,https://www.sciencedirect.com/science/article/pii/S0921889020304887,https://doi.org/10.1016/j.robot.2020.103648,0921-8890,2020,103648,134,Robotics and Autonomous Systems,Shared mixed reality-bilateral telerobotic system,article,SUN2020103648
"We propose a representation for the set of forces a robot can counteract using full system dynamics: the residual force polytope. Given the nominal torques required by a dynamic motion, this representation models the forces which can be sustained without interfering with that motion. The residual force polytope can be used to analyze and compare the set of admissible forces of different trajectories, but it can also be used to define metrics for solving optimization problems, such as in trajectory optimization or system design. We demonstrate how such a metric can be applied to trajectory optimization and compare it against other objective functions typically used. Our results show that the trajectories computed by optimizing objectives defined as functions of the residual force polytope are more robust to unknown external disturbances. The computational cost of these metrics is relatively high and not compatible with the short planning times required by online methods, but they are acceptable for planning motions offline.","Robustness, Polytopes, Trajectory optimization, Robotic arms",Henrique Ferrolho and Wolfgang Merkt and Carlo Tiseo and Sethu Vijayakumar,https://www.sciencedirect.com/science/article/pii/S0921889021000993,https://doi.org/10.1016/j.robot.2021.103814,0921-8890,2021,103814,142,Robotics and Autonomous Systems,Residual force polytope: Admissible task-space forces of dynamic trajectories,article,FERROLHO2021103814
"Most current bipedal robots were modeled with an assumption that there is no slip between the stance foot and ground. This paper relaxes that assumption and undertakes a comprehensive study of the compass gait biped on slippery ground. It presents in detail the control of a biped that allows for foot slipping, and shows that feasible gaits fail on slippery ground for two causes: falling backward or requiring negative contact force which cannot be provided by the ground. To characterize a robust gait on slippery ground, three safety factors are proposed to measure the robustness: slip friction, falling friction and tolerance ability of slipping without falling. This study thus uses these factors to investigate independent influence of gait speed and step length on the robustness of the gait, and shows that gaits with small step length and moderate speed are robust and preferable on slippery surfaces. In contrast, gaits with large step length generally require large friction to maintain stable walking on slippery surfaces. Moreover, gaits with a backward swing foot velocity relative to the ground just before touch down are generally more robust than ones with a forward velocity. It is further shown that only one parameter in gait design determines the swing-backward feature, which can help design robust gaits. Models with varying physical parameters such as mass, leg length and position of center of mass (CoM) in each leg, are also studied to validate the universality of this result.","Biped walking, Gait design, Slipping, Low friction, Robustness",Tan Chen and Bill Goodwine,https://www.sciencedirect.com/science/article/pii/S0921889021000476,https://doi.org/10.1016/j.robot.2021.103762,0921-8890,2021,103762,140,Robotics and Autonomous Systems,Robust gait design for a compass gait biped on slippery surfaces,article,CHEN2021103762
"Micro-robotic fish (length ?10 cm) driven by smart materials have remarkable advantages over conventional motors and piston-based robotic fish. In particular, they are highly efficient and compact. One of the key challenges is attaining high mobility with high energy density, low driving voltage and power loss. In this work, a double caudal fin micro-robotic fish actuated by two piezoelectric bimorph cantilevers is proposed and fabricated from rigid carbon fiber/resin composites and flexible polyimide hinges. Its weight is about 1.93 g and the maximum uniform swimming velocity is as high as about 0.75 BL/s (4.5 cm/s), which is much faster than previously reported micro-robotic fish actuated by ionic polymer?metal composites, shape memory alloys and dielectric elastomers. A theoretical model is validated by the experimental results and can be used to design and analyze a variety of piezoelectric robotic fish propelled by caudal fins.","Fast movement, Micro-robotic fish, Piezoelectric actuator, Caudal fin",Quanliang Zhao and Shiqi Liu and Jinghao Chen and Guangping He and Jiejian Di and Lei Zhao and Tingting Su and Mengying Zhang and Zhiling Hou,https://www.sciencedirect.com/science/article/pii/S092188902100018X,https://doi.org/10.1016/j.robot.2021.103733,0921-8890,2021,103733,140,Robotics and Autonomous Systems,Fast-moving piezoelectric micro-robotic fish with double caudal fins,article,ZHAO2021103733
"This paper presents an efficient multi-fingered grasping force optimization (GFO) method based on generalized penalty-function concepts. In view of the fact that the mainstream multi-fingered GFO method often treats the second-order cone programming (SOCP) problem as a semi-definite programming (SDP) problem, whose computational complexity is high, we hereby use the barrier function to construct the regularized optimization problem. The trade-off representation of different dimension objective functions is given, and the penalty factor is introduced to form the augmented optimization objective function. For specific operational tasks, by adjusting the penalty factor, a more compact, stable or slack, flexible grasping scheme could be obtained. Monte Carlo simulation is used to determine the probability of successful grasping when variability is introduced, and the robustness of the proposed method in the change of contact position and the friction coefficient between hand and object is verified. Experimental results and dynamic simulation are given, which show that the proposed algorithm outperforms the mainstream SDP method in execution time and iteration number, and the obtained force distribution has both continuity and distribution. Operational flexibility is instructive for practical applications.","Grasping force optimization, Multi-fingered hand, Second-order cone programming, Generalized penalty function",Zhong Chen and Qisen Wu and Cao Hong and Xianmin Zhang,https://www.sciencedirect.com/science/article/pii/S0921889020305121,https://doi.org/10.1016/j.robot.2020.103672,0921-8890,2021,103672,135,Robotics and Autonomous Systems,Multi-fingered grasping force optimization based on generalized penalty-function concepts,article,CHEN2021103672
"In this paper, a Gaussian process-based nonlinear model predictive control (GP-based NMPC) algorithm is presented to deal with the visual servoing problem for constrained mobile robots. Firstly, a GP-enhanced model is established by incorporating a GP model and a visual servoing kinematic model where the GP-model is used to capture the robot dynamics with on-line updating. Then, a nonlinear model predictive control (NMPC) strategy is proposed to transform the visual servoing task into a nonlinear optimization problem with robot-physical and camera-visibility constraints. Subsequently, a variant iterative linear quadratic regulator algorithm is presented to solve the constrained NMPC problem in real time. Finally, simulations and experiments are conducted to show the effectiveness of the presented method.","Visual servoing, Gaussian process, Nonlinear model predictive control, Mobile robots, Variant iterative linear quadratic regulator",Zhehao Jin and Jinhui Wu and Andong Liu and Wen-An Zhang and Li Yu,https://www.sciencedirect.com/science/article/pii/S0921889020305522,https://doi.org/10.1016/j.robot.2020.103712,0921-8890,2021,103712,136,Robotics and Autonomous Systems,Gaussian process-based nonlinear predictive control for visual servoing of constrained mobile robots with unknown dynamics,article,JIN2021103712
"Robotic simulators are often used to speed up the Evolutionary Robotics (ER) process. Most simulation approaches are based on physics modelling. However, physics-based simulators can become complex to develop and require prior knowledge of the robotic system. Robotics simulators can be constructed using Machine Learning techniques, such as Artificial Neural Networks (ANNs). ANN-based simulator development usually requires a lengthy behavioural data collection period before the simulator can be trained and used to evaluate controllers during the ER process. The Bootstrapped Neuro-Simulation (BNS) approach can be used to simultaneously collect behavioural data, train an ANN-based simulator and evolve controllers for a particular robotic problem. This paper investigates proposed improvements to the BNS approach and demonstrates the viability of the approach by optimising gait controllers for a Hexapod and Snake robot platform.","Evolutionary Robotics, Coevolution, Simulator, Artificial Neural Networks, Snake robot, Hexapod robot, Bootstrapped Neuro-Simulation",Grant W. Woodford and Mathys C. {du Plessis},https://www.sciencedirect.com/science/article/pii/S0921889020305480,https://doi.org/10.1016/j.robot.2020.103708,0921-8890,2021,103708,136,Robotics and Autonomous Systems,Bootstrapped Neuro-Simulation for complex robots,article,WOODFORD2021103708
"Object manipulation planning in clutter suffers from perception uncertainties due to occlusion, as well as action constraints required by collision avoidance. Partially observable Markov decision process (POMDP) provides a general model for planning under uncertainties. But a manipulation task usually have a large action space, which not only makes task planning intractable but also brings significant motion planning effort to check action feasibility. In this work, a new kind of hierarchical POMDP is presented for object manipulation tasks, in which a brief abstract POMDP is extracted and utilized together with the original POMDP. And a hierarchical belief tree search algorithm is proposed for efficient online planning, which constructs fewer belief nodes by building part of the tree with the abstract POMDP and invokes motion planning fewer times by determining action feasibility with observation function of the abstract POMDP. A learning mechanism is also designed in case there are unknown probabilities in transition and observation functions. This planning framework is demonstrated with an object fetching task and the performance is empirically validated by simulations and experiments.","Object manipulation, Task planning, Motion planning, POMDP, Clutter",Wenrui Zhao and Weidong Chen,https://www.sciencedirect.com/science/article/pii/S092188902100021X,https://doi.org/10.1016/j.robot.2021.103736,0921-8890,2021,103736,139,Robotics and Autonomous Systems,Hierarchical POMDP planning for object manipulation in clutter,article,ZHAO2021103736
"When data are organized in matrices or arrays of higher dimensions (tensors), classical regression methods first transform these data into vectors, therefore ignoring the underlying structure of the data and increasing the dimensionality of the problem. This flattening operation typically leads to overfitting when only few training data is available. In this paper, we present a mixture-of-experts model that exploits tensorial representations for regression of tensor-valued data. The proposed formulation takes into account the underlying structure of the data and remains efficient when few training data are available. Evaluation on artificially generated data, as well as offline and real-time experiments recognizing hand movements from tactile myography prove the effectiveness of the proposed approach.","Tensor methods, Mixture of experts, Generalized linear model, Tactile myography",Noémie Jaquier and Robert Haschke and Sylvain Calinon,https://www.sciencedirect.com/science/article/pii/S092188902100097X,https://doi.org/10.1016/j.robot.2021.103812,0921-8890,2021,103812,142,Robotics and Autonomous Systems,Tensor-variate mixture of experts for proportional myographic control of a robotic hand,article,JAQUIER2021103812
"We investigate a multi-agent planning problem, where each agent aims to achieve an individual task while avoiding collisions with other agents. Each agent?s task is expressed as a Time-Window Temporal Logic (TWTL) specification defined over a discretized environment. We propose a distributed receding horizon algorithm for online planning of agent trajectories. We show that under mild assumptions on the environment, the resulting trajectories are always safe (collision-free) and lead to the satisfaction of the TWTL specifications or a finite temporal relaxation. Accordingly, each agent is guaranteed to safely achieve its task, possibly with some minimal finite delay. Performance of the proposed algorithm is demonstrated via numerical simulations and experiments with quadrotors.","Multi-agent systems, Distributed planning, Formal methods, Collision avoidance",Ryan Peterson and Ali Tevfik Buyukkocak and Derya Aksaray and Yasin Yaz?c?o?lu,https://www.sciencedirect.com/science/article/pii/S0921889021000865,https://doi.org/10.1016/j.robot.2021.103801,0921-8890,2021,103801,142,Robotics and Autonomous Systems,Distributed safe planning for satisfying minimal temporal relaxations of TWTL specifications,article,PETERSON2021103801
"Developing safe autonomous robotic applications for outdoor agricultural environments is a research field that still presents many challenges. Simultaneous Localization and Mapping can be crucial to endow the robot to localize itself with accuracy and, consequently, perform tasks such as crop monitoring and harvesting autonomously. In these environments, the robotic localization and mapping systems usually benefit from the high density of visual features. When using filter-based solutions to localize the robot, such an environment usually uses a high number of particles to perform accurately. These two facts can lead to computationally expensive localization algorithms that are intended to perform in real-time. This work proposes a refinement step to a standard high-dimensional filter-based localization solution through the novelty of downsampling the filter using an online clustering algorithm and applying a scan-match procedure to each cluster. Thus, this approach allows scan-matchers without high computational cost, even in high dimensional filters. Experiments using real data in an agricultural environment show that this approach improves the Particle Filter performance estimating the robot pose. Additionally, results show that this approach can build a precise 3D reconstruction of agricultural environments using visual scans, i.e., 3D scans with RGB information.","SLAM, Clustering, Agricultural robotics",André Silva Aguiar and Filipe Neves {dos Santos} and Héber Sobreira and José Boaventura Cunha and Armando Jorge Sousa,https://www.sciencedirect.com/science/article/pii/S0921889021000105,https://doi.org/10.1016/j.robot.2021.103725,0921-8890,2021,103725,137,Robotics and Autonomous Systems,Particle filter refinement based on clustering procedures for high-dimensional localization and mapping systems,article,AGUIAR2021103725
"Animals learn to master their capabilities by trial and error, and with out having any knowledge about their dynamics model and mathematical or physical rules. They use their maximum capabilities in an optimized way. This is the result of millions of years of evolution where the best of different possibilities are kept, and makes us rethink How does the nature perform things?, particularly when natural systems outperform our rigid systems. In this study, inspired by the nature, we developed an innovative algorithm by enhancing an existing reinforcement learning algorithm (proximal policy optimization (PPO)). Our algorithm is capable of learning to control a quad-rotor drone in order to fly. This new algorithm called Bio-inspired Flight Controller (BFC) does not use any conventional controller such as PID or MPC to control the quad-rotor drone. The goal of BFC is to completely replace the conventional controller with a controller that acts in a similar way to the animals where they learn to control their movements. It is capable of stabilizing a quad-copter in a desired point, and following way points. We implemented our algorithm in an AscTec Hummingbird quad-copter simulated in Gazebo, and tested it using different scenarios to fully measure its capabilities.","Reinforcement learning, Autonomous system, Bio-inspired artificial intelligence, Policy optimization, Artificial neural network, Bio-inspired controller, Machine learning",Amir {Ramezani Dooraki} and Deok-Jin Lee,https://www.sciencedirect.com/science/article/pii/S092188902030511X,https://doi.org/10.1016/j.robot.2020.103671,0921-8890,2021,103671,135,Robotics and Autonomous Systems,An innovative bio-inspired flight controller for quad-rotor drones: Quad-rotor drone learning to fly using reinforcement learning,article,RAMEZANIDOORAKI2021103671
"Trajectory planning through dynamical systems (DS) provides robust control for robots and has found numerous applications from locomotion to manipulation. However, to date, DS for controlling rhythmic patterns are distinct from DS used to control point to point motion and current approaches switch at run time across these to enable multiple behaviors. This switching can be brittle and subject to instabilities. We present an approach to embed cyclic and point to point dynamics in a single DS. We offer a method to learn the parameters of complete DS through a two-step optimization. By exploiting Hopf bifurcations, we can explicitly and smoothly transit across periodic and non-periodic phases, linear and nonlinear limit cycles, and non-periodic phases, in addition to changing the equilibrium?s location and the limit cycle?s amplitude. We use diffeomorphism and learn a mapping to modify the learned limit cycle to generate nonlinear limit cycles. The approach is validated with a real 7 DOF KUKA LWR 4+ manipulator to control wiping and with a humanoid robot in simulation.","Learning from demonstration, Model learning for control, Motion control, Optimization and optimal control",Farshad Khadivar and Ilaria Lauzana and Aude Billard,https://www.sciencedirect.com/science/article/pii/S0921889020305406,https://doi.org/10.1016/j.robot.2020.103700,0921-8890,2021,103700,136,Robotics and Autonomous Systems,Learning dynamical systems with bifurcations,article,KHADIVAR2021103700
"We present a real-time stereo visual-inertial-SLAM system which is able to recover from complicated kidnap scenarios and failures online in realtime. We propose to learn the whole-image-descriptor in a weakly supervised manner based on NetVLAD and decoupled convolutions. We analyze the training difficulties in using standard loss formulations and propose an allpairloss and show its effect through extensive experiments. Compared to standard NetVLAD, our network takes an order of magnitude fewer computations and model parameters, as a result runs about three times faster. We evaluate the representation power of our descriptor on standard datasets with precision?recall. Unlike previous loop detection methods which have been evaluated only on fronto-parallel revisits, we evaluate the performance of our method with competing methods on scenarios involving large viewpoint difference. Finally, we present the fully functional system with relative computation and handling of multiple world co-ordinate system which is able to reduce odometry drift, recover from complicated kidnap scenarios and random odometry failures. We open source our fully functional system as an add-on for the popular VINS-Fusion.","Kidnap recovery, Loop closure, VINS, Whole image descriptor",Manohar Kuse and Shaojie Shen,https://www.sciencedirect.com/science/article/pii/S0921889021000981,https://doi.org/10.1016/j.robot.2021.103813,0921-8890,2021,103813,143,Robotics and Autonomous Systems,Learning whole-image descriptors for real-time loop detection and kidnap recovery under large viewpoint difference,article,KUSE2021103813
"Programming robots to perform complex manipulation tasks is difficult because many tasks require sophisticated controllers that may rely on data such as manipulability ellipsoids, stiffness/damping and inertia matrices. Such data are naturally represented as Symmetric Positive Definite (SPD) matrices to capture specific geometric characteristics of the data, which increases the complexity of hard-coding them. To alleviate this difficulty, the Learning from Demonstration (LfD) paradigm can be used in order to learn robot manipulation skills with specific geometric constraints encapsulated in SPD matrices. Learned skills often need to be adapted when they are applied to new situations. While existing techniques can adapt Cartesian and joint space trajectories described by various desired points, the adaptation of motion skills encapsulated in SPD matrices remains an open problem. In this paper, we introduce a new LfD framework that can learn robot manipulation skills encapsulated in SPD matrices from expert demonstrations and adapt them to new situations defined by new start-, via- and end-matrices. The proposed approach leverages Kernelized Movement Primitives (KMPs) to generate SPD-based robot manipulation skills that smoothly adapt the demonstrations to conform to new constraints. We validate the proposed framework using a couple of simulations in addition to a real experiment scenario.","Learning from demonstration, Variable impedance, Robot learning, Manipulability ellipsoids, Riemannian manifolds",Fares J. Abu-Dakka and Yanlong Huang and João Silvério and Ville Kyrki,https://www.sciencedirect.com/science/article/pii/S0921889021000464,https://doi.org/10.1016/j.robot.2021.103761,0921-8890,2021,103761,141,Robotics and Autonomous Systems,A probabilistic framework for learning geometry-based robot manipulation skills,article,ABUDAKKA2021103761
"Humanoid robots generated by inspiring by human appearances and abilities have became essential in human society to improve the quality of their life. All over the world, there have been many researchers who have focused on humanoid robots to develop the capabilities of humanoid robots. Generally, humanoid robot systems include mechanisms of decision making and information processing. Because of the uncertainty behind decision making and information processes, fuzzy sets are used most commonly. This study investigates a comprehensive literature review about humanoid robots that presents the recent technological developments and the theories associated with fuzzy set models. The basic principles and concepts of fuzzy sets for humanoid robots are presented.","Humanoid robots, Robots, Fuzzy control, Fuzzy sets, Classification",Cengiz Kahraman and Muhammet Deveci and Eda Boltürk and Seda Türk,https://www.sciencedirect.com/science/article/pii/S0921889020304838,https://doi.org/10.1016/j.robot.2020.103643,0921-8890,2020,103643,134,Robotics and Autonomous Systems,Fuzzy controlled humanoid robots: A literature review,article,KAHRAMAN2020103643
"In this study, a new convex optimization (CO) approach to time-optimal trajectory planning (TOTP) is described, which considers both torque and jerk limits. The key insight of the approach is that the non-convex jerk limits are transformed to linear acceleration constraints and indirectly introduced into CO as the linear acceleration constraints. In this way, the convexity of CO will not be destroyed and the number of optimization variables will not increase, which give the approach a fast computation speed. The proposed approach is implemented on random geometric path of a 6-DOF manipulator. Compared with a similar method, the results show that the torque and jerk limits are addressed by a reasonable increase in the computation time. In addition, the maximum value of joint jerk reduces by over 80% and the joint torque curves are smoother in the comparison, which demonstrates that this approach has the ability to effectively restrain acceleration mutation.","Robotic system, Time-optimal trajectory planning, Convex optimization, Torque limits, Jerk limits",Jian-wei Ma and Song Gao and Hui-teng Yan and Qi Lv and Guo-qing Hu,https://www.sciencedirect.com/science/article/pii/S0921889021000294,https://doi.org/10.1016/j.robot.2021.103744,0921-8890,2021,103744,140,Robotics and Autonomous Systems,A new approach to time-optimal trajectory planning with torque and jerk limits for robot,article,MA2021103744
"This paper addresses the challenging concept of Assist-As-Needed control of exoskeleton robots. The proposed controller boosts the voluntary participation of the patient by providing assistance according to the ability of the wearer in performing the assigned task. A novel strength index is presented that combines interaction force and position-tracking error into a single quantity to estimate the physical strength of the wearer during the therapy. The estimated strength is used to adjust the boundaries of a virtual tunnel around the desired trajectory, defined to assume a degree of freedom for the wearer?s motions and to compensate for asymmetric gait patterns. The required assistance is then defined by an adaptive impedance controller according to the distance of the tracking error from the tunnel boundaries. To ensure that the assistance is accurately supplied to the patient, an adaptive torque controller is integrated into the control loop. The adaptive torque controller uses a generalized fuzzy hyperbolic model to compensate for the inherent impedance of the exoskeleton. Simulation results on a hemiplegic model show that the proposed index can estimate the wearer?s strength properly and the proposed assist-as-needed controller can reduce the tracking error. The performance of the proposed method is also evaluated experimentally on a healthy subject wearing a hip exoskeleton. The results verify that the proposed method can be used in a variety of therapeutic applications where it is important to track the desired trajectory with minimum interventions.","Adaptive torque controller, Assist-As-Needed controller, Generalized fuzzy hyperbolic model, Hip assistive exoskeleton, Strength index",Naeim Naghavi and Alireza Akbarzadeh and S. Mohammad Tahamipour-Z. and Iman Kardan,https://www.sciencedirect.com/science/article/pii/S0921889020305078,https://doi.org/10.1016/j.robot.2020.103667,0921-8890,2020,103667,134,Robotics and Autonomous Systems,Assist-As-Needed control of a hip exoskeleton based on a novel strength index,article,NAGHAVI2020103667
"Robots are increasingly exploited in production plants. Within the Industry 4.0 paradigm, the robot complements the human?s capabilities, learning new tasks and adapting itself to compensate for uncertainties. With this aim, the presented paper focuses on the investigation of machine learning techniques to make a sensorless robot able to learn and optimize an industrial assembly task. Relying on sensorless Cartesian impedance control, two main contributions are defined: (1) a task-trajectory learning algorithm based on a few human?s demonstrations (exploiting Hidden Markov Model approach), and (2) an autonomous optimization procedure of the task execution (exploiting Bayesian Optimization). To validate the proposed methodology, an assembly task has been selected as a reference application. The task consists of mounting a gear into its square-section shaft on a fixed base to simulate the assembly of a gearbox. A Franka EMIKA Panda manipulator has been used as a test platform, implementing the proposed methodology. The experiments, carried out on a population of 15 subjects, show the effectiveness of the proposed strategy, making the robot able to learn and optimize its behavior to accomplish the assembly task, even in the presence of task uncertainties.",,Loris Roveda and Mauro Magni and Martina Cantoni and Dario Piga and Giuseppe Bucca,https://www.sciencedirect.com/science/article/pii/S0921889020305510,https://doi.org/10.1016/j.robot.2020.103711,0921-8890,2021,103711,136,Robotics and Autonomous Systems,Human?robot collaboration in sensorless assembly task learning enhanced by uncertainties adaptation via Bayesian Optimization,article,ROVEDA2021103711
"In the recent years, many studies claim that humans have a unique driving behavior style that could be used as a fingerprint in recognizing the identity of the driver. With the rising evolution of Machine Learning (ML), the research efforts aiming to take advantage of the human driving style identifiers have been increasing exponentially. For Advanced Driver Assistance Systems (ADAS), this attribute can be an efficient factor to ensure the security and protection of the vehicle. Additionally, it extends the ADAS capabilities by creating different profiles for the drivers, which helps every driver according to his own driving style and improve the ADAS fidelity. Nonetheless, certain problems in the unpredictability of human behavior and the effectiveness of capturing the temporal features of the signal represented an ongoing challenge to accomplish driver identification. In this paper, we propose a novel deep learning approach to driver identification based on a Residual Convolutional Network (RCN). This approach outperforms the existing state of the art methods in less than two hours of training, while simultaneously achieving 99.3% accuracy. The used data are exclusively provided by the Controller Area Network (CAN-Bus) vehicle data that eliminates any privacy invading concerns from the user.","Driver behavior, Identification, Machine learning, CNN, Residual neural network, Classification",N. Abdennour and T. Ouni and N. Ben Amor,https://www.sciencedirect.com/science/article/pii/S0921889020305479,https://doi.org/10.1016/j.robot.2020.103707,0921-8890,2021,103707,136,Robotics and Autonomous Systems,Driver identification using only the CAN-Bus vehicle data through an RCN deep learning approach,article,ABDENNOUR2021103707
"Real-time robotic grasping, supporting a subsequent precise object-in-hand operation task, is a priority target towards highly advanced autonomous systems. However, such an algorithm which can perform sufficiently-accurate grasping with time efficiency is yet to be found. This paper proposes a novel method with a 2-stage approach that combines a fast 2D object recognition using a deep neural network and a subsequent accurate and fast 6D pose estimation based on Point Pair Feature framework to form a real-time 3D object recognition and grasping solution capable of multi-object class scenes. The proposed solution has a potential to perform robustly on real-time applications, requiring both efficiency and accuracy. In order to validate our method, we conducted extensive and thorough experiments involving laborious preparation of our own dataset. The experiment results show that the proposed method scores 97.37% accuracy in 5cm5deg metric and 99.37% in Average Distance metric. Experiment results have shown an overall 62% relative improvement (5cm5deg metric) and 52.48% (Average Distance metric) by using the proposed method. Moreover, the pose estimation execution also showed an average improvement of 47.6% in running time. Finally, to illustrate the overall efficiency of the system in real-time operations, a pick-and-place robotic experiment is conducted and has shown a convincing success rate with 90% of accuracy. This experiment video is available at https://sites.google.com/view/dl-ppf6dpose/.","6D pose estimation, Random bin-picking, Deep learning, Point pair feature",Tuan-Tang Le and Trung-Son Le and Yu-Ru Chen and Joel Vidal and Chyi-Yeu Lin,https://www.sciencedirect.com/science/article/pii/S0921889021000609,https://doi.org/10.1016/j.robot.2021.103775,0921-8890,2021,103775,141,Robotics and Autonomous Systems,6D pose estimation with combined deep learning and 3D vision techniques for a fast and accurate object grasping,article,LE2021103775
"For sensory data fusion, a calibration method between 3D light detection and ranging (LiDAR) and color camera based on ranging statistical characteristics and improved RANSAC algorithm is proposed. The multi-frame LiDAR point cloud data of the calibration triangular board are recorded. The scanned points with close angles are defined a cluster within same degrees. Furthermore, accurate points are preserved using statistical filtering based on Gaussian distribution. Afterwards, the plane and edge parameters of the triangular board are estimated by the reserved point cloud using improved the random sample consensus (RANSAC) algorithm to obtain the 3D locations of the vertices. Meanwhile, corner points in the image can be extracted manually. Finally, the projection matrix between the camera and the LiDAR is estimated by using the 2D?3D? correspondences in different positions. The projection errors of different frames and corresponding points are calculated. The results demonstrate that the average error with 300 frames is reduced by 23.05% compared to 1 frame. Moreover, the standard deviation diminishes with the increasing of corresponding points. The reliability and advantage of the method are verified compared with other state-of-art methods. It provides theoretical and technical support for low resolution LiDAR.","LiDAR, Color camera, Statistical filtering, Adjacent points, Improved RANSAC method",Xiaobin Xu and Lei Zhang and Jian Yang and Cong Liu and Yiyang Xiong and Minzhou Luo and Zhiying Tan and Bo Liu,https://www.sciencedirect.com/science/article/pii/S0921889021000610,https://doi.org/10.1016/j.robot.2021.103776,0921-8890,2021,103776,141,Robotics and Autonomous Systems,LiDAR?camera calibration method based on ranging statistical characteristics and improved RANSAC algorithm,article,XU2021103776
"This paper introduces a concept of safe path planning for UAV?s autonomous operation in an urban environment where GNSS-positioning may become unreliable or even unavailable. If the operation environment is a priori known and geo-localized, it is possible to predict a GNSS satellite constellation and hence to anticipate its signal occlusions at a given point and time. Motivated from this, our main idea is to utilize such sensor availability map in path planning task for ensuring UAV navigation safety. The proposed concept is implemented by a Partially Observable Markov Decision Process (POMDP) model. It incorporates a low-level navigation and guidance module for propagating the UAV state uncertainty in function of the probabilistic sensor availability. A new definition of cost function is introduced in this model such that the resulting optimal policy respects a user-defined safety requirement. A goal-oriented version of Monte-Carlo Tree Search algorithm, called POMCP-GO, is proposed for POMDP solving. The developed safe path planner is evaluated on two simple obstacle benchmark maps as well as on a real elevation map of San Diego downtown, along with GPS availability maps.","Navigation, Path planning, POMDP, PO-SSP, UAV, Safety",Jean-Alexis Delamer and Yoko Watanabe and Caroline P.C. Chanel,https://www.sciencedirect.com/science/article/pii/S0921889021000853,https://doi.org/10.1016/j.robot.2021.103800,0921-8890,2021,103800,142,Robotics and Autonomous Systems,Safe path planning for UAV urban operation under GNSS signal occlusion risk,article,DELAMER2021103800
"For effective verbal communication in collaborative tasks, robots need to account for the different perspectives of their human partners when referring to objects in a shared space. For example, when a robot helps its partner find correct pieces while assembling furniture, it needs to understand how its collaborator perceives the world and refer to objects accordingly. In this work, we propose a method to endow robots with perspective-taking abilities while spatially referring to objects. To examine the impact of our proposed method, we report the results of a user study showing that when the objects are spatially described from the users? perspectives, participants take less time to find the referred objects, find the correct objects more often and consider the task easier.","Perspective-taking, Spatial referring expressions",Fethiye Irmak Do?an and Sarah Gillet and Elizabeth J. Carter and Iolanda Leite,https://www.sciencedirect.com/science/article/pii/S0921889020304942,https://doi.org/10.1016/j.robot.2020.103654,0921-8890,2020,103654,134,Robotics and Autonomous Systems,The impact of adding perspective-taking to spatial referencing during human?robot interaction,article,DOGAN2020103654
"The paper at hand introduces a novel system for producing an enhanced semantic map that leverages a reconstruction approach of street-view scenes using computer vision and machine learning techniques. Focusing on the recognition and localization of objects/entities, the composed map combines semantic information from publicly available, yet of lower accuracy, satellite images, with more detailed data from ground-level camera measurements. This merging is achieved by utilizing odometry information from a street-moving vehicle and the 3D reconstruction of its recorded view. Then, the 3D semantic segmentation results are georeferenced and superimposed on the semantic map from the satellite images. In such a way, areas that require fine semantic accuracy can be improved, while the rest are left with the segmentation results of the satellite information. Every part of the proposed system is individually evaluated. We additionally test the overall approach on a case-study of georeferencing new labels of traffic signs, which are detected through a specifically designed classification network over a publicly available dataset collected around the city of Berlin.","Semantic segmentation, Semantic maps, Machine learning, Deep Neural Networks, 3D reconstruction, Street and satellite images",Vasiliki Balaska and Loukas Bampis and Ioannis Kansizoglou and Antonios Gasteratos,https://www.sciencedirect.com/science/article/pii/S0921889021000452,https://doi.org/10.1016/j.robot.2021.103760,0921-8890,2021,103760,139,Robotics and Autonomous Systems,Enhancing satellite semantic maps with ground-level imagery,article,BALASKA2021103760
"Hand-assistive devices are used to help post-stroke victims encumbered with hand impairments perform activities of daily living (ADL). Unlike robotic rehabilitation devices used in restricted medical conditions for designated periods, hand-assistive devices are designed to be portable and to be used for extended periods by individuals engaging in ADL. Several hand-assistive device designs have been proposed. With these, designers have focused on key elements, such as size, weight, motion profile of the fingers, and generated grip/pinch force. In this paper, we propose a unique compact hand-assistive device (CHAD) that incorporates most of these design parameters, but with less trade-offs. CHAD consists of a single unit worn on the patient?s forearm, which includes all necessary components. It is compact and does not compromise functionality. The novelty of this design can be found in the use of a unique cable-driven mechanism. This mechanism uses dual linear actuators to achieve the flexion of both the index and the middle fingers via the pull of tendon-like structures originating in two selected interphalangeal joints. This permits the numerous necessary sequences in the motion profiles of the digits. The thumb is also made able to flex with a single linear actuator. Finger extensions, in contrast, are achieved passively via adjustable flexible rubber cords joined to the dorsal side of the glove. Experimental results demonstrate that CHAD generates sufficient force and motion profiles for the comfortable execution of ADL. Additionally, CHAD produces a grip and pinch motion profile similar to that of a natural hand and does not force unwanted muscle activities.","Assistive wearable robot, Post-stroke, Activities of daily living, Soft robotic glove",Fady Alnajjar and Hassan Umari and Waleed K. Ahmed and Munkhjargal Gochoo and Alistair A. Vogan and Adel Aljumaily and Peer Mohamad and Shingo Shimoda,https://www.sciencedirect.com/science/article/pii/S0921889021000695,https://doi.org/10.1016/j.robot.2021.103784,0921-8890,2021,103784,142,Robotics and Autonomous Systems,CHAD: Compact Hand-Assistive Device for enhancement of function in hand impairments,article,ALNAJJAR2021103784
"This paper presents a state-of-the-art filter that reduces the complexity in object detection, tracking and mapping applications. Existing edge detection and tracking methods are proposed to create suitable autonomy for mobile robots, however, many of them face overconfidence and large computations at the entrance to scenarios with an immense number of landmarks. The method in this work, the Line?Circle?Square (LCS) filter, claims that mobile robots without a large database for object recognition and highly advanced prediction methods can deal with incoming objects that the camera captures in real-time. The proposed filter applies detection, tracking and learning to each defined expert to extract higher level information for judging scenes without over-calculation. The interactive learning feed between each expert increases the consistency of detected landmarks that works against overwhelming detected features in crowded scenes. Our experts are dependent on trust factors? covariance under the geometric definitions to ignore, emerge and compare detected landmarks. The experiment validates the effectiveness of the proposed filter in terms of detection precision and resource usage in both experimental and real-world scenarios.","Edge detection, Motion field, Geometric filter, Vision",Seyed Amir Tafrishi and Xiaotian Dai and Vahid {Esmaeilzadeh Kandjani},https://www.sciencedirect.com/science/article/pii/S0921889021000178,https://doi.org/10.1016/j.robot.2021.103732,0921-8890,2021,103732,137,Robotics and Autonomous Systems,Line?Circle?Square (LCS): A multilayered geometric filter for edge-based detection,article,TAFRISHI2021103732
"Magnetic actuation techniques and microrobots have attracted great interest since they have potential in biomedicine applications. Interventional techniques have emerged as a tool to handle a wide range of minimally invasive surgeries (MIS). However, current MIS procedures are constrained by the limitation of manual operation by surgeon. Thus, various microrobotic solutions including magnetic navigation systems have been proposed for MIS, which carries many potential benefits such as reduced incision, less intraoperative hemorrhaging and postoperative pain, and faster recovery time. In recent decades, many electromagnetic actuation (EMA) systems have been reported and involved to general surgery. The EMA system allows to generate efficiently magnetic source for microrobot control when its specifications are further investigated and satisfied for the desired application. To precisely manipulate the biomedical microrobot, a key issue still relies on the design of a suitable EMA platform. In this paper, we demonstrate a mathematical approach for the design configuration of magnetic system with multiple electromagnets. Especially, the required magnetic coil number has been investigated where the heading motion control, magnetic force control and their combination control are discussed respectively. The singular cases of control are pre-evaluated by a mathematical analysis of the simulated electromagnetic field. In addition, the placed positions and tilted orientations of the applied electromagnets are investigated for the optimization regarding the six typical configurations of EMA platform with 4, 6 and 8 coils. The various configurations of EMA systems have been comprehensively analyzed. Therefore, with the number of electromagnets and their optimal configuration obtained by the proposed approach, the EMA system can be initially established.","Electromagnetic actuation system, Magnetic microrobot, Design methodology, Robotic magnetic platform",Ruipeng Chen and David Folio and Antoine Ferreira,https://www.sciencedirect.com/science/article/pii/S0921889020305145,https://doi.org/10.1016/j.robot.2020.103674,0921-8890,2021,103674,135,Robotics and Autonomous Systems,Mathematical approach for the design configuration of magnetic system with multiple electromagnets,article,CHEN2021103674
"Pattern formation for multi-robot systems has received increasing attention in different scenarios. However, existing methods cannot efficiently optimize pattern formation in the obstacle environment. To address this limitation, this paper proposes a new planning method that assigns the optimal goals to the robots and iteratively computes collision-free paths to reach goal positions. Firstly, according to the random initial position of the group robot and the arbitrary shape, convex quadratic programming is used to minimize the distance to obtain the optimal pattern parameters under certain constraints. Secondly, the iterative controller plans the collision-free path of each robot to the goal considering a preferred velocity. Simulation results verified the effectiveness of the proposed methodology for scenarios of letter formation, in comparison to a commonly-used method.","Multi-robot systems, Pattern formation, Convex quadratic programming, Collision avoidance",Fangfang Zhang and Tingting Wang and Qiyan Li and Jianbin Xin,https://www.sciencedirect.com/science/article/pii/S0921889020304851,https://doi.org/10.1016/j.robot.2020.103645,0921-8890,2020,103645,133,Robotics and Autonomous Systems,An iterative optimization approach for multi-robot pattern formation in obstacle environment,article,ZHANG2020103645
"Autonomous driving and driver assistance require a continuous and reliable perception of the road boundaries, namely curbs and berms, including also other minor, or not so minor, obstacles in the neighborhood of the car. This paper proposes to use a 4-layer LIDAR placed close to the ground to capture measurements of the road ahead of the car and allow the detection of the boundaries. This setup provides a special point of view that allows the accumulation of points on vertical surfaces on the road as the car moves, which increases the point density in vertical surfaces but keeps it limited in horizontal surfaces. This technique allows to successfully distinguish curbs from the flat parts of the road. However, this approach has some limitations, namely to detect berms, and another approach had to be developed using the gradient of point density, which extends the detection capabilities to berms and negative obstacles. This is achieved by flattening the point clouds to 2D and use traditional computer vision gradient and edge detection techniques, which also improves the processing speed. Results are obtained on the ATLASCAR real system, at different velocities, and a good performance is reached when comparing to a manually created ground truth.","LIDAR, Road curbs, Point clouds, Occupancy grid, Gradient",Daniela Rato and Vítor Santos,https://www.sciencedirect.com/science/article/pii/S0921889020305546,https://doi.org/10.1016/j.robot.2020.103714,0921-8890,2021,103714,138,Robotics and Autonomous Systems,LIDAR based detection of road boundaries using the density of accumulated point clouds and their gradients,article,RATO2021103714
"Understanding of the driving scenario represents a necessary condition for autonomous driving. Within the control routine of an autonomous vehicle, it represents the preliminary step for the motion planning system. Estimation algorithms hence need to handle a considerable number of information coming from multiple sensors, to provide estimates regarding the motion of ego-vehicle and surrounding obstacles. Furthermore, tracking is crucial in obstacles state estimation, because it ensures obstacles recognition during time. This paper presents an integrated algorithm for the estimation of ego-vehicle and obstacles? positioning and motion along a given road, modeled in curvilinear coordinates. Sensor fusion deals with information coming from two Radars and a Lidar to identify and track obstacles. The algorithm has been validated through experimental tests carried on a prototype of an autonomous vehicle.","Obstacles tracking, Sensor fusion, State estimation, Autonomous driving",Mattia Bersani and Simone Mentasti and Pragyan Dahal and Stefano Arrigoni and Michele Vignati and Federico Cheli and Matteo Matteucci,https://www.sciencedirect.com/science/article/pii/S0921889020305029,https://doi.org/10.1016/j.robot.2020.103662,0921-8890,2021,103662,139,Robotics and Autonomous Systems,An integrated algorithm for ego-vehicle and obstacles state estimation for autonomous driving,article,BERSANI2021103662
"Just like humans, robots can improve their performance by practicing, i.e. by performing the desired behavior many times and updating the underlying skill representation using the newly gathered data. In this paper, we propose to implement robot practicing by applying statistical and reinforcement learning (RL) in a latent space of the selected skill representation. The latent space is computed by a deep autoencoder neural network, with the data to train the network generated in simulation. However, we show that the resulting latent space representation is useful also for learning on a real robot. Our simulation and real-world results demonstrate that by exploiting the latent space of the underlying motor skill representation, a significant reduction of the amount of data needed for effective learning by Gaussian Process Regression (GPR) can be achieved. Similarly, the number of RL epochs can be significantly reduced. Finally, it is evident from our results that an autoencoder-based latent space is more effective for these purposes than a latent space computed by principal component analysis.","Skill learning, Latent space representations, Deep autoencoder neural networks",Rok Pahi? and Zvezdan Lon?arevi? and Andrej Gams and Ale? Ude,https://www.sciencedirect.com/science/article/pii/S0921889020305303,https://doi.org/10.1016/j.robot.2020.103690,0921-8890,2021,103690,135,Robotics and Autonomous Systems,Robot skill learning in latent space of a deep autoencoder neural network,article,PAHIC2021103690
"This paper takes a novel look at formation control by comparing control setups based on two very different frameworks. These are applied to the distributed control of communicating omnidirectional mobile robots. One framework, which is possibly the most common approach to formation control, is based on algebraic graph theory, whereas the other, namely distributed model predictive control (DMPC), is based on distributed optimization, representing a rather uncommon view on the task. In this study, formation control is understood as the task of attaining and maintaining a specific relative positioning between robotic agents while moving the formation through the environment. While interesting on its own, formation control can serve as the basis for superordinate tasks like cooperative transportation. For an encompassing treatment of the task, two different control goals are considered, resulting in different setups for each control framework. One goal consists of moving the formation?s geometric center to a specific position, whereas the other aims at letting the whole formation move with the desired velocity. In both cases, the involved robots are subject to input constraints. Already during control design, some qualitative differences between the two frameworks become apparent, with the DMPC controller exhibiting characteristic beneficial qualities in exchange for its higher computational demand. Results from various simulation scenarios confirm these observations. Considerations on the practical implementation of the two schemes, as well as hardware experiments with tailor-made mobile robots, provide valuable insight for robotics practitioners, and highlight the applicability of the two frameworks.","Formation control, Model predictive control, Distributed control, Algebraic graph theory, Mobile robots, Robotic network, Experiments",Henrik Ebel and Peter Eberhard,https://www.sciencedirect.com/science/article/pii/S0921889020305261,https://doi.org/10.1016/j.robot.2020.103686,0921-8890,2021,103686,136,Robotics and Autonomous Systems,A comparative look at two formation control approaches based on optimization and algebraic graph theory,article,EBEL2021103686
"This paper proposes a unified vision-based manipulation framework using image contours of deformable/rigid objects. Instead of explicitly defining the features by geometries or functions, the robot automatically learns the visual features from processed vision data. Our method simultaneously generates ? from the same data ? both visual features and the interaction matrix that relates them to the robot control inputs. Extraction of the feature vector and control commands is done online and adaptively, and requires little data for initialization. Our method allows the robot to manipulate an object without knowing whether it is rigid or deformable. To validate our approach, we conduct numerical simulations and experiments with both deformable and rigid objects.","Visual servoing, Sensor-based control, Deformable object manipulation",Jihong Zhu and David Navarro-Alarcon and Robin Passama and Andrea Cherubini,https://www.sciencedirect.com/science/article/pii/S092188902100083X,https://doi.org/10.1016/j.robot.2021.103798,0921-8890,2021,103798,142,Robotics and Autonomous Systems,Vision-based manipulation of deformable and rigid objects using subspace projections of 2D contours,article,ZHU2021103798
"Accurate prediction of acoustic communication performance is an important capability for marine robots. In this paper, we propose a model-based learning methodology for the prediction of underwater acoustic communication performance. The learning algorithm consists of two steps: (i) estimation of the covariance matrix by evaluating candidate functions with estimated parameters using detrended measurements;and (ii) prediction of communication performance. Covariance estimation is addressed with a multi-stage iterative training method that produces unbiased and robust results with nested models. The efficiency of the framework is validated with simulations and experimental data from field trials. The field trials involved a manned surface vehicle and an autonomous underwater vehicle.","Model-based learning, Autonomous underwater vehicles, Wireless communications, Spatial statistics, Kriging",George P. Kontoudis and Stephen Krauss and Daniel J. Stilwell,https://www.sciencedirect.com/science/article/pii/S0921889021000968,https://doi.org/10.1016/j.robot.2021.103811,0921-8890,2021,103811,142,Robotics and Autonomous Systems,Model-based learning of underwater acoustic communication performance for marine robots,article,KONTOUDIS2021103811
"A robotic system for the reduction of fractured femur bone is proposed in this research to help orthopedics during the labor intensive bone reduction procedures and also save them from radiation stimulated environment. Fractured femur reduction is a good candidate for robotics application owing to its elongated anatomy and strong counteracting forces from surrounding muscles. However, the robot forces should be compliant, and motions need to be accurate. Aiming to achieve these two conflicting objective, a parallel robot actuated by six intrinsically compliant actuators is being proposed here. After an initial design analysis, three performance metrics, namely, the conditioning index, actuator force index and interaction compliance index were identified and formulated. An evolutionary algorithm SPEA2 was employed to simultaneously optimize these objectives by varying the key robot design variables. Subsequent to the optimization, an optimal robot design is obtained which provides the best trade-off between the performance measures. Initial proof of concept experiments were carried out whereby the robot was tested for trajectory following accuracies while maneuvering the moving platform about the three axes. A fuzzy based closed loop feedback controller was implemented on the robot. Excellent trajectory tracking results were observed in response to the sinusoidal inputs.","Femur, Fracture reduction, Parallel robot, Compliant actuation, Robot control, Optimization",Prashant K. Jamwal and Shahid Hussain and Mergen H. Ghayesh,https://www.sciencedirect.com/science/article/pii/S0921889021000725,https://doi.org/10.1016/j.robot.2021.103787,0921-8890,2021,103787,141,Robotics and Autonomous Systems,Intrinsically compliant parallel robot for fractured femur reduction: Mechanism optimization and control,article,JAMWAL2021103787
"Human-joint-position estimation is crucial for patient-transfer robots. However, high accuracy and real-time property are difficult to achieve simultaneously. To tackle the problem, we develop a new convolutional neural network (CNN), containing two levels of subnetworks, to fuse the information in color and depth images. The first-level subnetwork generates two-dimensional (2D) human joint positions from a color image by the part-affinity-fields method. The second-level subnetwork estimates 3D human-joint positions from 2D ones and corresponding depth images. Here, strong feature-extraction function of the CNN may suppress the negative effect caused by invalid information in depth images. Meanwhile, all the estimations are implemented with the 2D CNNs, which may cause higher time-efficiency than 3D ones (mostly used in previous studies). To assess the validity, first we employed the CNN to estimate human joint positions, and obtained the accuracy and speed of respectively 90.3% and 210 ms (implemented with an affordable processing unit). Then we applied the CNN to a dual-arm nursing-care robot and found that the accuracy and processing speed satisfied the requirements in practical usage; these validated the effectiveness of our proposal and provided a new approach to generate 3D-human-joint positions through information fusion of color and depth images.","Patient-transfer robot, Human-joint-position estimation, Information fusion, Convolution neural network",Mengqian Chen and Jiang Wu and Shunda Li and Jinyue Liu and Hideo Yokota and Shijie Guo,https://www.sciencedirect.com/science/article/pii/S0921889021000208,https://doi.org/10.1016/j.robot.2021.103735,0921-8890,2021,103735,139,Robotics and Autonomous Systems,Accurate and real-time human-joint-position estimation for a patient-transfer robot using a two-level convolutional neutral network,article,CHEN2021103735
"In the last decades, visual target tracking has been one of the primary research interests of the Robotics research community. The recent advances in Deep Learning technologies have made the exploitation of visual tracking approaches effective and possible in a wide variety of applications, ranging from automotive to surveillance and human assistance. However, the majority of the existing works focus exclusively on passive visual tracking, i.e., tracking elements in sequences of images by assuming that no actions can be taken to adapt the camera position to the motion of the tracked entity. On the contrary, in this work, we address visual active tracking, in which the tracker has to actively search for and track a specified target. Current State-of-the-Art approaches use Deep Reinforcement Learning (DRL) techniques to address the problem in an end-to-end manner. However, two main problems arise: (i) most of the contributions focus only on discrete action spaces, and the ones that consider continuous control do not achieve the same level of performance; and (ii) if not properly tuned, DRL models can be challenging to train, resulting in considerably slow learning progress and poor final performance. To address these challenges, we propose a novel DRL-based visual active tracking system that provides continuous action policies. To accelerate training and improve the overall performance, we introduce additional objective functions and a Heuristic Trajectory Generator (HTG) to facilitate learning. Through extensive experimentation, we show that our method can reach and surpass other State-of-the-Art approaches performances, and demonstrate that, even if trained exclusively in simulation, it can successfully perform visual active tracking even in real scenarios.","Visual active tracking, Deep learning for robotic applications, Reinforcement learning",Alessandro Devo and Alberto Dionigi and Gabriele Costante,https://www.sciencedirect.com/science/article/pii/S0921889021000841,https://doi.org/10.1016/j.robot.2021.103799,0921-8890,2021,103799,142,Robotics and Autonomous Systems,Enhancing continuous control of mobile robots for end-to-end visual active tracking,article,DEVO2021103799
"The spread of the use of robotic devices in neuro-rehabilitation therapies requires the availability of lightweight, easy-to-use, cost-effective and versatile systems. RobHand has been designed with these goals in mind. It is a hand exoskeleton especially suitable for patients suffering from spasticity in the fingers since it is easy to place in the hand and, from an underactuated design, allows both flexion and extension of the fingers. In this work, the structural characteristics, the mechanical design and the development and validation of the kinematic model of the device are presented, all of which has been carried out taking into account the recommendations of the new IEC 80601-2-78 standard, which formalizes the concept of RACA (Rehabilitation, Assessment, Compensation, Alleviation) robot and addresses aspects of efficiency and safety, essential in this type of equipment.","RACA robots, Hand exoskeleton, Stroke rehabilitation, Underactuated mechanisms, Mechanical design, Kinematic model",Victor Moreno-SanJuan and Ana Cisnal and Juan-Carlos Fraile and Javier Pérez-Turiel and Eusebio de-la-Fuente,https://www.sciencedirect.com/science/article/pii/S0921889021001135,https://doi.org/10.1016/j.robot.2021.103828,0921-8890,2021,103828,143,Robotics and Autonomous Systems,Design and characterization of a lightweight underactuated RACA hand exoskeleton for neurorehabilitation,article,MORENOSANJUAN2021103828
"In the problem of driving forces/torques distribution of the redundantly actuated parallel mechanisms (PMs), although numerous optimization analysis methods, including the minimum input torque method and minimum energy consumption method have been proposed so far, however, the actual control modes of the actuators were not taken into account among the existing methods for the above problem. Therefore, the present study comprehensively considers both the elastic deformation and actuator?s displacement of each limb, proposes the idea of ?displacement coordination? and establishes the overall displacement coordination equations of the mechanisms. Three different control methodologies of the redundantly actuated PMs, including the full-position methodology, hybrid position?force control methodology and full-force methodology, are studied. For each control methodology, the correlation among the driving forces/torques, actuators? displacements, external loads and limbs? stiffness are discussed. An experimental platform of a redundantly actuated PM is built, and the corresponding test investigations for three control methodologies are conducted. In the present study, different control methodologies of the redundantly actuated PMs are considered for the first time, the principle of the dynamic coordination distribution is revealed in different methodologies, which have important reference values for design of coordinated motion control strategy of such kind of mechanisms.","Parallel robots, Redundantly actuated, Force?control",Yundou Xu and Ze Jiang and Zhongjin Ju and Zengzhao Wang and Wenlan Liu and Yongsheng Zhao,https://www.sciencedirect.com/science/article/pii/S0921889021000683,https://doi.org/10.1016/j.robot.2021.103783,0921-8890,2021,103783,142,Robotics and Autonomous Systems,Force analysis of the redundantly actuated parallel mechanism 2RP?R+P considering different control methodologies,article,XU2021103783
"In this paper, we propose a two-stage learning framework for visual navigation in which the experience of the agent during exploration of one goal is shared to learn to navigate to other goals. We train a deep neural network for estimating the robot?s position in the environment using ground truth information provided by a classical localization and mapping approach. The second simpler multi-goal Q-function learns to traverse the environment by using the provided discretized map. Transfer learning is applied to the multi-goal Q-function from a maze structure to a 2D simulator and is finally deployed in a 3D simulator where the robot uses the estimated locations from the position estimator deep network. In the experiments, we first compare different architectures to select the best deep network for location estimation, and then compare the effects of the multi-goal reinforcement learning method to traditional reinforcement learning. The results show a significant improvement when multi-goal reinforcement learning is used. Furthermore, the results of the location estimator show that a deep network can learn and generalize in different environments using camera images with high accuracy in both position and orientation.","Robotic navigation, Reinforcement learning, Deep neural networks, Localization and mapping, Robot simulation",Amirhossein Shantia and Rik Timmers and Yiebo Chong and Cornel Kuiper and Francesco Bidoia and Lambert Schomaker and Marco Wiering,https://www.sciencedirect.com/science/article/pii/S0921889021000166,https://doi.org/10.1016/j.robot.2021.103731,0921-8890,2021,103731,138,Robotics and Autonomous Systems,Two-stage visual navigation by deep neural networks and multi-goal reinforcement learning,article,SHANTIA2021103731
"In this paper, we study Emergency Landing Aware Surveillance Planning (ELASP) to determine a cost-efficient trajectory to visit a given set of target locations such that a safe emergency landing is possible at any point of the multi-goal trajectory. The problem is motivated to guarantee a safe mission plan in a case of loss of thrust for which it is desirable to have a safe gliding trajectory to a nearby airport. The problem combines computational challenges of the combinatorial multi-goal planning with demanding motion planning to determine safe landing trajectories for the curvature-constrained aerial vehicle. The crucial property of safe landing is a minimum safe altitude of the vehicle that can be found by trajectory planning to nearby airports using sampling-based motion planning such as RRT*. A trajectory is considered safe if the vehicle is at least at the minimum safe altitude at any point of the trajectory. Thus, a huge number of samples have to be evaluated to guarantee the safety of the trajectory, and an evaluation of all possible multi-goal trajectories is quickly computationally intractable. Therefore, we propose to utilize a roadmap of safe altitudes combined with the estimation of the trajectory lengths to evaluate only the most promising candidate trajectories. Based on the reported results, the proposed approach significantly reduces the computational burden and enables a solution of ELASP instances with tens of locations in units of minutes using standard single-core computational resources.","Unmanned aerial vehicle, Surveillance planning, Emergency landing guarantee",Petr Vá?a and Jakub Sláma and Jan Faigl,https://www.sciencedirect.com/science/article/pii/S092188902030484X,https://doi.org/10.1016/j.robot.2020.103644,0921-8890,2020,103644,133,Robotics and Autonomous Systems,Surveillance planning with safe emergency landing guarantee for fixed-wing aircraft,article,VANA2020103644
"Simultaneous localization and mapping is a fundamental process in robot navigation. We focus on LiDAR to complete this process in ground robots traveling on complex terrain by proposing GR-LOAM, a method to estimate robot ego-motion by fusing LiDAR, inertial measurement unit (IMU), and encoder measurements in a tightly coupled scheme. First, we derive a odometer increment model that fuses the IMU and encoder measurements to estimate the robot pose variation on a manifold. Then, we apply point cloud segmentation and feature extraction to obtain distinctive edge and planar features. Moreover, we propose an evaluation algorithm for the sensor measurements to detect abnormal data and reduce their corresponding weight during optimization. By jointly optimizing the cost derived from the LiDAR, IMU, and encoder measurements in a local window, we obtain low-drift odometry even on complex terrain. We use the estimated relative pose in the local window to reevaluate the matching distance across features and remove dynamic objects and outliers, thus refining the features before being fed to a mapping thread and increasing the mapping efficiency. In the back end, GR-LOAM uses the refined point cloud and tightly couples the IMU and encoder measurements with ground constraints to further refine the estimated pose by aligning the features on a global map. Results from extensive experiments performed in indoor and outdoor environments using real ground robot demonstrate the high accuracy and robustness of the proposed GR-LOAM for state estimation of ground robots.","Simultaneous localization and mapping (SLAM), Ground robot, Encoder, Sensor fusion, Tight coupling scheme",Yun Su and Ting Wang and Shiliang Shao and Chen Yao and Zhidong Wang,https://www.sciencedirect.com/science/article/pii/S0921889021000440,https://doi.org/10.1016/j.robot.2021.103759,0921-8890,2021,103759,140,Robotics and Autonomous Systems,GR-LOAM: LiDAR-based sensor fusion SLAM for ground robots on complex terrain,article,SU2021103759
"Search and find mission in ocean environment is a none trivial operation given the amount of random parameters associated with it. The uncertain and dynamic aspects related to ocean current movement make the trajectory prediction of drifting lost object onto sea water a very complicated task. In this work we present a novel lost target searching algorithm based on Recursive Area Clustering and target trajectory predication in ocean environment. Based on the widely known GlobCurrent v2 dataset which model the drifting of ocean surface current using satellite sensory data combined with mathematical and simulation modeling, we propose a regression algorithm based on our Recursive Area Clustering algorithm that we have developed previously to determine the strategic zones (weight centers) characterizing the high density areas extracted from drifting target history. Given those weight centers, we predict the object trajectory through refined regression. The predicted lost object trajectory is used to plan the path of UAV search mission. The model developed has a significant impact as we have tested our strategy in a scenario for searching an area covering 68517 km2, we have shown that 78% of the time, the lost object can be found within 32 km distance of the predicted trajectories limiting the significant search area to be about 5% of the whole searched area.","Dynamic target path prediction, UAV, High dense clustering, Surface Ekman current, Machine Leaning Regression",Mehrez Boulares and Ahmed Barnawi,https://www.sciencedirect.com/science/article/pii/S0921889020305133,https://doi.org/10.1016/j.robot.2020.103673,0921-8890,2021,103673,135,Robotics and Autonomous Systems,A novel UAV path planning algorithm to search for floating objects on the ocean surface based on object?s trajectory prediction by regression,article,BOULARES2021103673
"It is one of the great challenges for a robot to learn compliant movements in interaction tasks. The robot can easily acquire motion skills from a human tutor by kinematics demonstration, however, this becomes much more difficult when it comes to the compliant skills. This paper aims to provide a possible solution to address this problem by proposing a two-stage approach. In the first stage, the human tutor demonstrates the robot how to perform a task, during which only motion trajectories are recorded without the involvement of force sensing. A dynamical movement primitives (DMPs) model which can generate human-like motion is then used to encode the kinematics data. In the second stage, a biomimetic controller, which is inspired by the neuroscience findings in human motor learning, is employed to obtain the desired robotic compliant behaviors by online adapting the impedance profiles and the feedforward torques simultaneously. Several tests are conducted to validate the effectiveness of the proposed approach.","Compliant robotic movements, Biomimetic motor control, Impedance adaptation, Learning from demonstration (LfD), Human?robot interaction and collaboration",Chao Zeng and Xiongjun Chen and Ning Wang and Chenguang Yang,https://www.sciencedirect.com/science/article/pii/S092188902030508X,https://doi.org/10.1016/j.robot.2020.103668,0921-8890,2021,103668,135,Robotics and Autonomous Systems,Learning compliant robotic movements based on biomimetic motor adaptation,article,ZENG2021103668
"We consider the problem of distributed goal conflict resolution in multi-robot systems while remaining resilient to intermittent communication losses between robots. Our proposed approach uses a spatial approximation technique called ?-shape to represent the regions that have been explored by robots followed by a O(logn) algorithm that incrementally combines and shares the ?-shape information between robots along the robots? communication tree and rapidly checks for conflicts of a robot?s selected location. We provide theoretical guarantees of the time complexity of our proposed algorithm along with experimental results with simulated and physical robots in different environments. The results show that our approach can rapidly determine conflicts between goal locations selected by multiple robots as well as reduce message loss and re-transmissions between robots. These result in more efficient inter-robot communications as well as less extraneous distance traveled by robots, as compared to a flooding-based communications approach.","Multi-robot, Communications constrained environment, Goal conflict resolution, Alpha Shapes",Bradley Woosley and Prithviraj Dasgupta and John G. Rogers and Jeffery Twigg,https://www.sciencedirect.com/science/article/pii/S0921889020305534,https://doi.org/10.1016/j.robot.2020.103713,0921-8890,2021,103713,138,Robotics and Autonomous Systems,Multi-robot goal conflict resolution under communication constraints using spatial approximation and strategic caching,article,WOOSLEY2021103713
"The FastSLAM is a typical tracking algorithm for SLAM, but it often suffers from the low tracking accuracy. To mitigate the problem, an improved H-Infinity unscented FastSLAM (IHUFastSLAM) with adaptive genetic resampling is proposed in this paper. Specifically, the H-Infinity unscented Kalman filter algorithm is improved using an adaptive factor and is employed as importance sampling in particle filter. Next, the process noise and the measurement noise are estimated by a time varying noise estimator. Moreover, an adaptive genetic algorithm is used to complete the resampling of particle filter. Finally, the improved H-Infinity UFastSLAM with adaptive genetic resampling is proposed to complete robot tracking. The proposed algorithm can track robot with good accuracy, and obtain reliable state estimation in SLAM. Simulation results reveal the validity of the proposed algorithm.","Simultaneous localization and mapping (SLAM), FastSLAM, Unscented Kalman filter, Particle filter, Time varying noise estimator, Adaptive genetic algorithm",Ming Tang and Zhe Chen and Fuliang Yin,https://www.sciencedirect.com/science/article/pii/S0921889020305017,https://doi.org/10.1016/j.robot.2020.103661,0921-8890,2020,103661,134,Robotics and Autonomous Systems,An improved H-infinity unscented FastSLAM with adaptive genetic resampling,article,TANG2020103661
"The collision-free navigation of a mobile robot in clutter environments is challenging. Global Positioning System (GPS) and adaptive neuro-fuzzy inference system (ANFIS) are well-known techniques widely used for navigation and control, respectively. This paper proposes a hybrid GPS-ANFIS based method for collision-free navigation of autonomous mobile robots. The GPS-based controller keeps the navigation direction of the robot toward the static or dynamic target. It uses the coordinates received from the two GPS modules on the edges of the longitudinal axis of the robot all together with the coordinates of the target to divert it from the current path making a certain angle towards the target. The performance of the proposed method in navigating a mobile robot in clutter environments and its effectiveness in comparison with the other collision-free navigation methods has been evaluated through simulations. The evaluation criteria are on the basis of the obstacle avoidance behavior and the length of the discovered collision-free path by the robot. The results have shown that our hybrid GPS-ANFIS method navigates the robot toward the goal via a shorter path while avoiding the obstacles.","Adaptive Neuro-Fuzzy Inference System (ANFIS), Autonomous mobile robot, Global Positioning System (GPS), Obstacle avoidance",Mohammad Samadi Gharajeh and Hossein B. Jond,https://www.sciencedirect.com/science/article/pii/S0921889020305091,https://doi.org/10.1016/j.robot.2020.103669,0921-8890,2020,103669,134,Robotics and Autonomous Systems,Hybrid Global Positioning System-Adaptive Neuro-Fuzzy Inference System based autonomous mobile robot navigation,article,GHARAJEH2020103669
"Due to their ubiquity and long-term stability, pole-like objects are well suited to serve as landmarks for vehicle localization in urban environments. In this work, we present a complete mapping and long-term localization system based on pole landmarks extracted from 3-D lidar data. Our approach features a novel pole detector, a mapping module, and an online localization module, each of which are described in detail, and for which we provide an open-source implementation (Schaefer and Büscher, 0000). In extensive experiments, we demonstrate that our method improves on the state of the art with respect to long-term reliability and accuracy: First, we prove reliability by tasking the system with localizing a mobile robot over the course of 15 months in an urban area based on an initial map, confronting it with constantly varying routes, differing weather conditions, seasonal changes, and construction sites. Second, we show that the proposed approach clearly outperforms a recently published method in terms of accuracy.","Mapping, Localization, Lidar, Pole, Landmark, Feature extraction, Autonomous driving",Alexander Schaefer and Daniel Büscher and Johan Vertens and Lukas Luft and Wolfram Burgard,https://www.sciencedirect.com/science/article/pii/S0921889020305492,https://doi.org/10.1016/j.robot.2020.103709,0921-8890,2021,103709,136,Robotics and Autonomous Systems,Long-term vehicle localization in urban environments based on pole landmarks extracted from 3-D lidar scans,article,SCHAEFER2021103709
"We present an integrated Task-Motion Planning (TMP) framework for navigation in large-scale environments. Of late, TMP for manipulation has attracted significant interest resulting in a proliferation of different approaches. In contrast, TMP for navigation has received considerably less attention. Autonomous robots operating in real-world complex scenarios require planning in the discrete (task) space and the continuous (motion) space. In knowledge-intensive domains, on the one hand, a robot has to reason at the highest-level, for example, the objects to procure, the regions to navigate to in order to acquire them; on the other hand, the feasibility of the respective navigation tasks have to be checked at the execution level. This presents a need for motion-planning-aware task planners. In this paper, we discuss a probabilistically complete approach that leverages this task-motion interaction for navigating in large knowledge-intensive domains, returning a plan that is optimal at the task-level. The framework is intended for motion planning under motion and sensing uncertainty, which is formally known as belief space planning. The underlying methodology is validated in simulation, in an office environment and its scalability is tested in the larger Willow Garage world. A reasonable comparison with a work that is closest to our approach is also provided. We also demonstrate the adaptability of our approach by considering a building floor navigation domain. Finally, we also discuss the limitations of our approach and put forward suggestions for improvements and future work.","Task-motion planning, Belief space planning, Autonomous navigation",Antony Thomas and Fulvio Mastrogiovanni and Marco Baglietto,https://www.sciencedirect.com/science/article/pii/S0921889021000713,https://doi.org/10.1016/j.robot.2021.103786,0921-8890,2021,103786,141,Robotics and Autonomous Systems,MPTP: Motion-planning-aware task planning for navigation in belief space,article,THOMAS2021103786
"Robot grasping and manipulation require estimation of 3D object poses. Recently, a number of methods and datasets for vision-based pose estimation have been proposed. However, it is unclear how well the performance measures developed for visual pose estimation predict success in robot manipulation. In this work, we introduce an approach that connects error in pose and success in robot manipulation, and propose a probabilistic performance measure of the task success rate. A physical setup is needed to estimate the probability densities from real world samples, but evaluation of pose estimation methods is offline using captured test images, ground truth poses and the estimated densities. We validate the approach with four industrial manipulation tasks and evaluate a number of publicly available pose estimation methods. The popular pose estimation performance measure, Average Distance of Corresponding model points (ADC), does not offer any quantitatively meaningful indication of the frequency of success in robot manipulation. Our measure is instead quantitatively informative: e.g., a score of 0.24 corresponds to average success probability of 24%.","Object pose estimation, Robot manipulation, Evaluation",Antti Hietanen and Jyrki Latokartano and Alessandro Foi and Roel Pieters and Ville Kyrki and Minna Lanz and Joni-Kristian Kämäräinen,https://www.sciencedirect.com/science/article/pii/S0921889021000956,https://doi.org/10.1016/j.robot.2021.103810,0921-8890,2021,103810,143,Robotics and Autonomous Systems,Benchmarking pose estimation for robot manipulation,article,HIETANEN2021103810
"During execution, activity durations may vary from those predicted in the generated schedule. In this article we study (re) scheduling invocation, execution during rescheduling, and flexible execution to enable a high level of responsiveness to uncertainty in activity execution duration. We discuss these methods theoretically in the context of an embedded scheduler and practically in the context of a limited CPU embedded scheduler with a nonzero scheduler runtime intended for a planetary rover. We use the concept of a commit window to enable execution of the previously generated schedule while (re) scheduling. We define Fixed Cadence and Event Driven scheduling as methods to decide when to reinvoke the scheduler. We define and analyze Flexible Execution (FE) as an approach to execute the generated schedule while adapting it to variations in execution. Specifically, FE focuses on (1) how to take advantage of activities ending earlier than expected and (2) how to maintain a consistent schedule if activities take more time than expected. We present a theoretical model and empirical results documenting how these various methods interact and perform on both synthetic data and best available data for NASA?s next planetary rover, the Mars 2020 rover. We then describe how these analyses influenced the onboard software for the Mars 2020 rover.","Scheduling, Rescheduling, Flexible Execution",Jagriti Agrawal and Wayne Chi and Steve Chien and Gregg Rabideau and Daniel Gaines and Stephen Kuhn,https://www.sciencedirect.com/science/article/pii/S0921889021000439,https://doi.org/10.1016/j.robot.2021.103758,0921-8890,2021,103758,140,Robotics and Autonomous Systems,Analyzing the effectiveness of rescheduling and Flexible Execution methods to address uncertainty in execution duration for a planetary rover,article,AGRAWAL2021103758
"Position resolution is a major problem in teleoperation applications with significant disparity between master and slave workspace. While rate mode control is suitable for slave free motion operations, it poses significant stability and performance challenges for task manipulation. In this paper, we propose a hybrid control scheme that offers seamless transition between position and rate control modes based on the environment location information collected from a range sensor. The system incorporates the strengths of position and rate control modes while masking their shortcomings. Experiments to determine the viability of this method are carried out on a single degree-of-freedom teleoperation test-bed.","Position mode, Rate mode, Range sensor, Stability, Bilateral teleoperation, Workspace expansion",Chiedu N. Mokogwu and Keyvan Hashtrudi-Zaad,https://www.sciencedirect.com/science/article/pii/S092188902100066X,https://doi.org/10.1016/j.robot.2021.103781,0921-8890,2021,103781,141,Robotics and Autonomous Systems,A hybrid position?rate teleoperation system,article,MOKOGWU2021103781
"Inferring the depth of images is a fundamental inverse problem within the field of Computer Vision since depth information is obtained through 2D images, which can be generated from infinite possibilities of observed real scenes. Benefiting from the progress of Convolutional Neural Networks (CNNs) to explore structural features and spatial image information, Single Image Depth Estimation (SIDE) is often highlighted in scopes of scientific and technological innovation, as this concept provides advantages related to its low implementation cost and robustness to environmental conditions. In the context of autonomous vehicles, state-of-the-art CNNs optimize the SIDE task by producing high-quality depth maps, which are essential during the autonomous navigation process in different locations. However, such networks are usually supervised by sparse and noisy depth data, from Light Detection and Ranging (LiDAR) laser scans, and are carried out at high computational cost, requiring high-performance Graphic Processing Units (GPUs). Therefore, we propose a new lightweight and fast supervised CNN architecture combined with novel feature extraction models which are designed for real-world autonomous navigation. We also introduce an efficient surface normals module, jointly with a simple geometric 2.5D loss function, to solve SIDE problems. We also innovate by incorporating multiple Deep Learning techniques, such as the use of densification algorithms and additional semantic, surface normals and depth information to train our framework. The method introduced in this work focuses on robotic applications in indoor and outdoor environments and its results are evaluated on the competitive and publicly available NYU Depth V2 and KITTI Depth datasets.","SIDE, CNN, Deep learning",Raul {de Queiroz Mendes} and Eduardo Godinho Ribeiro and Nicolas {dos Santos Rosa} and Valdir Grassi,https://www.sciencedirect.com/science/article/pii/S0921889020305418,https://doi.org/10.1016/j.robot.2020.103701,0921-8890,2021,103701,136,Robotics and Autonomous Systems,On deep learning techniques to boost monocular depth estimation for autonomous navigation,article,DEQUEIROZMENDES2021103701
"Swarms of autonomous agents are useful in many applications due to their ability to accomplish tasks in a decentralized manner, making them more robust to failures. Due to the difficulty in running experiments with large numbers of hardware agents, researchers often make simplifying assumptions and remove constraints that might be present in a real swarm deployment. While simplifying away some constraints is tolerable, we feel that two in particular have been overlooked: one, that agents in a swarm take up physical space, and two, that agents might be damaged in collisions. Many existing works assume agents have negligible size or pass through each other with no added penalty. It seems possible to ignore these constraints using collision avoidance, but we show using an illustrative example that this is easier said than done. In particular, we show that collision avoidance can interfere with the intended swarming behavior and significant parameter tuning is necessary to ensure the behavior emerges as best as possible while collisions are avoided. We compare four different collision avoidance algorithms, two of which we consider to be the best decentralized collision avoidance algorithms available. Despite putting significant effort into tuning each algorithm to perform at its best, we believe our results show that further research is necessary to develop swarming behaviors that can achieve their goal while avoiding collisions with agents of non-negligible volume.",,Chris Taylor and Cameron Nowzari,https://www.sciencedirect.com/science/article/pii/S0921889021000397,https://doi.org/10.1016/j.robot.2021.103754,0921-8890,2021,103754,140,Robotics and Autonomous Systems,The impact of catastrophic collisions and collision avoidance on a swarming behavior,article,TAYLOR2021103754
"A key feature in the context of simultaneous localization and mapping is loop-closure detection, a process determining whether the current robot?s environment perception coincides with previous observation. However, in long-term operations, both computational efficiency and memory requirements involved in an autonomous robot operation in uncontrolled environments, are of particular importance. The majority of approaches scale linearly with the environment?s size in terms of storage and query time. The article at hand presents an efficient appearance-based loop-closure detection pipeline, which encodes the traversed trajectory by a low amount of unique visual words generated on-line through feature tracking. The incrementally constructed visual vocabulary is referred to as the ?Bag of Tracked Words.? A nearest-neighbor voting scheme is utilized to query the database and assign probabilistic scores to all visited locations. Exploiting the inherent temporal coherency in the loop-closure task, the produced scores are processed through a Bayesian filter to estimate the belief state about the robot?s location on the map. Also, a geometrical verification step ensures consistency between image matches. Management is also applied to the resulting vocabulary to reduce its growth rate and constraint the system?s computational complexity while improving its voting distinctiveness. The proposed approach?s performance is experimentally evaluated on several publicly available and challenging datasets, including hand-held, car-mounted, aerial, and ground trajectories. Results demonstrate the method?s adaptability, which retains high operational frequency in environments of up to 13 km and high recall rates for perfect precision, outperforming other state-of-the-art techniques. The system?s effectiveness is owed to the reduced vocabulary size, which is at least one order of magnitude smaller than other contemporary approaches. An open research-oriented source code has been made publicly available, which is dubbed as ?BoTW-LCD.?","Loop-closure detection, Mapping, Recognition, SLAM, Visual-based navigation",Konstantinos A. Tsintotas and Loukas Bampis and Antonios Gasteratos,https://www.sciencedirect.com/science/article/pii/S0921889021000671,https://doi.org/10.1016/j.robot.2021.103782,0921-8890,2021,103782,141,Robotics and Autonomous Systems,Modest-vocabulary loop-closure detection with incremental bag of tracked words,article,TSINTOTAS2021103782
"The manipulation of an object into a desired location in a cluttered and restricted environment requires reasoning over the long-term consequences of an action while reacting locally to the multiple physics-based interactions. We present Visual Receding Horizon Planning (VisualRHP) in a framework which interleaves real-world execution with look-ahead planning to efficiently solve a short-horizon approximation to a multi-step sequential decision making problem. VisualRHP is guided by a learned heuristic that acts on an abstract colour-labelled image-based representation of the state. With this representation, the robot can generalize its behaviours to different environment setups, that is, different number and shape of objects, while also having transferable manipulation skills that can be applied to a multitude of real-world objects. We train the heuristic with imitation and reinforcement learning in discrete and continuous actions spaces. We detail our heuristic learning process for environments with sparse rewards, and non-linear, non-continuous, dynamics. In particular, we introduce necessary changes for improving the stability of existing reinforcement learning algorithms that use neural networks with shared parameters. In a series of simulation and real-world experiments, we show the robot performing prehensile and non-prehensile actions in synergy to successfully manipulate a variety of real-world objects in real-time.","Manipulation in clutter, Physics-based manipulation, Heuristic learning, Receding Horizon Planning, Imitation and reinforcement learning, Abstract state representation",Wissam Bejjani and Matteo Leonetti and Mehmet R. Dogar,https://www.sciencedirect.com/science/article/pii/S0921889021000154,https://doi.org/10.1016/j.robot.2021.103730,0921-8890,2021,103730,138,Robotics and Autonomous Systems,Learning image-based Receding Horizon Planning for manipulation in clutter,article,BEJJANI2021103730
"Aimed at the negative effect of dynamics characteristics of leg hydraulic drive system (LHDS) on the accuracy of motion control of the hydraulic drive legged robot, a dynamics compensation control method is proposed. First, according to the mechanical structure of LHDS, the kinematics and statics models of LHDS are analyzed and obtained respectively. Based on the principle of force-based impedance control of LHDS, an impedance based motion control simulation model of LHDS is built and analyzed. The simulation results show that the dynamics characteristics have a great influence on the accuracy of impedance based motion control. Then, a dynamics compensation method considering gravity and inertia force is proposed to solve this problem. Finally, the effect of the dynamics compensation method is verified on the robot single leg test platform. The experimental results show that the compensation method reduces the negative effect of the dynamics characteristics of LHDS on impedance based motion control accuracy, and the position tracking accuracy of the robot?s foot end can be improved by more than 65%. The theory proposed in this paper provides a theoretical basis for the motion control of the whole robot prototype.","Legged robot, Leg hydraulic drive system (LHDS), Dynamics compensation, Impedance based motion control",Kaixian Ba and Yanhe Song and Bin Yu and Xiaolong He and Zhipeng Huang and Chunhe Li and Lipeng Yuan and Xiangdong Kong,https://www.sciencedirect.com/science/article/pii/S0921889020305443,https://doi.org/10.1016/j.robot.2020.103704,0921-8890,2021,103704,139,Robotics and Autonomous Systems,Dynamics compensation of impedance-based motion control for LHDS of legged robot,article,BA2021103704
"Autonomous mobile robots are becoming increasingly important in many industrial and domestic environments. Dealing with unforeseen situations is a difficult problem that must be tackled to achieve long-term robot autonomy. In vision-based localization and navigation methods, one of the major issues is the scene dynamics. The autonomous operation of the robot may become unreliable if the changes occurring in dynamic environments are not detected and managed. Moving chairs, opening and closing doors or windows, replacing objects and other changes make many conventional methods fail. To deal with these challenges, we present a novel method for change detection based on weighted local visual features. The core idea of the algorithm is to distinguish the valuable information in stable regions of the scene from the potentially misleading information in the regions that are changing. We evaluate the change detection algorithm in a visual localization framework based on feature matching by performing a series of long-term localization experiments in various real-world environments. The results show that the change detection method yields an improvement in the localization accuracy, compared to the baseline method without change detection. In addition, an experimental evaluation on a public long-term localization data set with more than 10000 images reveals that the proposed method outperforms two alternative localization methods on images recorded several months after the initial mapping.","Mobile robotics, Image-based localization, Change detection, Long-term autonomy",Erik Derner and Clara Gomez and Alejandra C. Hernandez and Ramon Barber and Robert Babu?ka,https://www.sciencedirect.com/science/article/pii/S0921889020305169,https://doi.org/10.1016/j.robot.2020.103676,0921-8890,2021,103676,135,Robotics and Autonomous Systems,Change detection using weighted features for image-based localization,article,DERNER2021103676
"We propose a methodology for lidar super-resolution with ground vehicles driving on roadways, which relies completely on a driving simulator to enhance, via deep learning, the apparent resolution of a physical lidar. To increase the resolution of the point cloud captured by a sparse 3D lidar, we convert this problem from 3D Euclidean space into an image super-resolution problem in 2D image space, which is solved using a deep convolutional neural network. By projecting a point cloud onto a range image, we are able to efficiently enhance the resolution of such an image using a deep neural network. Typically, the training of a deep neural network requires vast real-world data. Our approach does not require any real-world data, as we train the network purely using computer-generated data. Thus our method is applicable to the enhancement of any type of 3D lidar theoretically. By novelly applying Monte-Carlo dropout in the network and removing the predictions with high uncertainty, our method produces high accuracy point clouds comparable with the observations of a real high resolution lidar. We present experimental results applying our method to several simulated and real-world datasets. We argue for the method?s potential benefits in real-world robotics applications such as occupancy mapping and terrain modeling.","Lidar super-resolution, Range sensing, Perception & driving systems",Tixiao Shan and Jinkun Wang and Fanfei Chen and Paul Szenher and Brendan Englot,https://www.sciencedirect.com/science/article/pii/S0921889020304875,https://doi.org/10.1016/j.robot.2020.103647,0921-8890,2020,103647,134,Robotics and Autonomous Systems,Simulation-based lidar super-resolution for ground vehicles,article,SHAN2020103647
"Triangle mesh maps for robotic applications are becoming increasingly popular, but are not yet effectively supported in the Robot Operating System (ROS). We introduce the Mesh Tools package consisting of message definitions, RViz plugins and tools, as well as a persistence layer. These tools make annotated triangle maps available in ROS and allow to publish, edit and inspect such maps within the existing ROS software stack. The persistence layer efficiently loads and stores large mesh maps. The proposed plugins and tools enable the visualization and validation of the complete layered map and associated properties to allow fluid interaction. We demonstrate the seamless integration of our tools in two application areas as a proof-of-concept: Labeling of triangle clusters for semantic mapping and robot navigation on triangle meshes in rough terrain outdoor environments by integrating our tools into an existing navigation stack.","ROS, Triangle meshes, RViz, 3D mesh navigation",Sebastian Pütz and Thomas Wiemann and Joachim Hertzberg,https://www.sciencedirect.com/science/article/pii/S0921889020305285,https://doi.org/10.1016/j.robot.2020.103688,0921-8890,2021,103688,138,Robotics and Autonomous Systems,The Mesh Tools Package ? Introducing Annotated 3D Triangle Maps in ROS,article,PUTZ2021103688
"Anticipation of human movements is of great importance for service robots, as it is necessary to avoid interferences and predict areas where human?robot collaboration may be needed. In indoor scenarios, human movements often depend on objects with which they interacted before. For example, if a human interacts with a cup the probability that a table or coffee machine might be the next navigation goal is high. Typically, objects are grouped together in regions depending on the related activities so that environments consist of a set of activity regions. For example, a workspace region may contain a PC, a chair, and a table with many smaller objects on top of it. In this article, we present an approach to predict the navigation goal of a moving human in indoor environments. We hereby combine prior knowledge about typical human transitions between activity regions with robot observations about the human?s current pose and the last object interaction to predict the navigation goal using Bayesian inference. In the experimental evaluation in several simulated environments we demonstrate that our approach leads to a significantly more accurate prediction of the navigation goal in comparison to previous work. Furthermore, we show in a real-world experiment how such human motion anticipation can be used to realize foresighted navigation with an assistance robot, i.e. how predicted human movements can be used to increase the time efficiency of the robot?s navigation policy by early anticipating the user?s navigation goal and moving towards it.","Anticipating human behavior, Robot path planning, Human-centered systems",Lilli Bruckschen and Kira Bungert and Nils Dengler and Maren Bennewitz,https://www.sciencedirect.com/science/article/pii/S0921889020305042,https://doi.org/10.1016/j.robot.2020.103664,0921-8890,2020,103664,134,Robotics and Autonomous Systems,Predicting human navigation goals based on Bayesian inference and activity regions,article,BRUCKSCHEN2020103664
"Replacement of lightning arrester is one of the common tasks in live-line maintenance, and peg-in-hole assembly is a very difficult operation for a robot, because there are visual inaccuracy and force model uncertainty in the process of assembly. This paper presents a new implementation approach fusing signals of vision detection and fuzzy force to realize the high efficiency peg-in-hole assembly by a manipulator autonomously. YOLOv3 is applied as the visual detection network for rough alignment. In the phase of precise hole-searching, we establish a two-dimensional hole-searching model by fusing signal of vision detection and fuzzy force as the condition of state transitions, and propose a new semi-supervised learning network to optimize the hole-searching routine. The performance of the approach is verified by experiments in the simulation environment and the laboratory environment.","Peg-in-hole assembly, Live-line maintenance robot, Fusion signal, Semi-supervised learning network",Wei Wu and Hui Zhou and Yu Guo and Yifei Wu and Jian Guo,https://www.sciencedirect.com/science/article/pii/S0921889021000828,https://doi.org/10.1016/j.robot.2021.103797,0921-8890,2021,103797,143,Robotics and Autonomous Systems,Peg-in-hole assembly in live-line maintenance based on generative mapping and searching network,article,WU2021103797
"An environment cannot be effectively described with a single perception form in skill learning for robotic assembly. The visual perception may provide the object?s apparent characteristics and the softness or stiffness of the object could be detected using the contact force/torque information during the assembly process. In the process of inserting assembly strategy learning, most of the work takes the contact force information as the current observation state of the assembly process, ignoring the influence of visual information on the assembly state. This paper proposes robotic assembly skill learning with deep Q-learning using visual perspectives and force sensing to learn an assembly policy. The reward system is designed with an image template matching for assembly state, which is used to judge whether the process is completed successfully. The observations of assembly state are described by force/torque information and the pose of the end effector. To evaluate the performance of the proposed skill learning method, experiments with a KUKA iiwa robot are performed for a plastic fasten assembly in a low-voltage apparatus. The results indicate that the robot can complete the plastic fasten assembly using the learned inserting assembly strategy with visual perspectives and force sensing.","Skill learning, Reinforcement learning, Robot assembly, Visual perspectives, Force sensing",Rui Song and Fengming Li and Wei Quan and Xuting Yang and Jie Zhao,https://www.sciencedirect.com/science/article/pii/S0921889020304917,https://doi.org/10.1016/j.robot.2020.103651,0921-8890,2021,103651,135,Robotics and Autonomous Systems,Skill learning for robotic assembly based on visual perspectives and force sensing,article,SONG2021103651
"Modern laser SLAM (simultaneous localization and mapping) and structure from motion algorithms face the problem of processing redundant data. Even if a sensor does not move, it still continues to capture scans that should be processed. This paper presents the novel filter that allows dropping 2D scans that bring no new information to the system. Experiments on MIT and TUM datasets show that it is possible to drop more than half of the scans. Moreover the paper describes the formulas that enable filter adaptation to a particular robot with known speed and characteristics of lidar. In addition, the indoor corridor detector is introduced that also can be applied to any specific shape of a corridor and sensor.","SLAM, Laser scan, Filtering, Correlation, Histogram",Kirill Krinkin and Anton Filatov,https://www.sciencedirect.com/science/article/pii/S0921889021000944,https://doi.org/10.1016/j.robot.2021.103809,0921-8890,2021,103809,142,Robotics and Autonomous Systems,Correlation filter of 2D laser scans for indoor environment,article,KRINKIN2021103809
"Robots still cannot perform everyday manipulation tasks, such as grasping, with the same dexterity as humans do. In order to explore the potential of supervised deep learning for robotic grasping in unstructured and dynamic environments, this work addresses the visual perception phase involved in the task. This phase involves the processing of visual data to obtain the location of the object to be grasped, its pose and the points at which the robot?s grippers must make contact to ensure a stable grasp. For this, the Cornell Grasping Dataset (CGD) is used to train a Convolutional Neural Network (CNN) that is able to consider these three stages simultaneously. In other words, having an image of the robot?s workspace, containing a certain object, the network predicts a grasp rectangle that symbolizes the position, orientation and opening of the robot?s parallel grippers the instant before its closing. In addition to this network, which runs in real-time, another network is designed, so that it is possible to deal with situations in which the object moves in the environment. Therefore, the second convolutional network is trained to perform a visual servo control, ensuring that the object remains in the robot?s field of view. This network predicts the proportional values of the linear and angular velocities that the camera must have to ensure the object is in the image processed by the grasp network. The dataset used for training was automatically generated by a Kinova Gen3 robotic manipulator with seven Degrees of Freedom (DoF). The robot is also used to evaluate the applicability in real-time and obtain practical results from the designed algorithms. Moreover, the offline results obtained through test sets are also analyzed and discussed regarding their efficiency and processing speed. The developed controller is able to achieve a millimeter accuracy in the final position considering a target object seen for the first time. To the best of our knowledge, we have not found in the literature other works that achieve such precision with a controller learned from scratch. Thus, this work presents a new system for autonomous robotic manipulation, with the ability to generalize to different objects and with high processing speed, which allows its application in real robotic systems.","Robotic grasping, Visual servoing, Real-time, Deep learning, 7DoF robot",Eduardo Godinho Ribeiro and Raul {de Queiroz Mendes} and Valdir Grassi,https://www.sciencedirect.com/science/article/pii/S0921889021000427,https://doi.org/10.1016/j.robot.2021.103757,0921-8890,2021,103757,139,Robotics and Autonomous Systems,Real-time deep learning approach to visual servo control and grasp detection for autonomous robotic manipulation,article,RIBEIRO2021103757
"Snake robots have advantages of terrain adaptability over wheeled mobile robots and traditional articulated robot arms because of their limbless thin body structure and high flexibility. They have extensive applications in tasks such as rescue, disaster recovery, inspection and minimally invasive surgery. Current research on snake robots is mainly focused on snake-like locomotion and the embodiment of these motion gaits for different applications. Modular structure and real-time control algorithms are two key aspects for snake robots operating in constrained environments. This review will attempt to address both. First, a review on the snake motion and the body structure is provided, which outlines the biological foundation of all snake robots. This is followed by the mechanical structure of snake robots, especially the structure of elemental snake modules. Finally, control algorithms for variant terrain contours and obstacle avoidance are discussed. The review also outlines emerging application areas and potential future directions of snake robots.","Snake robots, Joint structure, Control algorithms, Constrained environment",Jindong Liu and Yuchuang Tong and Jinguo Liu,https://www.sciencedirect.com/science/article/pii/S0921889021000701,https://doi.org/10.1016/j.robot.2021.103785,0921-8890,2021,103785,141,Robotics and Autonomous Systems,Review of snake robots in constrained environments,article,LIU2021103785
"Pouring is one of the most commonly executed tasks in humans? daily lives, whose accuracy is affected by multiple factors, including the type of material to be poured and the geometry of the source and receiving containers. In this work, we propose a self-supervised learning approach that learns the pouring dynamics, pouring motion, and outcomes from unsupervised demonstrations for accurate pouring. The learned pouring model is then generalized by self-supervised practicing to different conditions such as using unaccustomed pouring cups. We have evaluated the proposed approach first with one container from the training set and four new but similar containers. The proposed approach achieved better pouring accuracy than a regular human with a similar pouring speed for all five cups. Both the accuracy and pouring speed outperform state-of-the-art works. We have also evaluated the proposed self-supervised generalization approach using unaccustomed containers that are far different from the ones in the training set. The self-supervised generalization reduces the pouring error of the unaccustomed containers to the desired accuracy level.","Sensorimotor learning, Sensor-based control, Generalization",Yongqiang Huang and Juan Wilches and Yu Sun,https://www.sciencedirect.com/science/article/pii/S0921889020305327,https://doi.org/10.1016/j.robot.2020.103692,0921-8890,2021,103692,136,Robotics and Autonomous Systems,Robot gaining accurate pouring skills through self-supervised learning and generalization,article,HUANG2021103692
"This paper proposed an image-based visual servoing (IBVS) control law for a quadrotor that is equipped with a single monocular camera attached to its bottom. For control purposes virtual reticle plane (VRP) algorithm is used to track the relative 3D position of the quadrotor to the tilting and moving target landing platform within the range of the camera?s field of view (FOV). In this article, the landing platform?s tilting motion is considered sinusoidal type oscillatory motion for the overhead camera. For control purposes, an adaptive finite-time control (AFTC) is proposed, based on the finite-time control (FTC) and adaptive approximation of uncertainties. A constructive combination of FTC and adaptive approximation inherits benefits of both to overcome each other?s limitations. The task of the controller is to regulate the position error to zero in time calculated by VRP. The experimental results confirmed the effectiveness of the VRP algorithm to track the desired parameters of the moving target. Finally, simulations are performed to illustrate the effectiveness and improved performance of the proposed AFTC in response time, robustness, and tracking accuracy.","Virtual Reticle Plane Algorithm, Visual servoing, Finite-time control, Adaptive feedback linearization",Adeel Arif and Hesheng Wang and Zhe Liu and Herman Castañeda and Yong Wang,https://www.sciencedirect.com/science/article/pii/S092188902100049X,https://doi.org/10.1016/j.robot.2021.103764,0921-8890,2021,103764,141,Robotics and Autonomous Systems,Adaptive visual servo control law for finite-time tracking to land quadrotor on moving platform using virtual reticle algorithm,article,ARIF2021103764
"Autonomous unmanned systems and robots must be able to actively leverage all available information sources ? including imprecise but readily available semantic observations provided by human collaborators. This work develops and validates a novel active collaborative human?machine sensing solution for robotic information gathering and optimal decision making problems, with an example implementation of a dynamic target search scenario. Our approach uses continuous partially observable Markov decision process (CPOMDP) planning to generate vehicle trajectories that optimally exploit imperfect detection data from onboard sensors, as well as semantic natural language observations that can be specifically requested from human sensors. The key innovations are a method for the inclusion of a human querying/sensing model in a CPOMDP based autonomous decision making process, as well as a scalable hierarchical Gaussian mixture model formulation for efficiently solving CPOMDPs with semantic observations in continuous dynamic state spaces. Unlike previous state-of-the-art approaches this allows planning in large, complex, highly segmented environments. Our solution is demonstrated and validated with a real human?robot team engaged in dynamic indoor target search and capture scenarios on a custom testbed.","Human?robot interaction, Data fusion, Partially observable Markov decision processes, Planning, Bayesian methods, Target search, Target localization, Mobile robots, Autonomy",Luke Burks and Nisar Ahmed and Ian Loefgren and Luke Barbier and Jeremy Muesing and Jamison McGinley and Sousheel Vunnam,https://www.sciencedirect.com/science/article/pii/S0921889021000385,https://doi.org/10.1016/j.robot.2021.103753,0921-8890,2021,103753,140,Robotics and Autonomous Systems,Collaborative human-autonomy semantic sensing through structured POMDP planning,article,BURKS2021103753
"Multi-UAV system is widely used in surveillance, search and rescue, and industrial inspection. Multi-UAV trajectory planning is crucial for the multi-UAV system, but multi-UAV trajectory planning often needs to consider many constraints, such as trajectory smoothness, obstacle collisions, mutual collisions, dynamic limits, time-consuming, and trajectory length. It is a challenge to balance these constraints while considering computational performance. This paper proposes a novel multi-UAV trajectory planning method to solve the challenge. This method uses time segmentation instead of traditional waypoint segmentation to establish a trajectory optimization model based on the unified time interval, which simplifies the calculation of cost functions. At the same time, virtual segments are introduced to adapt to the trajectory length of different UAVs to reduce the total arrival time. Nonlinear constraints are cast into cost functions and a gradient-based sequential minimal optimization (GB-SMO) algorithm is proposed to minimize the cost function, which decouples the constraint of the mutual collisions in each iteration to save the planning time. Experiments are performed on a multi-UAV system to prove the effectiveness of the proposed method. Results show that this method has good performance in obstacle-rich environments and is efficient for a large number of UAVs.","Multi-UAV trajectory planning, Time segmentation, Sequential minimal optimization, Decoupled mutual collision",Qiaoyang Xia and Shuang Liu and Mingyang Guo and Hui Wang and Qigao Zhou and Xiancheng Zhang,https://www.sciencedirect.com/science/article/pii/S0921889021000130,https://doi.org/10.1016/j.robot.2021.103728,0921-8890,2021,103728,137,Robotics and Autonomous Systems,Multi-UAV trajectory planning using gradient-based sequence minimal optimization,article,XIA2021103728
"Dynamics performance is very important for a manipulator used for high-speed machining. In this paper, the dynamic performance evaluation method of the 2UPU/SP parallel mechanism in a hybrid robot for aerospace composite machining is studied. The dynamic model is obtained by the virtual work principle, and a dynamic performance index considering gravity is proposed. Based on the given performance index, the effect of placement direction on dynamic performance of 2UPU/SP mechanism is studied, and the comparison between the dynamic performance of 2UPU/SP and the traditional Tricept mechanism is carried out. The results show that the 2UPU/SP mechanism has better dynamic performance in the vertical placement than the horizontal placement, and 2UPU/SP mechanism has better dynamic performance than Tricept mechanism.","Parallel mechanism, Dynamics evaluation, Gravity, Placement direction",Xiaojian Wang and Jun Wu and Yutian Wang,https://www.sciencedirect.com/science/article/pii/S0921889020305157,https://doi.org/10.1016/j.robot.2020.103675,0921-8890,2021,103675,135,Robotics and Autonomous Systems,Dynamics evaluation of 2UPU/SP parallel mechanism for a 5-DOF hybrid robot considering gravity,article,WANG2021103675
"This paper presents a planning framework for jumping over obstacles with quadruped robots. The framework accomplishes planning via a structured predictive control strategy that combines the use of heterogeneous simplified models over different prediction time scales. A receding multi-horizon predictive controller coordinates the approach before the jump using a kinematic point-mass model. Consideration of the optimal value function over different planning horizons enables the system to select an appropriate number of steps to take before jumping. The jumping motion is then tailored to the sensed obstacle by solving a nonlinear trajectory optimization problem. The solution of this problem online is enabled by exploiting the analyticity of the flow map for a planar bounding template model under polynomial inputs. By planning with this combination of models, MIT Cheetah 2 is shown to autonomously jump over obstacles up to 40 cm in height during high-speed bounding. Untethered results showcase the ability of the method to automatically adapt to obstacles of different heights and placements in a single trial.","Legged locomotion, Quadruped robots, Sensor-based planning",Hae-Won Park and Patrick M. Wensing and Sangbae Kim,https://www.sciencedirect.com/science/article/pii/S0921889020305431,https://doi.org/10.1016/j.robot.2020.103703,0921-8890,2021,103703,136,Robotics and Autonomous Systems,Jumping over obstacles with MIT Cheetah 2,article,PARK2021103703
"The risk toward human lives in situations involving chemical, biological, radiological, and nuclear (CBRN) threats can be mitigated or even neutralized by deploying carrying a suite of suitable sensors. Furthermore, mobile robots open up the possibility for automated radiological field surveys and monitoring operations, which have important applications in scenarios with CBRN threats. A path planner is one of the essential tools required for these robots to perform their tasks autonomously. Moreover, sophisticated path planners can greatly increase the efficiency of monitoring tasks by maximizing the information gathered in the minimum amount of time. This work proposes an informative path planner as an instrument to efficiently estimate maps of scalar quantities (e.g., radiation intensity, chemical concentration), motivated by applications in radiological inspection. The proposed path planner models the path with B-splines, enabling planning in continuous space. A Gaussian Process with a squared exponential kernel is used to model the underlying field. A modified form of mutual information, estimated from the Gaussian Process, is maximized to determine the most informative path, additionally rewarding observations made in regions where the field magnitude is large (e.g., near a radioactive source). A maximum likelihood estimator for source parameters is used to demonstrate that the proposed solution increases the accuracy of the estimated source positions. Simulation results show that the informative path planner adapts to non-convex environments and increases the number of observations made close to radioactive sources while avoiding obstacles.","Informative path planning, Area coverage, Radiological monitoring, Autonomous vehicles, Gaussian Processes",Yoeri Brouwer and Alberto Vale and Rodrigo Ventura,https://www.sciencedirect.com/science/article/pii/S0921889020305315,https://doi.org/10.1016/j.robot.2020.103691,0921-8890,2021,103691,136,Robotics and Autonomous Systems,Informative path planner with exploration?exploitation trade-off for radiological surveys in non-convex scenarios,article,BROUWER2021103691
"The achievement of adaptive, stable, and robust locomotion and dealing with asymmetrical conditions for bipedal robots remain a challenging problem. To address the problem, this paper introduces adaptive parallel reflex- and decoupled central pattern generator (CPG)-based control for a planar bipedal robot. The control has modular structure consisting of two parallel modules that work together. Firstly, as the main controller, the reflex-based control module inspired by an agonist?antagonist model, utilizes proprioceptive sensory feedback to adaptively generate various stable gaits. In parallel, as an auxiliary controller, the decoupled CPG-based control units individually governing the robot legs have the ability to learn the generated gaits in an online manner. Using the proposed framework, our study shows that this real-time control approach contributes to stable gait generation with robustness toward sensory feedback malfunction and adaptability to deal with environmental and morphological changes. Herein this study, we demonstrate the planar bipedal robot control functionality on a variable speed treadmill, dealing with asymmetric conditions such as weight imbalance and asymmetrical elastic resistance in the legs. However, the approach does not require robot kinematic and dynamic models as well as an environmental model and is therefore flexible. As such, it can be used as a basis for controlling other bipedal locomotion systems, like lower-limb exoskeletons.","Bipedal walking robots, Central pattern generator, Adaptive online learning, Asymmetric gait",Chaicharn Akkawutvanich and Frederik Ibsgaard Knudsen and Anders Falk Riis and Jørgen Christian Larsen and Poramate Manoonpong,https://www.sciencedirect.com/science/article/pii/S0921889020305030,https://doi.org/10.1016/j.robot.2020.103663,0921-8890,2020,103663,134,Robotics and Autonomous Systems,Adaptive parallel reflex- and decoupled CPG-based control for complex bipedal locomotion,article,AKKAWUTVANICH2020103663
"We present an experimental investigation of a multi-sensor fusion-learning system for detecting pedestrians in foggy weather conditions. The method combines two pipelines for people detection running on two different sensors commonly found on moving vehicles: lidar and radar. The two pipelines are not only combined by sensor fusion, but information from one pipeline is used to train the other. We build upon our previous work, where we showed that a lidar pipeline can be used to train a Support Vector Machine (SVM)-based pipeline to interpret radar data, which is useful when conditions then become unfavourable to the original lidar pipeline. In this paper, we test the method on a wider range of conditions, such as from a moving vehicle, and with multiple people present. Additionally, we also compare how the traditional SVM performs interpreting the radar data versus a modern deep neural network on these experiments. Our experiments indicate that either of the approaches results in progressive improvement in the performance during normal operation. Further, our experiments indicate that in the event of the loss of information from a sensor, pedestrian detection and position estimation is still effective.","Mobile robotics, 3D radar, 2D lidar, Machine learning, Pointnet, SVM, Learning fusion, Sensor fusion, On-line learning",George Broughton and Filip Majer and Tomá? Rou?ek and Yassine Ruichek and Zhi Yan and Tomá? Krajník,https://www.sciencedirect.com/science/article/pii/S0921889020305273,https://doi.org/10.1016/j.robot.2020.103687,0921-8890,2021,103687,136,Robotics and Autonomous Systems,Learning to see through the haze: Multi-sensor learning-fusion System for Vulnerable Traffic Participant Detection in Fog,article,BROUGHTON2021103687
"Imitation learning (IL) is a popular method used to train machine learning models that are capable of acting on their environment based on expert examples. Two types of IL models are inverse reinforcement learning (IRL) and behavioral cloning (BC). Models trained under IRL traditionally perform better than those trained under BC due to compounding covariate shift associated with the latter, which typically requires algorithms such as DAGGer to help compensate for this. More recently, however, deep learning architectures with increased generalization performance have been developed, which may help to alleviate the problem of compounding covariate shift and allow researchers to take advantage of the simplicity of BC. Despite these developments, recent studies on BC in sub-scale autonomous robots employ relatively primitive convolutional networks without such tools as batch normalization and skip connections, and it is difficult to judge their networks? performance relative to others due to drastically different training and testing conditions. Here, we examine how an array of artificial neural networks, chosen to reflect more recent architectural choices available, behave in a highly controlled IL task ? navigating around a small, indoor racetrack ? upon being embedded in a sub-scale RC vehicle as an end-to-end steering system. For our main findings, we report the lap completion rate and path smoothness of each network under the exact same conditions as it controls the vehicle on the track. To supplement these findings, we also measure each network?s bias toward the distribution of the training actions and develop a method to highlight regions of a given input image that are deemed ?important? to a given network. We observe that most of the more recent neural networks perform reasonably well during testing, as opposed to the more primitive networks which did not perform as well. For these reasons and others, we identify VGG-16 and AlexNet ? out of the networks tested here ? as attractive candidate architectures for such tasks.","End-to-end control systems, Deep neural networks, Autonomous vehicles, Imitation learning, Behavioral cloning",Michael Teti and William Edward Hahn and Shawn Martin and Christopher Teti and Elan Barenholtz,https://www.sciencedirect.com/science/article/pii/S0921889021000658,https://doi.org/10.1016/j.robot.2021.103780,0921-8890,2021,103780,142,Robotics and Autonomous Systems,A controlled investigation of behaviorally-cloned deep neural network behaviors in an autonomous steering task,article,TETI2021103780
"Balancing two-wheeled autonomous vehicles at low forward speeds is one of the primary challenges in the development of such vehicles. Gyrostabilizers can be used as actuators to make the balance; however, conventional gyros are not typically able to maintain constant moments and directions to stabilize against constant ?heel?. In this paper, we present an innovative gyrostabilizer including a twin-flywheel arrangement that can provide any desired gyroscopic roll moment. The dynamical model of a bicycle together with the gyrostabilizer is derived using Newton?Euler method. The actuator dynamics is included when designing the control system. A robust non-integer sliding mode controller is then developed to guarantee perfect trajectory tracking in the presence of roll disturbance. Extensive comparative simulations (based on the experimentally measured parameters of a typical bike) are conducted to evaluate the method and to show the impact of introducing the novel actuator. Results demonstrate that the proposed system offers superior performance while the control effort also remains within the capacity of normal actuators.","Gyrostabilizer, Fractional sliding mode, Robust control, Two-wheeled autonomous vehicle, Gyroscopic actuator",M.A. Tofigh and M.J. Mahjoob and M.R. Hanachi and M. Ayati,https://www.sciencedirect.com/science/article/pii/S0921889021000415,https://doi.org/10.1016/j.robot.2021.103756,0921-8890,2021,103756,140,Robotics and Autonomous Systems,Fractional sliding mode control for an autonomous two-wheeled vehicle equipped with an innovative gyroscopic actuator,article,TOFIGH2021103756
"Inspired by the abilities of amoeba to alter their shape, a continuous-track robot called Ourobot has been developed that is able to adapt its shape to the environment. Using tactile sensors at the outer hull of the robot, the outline of the terrain and collisions with obstacles can be detected. Thus, the robot is able to locomote in uneven terrain and climb steep slopes. Since the shape adaption is based on run-time optimization, the quality function can be easily expanded to consider additional side conditions. The functionality of the proposed approach is demonstrated both in simulation and hardware.","Closed-kinematic-chain, Mobile robotics, Bioinspired, Tactile sensors, Terrain adaptation, Obstacle evasion, High DoF, Online optimization",Jan Paskarbeit and Simon Beyer and Matthäus Engel and Adrian Gucze and Johann Schröder and Axel Schneider,https://www.sciencedirect.com/science/article/pii/S0921889020305558,https://doi.org/10.1016/j.robot.2020.103715,0921-8890,2021,103715,140,Robotics and Autonomous Systems,Ourobot?A sensorized closed-kinematic-chain robot for shape-adaptive rolling in rough terrain,article,PASKARBEIT2021103715
"Accurate robot localization represents a challenge inside pipes due to the particular conditions that characterize this type of environment. Outdoor techniques (GPS in particular) do not work at all inside metal pipes, while traditional indoor localization methods based on camera or laser sensors do not perform well mainly due to a lack of external illumination and distinctive features along pipes. Moreover, humidity and slippery surfaces make wheel odometry unreliable. In this paper, we estimate the localization of a robot along a pipe with an alternative Radio Frequency (RF) approach. We first analyze wireless propagation in metallic pipes and propose a series of setups that allow us to obtain periodic RF spatial fadings (a sort of standing wave periodic pattern), together with the influence of the antenna position and orientation over these fadings. Subsequently, we propose a discrete RF odometry-like method, by means of counting the fadings while traversing them. The transversal fading analysis (number of antennas and cross-section position) makes it possible to increase the resolution of this method. Lastly, the model of the signal is used in a continuous approach serving as an RF map. The proposed localization methods outperform our previous contributions in terms of resolution, accuracy, reliability and robustness. Experimental results demonstrate the effectiveness of the RF-based strategy without the need for a previously known map of the scenario or any substantial modification of the existing infrastructure.","Robotics, Pipes, Tunnels, Propagation, RF fadings, Localization, Navigation, Inspection, Maintenance",Carlos Rizzo and Teresa Seco and Jesús Espelosín and Francisco Lera and José Luis Villarroel,https://www.sciencedirect.com/science/article/pii/S092188902030542X,https://doi.org/10.1016/j.robot.2020.103702,0921-8890,2021,103702,136,Robotics and Autonomous Systems,An alternative approach for robot localization inside pipes using RF spatial fadings,article,RIZZO2021103702
"Parallel continuum robots get their compliance and compactness from continuum rods while also having the stability and strength of parallel robots. Their potential to provide multi-degree-of-freedom articulation gives them versatility and makes them very useful in various applications. The purpose of this paper is to model a six link parallel continuum robot using the Cosserat theory. The single rod model is initially derived and experimentally verified with an average error of 12%. Then, the parallel continuum robot model is obtained by combining six elastic links, and eventually, some experiments are done on a real system to analyze the results of the obtained model.","Cosserat theory, Rod, Modeling, Parallel robot, Continuum robot, Elasticity",Morteza Ghafoori and Ali {Keymasi Khalaji},https://www.sciencedirect.com/science/article/pii/S0921889020304905,https://doi.org/10.1016/j.robot.2020.103650,0921-8890,2020,103650,134,Robotics and Autonomous Systems,Modeling and experimental analysis of a multi-rod parallel continuum robot using the Cosserat theory,article,GHAFOORI2020103650
"Place recognition is an essential component to address the problem of visual navigation and SLAM. The long-term place recognition is challenging as the environment exhibits significant variations across different times of the days, months, and seasons. In this paper, we view appearance changes as multiple domains and propose a Feature Disentanglement Network (FDNet) based on a convolutional auto-encoder and adversarial learning to extract two independent deep features ? content and appearance. In our network, the content feature is learned which only retains the content information of images through the competition with the discriminators and content encoder. Besides, we utilize the triplets loss to make the appearance feature encode the appearance information. The generated content features are directly used to measure the similarity of images without dimensionality reduction operations. We use datasets that contain extreme appearance changes to carry out experiments, which show how meaningful recall at 100% precision can be achieved by our proposed method where existing state-of-art approaches often get worse performance.","Visual place recognition, Changing environment, Adversarial learning, Representation disentanglement",Cao Qin and Yunzhou Zhang and Yan Liu and Sonya Coleman and Dermot Kerr and Guanghao Lv,https://www.sciencedirect.com/science/article/pii/S0921889020304012,https://doi.org/10.1016/j.robot.2020.103561,0921-8890,2020,103561,131,Robotics and Autonomous Systems,Appearance-invariant place recognition by adversarially learning disentangled representation,article,QIN2020103561
"In this study, we present a novel concept of a multi tethered drone system. The system includes an arbitrary number of drones connected serially to an active ground station. The considered drones are of quadrotor type. Utilizing a unique pulley?gimbal mechanism, each drone can freely move along the tether, and its state is measured with respect to the ground station without the use of standard onboard inertial sensors or GPS. The proposed system can be thought of as a robotic arm where each tether section acts as a variable-length link and each drone is a joint actuator. We model the coupled behavior of the ground station and the string, taking into account an arbitrary number of drones. Then, a controller that combines tools from geometric-control and Model Predictive Control is suggested. The developed model and control approach are also applicable for other swarm applications where the position of agents is to be controlled to a string-like form. Finally, the concept is demonstrated using numerical simulations and an initial experiment, which illustrate its potential effectiveness.",,Benny Kosarnovsky and Shai Arogeti,https://www.sciencedirect.com/science/article/pii/S0921889020304498,https://doi.org/10.1016/j.robot.2020.103609,0921-8890,2020,103609,133,Robotics and Autonomous Systems,Geometric and constrained control for a string of tethered drones,article,KOSARNOVSKY2020103609
"Legged-wheeled robots combine the advantages of efficient wheeled mobility with the capability of adapting to real-world terrains through the legged locomotion. Thanks to their hybrid mobility skill, they can excel in many application scenarios where other mobile platforms are not suitable for. However, the improved versatility of their mobility increases the number of constraints in their motion control, where both the properties of legged and wheeled functionalities need to be considered. Relevant schemes for legged-wheeled motion control so far have attempted to address the problem by exploiting separate motion control of the wheeled and legged functionalities. The contribution of this paper is the introduction of derivation of the legged-wheeled motion kinematics without constraining the camber angles of the wheels. To this end, the wheel geometry is approximated by torus that more precisely represents a real wheel geometry than a standard sphere/cylinder. On the basis of the derived legged-wheeled motion kinematics, a first-order inverse kinematics (IK) scheme that resolves the legged-wheeled robot whole-body motion respecting the wheel rolling constraint is described. Furthermore, a higher-level method to resolve wheel steering to comply with a non-holonomic constraint is designed. A damping scheme is proposed to handle a structural singularity when a system non-holonomy deteriorates. Finally, the work adopts a floating base model that allows to easily incorporate the legged motion into the proposed scheme. The developed control scheme is tested in experiments on a legged-wheeled centaur-like robot ? CENTAURO.","Hybrid locomotion, Wheeled-legged robots, Wheeled robots, Legged robots, Kinematic modelling, Motion control",Ma?gorzata Kamedu?a and Navvab Kashiri and Nikos G. Tsagarakis,https://www.sciencedirect.com/science/article/pii/S0921889019304634,https://doi.org/10.1016/j.robot.2020.103482,0921-8890,2020,103482,128,Robotics and Autonomous Systems,Wheeled motion kinematics and control of a hybrid mobility CENTAURO robot,article,KAMEDULA2020103482
"Vehicle tracking is an attractive problem in the field of public transportation with several research projects conducted using Kalman filter (KF) to tackle this. While a driver may act on his own decision, there exist parameters affecting his behavior so called situation assessment such as neighboring drivers, possible obstacles, or alternative routes changing over time. In this paper, utilizing online situation assessment (SA) inside Kalman filter is studied. Motion History Graph is used as online modeling of the history of the vehicle motions and is used to augment the estimation. Experimental results on video sequences from different datasets show an average 25 percent performance improvement when using online SA inside KF.","Vehicle tracking, Kalman filter, Situation assessment",Maryam {Baradaran Khalkhali} and Abedin Vahedian and Hadi {Sadoghi Yazdi},https://www.sciencedirect.com/science/article/pii/S092188902030436X,https://doi.org/10.1016/j.robot.2020.103596,0921-8890,2020,103596,131,Robotics and Autonomous Systems,Vehicle tracking with Kalman filter using online situation assessment,article,BARADARANKHALKHALI2020103596
"In human?robot cooperation, the information interaction plays a key role. Most of the information interaction rely on Border Gateway Protocol (BGP), which is a vital route protocol on networks. However, the BGP is susceptible to the prefix interception attacks because the rightful origin of each prefix cannot be verified in BGP. For this reason, we propose a novel and effective route selection method against prefix interception attacks, which combines the resilience of routers and the historical performance of routers to choose a secure route. Moreover, we estimate the performance of BGP by introducing the definition of resilience and the historical performance of routers via online learning against the prefix interception attack. Furthermore, we analyze the bound of regret and obtain O(T) regret, where T denotes the time horizon. In addition, the proposed method is verified both on synthetic data and network simulations. The results show that the proposed method has more resilience against prefix interception attacks than Counter-Raptor.","Online learning, Prefix interception, Routing attacks, Secure route",Meng Meng and Ruijuan Zheng and Ruxi Peng and Junlong Zhu and Mingchuan Zhang and Qingtao Wu,https://www.sciencedirect.com/science/article/pii/S0921889020303961,https://doi.org/10.1016/j.robot.2020.103556,0921-8890,2020,103556,131,Robotics and Autonomous Systems,Safeguarding against prefix interception attacks via online learning,article,MENG2020103556
"Within the wide field of self-assembly, the self-folding chain has the unique capability to pass through narrow openings, too small for the assembled structure, yet consists in one connected body. This paper presents a novel analytical framework and corresponding experimental setup to quantify the results of a self-folding process using magnetic forces at the centimetre-scale, with the aim to put experimental results and prediction methods in the context of surgical anchoring and therapy. Two possibilities to predict the folding of a chain of magnetic components in 2D are compared and investigated in an experimental setup. Folding prediction by system Coulomb energy, neglecting folding dynamics, is compared with a simulation of the system dynamics using a novel approach for 2D folding chains, derived from the Newton?Euler equations. The presented algorithm is designed for the parallel computation architecture of modern computer systems to be easily applicable and to achieve an improved simulation speed. The experimental setup for the self-folding chain used to validate the simulation results consists of a chain of magnetic components where movement is limited to one plane and the chain is agitated by the magnetic forces between the chain components. The folding process of the experimental setup is validated for its stability and predictability under different deployment modes. Finally, the results are discussed in light of the folding prediction of longer chains. The implications of the presented findings for a 3D folding chain are discussed together with the challenges to apply the novel dynamics simulation algorithm to the 3D case. The work clearly demonstrates the potential for this novel approach for complex self-folding applications such as magnetic compression anastomosis and anchoring in minimally invasive surgery.","Magnetic self-folding chain, Self-assembly,  dynamics, Magnetic surgery",T.H. Fass and Guangbo Hao and Pádraig Cantillon-Murphy,https://www.sciencedirect.com/science/article/pii/S0921889020304413,https://doi.org/10.1016/j.robot.2020.103601,0921-8890,2020,103601,132,Robotics and Autonomous Systems,On planar self-folding magnetic chains: Comparison of Newton?Euler dynamics and internal energy optimisation,article,FASS2020103601
"A 3UPU-I parallel sensor with six division-force limbs and six standard force sensors is developed for measuring robotic wrist load. Its measuring approach and performances are studied and evaluated. A prototype of the developed parallel sensor is built up and its merits are analyzed. A statics equation among the forces of the six standard force sensors and the wrist load is established, and a mapped matrix from the workload to the forces of the six standard force sensors is derived based on a 3UPU-I parallel mechanism of the developed parallel sensor. The performances of the developed parallel sensor are analyzed and evaluated by respectively varying key parameters for constructing the developed parallel sensor, and the reasonable values of the key parameters are determined. The forces of the six standard force sensors are measured by adding different workload components onto the loaded platform of the prototype. Finally, some theoretical solutions of the developed parallel sensor are solved and verified by the FE simulation solutions of the developed parallel sensor. The experimental calibration solutions of the prototype are coincident with the theoretical solutions.","Parallel structure sensor, Division-force limb, Six-component force/torque, Performance evaluation",Yi Lu and Yongli Wang and Yang Lu,https://www.sciencedirect.com/science/article/pii/S0921889019309133,https://doi.org/10.1016/j.robot.2020.103486,0921-8890,2020,103486,127,Robotics and Autonomous Systems,Development of 3UPU-I parallel sensor with six division-force limbs for measuring robotic wrist load,article,LU2020103486
"In autonomous driving, many intelligent perception technologies have been put in use. However, visual SLAM still has problems with robustness, which limits its application, although it has been developed for a long time. We propose a feature-aided semi-direct approach to combine the direct and indirect methods in visual SLAM to allow robust localization under various situations, including large-baseline motion, textureless environment, and great illumination changes. In our approach, we first calculate inter-frame pose estimation by feature matching. Then we use the direct alignment and a multi-scale pyramid, which employs the previous coarse estimation as a priori, to obtain a more precise result. To get more accurate photometric parameters, we combine the online photometric calibration method with visual odometry. Furthermore, we replace the Shi?Tomasi corner with the ORB feature, which is more robust to illumination. For extreme brightness change, we employ the dark channel prior to weaken the halation and maintain the consistency of the image. To evaluate our approach, we build a full stereo visual SLAM system. Experiments on the publicly available dataset and our mobile robot dataset indicate that our approach improves the accuracy and robustness of the SLAM system.","Visual SLAM, Hybrid method, Image brightness rectification",Xiangrui Zhao and Lina Liu and Renjie Zheng and Wenlong Ye and Yong Liu,https://www.sciencedirect.com/science/article/pii/S0921889020304371,https://doi.org/10.1016/j.robot.2020.103597,0921-8890,2020,103597,132,Robotics and Autonomous Systems,A Robust Stereo Feature-aided Semi-direct SLAM System,article,ZHAO2020103597
"Robotic obstacle avoidance is an important issue in robotic navigation for unknown or partially known, dynamic environments. A good number of techniques have already been proposed to navigate obstacles in this kind of environment. They include a series of velocity space methods that have been successful implemented in several applications. They formulate the problem as one of constrained optimization in the velocity space of the robot. The constraints include the obstacles in the environment assuming they are static. In this paper, we present an efficient, real-time method (BCM-DO) to include the restrictions imposed by dynamic objects. The optimization function has also been adapted to include these new restrictions. The new function is evaluated in two sets of points. A first set is obtained from a coarse sampling in the reachable window of velocities and a second set is selected in the limits of each curvature interval to avoid missing small openings between static objects. The whole system has first been extensively tested in several simulated robots and finally applied to a hotel assistant robot (BellBot) resulting in an efficient, real-time obstacle avoidance method that produces smooth and reliable routes.","Collision avoidance, Dynamic environment, Robot motion control, Reactive control",Joaquín López and Pablo Sanchez-Vilariño and Miguel Díaz Cacho and Elena López Guillén,https://www.sciencedirect.com/science/article/pii/S0921889020304097,https://doi.org/10.1016/j.robot.2020.103569,0921-8890,2020,103569,131,Robotics and Autonomous Systems,Obstacle avoidance in dynamic environments based on velocity space optimization,article,LOPEZ2020103569
"Recent research on automotive driving has developed an efficient end-to-end learning mode that directly maps visual input to control commands. However, it models distinct driving variations in a single network, which increases learning complexity and is less adaptive for modular integration. In this paper, we re-investigate human?s driving style and propose to learn an intermediate driving intention region to relax the difficulties in end-to-end approach. The intention region follows both road structure in image and direction towards goal in public route planner, which addresses visual variations only and figures out where to go without conventional precise localization. Then the learned visual intention is projected on vehicle local coordinate and fused with reliable obstacle perception to render a navigation score map that is widely used for motion planning. The core of the proposed system is a weakly-supervised cGAN-LSTM model trained to learn driving intention from human demonstration. The adversarial loss learns from limited demonstration data with one local planned route and enables reasoning of multi-modal behaviors with diverse routes while testing. Comprehensive experiments are conducted with real-world datasets. Results indicate the proposed paradigm can produce more consistent motion commands with human demonstration and shows better reliability and robustness to environment change. Our code is available at https://github.com/HuifangZJU/visual-navigation.",,Huifang Ma and Yue Wang and Rong Xiong and Sarath Kodagoda and Li Tang,https://www.sciencedirect.com/science/article/pii/S0921889019308048,https://doi.org/10.1016/j.robot.2020.103477,0921-8890,2020,103477,127,Robotics and Autonomous Systems,DeepGoal: Learning to drive with driving intention from human control demonstration,article,MA2020103477
"We present a Visual Place Recognition (VPR) pipeline that achieves substantially improved precision as compared with approaches commonly appearing in the literature. It is based on a standard image retrieval configuration, with an initial stage that retrieves the closest candidates to a query from a database and a second stage where the list of candidates is re-ranked. The latter is realized by the introduction of a novel geometric verification procedure that uses the activations of a pre-trained convolutional neural network. It is both remarkably simple and robust to viewpoint and condition changes. As a stand-alone, general spatial matching methodology, it could be easily added and used to enhance existing VPR approaches whose output is a ranked list of candidates. The proposed two-stage pipeline is also improved through extensive optimization of hyperparameters and by the implementation of a frame-based temporal filter that takes into account past recognition results.","Visual Place Recognition, Convolutional neural networks, Autonomous navigation, Image retrieval, Computer vision, Deep learning",Luis G. Camara and Libor P?eu?il,https://www.sciencedirect.com/science/article/pii/S0921889020304656,https://doi.org/10.1016/j.robot.2020.103625,0921-8890,2020,103625,133,Robotics and Autonomous Systems,Visual Place Recognition by spatial matching of high-level CNN features,article,CAMARA2020103625
"This paper continues the previous effort on the development of a trajectory generation platform that assures minimum-control expenditure and collision-free manoeuvre of a torpedo-shaped autonomous underwater vehicle (AUV) into a funnel-shaped stationary docking station (DS). The earlier-developed guidance system was based on the Inverse Dynamics in the Virtual Domain (IDVD) method accounting for AUV?s dynamics and producing a smooth trackable trajectory, thus guaranteeing safe arrival to DS. The optimality of the real-time generated solutions has been assessed via comparing them with the Legendre?Gauss?Lobatto pseudo-spectral (PS) method solutions that could only be obtained off-line. This paper explores a possibility of employing a more advanced hp-adaptive Radau (hp-AR) PS method for the same Hamiltonian two-point boundary-value problem. The considered approach explicitly encapsulates all realistic vehicular and environmental constraints such as the AUV?s dynamics, ocean current disturbances, no-fly zones, and DS pose while minimizing the vehicle?s controls expenditure and permitting precise manoeuvring into DS. The performance evaluation of the hp-AR PS based optimization routine is carried out through extensive software-in-the-loop simulations. For completeness, computational effectiveness and solution optimality of the trajectory generator engine based on the hp-AR method is compared with two other well-known PS methods based on Legendre and Chebyshev polynomial approximation. The results of this study show the superb performance of the hp-AR method-based trajectory generator among all other PS methods and a possibility of using it along with IDVD in the real-time implementation.","Underwater docking, Optimal trajectory generation, Two-point boundary-value problem, hp-adaptive Radau method",A.M. Yazdani and K. Sammut and O.A. Yakimenko and A. Lammas,https://www.sciencedirect.com/science/article/pii/S0921889020304814,https://doi.org/10.1016/j.robot.2020.103641,0921-8890,2020,103641,133,Robotics and Autonomous Systems,Feasibility analysis of using the hp-adaptive Radau pseudospectral method for minimum-effort collision-free docking operations of AUV,article,YAZDANI2020103641
"Robotic skill learning suffers from the diversity and complexity of robotic tasks in continuous domains, making the learning of transferable skills one of the most challenging issues in this area, especially for the case where robots differ in terms of structure. Aiming at making the policy easier to be generalized or transferred, the graph neural networks (GNN) was previously employed to incorporate explicitly the robot structure into the policy network. In this paper, with the help of graph neural networks, we further investigate the problem of efficient learning transferable policies for robots with serial structure, which commonly appears in various robot bodies, such as robotic arms and the leg of centipede. Based on a kinematics analysis on the serial robotic structure, the policy network is improved by proposing a weighted information aggregation strategy. It is experimentally shown on different robotics structures that in a few-shot policy learning setting, the new aggregation strategy significantly improves the performance not only on the learning speed, but also on the control accuracy.","Skill transfer learning, Serial structures, Robot skill learning, Graph Neural Network",Fengyi Zhang and Zhiyong Liu and Fangzhou Xiong and Jianhua Su and Hong Qiao,https://www.sciencedirect.com/science/article/pii/S092188902030395X,https://doi.org/10.1016/j.robot.2020.103555,0921-8890,2020,103555,130,Robotics and Autonomous Systems,WAGNN: A Weighted Aggregation Graph Neural Network for robot skill learning,article,ZHANG2020103555
"This paper addresses multi-robot task scheduling for two robot types arising from heterogeneous robotic order fulfillment systems. The heterogeneous multi-robot system comprises two types of robots with specialized and complementary capabilities to achieve long-cycle and multi-station order fulfillment tasks on a logistic network. This problem is extremely challenging because of innate complex-schedule constraints of tasks and coupled temporal?spatial relations between all robots. After set-theoretic and mixed integer linear programming problem formulations, we use coupled approach, instead of decoupled approaches to explore the synergy between heterogeneous robots, which is different from most existing similar works. To model the structural (complex-schedule) and quantitative (temporal?spatial) coupledness of robots? time-extended task schedules, an edge-weighted and vertex-weighted block sequence graph is introduced. Based on this model, time-extended task scheduling is achieved using rank-minimal heuristic and genetic algorithm metaheuristic. Theoretically, this model is complete and non-redundant. Empirically, compared with decoupled approach, optimality and efficiency of the proposed methods are evaluated on designed instances. The results demonstrate that coupled methods can achieve near-optimal solutions with higher performance ratio than decoupled methods in moderate time. At the same time, coupled methods can leverage spatial and temporal properties of miscellaneous tasks, and balance instantaneous and time-extended decisions to achieve tight collective synergy in the long run.","Task scheduling, Heterogeneous multi-robot system, Complex-schedule constraints, Block sequence graph",Hanfu Wang and Weidong Chen and Jingchuan Wang,https://www.sciencedirect.com/science/article/pii/S0921889020304000,https://doi.org/10.1016/j.robot.2020.103560,0921-8890,2020,103560,131,Robotics and Autonomous Systems,Coupled task scheduling for heterogeneous multi-robot system of two robot types performing complex-schedule order fulfillment tasks,article,WANG2020103560
"The motion coordination problem for a fleet of Autonomous Guided Vehicles (AGVs) in a confined industrial facility is addressed. The working scenario involves a group of AGVs that is tasked to transport without collisions to predefined locations within the industrial facility. We introduce a centralized motion coordination controller that utilizes a dynamic priority logic to resolve motion conflicts between AGVs as they appear. The controller relies on the implementation of a predefined, virtual transportation network that is comparable to a conventional right-handed bidirectional traffic system. The construction of the transportation network considers the physical and motion characteristics of the AGVs (dimensions and maximum speed). The high-level function of the controller is to detect imminent collisions and determine the right-of-way of conflicting AGVs in same-directional routes and intersection junctions of the transportation network. The priority update logic is inspired by the traffic control of conventional four-way stop-controlled intersections. Based on the updated priorities, the motion coordinator adjusts the advancement of the AGVs to eliminate collisions. The proposed formulation combines a high-level event-driven logic for collision avoidance with low-level feedback control laws for guidance and navigation. As a result, the controller relies only on real-time measurements, removing the need for computationally demanding look-ahead predictions (heuristics) of the AGVs? motion. It is shown that the proposed method ensures collision- and blockage-free motion of a large number of AGVs. Extensive numerical simulations validate the performance of the motion coordination algorithm.","Multi-robot systems, Motion coordination, Autonomous Guided Vehicles",Mehmet Ali Guney and Ioannis A. Raptis,https://www.sciencedirect.com/science/article/pii/S0921889018305505,https://doi.org/10.1016/j.robot.2020.103534,0921-8890,2021,103534,139,Robotics and Autonomous Systems,Dynamic prioritized motion coordination of multi-AGV systems,article,GUNEY2021103534
"We address the general problem of multiple target localization and pursuit using measurements of the ranges from the targets to a set of autonomous pursuing vehicles, referred to as trackers. We develop a general framework for targets with models exhibiting uncertainty in the initial state, process, and measurement noise. The main objective is to compute optimal motions for the trackers that maximize the range-based information available for target localization and at the same time yield good target pursuit performance. The solution proposed is rooted in an estimation-theoretical setting that involves the computation of an appropriately defined Bayesian Fisher Information Matrix (FIM). The inverse of the latter yields a posterior Cramér?Rao Lower Bound (CRLB) on the covariance of the targets? state estimation errors that can be possibly achieved with any estimator. Using the FIM, sufficient conditions on the trackers? motions are derived for the ideal relative geometry between the trackers and the targets for which the range information acquired is maximal. This allows for an intuitive understanding of the types of ideal tracker trajectories. To deal with realistic constraints on the trackers? motions and the requirement that the trackers pursue the targets, we then propose a model predictive control (MPC) framework for optimal tracker motion generation with a view to maximizing the predicted range information for target localization while taking explicitly into account the trackers? dynamics, strict constraints on the trackers? states and inputs, and prior knowledge about the targets? states. The efficacy of the MPC is assessed in simulation through the help of representative examples motivated by operational scenarios involving single and multiple targets and trackers.","Range-based target localization, Target tracking, Target pursuit, MPC, Fisher information matrix, Posterior CRLB, Autonomous vehicle",Nguyen T. Hung and N. Crasta and David Moreno-Salinas and António M. Pascoal and Tor A. Johansen,https://www.sciencedirect.com/science/article/pii/S0921889020304486,https://doi.org/10.1016/j.robot.2020.103608,0921-8890,2020,103608,132,Robotics and Autonomous Systems,Range-based target localization and pursuit with autonomous vehicles: An approach using posterior CRLB and model predictive control,article,HUNG2020103608
"Advanced Driver Assistance Systems (ADAS) and Automated and Autonomous Vehicles (AV) are cooperative systems and processes that use: artificial intelligence, cognitive methods, cloud technologies, cooperative vehicle-to-everything-communications (V2X), software?hardwareplatforms, sensor platforms and incipient intelligent transport infrastructures, to get self-driving systems and smart connected mobility services. This paper, to support automated driving systems (assisted, semi-autonomous and fully autonomous vehicles), introduces a cognitive layer called Associated Reality to enhance the involved information, knowledge and communication processes. The architecture defined includes an augmented Local Dynamic Map, with complementary layers, and an augmented Graph Database, with complementary semantic?cognitive relations, for the considered purpose, in cooperative human?machine and machine?machine systems. Virtual augmented landmarks are defined to improve the connectivity and intelligence of the involved spatial-information systems. Different structure landmarks and sequence landmarks (which includes regular, repetitive and periodic landmarks) are defined, categorized and used in diverse visual localization and mapping scenarios, for autonomous driving. In this paper, it is also shown, as a proof-of-concept for vehicle localization and mapping in road tunnels, the visual detection of different sequences of periodic luminaires, using YOLO v3 for the corresponding LED lights detection, or a specific alternative procedure developed with very low computational cost.","ADAS and autonomous vehicle, Cooperative-ITS, Human?Machine? system, Augmented Local Dynamic Map, Cognitive system, Cognitive landmark",Felipe Fernandez and Angel Sanchez and Jose F. Velez and Belen Moreno,https://www.sciencedirect.com/science/article/pii/S0921889020304644,https://doi.org/10.1016/j.robot.2020.103624,0921-8890,2020,103624,133,Robotics and Autonomous Systems,Associated Reality: A cognitive Human?Machine Layer for autonomous driving,article,FERNANDEZ2020103624
"This paper addresses the problem of human grasp position estimation in a physical human?robot object handling scenario. The problem is formulated as a linear regression by considering the human grasp position and their exerted torque as unknown parameters. We propose a modified least-squares algorithm to estimate the parameters by evaluating the quality of the estimates based on the assumption that the parameters should remain constant for a period of time. The solution is model-agnostic in terms of the human force/torque model ? requiring only force/torque measurements on the robot side and proprioception ? and is model-based in terms of the object model. The proposed grasp position estimation method is compared statistically with a conventional contact point estimation method using the collected experimental data. Moreover, the performance of the developed method is evaluated through various scenarios of physical human?robot interaction.","Physical human?robot interaction, Collaborative robots, Object manipulation, Estimation",Ramin Jaberzadeh Ansari and Giuseppe Giordano and Jonas Sjöberg and Yiannis Karayiannidis,https://www.sciencedirect.com/science/article/pii/S0921889020304401,https://doi.org/10.1016/j.robot.2020.103600,0921-8890,2020,103600,131,Robotics and Autonomous Systems,Human grasp position estimation for human?robot cooperative object manipulation,article,ANSARI2020103600
"This work details the design and simulation results of a bioinspired minimalist algorithm based on C. elegans, using autonomous agents to forage for attractant energy sources. The robotic agents are energy-constrained and depend on the energy they forage to recharge their batteries, which is significant as the foraging task is one of the canonical testbeds for cooperative robotics. The algorithm consists of 6 input parameters which were simulated and optimised in 9 unbounded environments of varying difficulty levels, containing attractant sources which robots would then have to forage from to maintain energy levels and survive the entirety of the simulation. The robots running the algorithm were then optimised using Evolutionary Algorithms and the best solutions in all 9 environments were categorised with the use of clustering techniques. The clustering results highlighted the different strategies which emerged. Ultimately across the 9 environments, 6 different strategies have been identified. The results demonstrate the applicability of the proposed algorithm to localise attractant sources and harvest energy in different scenarios using the same core algorithm.",,Gabriela R. Andrade and Jordan H. Boyle,https://www.sciencedirect.com/science/article/pii/S0921889019304002,https://doi.org/10.1016/j.robot.2020.103499,0921-8890,2020,103499,128,Robotics and Autonomous Systems,A minimal biologically-inspired algorithm for robots foraging energy in uncertain environments,article,ANDRADE2020103499
"The design of high-level decision-making systems is a topical problem in the field of autonomous driving. In this paper, we combine traditional rule-based strategies and reinforcement learning (RL) with the goal of achieving transparency and robustness. On the one hand, the use of handcrafted rule-based controllers allows for transparency, i.e., it is always possible to determine why a given decision was made, but they struggle to scale to complex driving scenarios, in which several objectives need to be considered. On the other hand, black-box RL approaches enable us to deal with more complex scenarios, but they are usually hardly interpretable. In this paper, we combine the best properties of these two worlds by designing parametric rule-based controllers, in which interpretable rules can be provided by domain experts and their parameters are learned via RL. After illustrating how to apply parameter-based RL methods (PGPE) to this setting, we present extensive numerical simulations in the highway and in two urban scenarios: intersection and roundabout. For each scenario, we show the formalization as an RL problem and we discuss the results of our approach in comparison with handcrafted rule-based controllers and black-box RL techniques.","Autonomous driving, Decision making, Interpretability, Reinforcement learning, Parameter-based exploration",Amarildo Likmeta and Alberto Maria Metelli and Andrea Tirinzoni and Riccardo Giol and Marcello Restelli and Danilo Romano,https://www.sciencedirect.com/science/article/pii/S0921889020304085,https://doi.org/10.1016/j.robot.2020.103568,0921-8890,2020,103568,131,Robotics and Autonomous Systems,Combining reinforcement learning with rule-based controllers for transparent and general decision-making in autonomous driving,article,LIKMETA2020103568
"The design of a phase-based robust oscillator for wearable robots, that could assist humans performing periodic or repetitive tasks, is presented in this paper. The bounds on perturbations, that guaranteed the stability of the output for the phase oscillator controller, were identified and the Lyapunov redesign method was applied to construct a robust controller using a bounding function. The robust controller produced a bounded control signal to modify the amplitude and frequency of the resulting second-order oscillator to modulate the stiffness and damping properties. In this paper, the focus is on the mathematical modeling of the controller, its dynamic stability and robustness for human?robot application. The proposed approach was verified through a simple pendulum experiment. The results provided evidence that a better limit cycle, with a controlled radial spread of the steady state, was obtained with Lyapunov redesigned phase oscillator. Finally, the potential of the proposed approach for hip assistance in a healthy subject wearing HeSa (Hip Exoskeleton for Superior Assistance) during periodic activities are discussed with preliminary results.","Phase oscillator, Wearable robot, Hip exoskeleton, Nonlinear controller",Juan {De La Fuente} and Susheelkumar C. Subramanian and Thomas G. Sugar and Sangram Redkar,https://www.sciencedirect.com/science/article/pii/S0921889019305287,https://doi.org/10.1016/j.robot.2020.103514,0921-8890,2020,103514,128,Robotics and Autonomous Systems,A robust phase oscillator design for wearable robotic systems,article,DELAFUENTE2020103514
"Most designs of wearable robots are based on human biomechanical statistics, engineering experience or individual experiments. Despite great successes, few of them consider the human?robot integration and individual differences between users. Additionally, the design periods, cost and safety also need to be further improved. Learning from the natural driving mechanism of human body, we propose a general human-in-the-loop (HIL) optimization designing approach for this kind of wearable robots. Firstly, the human?robot coupling model of the personalized wearable robot and the human musculoskeletal model are established. Then, the Computed Muscle Control (CMC) tool embedded in software OpenSim and the Bayesian optimization used in machine learning are combined to find the optimal design scheme for the personalized wearable robots to reduce the human metabolic energy cost in specific physical movement. The HIL approach could not only optimize the control parameters of wearable robots, but also optimize their geometry, material and any other design parameters flexibly and effectively. An application example for the HIL approach is also provided to help designers better understand and use the HIL method proposed in this paper.","Wearable robotics, Human?robot interaction, Human-in-the-loop design",Jing Fang and Yuan Yuan,https://www.sciencedirect.com/science/article/pii/S0921889019308036,https://doi.org/10.1016/j.robot.2020.103495,0921-8890,2020,103495,127,Robotics and Autonomous Systems,Human-in-the-loop optimization of wearable robots to reduce the human metabolic energy cost in physical movements,article,FANG2020103495
"Operating Micro Aerial Vehicles (MAVs) in subterranean environments is becoming more and more relevant in the field of aerial robotics. Despite the large spectrum of technological advances in the field, flying in such challenging environments is still an ongoing quest that requires the combination of multiple sensor modalities like visual/thermal cameras as well as 3D and 2D lidars. Nevertheless, there exist cases in subterranean environments where the aim is to deploy fast and lightweight aerial robots for area reckoning purposes after an event (e.g. blasting in production areas). This work proposes a novel baseline approach for the navigation of resource constrained robots, introducing the aerial underground scout, with the main goal to rapidly explore unknown areas and provide a feedback to the operator. The main proposed framework focuses on the navigation, control and vision capabilities of the aerial platforms with low-cost sensor suites, contributing significantly towards real-life applications. The merit of the proposed control architecture is that it considers the flying platform as a floating object, composing a velocity controller on the x, y axes and altitude control to navigate along the tunnel. Two novel approaches make up the cornerstone of the proposed contributions for the task of navigation: (1) a vector geometry method based on 2D lidar, and (2) a Deep Learning (DL) method through a classification process based on an on-board image stream, where both methods correct the heading towards the center of the mine tunnel. Finally, the framework has been evaluated in multiple field trials in an underground mine in Sweden.","MAVs navigation, Autonomous tunnel inspection, Mining aerial robotics",Sina Sharif Mansouri and Christoforos Kanellakis and Dariusz Kominiak and George Nikolakopoulos,https://www.sciencedirect.com/science/article/pii/S0921889019306256,https://doi.org/10.1016/j.robot.2020.103472,0921-8890,2020,103472,126,Robotics and Autonomous Systems,Deploying MAVs for autonomous navigation in dark underground mine environments,article,MANSOURI2020103472
"We present a novel method to localize the vehicle on an easily accessible geo-referenced satellite image based on LiDAR. We first design a neural network to extract and compare the spatial-discriminative feature maps of the satellite image patch and the LiDAR points, and obtain the probability of correspondence. Then based on the outputs of the network, a particle filter is used to obtain the probability distribution of the vehicle pose. This method can use LiDAR points and any type of odometry as input to localize the vehicle. The experimental results show that our model can generalize well on several datasets. Compared with other methods, ours is more robust in some challenging scenarios such as the occluded or shadowed area on the satellite image.","Localization, Deep learning, LiDAR, Satellite image matching",Mengyin Fu and Minzhao Zhu and Yi Yang and Wenjie Song and Meiling Wang,https://www.sciencedirect.com/science/article/pii/S0921889019305202,https://doi.org/10.1016/j.robot.2020.103519,0921-8890,2020,103519,129,Robotics and Autonomous Systems,LiDAR-based vehicle localization on the satellite image via a neural network,article,FU2020103519
"With the rapid development of computer vision, vision-based simultaneous localization and mapping (vSLAM) plays an increasingly important role in the field of unmanned driving. However, traditional SLAM methods based on a monocular camera only perform well in simple indoor environments or urban environments with obvious structural features. In off-road environments, the situation that SLAM encounters could be complicated by problems such as direct sunlight, leaf occlusion, rough roads, sensor failure, sparsity of stably trackable texture. Traditional methods are highly susceptible to these factors, which lead to compromised stability and reliability. To counter such problems, we propose a panoramic vision SLAM method based on multi-camera collaboration, aiming at utilizing the characters of panoramic vision and stereo perception to improve the localization precision in off-road environments. At the same time, the independence and information sharing of each camera in multi-camera system can improve its ability to resist bumps, illumination, occlusion and sparse texture in an off-road environment, and enable our method to recover the metric scale. These characters ensure unmanned ground vehicles (UGVs) to locate and navigate safely and reliably in complex off-road environments.","Multi-camera, Panorama, Off-road, Simultaneous localization and mapping",Yi Yang and Di Tang and Dongsheng Wang and Wenjie Song and Junbo Wang and Mengyin Fu,https://www.sciencedirect.com/science/article/pii/S0921889019308711,https://doi.org/10.1016/j.robot.2020.103505,0921-8890,2020,103505,128,Robotics and Autonomous Systems,Multi-camera visual SLAM for off-road navigation,article,YANG2020103505
"Novel applications of soft pneumatic actuation in minimally invasive surgery (MIS) are proposed due to its relatively safe robot?environment interactions. Although the inherent compliance of soft robots makes them suitable for surgery, their low force output and complicated system response and behavior may limit their potential as practical MIS instruments. In this paper, three lobster-inspired antagonistic modules are proposed to realize bidirectional translational, bending and rotational motions and variable stiffness in centimeter scale. Their modular design enables flexible combinations of articulated shafts to satisfy end-effector workspace requirements in MIS. Theoretical models are proposed to relate the input pressure, deformation, output force/torque and stiffness, which provide quantitative solutions for independent adjustment on the deformation and stiffness of each module. A series of experimental results show that the proposed modules can deliver sufficient force and torque output for MIS applications, and they can be conveniently assembled into articulated shafts featuring safe actuation, high dexterity, stiffness tuning and reconfigurability.","Soft pneumatic actuation, Hybrid robots, Minimally invasive surgery, Soft robotics",Yaohui Chen and Hoam Chung and Bernard Chen and  Baoyinjiya,https://www.sciencedirect.com/science/article/pii/S0921889020304395,https://doi.org/10.1016/j.robot.2020.103599,0921-8890,2020,103599,131,Robotics and Autonomous Systems,A lobster-inspired articulated shaft for minimally invasive surgery,article,CHEN2020103599
"A methodology for planning the sequence of tasks for a harvesting robot is presented. The fruit targets are situated at unknown locations and must be detected by the robot through a sequence of sensing tasks. Once the targets are detected, the robot must execute a harvest action at each target location. The traveling salesman paradigm (TSP) is used to plan the sequence of sensing and harvesting tasks taking into account the costs of the sensing and harvesting actions and the traveling times. Sensing is planned online. The methodology is validated and evaluated in both laboratory and greenhouse conditions for a case study of a sweet pepper harvesting robot. The results indicate that planning the sequence of tasks for a sweet pepper harvesting robot results in 12% cost reduction. Incorporating the sensing operation in the planning sequence for fruit harvesting is a new approach in fruit harvesting robots and is important for cycle time reduction. Furthermore, the sequence is re-planned as sensory information becomes available and the costs of these new sensing operations are also considered in the planning.","Harvesting robot, Task sequencing, Traveling salesman problem, Sweet pepper, Agriculture robotics",Polina Kurtser and Yael Edan,https://www.sciencedirect.com/science/article/pii/S0921889020304310,https://doi.org/10.1016/j.robot.2020.103591,0921-8890,2020,103591,131,Robotics and Autonomous Systems,Planning the sequence of tasks for harvesting robots,article,KURTSER2020103591
"Automated image completion and masking have been emerged as a subject of keen interest due to their impact on image modification and interpretation. The current state-of-the-art approaches require a fixed format of missing parts and are ineffective for handling corrupted images. Besides, they focus exclusively on the image completion without taking into consideration the image masking as an inverse process of completion. This paper proposes a deep learning approach to an integrated framework of image completion and masking based on the cross-mapping generative adversarial network or CM-GAN, in short. CM-GAN offers the robustness in image completion under corruptions as well as the capability of synthesizing various masked images with arbitrary mask locations and shapes. In particular, the capability of CM-GAN in image masking is shown to be extended into the removal of unwanted backgrounds in images. We verify the superior performance of CM-GAN for image completion and masking based on extensive experiments. Furthermore, we implement a deep learning based robotic bin picking to demonstrate that the background removal capability of CM-GAN plays a key role for estimating the 3D pose of randomly filed multiple industrial parts in a bin.","Generative adversarial network, Latent space association network, Image completion, Image masking, Robotic bin picking",Sukhan Lee and Naeem Ul Islam and Soojin Lee,https://www.sciencedirect.com/science/article/pii/S0921889020304036,https://doi.org/10.1016/j.robot.2020.103563,0921-8890,2020,103563,131,Robotics and Autonomous Systems,Robust image completion and masking with application to robotic bin picking,article,LEE2020103563
"Despite the increment of researches related to Social Assistive Robotics (SAR), achieving a plausible Robot-Assisted Diagnosis (RAD) for Children with Autism Spectrum Disorders (CwASD) remains a considerable challenge to the clinical and robotics community. The work of specialists regarding ASD diagnosis is hard and labor-intensive due to the condition?s manifestations are inherently heterogeneous and makes the process more difficult. Besides, the aforementioned complexity may be the main reason for the slow progress in the development of SAR with diagnostic purposes. Thus, this work provides a comprehensive Robot-Assisted Intervention for CwASD showing the conditions in which a Robot-based approach can be useful to assess autism risk factors for an autism diagnosis purpose. The intervention scheme consists of an improved version of a multimodal environment for Robot-based intervention proposed in our previous work. More specifically, we compared the behavior of CwASD with that of children in a control group during a human/robot-mediated intervention while Joint Attention (JA) behaviors are elicited and analyzed. Through statistical data analysis, it was possible to identify that 17 out of 23 children of the CwASD group showed a different behavior pattern related to three characteristics of autism, which suggests that this pattern can be used to identify autism risk factors through Robot-based interventions.","Autism Spectrum Disorder, Autism screening, Social Assistive Robotics, Child?Robot Interaction",Andrés A. Ramírez-Duque and Teodiano Bastos and Marcela Munera and Carlos A. Cifuentes and Anselmo Frizera-Neto,https://www.sciencedirect.com/science/article/pii/S0921889019304452,https://doi.org/10.1016/j.robot.2020.103484,0921-8890,2020,103484,127,Robotics and Autonomous Systems,Robot-Assisted Intervention for children with special needs: A comparative assessment for autism screening,article,RAMIREZDUQUE2020103484
"Combining model-based and model-free learning systems has been shown to improve the sample efficiency of learning to perform complex robotic tasks. However, dual-system approaches fail to consider the reliability of the learned model when it is applied to make multiple-step predictions, resulting in a compounding of prediction errors and performance degradation. In this paper, we present a novel dual-system motor learning approach where a meta-controller arbitrates online between model-based and model-free decisions based on an estimate of the local reliability of the learned model. The reliability estimate is used in computing an intrinsic feedback signal, encouraging actions that lead to data that improves the model. Our approach also integrates arbitration with imagination where a learned latent-space model generates imagined experiences, based on its local reliability, to be used as additional training data. We evaluate our approach against baseline and state-of-the-art methods on learning vision-based robotic grasping in simulation and real world. The results show that our approach outperforms the compared methods and learns near-optimal grasping policies in dense- and sparse-reward environments.","Meta-control, Arbitration, Experience imagination, Intrinsic motivation, Reinforcement learning, Robotic grasping",Muhammad Burhan Hafez and Cornelius Weber and Matthias Kerzel and Stefan Wermter,https://www.sciencedirect.com/science/article/pii/S092188902030470X,https://doi.org/10.1016/j.robot.2020.103630,0921-8890,2020,103630,133,Robotics and Autonomous Systems,Improving robot dual-system motor learning with intrinsically motivated meta-control and latent-space experience imagination,article,HAFEZ2020103630
"This paper presents the manipulability analysis of free-floating multi-arm space robots. Evaluation of manipulator capability is useful both in the design and in the operation phase. After capturing a target, closed kinematic chains are formed with multi-arm cooperative manipulating a common object. Owing to the dynamic coupling effect, the manipulability analysis of free-floating systems is more complex than that of ground-fixed closed chain systems. To analyze the cooperative manipulability, kinematic and dynamic formulations for the free-floating closed chain systems are firstly derived. The formulations describe the mapping of joint velocities and torques, respectively, to task velocities and forces, as well as joint torques to task accelerations and forces, by using the generalized Jacobian matrices. Next, the well-known concepts of manipulability ellipsoid, manipulability measure and task compatibility of the free-floating closed chain system are formally extended. Besides, a new approach called scaling factor method is used in the analysis of the task compatibility, which is more accurate compared with the manipulability ellipsoid method. Three applications of the performance indices are considered: (1) the feasibility analysis for a given task, (2) the trajectory planing giving a desired task path, and (3) configuration optimization with different task requirements. The proposed index is proved a very efficient tool that can be utilized in the cooperative manipulation tasks for free-floating space robotic systems.","Cooperative manipulation, Free-floating, Multi-arm space robot, Closed chain system, Manipulability analysis",Ruonan Xu and Jianjun Luo and Mingming Wang,https://www.sciencedirect.com/science/article/pii/S0921889019309236,https://doi.org/10.1016/j.robot.2020.103548,0921-8890,2020,103548,130,Robotics and Autonomous Systems,Kinematic and dynamic manipulability analysis for free-floating space robots with closed chain constraints,article,XU2020103548
"This paper addresses the problem of obtaining an Earth-fixed trajectory and map (ETM), with the associated uncertainty, using the sensor-based map provided by a globally asymptotically/exponentially stable (GES) SLAM filter. The algorithm builds on an optimization problem with a closed-form solution, and its uncertainty description is derived resorting to perturbation theory. The combination of the algorithm proposed in this paper with sensor-based SLAM filtering results in a complete SLAM methodology, which is directly applied to the three main different formulations: range-and-bearing, range-only, and bearing-only. Simulation and experimental results for all these formulations are included in this work to illustrate the performance of the proposed algorithm under realistic conditions. The ETM algorithm proposed in this paper is truly sensor-agnostic, as it only requires a sensor-based map and imposes no constraints on how this map is acquired nor how egomotion is captured. However, in the experiments presented herein, all the sensor-based filters use a sensor to measure the angular velocity and, for the range-only and bearing-only formulations, a sensor to measure the linear velocity.","SLAM, Procrustes problem, Perturbation theory, Mapping, Robotics",Pedro Lourenço and Bruno J. Guerreiro and Pedro Batista and Paulo Oliveira and Carlos Silvestre,https://www.sciencedirect.com/science/article/pii/S0921889019305275,https://doi.org/10.1016/j.robot.2020.103552,0921-8890,2020,103552,130,Robotics and Autonomous Systems,Earth-fixed trajectory and map online estimation: Building on GES sensor-based SLAM filters,article,LOURENCO2020103552
"The detection of true loop closure in Visual Simultaneous Localization And Mapping (vSLAM) can help in many ways, it helps in re-localization, improves the accuracy of the map, and helps in registration algorithms to obtain more accurate and consistent results. The loop closure detection is affected by many parameters, including illumination conditions, seasons, different viewpoints and mobile objects. This paper proposes a novel approach based on super dictionary different from traditional BoW dictionary that uses more advanced and more abstract features of deep learning. The proposed approach does not need to generate vocabulary, which makes it memory efficient and instead it stores exact features, which are small in number and hold very less amount of memory as compared to traditional BoW approach in which each frame holds the same amount of memory as the number of words in the vocabulary. Two deep neural networks are used together to speed up the loop closure detection and to ignore the effect of mobile objects on loop closure detection. We have compared the results with most popular Bag of Words methods DBoW2 and DBoW3, and state-of-the-art iBoW-LCD using five publicly available datasets, and the results show that the proposed method robustly performs loop closure detection and is eight times faster than the state-of-the-art approaches of a similar kind.","Visual SLAM, Loop closure detection, Bag of words, Super dictionary",Azam Rafique Memon and Hesheng Wang and Abid Hussain,https://www.sciencedirect.com/science/article/pii/S0921889019308425,https://doi.org/10.1016/j.robot.2020.103470,0921-8890,2020,103470,126,Robotics and Autonomous Systems,Loop closure detection using supervised and unsupervised deep neural networks for monocular SLAM systems,article,MEMON2020103470
"This paper proposes a general approach to the problem of extrinsic calibration of multiple sensors of varied modalities. This is of particular relevance for intelligent vehicles, which are complex systems that often encompass several sensors of different modalities. Our approach is seamlessly integrated with the Robot Operating System (ROS) framework, and allows for the interactive positioning of sensors and labelling of data, facilitating the calibration procedure. The calibration is formulated as a simultaneous optimization for all sensors, in which the objective function accounts for the various sensor modalities. Results show that the proposed procedure produces accurate calibrations, on par with state of the art approaches which operate only for pairwise setups.","Extrinsic calibration, ROS, Optimization, Bundle adjustment, Intelligent vehicles, OpenCV",Miguel Oliveira and Afonso Castro and Tiago Madeira and Eurico Pedrosa and Paulo Dias and Vítor Santos,https://www.sciencedirect.com/science/article/pii/S0921889020303985,https://doi.org/10.1016/j.robot.2020.103558,0921-8890,2020,103558,131,Robotics and Autonomous Systems,"A ROS framework for the extrinsic calibration of intelligent vehicles: A multi-sensor, multi-modal approach",article,OLIVEIRA2020103558
"In crowded multi-agent navigation, the motion of the agents is significantly constrained by the motion of the nearby agents. This makes planning paths very difficult and leads to inefficient global motion. To address this problem, we propose a distributed approach, which we call C-Nav, that introduces politeness into multi agent navigation. With our approach, agents take into account the velocities and goals of their neighbors and optimize their motion accordingly and in real-time. Further, we perform a theoretical analysis of the algorithm, and experimentally demonstrate its advantages in simulation, with hundreds of agents in a variety of scenarios, and in real world navigation tasks with several mobile robots.","Multi-agent navigation, Multi-agent coordination, Robotics",Julio Godoy and Stephen J. Guy and Maria Gini and Ioannis Karamouzas,https://www.sciencedirect.com/science/article/pii/S0921889020304711,https://doi.org/10.1016/j.robot.2020.103631,0921-8890,2020,103631,133,Robotics and Autonomous Systems,C-Nav: Distributed coordination in crowded multi-agent navigation,article,GODOY2020103631
"Recently, there have been several studies on the research and development of service robots, such as reception or waiter robots for facilities and companion robots for support of baggage transportation or guidance in public spaces. Several experimental results in real environments have been reported. To realize socially acceptable human?robot interaction for service robots, human recognition, including not only position but also body direction, around the robot is important. Using an RGB-D camera, it is possible to detect the posture of a person. However, because the viewing angle of the camera is narrow, it is difficult to recognize the environment around the robot with a single device. This study proposes the estimation of the body direction based on the gait, that is, not only the position and velocity, but also the state of the legs (stance or swing phase), using laser range sensors installed at shin height. We verify the effectiveness of the proposed method for several patterns of movement, which are seen when a person interacts with the service robot and evaluate measurement accuracy.","Service robots, Human?robot interaction, Pedestrian tracking, Kalman filter, Laser range sensor",Ayanori Yorozu and Masaki Takahashi,https://www.sciencedirect.com/science/article/pii/S0921889020304437,https://doi.org/10.1016/j.robot.2020.103603,0921-8890,2020,103603,132,Robotics and Autonomous Systems,Estimation of body direction based on gait for service robot applications,article,YOROZU2020103603
"This paper proposes a novel control system design for a two-wheeled service robot that follows a person as an assistant without knowing the person?s destination. For this kind of service robot, the key skill is to realize human-friendly movement. However, appropriate motion always changed depending on the situation. For instance, when the robot is close and person turns toward it, it is important to suppress the robot?s acceleration. Likewise, if the person turns away from the robot, the robot should maintain its position within an appropriate area. Therefore, to deal with various required movements, our control system is able to change its properties automatically and suitably depending on the situation by using weights of the cost function in nonlinear model predictive control (NMPC) as a function of the relative distance between the person and the robot. Unlike previous methods, our design includes only one controller. Consequently, we are able to take into account system stability. Moreover, owing to proposing in NMPC framework, it is easy to extend our method by adopting other recognition or goal-setting methods. We conducted simulations using actual human walking data taken by the robot?s laser range sensors. The experiments demonstrate that the robot can follow a person who performs U-turn, confirming that our method can produce human-friendly robot movement in a practical scene.","Autonomous mobile service robot, Nonlinear model predictive control, Human-friendly control system",Shunichi Sekiguchi and Ayanori Yorozu and Kazuhiro Kuno and Masaki Okada and Yutaka Watanabe and Masaki Takahashi,https://www.sciencedirect.com/science/article/pii/S0921889020304024,https://doi.org/10.1016/j.robot.2020.103562,0921-8890,2020,103562,131,Robotics and Autonomous Systems,Human-friendly control system design for two-wheeled service robot with optimal control approach,article,SEKIGUCHI2020103562
"This work presents a series of demonstrations of our self-reconfigurable modular robots (SRMR) ?Roombots? in the context of adaptive and assistive furniture. In literature, simulations are often ahead of what currently can be demonstrated in hardware with such systems due to significant challenges in transferring them to the real world. Here, we describe how Roombots tackled these difficulties in real hardware and focus qualitatively on selected hardware experiments rather than on quantitative measurements (in hardware and simulation) to showcase the many possibilities of an SRMR. We envision Roombots to be used in our living space and define five key tasks that such a system must possess. Consequently, we demonstrate these tasks, including self-reconfiguration with 12 modules (36 Degrees of Freedom), autonomously moving furniture, object manipulation and gripping capabilities, human-module-interaction and the development of an easy-to-use user interface. We conclude with the remaining challenges and point out possible directions of research for the future of adaptive and assistive furniture with Roombots.","Self-reconfiguring, Modular robots, Universal Gripper, Assistive furniture, Adaptive furniture",S. Hauser and M. Mutlu and P.-A. Léziart and H. Khodr and A. Bernardino and A.J. Ijspeert,https://www.sciencedirect.com/science/article/pii/S0921889019303379,https://doi.org/10.1016/j.robot.2020.103467,0921-8890,2020,103467,127,Robotics and Autonomous Systems,Roombots extended: Challenges in the next generation of self-reconfigurable modular robots and their application in adaptive and assistive furniture,article,HAUSER2020103467
"The task of detecting 3D objects is important in various robotic applications. The existing deep learning-based detection techniques have achieved impressive performances. However, these techniques are limited to being run on a graphics processing unit (GPU) in a real-time environment. To achieve real-time 3D object detection with limited computational resources, we propose an efficient detection method based on 3D proposal generation and classification. The proposal generation is based mainly on point segmentation, while proposal classification is performed by a lightweight convolution neural network (CNN). KITTI datasets are then used to validate our method. It takes only 0.082 s for our method to process one point block with one core of the central processing unit (CPU). In addition to efficiency, the experimental results also demonstrate the capability of the proposed method of producing a competitive performance in object recall and classification.","Point cloud segmentation, 3D object detection, Optimization, CNN",Xuesong Li and Jose Guivant and Subhan Khan,https://www.sciencedirect.com/science/article/pii/S0921889020303973,https://doi.org/10.1016/j.robot.2020.103557,0921-8890,2020,103557,130,Robotics and Autonomous Systems,Real-time 3D object proposal generation and classification using limited processing resources,article,LI2020103557
"Visual localization is a challenging problem, especially over the long run, since places can exhibit significant variation due to dynamic environmental and seasonal changes. To tackle this problem, we propose a visual place recognition method based on directed acyclic graph matching and feature maps extracted from deep convolutional neural networks (DCNN). Furthermore, in order to find the best subset of DCNN feature maps with minimal redundancy, we propose to form probability distributions on image representation features and leverage the Jensen?Shannon divergence to rank features. We evaluate the proposed approach on two challenging public datasets, namely the Bonn and the Freiburg datasets, and compare it to the state-of-the-art methods. For image representations, we evaluated the following DCNN architectures: AlexNet, OverFeat, ResNet18 and ResNet50. Due to the proposed graph structure, we are able to account for any kind of correlations in image sequences, and therefore dub our approach NOSeqSLAM. Algorithms with and without feature selection were evaluated based on precision?recall curves, area under the curve score, best recall at 100% precision score and running time, with NOSeqSLAM outperforming the counterpart approaches. Furthermore, by formulating the mutual information-based feature selection specifically for visual place recognition and by selecting the feature percentile with the best score, all the algorithms, and not just NOSeqSLAM, exhibited enhanced performance with the reduced feature set.","Visual place recognition, Localization, Deep convolutional neural networks, Mutual information-based feature selection, SeqSLAM",Jurica Maltar and Ivan Markovi? and Ivan Petrovi?,https://www.sciencedirect.com/science/article/pii/S0921889020304383,https://doi.org/10.1016/j.robot.2020.103598,0921-8890,2020,103598,132,Robotics and Autonomous Systems,Visual place recognition using directed acyclic graph association measures and mutual information-based feature selection,article,MALTAR2020103598
"We investigate Model Predictive Control (MPC) schemes without stabilizing constraints or costs for the set-point stabilization of holonomic mobile robots. Herein, we ensure closed-loop asymptotic stability using the concept of cost controllability. To this end, we derive a growth bound on the finite-horizon value function in terms of the running costs evaluated at the current state, which is then used to determine a stabilizing prediction horizon. In the discrete-time setting, we additionally show that asymptotic stability holds for the shortest possible prediction horizon. Moreover, we deduce a lower bound on the MPC performance on the infinite horizon. Theoretical results are verified by numerical simulations as well as laboratory experiments of stabilizing a holonomic mobile robot to a reference set point.","Motion control, Holonomic mobile robots, Model Predictive Control, Stability analysis",Mohamed W. Mehrez and Karl Worthmann and Joseph P.V. Cenerini and Mostafa Osman and William W. Melek and Soo Jeon,https://www.sciencedirect.com/science/article/pii/S0921889019306232,https://doi.org/10.1016/j.robot.2020.103468,0921-8890,2020,103468,127,Robotics and Autonomous Systems,Model Predictive Control without terminal constraints or costs for holonomic mobile robots,article,MEHREZ2020103468
"Intelligent vehicle is an inevitable trend in urban transportation development. Whether for driver assistance systems or advanced driverless systems, safety issues are one of the cores of these systems. This paper proposes a scene safety evaluation method based on binocular camera. By proposing a comprehensive safety evaluation model, the uncertainty of the scene can be represented with a single value, which can be expressed as a quantitative evaluation of the safety of intended functionality (SOTIF). It provides real-time safety monitoring and protection for the driving process of drivers and occupants by the human?computer interaction. Based on the calculation results, different monitoring methods can be adopted for different levels of autonomous driving to further improve the safety of autonomous driving.",,Xinyu Zhang and Wenbo Shao and Mo Zhou and Qifan Tan and Jun Li,https://www.sciencedirect.com/science/article/pii/S0921889019309108,https://doi.org/10.1016/j.robot.2020.103503,0921-8890,2020,103503,128,Robotics and Autonomous Systems,A scene comprehensive safety evaluation method based on binocular camera,article,ZHANG2020103503
"In this paper, we propose a new formulation to consider visual?spatial attention in order to improve the comfort of a human standing or operating near a collaborative robot. This formulation is based on the principle of having the robot?s end-effector in the human visual?spatial attention as much as possible. The integration of this new constraint into the Inverse Kinematics (IK) problem is thoroughly studied and efficient solutions are proposed. Moreover, to allow the robot to react rapidly in the case of unforeseen events, adding the manipulability index to the IK problem is also studied and its impact is analyzed. The proposed method is then extensively tested in simulation and verified on the real Baxter research robot, these experiments pointed out the method efficiency to improve the task visibility while avoiding self-occlusion and singular configurations. Moreover, real experiments revealed the method robustness to uncertainties such as imprecision of detecting human gaze direction.","Collaborative robotics, Visual?spatial attention, Inverse kinematics, QP solver",Kévin Dufour and Jorge Ocampo-Jimenez and Wael Suleiman,https://www.sciencedirect.com/science/article/pii/S0921889020304668,https://doi.org/10.1016/j.robot.2020.103626,0921-8890,2020,103626,133,Robotics and Autonomous Systems,Visual?spatial attention as a comfort measure in human?robot collaborative tasks,article,DUFOUR2020103626
"This paper presents three fault-tolerant control (FTC) strategies for a coaxial octorotor unmanned aerial vehicle (UAV) regarding motor failures. The first FTC is based on a control mixing strategy which consists of a set of control laws designed offline, each one dedicated to a specific fault situation. The second FTC, a robust adaptive sliding mode control allocation is presented, where the control gains of the controller are adjusted online in order to redistribute the control signals among the healthy motors in order to stabilize the overall system. The third FTC strategy is a new strategy proposed in this article, which is based on a self-tuning sliding mode control (STSMC) where the control gains are readjusted based on the detected error to maintain the stability of the system. Multiple indoor experiments on an octorotor UAV are conducted to show and compare the effectiveness and the behavior of each FTC scheme after successive faults are injected. More specifically, we inject complete actuator?s failures into the top four motors of our octorotor. Every strategies show good fault tolerance results, although the control mixing method performs slightly better overall while the adaptive method performs slightly worse. However, the control mixing method requires a huge design effort to take into account as much situations as possible, while the adaptive method and the STSMC only require to determine a few gains. The adaptive method do not need fault detection to operate, but it thus does not provide information on the system?s health without an additional fault identification and diagnosis mechanism, while both the control mixing method and the STSMC provide such information.","Fault-tolerant control, Sliding mode control, Robust control, Multiplexing, Control allocation, Actuator redundancy, Adaptive control, UAV",Hussein Hamadi and Benjamin Lussier and Isabelle Fantoni and Clovis Francis and Hassan Shraim,https://www.sciencedirect.com/science/article/pii/S0921889020304425,https://doi.org/10.1016/j.robot.2020.103602,0921-8890,2020,103602,133,Robotics and Autonomous Systems,"Comparative study of self tuning, adaptive and multiplexing FTC strategies for successive failures in an Octorotor UAV",article,HAMADI2020103602
"Assist-as-needed control strategy is an emerging approach to improve the effectiveness of gait rehabilitation training. We have proposed a pneumatic muscle (PM) driven Gait Rehabilitation Exoskeleton (GAREX) implemented with a multi-input?multi-output (MIMO) sliding mode control system to actively adjust the assistance level provided during gait rehabilitation. To realize the assist-as-needed control strategy, a specific algorithm is imperative to assess the active participation or effort of wearers and adapt the amount of assistance accordingly. We sought to establish a fuzzy logic compliance adaptation (FLCA) controller to form a novel cascade control system. We evaluated the feasibility of implemented FLCA controller on the performance of adjusting the compliance of GAREX?s knee joint according to the online assessment of the wear?s active participation level once in every gait cycle. Using controlled, treadmill-based walking tests involved three healthy subjects, we demonstrate that FLCA controller could effectively distinguish the capability/effort levels of wearers and enable the exoskeleton to adapt the knee joint compliance accordingly. Obtained results reveal that FLCA controller can collaborate well with MIMO sliding mode controller in a system and indicate the novel method of realizing assist-as-needed concept with the pneumatic muscle powered mechanisms.","Fuzzy logic, Pneumatic muscle, Compliance adaptation, Gait rehabilitation, Assist-as-needed",Bin Zhong and Jinghui Cao and Kaiqi Guo and Andrew McDaid and Yuxin Peng and Qing Miao and ShengQ. Xie and Mingming Zhang,https://www.sciencedirect.com/science/article/pii/S0921889020304826,https://doi.org/10.1016/j.robot.2020.103642,0921-8890,2020,103642,133,Robotics and Autonomous Systems,Fuzzy logic compliance adaptation for an assist-as-needed controller on the Gait Rehabilitation Exoskeleton (GAREX),article,ZHONG2020103642
"This work considers the problem of locating a single robot given a set of squared noisy range difference measurements to a set of points (anchors) whose positions are known. In the sequel, localization problem is solved in the Least-Squares (LS) sense by writing the robot position in polar/spherical coordinates. This representation transforms the original nonconvex/multimodal cost function into the quotient of two quadratic forms, whose constrained maximization is more tractable than the original problem. Simulation results indicate that the proposed method has similar accuracy to state-of-the-art optimization-based localization algorithms in its class, and the simple algorithmic structure and computational efficiency makes it appealing for applications with strong computational constraints. Additionally, location information is used to find the initial orientation of the robot with respect to the previously obtained map in scan matching. Thus, the crucial problem of the autonomous initialization and localization in robotics is solved.","Squared range difference-based robot localization, TDOA, Least squares, LiDAR, Scan matching, Initialization",P?nar O?uz-Ekim,https://www.sciencedirect.com/science/article/pii/S0921889020304309,https://doi.org/10.1016/j.robot.2020.103590,0921-8890,2020,103590,131,Robotics and Autonomous Systems,TDOA based localization and its application to the initialization of LiDAR based autonomous robots,article,OGUZEKIM2020103590
"The daily working hours of mobile robots are limited primarily by battery life. Most systems use a combination of thresholds and fixed periods to decide when to charge. This produces charging behaviour that ignores high-value tasks that must be performed within time-windows or by deadlines. Instead the robot should schedule charging adaptively, taking into account the times of day when it is expected to be given more valuable tasks to perform. This paper proposes an approach that exploits the fact that, during long-term deployments, the robot can learn when it is most probable that valuable tasks are added to the system, enabling it to schedule charging at times that are expected to be less busy. We pose the problem of scheduling battery charging as a multi-objective sequential decision making problem over a time-dependent Markov decision process model of expected task rewards and battery dynamics. We evaluate the scalability and solution quality of our multi-objective scheduler, and compare it with a typical rule-based approach. Empirical results show that our approach enables more flexible and efficient robot behaviour, which takes into account both the value of current available tasks and the predicted value of future tasks to decide whether to charge at a given time.","Mobile service robots, Markov decision processes, Multi-objective reasoning, Long term autonomy",Milan Tomy and Bruno Lacerda and Nick Hawes and Jeremy L. Wyatt,https://www.sciencedirect.com/science/article/pii/S0921889020304693,https://doi.org/10.1016/j.robot.2020.103629,0921-8890,2020,103629,133,Robotics and Autonomous Systems,Battery charge scheduling in long-life autonomous mobile robots via multi-objective decision making under uncertainty,article,TOMY2020103629
"One of the most important challenges for Autonomous Driving and Driving Assistance systems is the detection of the road to perform or monitor navigation. Many works can be found in the literature to perform road and lane detection, using both algorithmic processing and learning based techniques. However, no single solution is mentioned to be applicable in any circumstance of mixed scenarios of structured, unstructured, lane based, line based or curb based limits, and other sorts of boundaries. So, one way to embrace this challenge is to have multiple techniques, each specialized on a different approach, and combine them to obtain the best solution from individual contributions. That is the central concern of this paper. By improving a previously developed architecture to combine multiple data sources, a solution is proposed to merge the outputs of two Deep Learning based techniques for road detection. A new representation for the road is proposed along with a workflow of procedures for the combination of two simultaneous Deep Learning models, based on two adaptations of the ENet model. The results show that the overall solution copes with the alternate failures or under-performances of each model, producing a road detection result that is more reliable than the one given by each approach individually.","Visual perception, Data combination, Deep learning, Computer vision, Road map detection, Road lane lines detection, Road segmentation, Driving assistance",Tiago Almeida and Bernardo Lourenço and Vitor Santos,https://www.sciencedirect.com/science/article/pii/S0921889020304450,https://doi.org/10.1016/j.robot.2020.103605,0921-8890,2020,103605,133,Robotics and Autonomous Systems,Road detection based on simultaneous deep learning approaches,article,ALMEIDA2020103605
"Teach and Repeat (T&R) refers to the technology that allows a robot to autonomously follow a previously traversed route, in a natural scene and using only its onboard sensors. In this paper we present a Visual-Inertial Teach and Repeat (VI-T&R) algorithm that uses stereo and inertial data and targets Unmanned Aerial Vehicles with limited on-board computational resources. We propose a tightly-coupled relative formulation of the visual-inertial constraints that is tailored to the T&R application. In order to achieve real-time operation on limited hardware, we reduce the problem to motion-only visual-inertial Bundle Adjustment. In the repeat stage, we detail how to generate a trajectory and smoothly follow it with a constantly changing relative frame. The proposed method is validated in simulated environments, using real sensor data from the public EuRoC dataset, and using our own robotic setup and closed-loop control. Our experimental results demonstrate high accuracy and real-time performance both on a standard desktop system and on a low-cost Odroid X-U4 embedded computer.","UAV, Embedded, Navigation, Visual-inertial, Stereo, Teach-and-replay, Relative",Matías Nitsche and Facundo Pessacg and Javier Civera,https://www.sciencedirect.com/science/article/pii/S0921889020304176,https://doi.org/10.1016/j.robot.2020.103577,0921-8890,2020,103577,131,Robotics and Autonomous Systems,Visual-inertial teach and repeat,article,NITSCHE2020103577
"In recent years, we have witnessed the proliferation of so-called collaborative robots or cobots, that are designed to work safely along with human operators. These cobots typically use the ?program from demonstration? paradigm to record and replay trajectories, rather than the traditional source-code based programming approach. While this requires less knowledge from the operator, the basic functionality of a cobot is limited to simply replay the sequence of actions as they were recorded. In this paper, we present a system that mitigates this restriction and learns to grasp an arbitrary object from visual input using demonstrated examples. While other learning-based approaches for robotic grasping require collecting a large amount of examples, either manually or automatically harvested in a real or simulated world, our approach learns to grasp from a single demonstration with the ability to improve on accuracy using additional input samples. We demonstrate grasping of various objects with the Franka Panda collaborative robot. We show that the system is able to grasp various objects from demonstration, regardless their position and rotation in less than 5 min of training time on a NVIDIA Titan X GPU, achieving over 90% average success rate.","Artificial neural networks, Machine learning, Collaborative robotics, Industrial internet of things",Elias {De Coninck} and Tim Verbelen and Pieter {Van Molle} and Pieter Simoens and Bart Dhoedt,https://www.sciencedirect.com/science/article/pii/S0921889019304956,https://doi.org/10.1016/j.robot.2020.103474,0921-8890,2020,103474,127,Robotics and Autonomous Systems,Learning robots to grasp by demonstration,article,DECONINCK2020103474
"Autonomous navigation of mobile robot via classic neural network (NN) models are no more valid in terms of efficiency and accuracy due to the development of new advanced techniques. However, the necessity of finding an implementable Recursive Neural Network (RNN) model to predict the motor control of the robot with both speed and accuracy constraints still remains stagnant because of the nonlinearity and complexity of the trajectories. To provide new solutions for smart navigation problems, this paper proposes a new implementable recursive neural network controller (RNNC) predictor that calculates the Pulse Width Modulation (PMW) signals of the motors. Such proposed Multi-input Multi-output (MIMO) Controller succeeded to solve the problem of speed and accuracy of autonomous navigation. The Smart RNNC model design is illustrated with its architecture in details. Due to the complexity and the non-efficiency of the training process in real-world, a 3D Simulator was developed to create all possible scenarios. The machine learning and navigation predictions processes for designing the new RNNC model are presented together in details. In addition, the motor commands generation speed and accuracy as well as their efficiency are theoretically and practically proven. Moreover, numerical studies, 3D scenarios of trajectory tracking and obstacle avoidance prove the effectiveness and robustness of the proposed technique.","Virtual simulator, Smart navigation, Mobile robot, RNNC, Prediction controller, TurtleBot",Khaled Khnissi and Chiraz {Ben Jabeur} and Hassene Seddik,https://www.sciencedirect.com/science/article/pii/S0921889020304334,https://doi.org/10.1016/j.robot.2020.103593,0921-8890,2020,103593,131,Robotics and Autonomous Systems,A smart mobile robot commands predictor using recursive neural network,article,KHNISSI2020103593
"Optics-based systems may provide high spatial and temporal resolution for close range object detection in underwater environments. By using a monocular camera on a low cost underwater vehicle manipulator system, objects can be tracked by the vehicle and handled by the manipulator. In this paper, a monocular camera is used to detect an object of interest through object detection. Spatial features of the object are extracted, and a dynamic positioning system is designed for the underwater vehicle in order for it to maintain a desired position relative to the object. A manipulator mounted under the vehicle is used to retrieve the object through a developed kinematic control system. Experimental tests verify the proposed methodology. A stability analysis proves asymptotic stability properties for the chosen sliding mode controller and exponential stability for the task error.","Underwater robotics, Object detection, Autonomy, Dynamic positioning, Manipulator",Bent Oddvar Arnesen Haugaløkken and Martin Breivik Skaldebø and Ingrid Schjølberg,https://www.sciencedirect.com/science/article/pii/S0921889020304292,https://doi.org/10.1016/j.robot.2020.103589,0921-8890,2020,103589,131,Robotics and Autonomous Systems,Monocular vision-based gripping of objects,article,HAUGALOKKEN2020103589
"Based on sensor input, a robot arm should dynamically adjust its trajectory while maintaining stability to react to a sudden change in the target point in an unknown environment. To solve this problem, in this study, a time-optimized online trajectory generation (OTG) method is proposed using an S-curve velocity profile, which can generate trajectories in response to external sensor signals. The generated trajectory has characteristics that can guarantee the synchronization of multijoints according to an arbitrary initial state and a desired target state under velocity, acceleration, and jerk constraints. For multijoints time synchronization, two different characteristics are considered according to different application scenarios: minimum velocity or peak acceleration, which correspond to two sub-methods. The first one can be used to calculate with a minimum velocity peak, which can quickly adjust the trajectory according to the signal feedback. The second can be used to calculate the minimization of the acceleration peak, which can reduce the vibration of the robot arm due to a change in the motion. Compared with other OTG methods, the second proposed sub-method can effectively reduce the acceleration peak of the planned motion with the same synchronization time and parameters. Additionally, both sub-methods have the advantage of a rapid calculation and can generate time synchronization motion trajectories for 6 axes in 0.21 ms on a personal computer, fully satisfying the requirements of online motion planning. Finally, the effectiveness of the algorithm is verified by simulations and experiments with a lab-developed robot arm.","Online trajectory generation, Jerk constraint, Time synchronization, Minimum peak of velocity, Minimum acceleration peak",Mingli Wang and Juliang Xiao and Fan Zeng and Guodong Wang,https://www.sciencedirect.com/science/article/pii/S0921889019305093,https://doi.org/10.1016/j.robot.2020.103453,0921-8890,2020,103453,126,Robotics and Autonomous Systems,Research on optimized time-synchronous online trajectory generation method for a robot arm,article,WANG2020103453
"We propose a means of omni-directional contact detection using accelerometers instead of tactile sensors for object shape estimation using touch. Unlike tactile sensors, our contact-based detection method tends to induce a degree of uncertainty with false-positive contact data because the sensors may react not only to actual contact but also to the unstable behavior of the robot. Therefore, it is crucial to consider a robust shape estimation method capable of handling such false-positive contact data. To realize this, we introduce the concept of heteroscedasticity into the contact data and propose a robust shape estimation algorithm based on Gaussian process implicit surfaces (GPIS). We confirmed that our algorithm not only reduces shape estimation errors caused by false-positive contact data but also distinguishes false-positive contact data more clearly than the GPIS through simulations and actual experiments using a quadcopter.","Tactile sensing, Shape estimation, Gaussian processes",Kazuki Shibata and Tatsuya Miyano and Tomohiko Jimbo and Takamitsu Matsubara,https://www.sciencedirect.com/science/article/pii/S0921889019307791,https://doi.org/10.1016/j.robot.2020.103527,0921-8890,2020,103527,129,Robotics and Autonomous Systems,Robust shape estimation with false-positive contact detection,article,SHIBATA2020103527
"Designing a robot system with reasoning and learning ability has gradually become a research focus in robotics research field. Recently, Skill Transfer Learning (STL), i.e., the ability of transferring human skills to robots, has become a research thrust for autonomous robots and human?robot cooperation. It provides the following benefits: (i) the skill transfer learning system with independent decision-making and learning ability enables the robot to learn and acquire manipulation skills in a complex and dynamic environment, which can overcome the shortages of conventional methods such as traditional programming, and greatly improve the adaptability of the robot to complex environments and (ii) human physiological signals allow us to extract motion control characteristics from physiological levels which create a rich sensory signal. In this survey, we provide an overview of the most important applications of STL by analyzing and categorizing existing works in autonomous robots and human?robot cooperation area. We close this survey by discussing remaining open challenges and promising research topics in future.","Skill transfer, Robot learning, Human demonstrations, Neurophysiological skill acquisition",Yueyue Liu and Zhijun Li and Huaping Liu and Zhen Kan,https://www.sciencedirect.com/science/article/pii/S0921889019309972,https://doi.org/10.1016/j.robot.2020.103515,0921-8890,2020,103515,128,Robotics and Autonomous Systems,Skill transfer learning for autonomous robots and human?robot cooperation: A survey,article,LIU2020103515
"Pose estimation of non-cooperative satellites has been a hot topic in the study of astronautics as the visual feedback will highly enhance the safety of on-orbit services. A stereo vision system is proposed in this paper. It works as an eye-to-hand vision camera in the final approach phase Based on circular feature extraction, a closed-form solution is presented. The position and orientation of the adapter ring can be figured out in real-time as well as the unknown radius. Neither additional sensors nor prior knowledge is required, and the orientation-duality problem has been solved. It works well on the partial ellipses and is robust to outliers, noise and occlusions. Experimental results on both synthetic and real images have demonstrated the effectiveness and efficiency of the proposed method.","Pose estimation, Non-cooperative target, Adapter ring, Ellipse detection, Space robot, On-orbit service",Yang Liu and Zongwu Xie and Qi Zhang and Xiaoyu Zhao and Hong Liu,https://www.sciencedirect.com/science/article/pii/S0921889019307158,https://doi.org/10.1016/j.robot.2020.103532,0921-8890,2020,103532,129,Robotics and Autonomous Systems,A new approach for the estimation of non-cooperative satellites based on circular feature extraction,article,LIU2020103532
"An essential capability of humans is the effortless identification of useful tasks based on visual cues in everyday situations. Objects and their surroundings are integrated and processed to differentiate plausible from implausible actions. In this work, we study how to teach this ability to robots. In contrast to many tasks in computer vision where the goal is an accurate description (object labels, caption, scene class) of the present situation here the challenge is to make reasonable guesses about which forms of plausible and implausible actions can be conducted. To this end, we collect a dataset that associates images with probabilities over a set of actions. A convolutional neural network is trained to match these ground truth plausibility scores using this dataset. We compare the performance of state-of-the-art encoder architectures and specifically analyze the role of contextual cues quantitatively. While the object recognition capabilities of the encoder have a strong impact on performance, using context did not lead to substantial improvements. We show qualitatively the utility of such a system for robotic action selection in a household setting.",,Timo Lüddecke and Florentin Wörgötter,https://www.sciencedirect.com/science/article/pii/S0921889019305536,https://doi.org/10.1016/j.robot.2020.103511,0921-8890,2020,103511,129,Robotics and Autonomous Systems,Fine-grained action plausibility rating,article,LUDDECKE2020103511
"This paper presents the design, implementation and polymer nanocomposite mixing application of a robust spatiotemporal chaotic delta robot. Blending fluids efficiently is a vital process for the preparation of graphene nanocomposite mixing. The most commonly used mixing materials are polymeric materials that need to be blended in non-Newtonian fluids. To achieve a superior blending performance over the conventional ones, it is used two different chaotification mechanisms for the realization of the spatiotemporal chaotic delta robot mixer system. One of them is for the chaotification of the mixer propeller while the second one is for the chaotification of the three-dimensional position of the endpoint of the delta robot. The model-based robust chaotification scheme based on sliding mode control is applied to chaotify the speed of the delta robot-mixer via dynamical state-feedback chaotification method. The chaotification of 3D position of the mixer is realized in a feedforward way by producing chaotic input signals. The implemented robust chaotic delta robot mixer exploits the efficacy of chaotic mixing in obtaining homogeneity in the mixture with less operation time, and hence reduced electrical energy consumption. In these performance evaluations, energy consumption and material characterization, which are measured by reliable material characterization methods such as X-ray diffraction, Fourier-transform-infrared spectroscopy, water contact angle, dynamical mechanical analysis, atomic force microscopy, Raman and field emission-scanning electron microscope analyses, are used as criteria. The obtained results show that, for the delta robot, the proposed chaotic-speed together with 3D chaotic-movement operation mode provides a better mixing performance than other mixing operation modes.","Delta robot, Chaotification, Robustness, Sliding mode control, Polymer nanocomposites mixing, Graphene",Savas Sahin and Ali Emre Kavur and Sibel {Demiroglu Mustafov} and Ozgur Seydibeyoglu and Ozgun Baser and Yalcin Isler and Cuneyt Guzelis,https://www.sciencedirect.com/science/article/pii/S0921889020304735,https://doi.org/10.1016/j.robot.2020.103633,0921-8890,2020,103633,134,Robotics and Autonomous Systems,Spatiotemporal chaotification of delta robot mixer for homogeneous graphene nanocomposite dispersing,article,SAHIN2020103633
"Drone racing is becoming a popular sport where human pilots have to control their drones to fly at high speed through complex environments and pass a number of gates in a pre-defined sequence. In this paper, we develop an autonomous system for drones to race fully autonomously using only onboard resources. Instead of commonly used visual navigation methods, such as simultaneous localization and mapping and visual inertial odometry, which are computationally expensive for micro aerial vehicles (MAVs), we developed the highly efficient snake gate detection algorithm for visual navigation, which can detect the gate at 20 HZ on a Parrot Bebop drone. Then, with the gate detection result, we developed a robust pose estimation algorithm which has better tolerance to detection noise than a state-of-the-art perspective-n-point method. During the race, sometimes the gates are not in the drone?s field of view. For this case, a state prediction-based feed-forward control strategy is developed to steer the drone to fly to the next gate. Experiments show that the drone can fly a half-circle with 1.5 m radius within 2 s with only 30cm error at the end of the circle without any position feedback. Finally, the whole system is tested in a complex environment (a showroom in the faculty of Aerospace Engineering, TU Delft). The result shows that the drone can complete the track of 15 gates with a speed of 1.5m?s which is faster than the speeds exhibited at the 2016 and 2017 IROS autonomous drone races.","Micro aerial vehicle, Visual navigation, Autonomous drone race",Shuo Li and Michaël M.O.I. Ozo and Christophe {De Wagter} and Guido C.H.E. {de Croon},https://www.sciencedirect.com/science/article/pii/S0921889020304619,https://doi.org/10.1016/j.robot.2020.103621,0921-8890,2020,103621,133,Robotics and Autonomous Systems,Autonomous drone race: A computationally efficient vision-based navigation and control strategy,article,LI2020103621
"In this paper we present a prototype integrated robotic system, the I-Support bathing robot, that aims at supporting new aspects of assisted daily-living activities on a real-life scenario. The paper focuses on describing and evaluating key novel technological features of the system, with the emphasis on cognitive human?robot interaction modules and their evaluation through a series of clinical validation studies. The I-Support project on its whole has envisioned the development of an innovative, modular, ICT-supported service robotic system that assists frail seniors to safely and independently complete an entire sequence of physically and cognitively demanding bathing tasks, such as properly washing their back and their lower limbs. A variety of innovative technologies have been researched and a set of advanced modules of sensing, cognition, actuation and control have been developed and seamlessly integrated to enable the system to adapt to the target population abilities. These technologies include: human activity monitoring and recognition, adaptation of a motorized chair for safe transfer of the elderly in and out the bathing cabin, a context awareness system that provides full environmental awareness, as well as a prototype soft robotic arm and a set of user-adaptive robot motion planning and control algorithms. This paper focuses in particular on the multimodal action recognition system, developed to monitor, analyze and predict user actions with a high level of accuracy and detail in real-time, which are then interpreted as robotic tasks. In the same framework, the analysis of human actions that have become available through the project?s multimodal audio?gestural dataset, has led to the successful modeling of Human?Robot Communication, achieving an effective and natural interaction between users and the assistive robotic platform. In order to evaluate the I-Support system, two multinational validation studies were conducted under realistic operating conditions in two clinical pilot sites. Some of the findings of these studies are presented and analyzed in the paper, showing good results in terms of: (i) high acceptability regarding the system usability by this particularly challenging target group, the elderly end-users, and (ii) overall task effectiveness of the system in different operating modes.","Human?robot communication, Assistive human?robot interaction (HRI), Bathing robot, Multimodal dataset, Audio?gestural command recognition, Online validation with elderly users",A. Zlatintsi and A.C. Dometios and N. Kardaris and I. Rodomagoulakis and P. Koutras and X. Papageorgiou and P. Maragos and C.S. Tzafestas and P. Vartholomeos and K. Hauer and C. Werner and R. Annicchiarico and M.G. Lombardi and F. Adriano and T. Asfour and A.M. Sabatini and C. Laschi and M. Cianchetti and A. Güler and I. Kokkinos and B. Klein and R. López,https://www.sciencedirect.com/science/article/pii/S0921889019304968,https://doi.org/10.1016/j.robot.2020.103451,0921-8890,2020,103451,126,Robotics and Autonomous Systems,I-Support: A robotic platform of an assistive bathing robot for the elderly population,article,ZLATINTSI2020103451
"This paper proposes a visual teleoperation with human?robot posture-consistent based on deep neural network. A multi-stage structure of visual teleoperation network, in which the angles of robotic joints are obtained from human, is deduced. Furthermore, a novel human?robot posture-consistent mapping method is developed to generate dataset of the visual teleoperation network by solving constrained nonlinear matrix functions. Based on the designed framework, the data generator and a well trained multi-stage visual teleoperation network are presented. Finally teleoperation experiments are implemented to demonstrate that the proposed method is effectiveness and reliable.","Visual teleoperation, Deep neural networks, Human?robot posture-consistent mapping, Data generator",Bin Fang and Xiao Ma and Jiachun Wang and Fuchun Sun,https://www.sciencedirect.com/science/article/pii/S0921889020304322,https://doi.org/10.1016/j.robot.2020.103592,0921-8890,2020,103592,131,Robotics and Autonomous Systems,Vision-based posture-consistent teleoperation of robotic arm using multi-stage deep neural network,article,FANG2020103592
"A fuel-efficient control strategy for a manipulator-equipped spacecraft is presented. The strategy uses the thrusters, the reaction wheels, and the arm drives in a coordinated way to limit the use of the thrusters and achieve ideally zero fuel consumption in contact-free maneuvering. The thrusters are activated automatically only after contact, to stabilize the inertial motion of the system. The controller regulates the translation of the center-of-mass (CoM) of the whole space robot, the rotation of the spacecraft, and the pose of the end-effector (EE) in a decoupled way, utilizing the thrusters to control the CoM translation only and the remaining actuators to control the rotation and end-effector coordinately. The method is validated experimentally using a hardware-in-the-loop simulator composed of a seven degrees-of-freedom (DOF) arm mounted on a 6DOF simulated spacecraft. Numerical simulations with discrete thrusters assess the fuel efficiency of the proposed strategy.","Space robotics, Thrusters, Reaction wheels, Stability analysis, Nonlinear control, Hardware-in-the-loop",Alessandro M. Giordano and Alexander Dietrich and Christian Ott and Alin Albu-Schäffer,https://www.sciencedirect.com/science/article/pii/S0921889020304048,https://doi.org/10.1016/j.robot.2020.103564,0921-8890,2020,103564,131,Robotics and Autonomous Systems,"Coordination of thrusters, reaction wheels, and arm in orbital robots",article,GIORDANO2020103564
"To achieve temporal and spatial correspondence between multiple robotic manipulators, the system must correctly analyze the coordinated path required for a specific task. Based on manipulator kinematics analysis, we first studied the kinematic constraints between the end-effectors of cooperative manipulators, and deduced the multi-manipulator cooperative kinematics constraint equations in the Cartesian coordinate system space under different motion modes. Then, we created two MD-6 manipulator models to simulate the trajectory simulation of the synchronous and relative motion of the manipulator. This allowed us to verify the correctness of the proposed trajectory coordination method, and analyze the influence of external loads on the position and posture of the end-effector of the manipulator, to effectively predict the cooperative motion error of the manipulator system. Finally, in order to verify the effectiveness of the proposed trajectory coordination method, we established a robotic experimental platform and conducted experimental research. The results show that the multi-manipulator trajectory coordination method studied in this paper can make multi-manipulators effectively achieve the target requirements of tasks such as time and space cooperative handling and circular drawing operations.","Multi-manipulator, Track coordination, Dynamic simulation",Chunjian Su and Shuai Zhang and Shumei Lou and Rui Wang and Gaohua Cao and Longyun Yang and Qing Wang,https://www.sciencedirect.com/science/article/pii/S0921889020304280,https://doi.org/10.1016/j.robot.2020.103588,0921-8890,2020,103588,131,Robotics and Autonomous Systems,Trajectory coordination for a cooperative multi-manipulator system and dynamic simulation error analysis,article,SU2020103588
"An important envisaged application of legged robots is the exploration and mapping of extreme environments with an unknown terrain. Corin is a hexapod designed at the University of Manchester, which is able to perform motions using footholds on surfaces perpendicular to the ground plane. This allows it to be able to navigate through confined and narrow spaces. The hexapod requires an accurate estimate of its pose in order to be able to perform these motions. Current state-of-the-art state estimators for legged robots that solely use proprioceptive sensors, fuse inertial and leg kinematic measurements through an extended Kalman filter (EKF). This paper describes the implementation and validation of a state estimator on the Corin hexapod whilst performing motions using surface perpendicular to the ground plane. Another novelty of the work is the analysis of the algorithm sensitivity to the filter parameters and motion variables, and the tuning of the EKF using particle swarm optimisation (PSO). The results show that the average error achieved was below 6% for both position and orientation estimates.","Extended Kalman filter, Indirect EKF, EKF tuning, Hexapod, State estimation, Particle swarm optimisation (PSO)",Hassan H. Khalili and Wei Cheah and Tomas B. Garcia-Nathan and Joaquin Carrasco and Simon Watson and Barry Lennox,https://www.sciencedirect.com/science/article/pii/S0921889019304166,https://doi.org/10.1016/j.robot.2020.103509,0921-8890,2020,103509,129,Robotics and Autonomous Systems,Tuning and sensitivity analysis of a hexapod state estimator,article,KHALILI2020103509
"The hydrodynamic model can be used to predict velocity of underwater vehicles in still water. However, there are few economical and effective methods for estimating the hydrodynamic parameters of irregular-shaped underwater vehicles. Thus, this paper proposes a hybrid estimation strategy, which contains a rough estimation using a least squares (LS) based algorithm and a precise estimation using an improved particle swarm optimization (IPSO) algorithm. The numerical simulation and field data based tests suggest that the accuracy of the predicted velocity using the hydrodynamic parameters estimated by the IPSO-based hybrid strategy is better than two state-of-the-art algorithms. Finally, a pool experiment is conducted to verify the accuracy of the predicted horizontal velocity of the underwater vehicle.","Hydrodynamic model, Parameter estimation, Underwater vehicles, Model-based velocity prediction, Hybrid strategy",Mingwei Lin and Canjun Yang and Dejun Li,https://www.sciencedirect.com/science/article/pii/S0921889019309285,https://doi.org/10.1016/j.robot.2020.103480,0921-8890,2020,103480,127,Robotics and Autonomous Systems,Hybrid strategy based model parameter estimation of irregular-shaped underwater vehicles for predicting velocity,article,LIN2020103480
"In this article, we show how visual constraints such as homographies and fundamental matrices can be integrated tightly into the locomotion controller of a humanoid robot to drive it from one configuration to another (pose-regulation), only by means of images. The visual errors generated by these constraints are stacked as terms of the objective function of a Quadratic Program so as to specify the final pose of the robot with a reference image. By using homographies or fundamental matrices instead of specific points, we avoid the features occlusion problem. This image-based strategy is also extended to solve the problem of following a visual path by a humanoid robot, which allows the robot to execute much longer paths and plans than when using just one reference image. The effectiveness of our approach is validated with a humanoid dynamic simulator.","Humanoid robots locomotion, Visual servoing, Visual path following, Visual geometric constraint",Noé G. Aldana-Murillo and Luis Sandoval and Jean-Bernard Hayet and Claudia Esteves and Hector M. Becerra,https://www.sciencedirect.com/science/article/pii/S0921889019306694,https://doi.org/10.1016/j.robot.2020.103497,0921-8890,2020,103497,128,Robotics and Autonomous Systems,Coupling humanoid walking pattern generation and visual constraint feedback for pose-regulation and visual path-following,article,ALDANAMURILLO2020103497
"With the development of the robotic technology, Autonomous Mobile Manipulator (AMM) is increasingly used in more applications. Reasonable motion planning for AMM to maintain high manipulation capability is the prerequisite for the success of the mobile manipulation task. In this paper, the Capability Map (CM) of AMM that gives the distribution of the manipulability in cartesian space is first built. Then given the path of the end effector, we design a novel path planner for the mobile robot by querying CM online so that AMM keeps high manipulability. Moreover, a task-priority coordinated motion controller is developed to control the mobile robot and the manipulator to track their trajectories. In this controller, the trajectory of the manipulator is used as the primary task, and the trajectory of the mobile robot is treated as the constrained task. Simulation results show that the path of the mobile robot can be found online, and AMM follows the trajectories well.","Autonomous mobile manipulator, Coordinated motion, Capability map, Motion planning",Heng Zhang and Qi Sheng and Yuxin Sun and Xinjun Sheng and Zhenhua Xiong and Xiangyang Zhu,https://www.sciencedirect.com/science/article/pii/S0921889019310553,https://doi.org/10.1016/j.robot.2020.103554,0921-8890,2020,103554,129,Robotics and Autonomous Systems,A novel coordinated motion planner based on capability map for autonomous mobile manipulator,article,ZHANG2020103554
"We present an approach for recognizing objects present in a scene and estimating their full pose by means of an accurate 3D instance-aware semantic reconstruction. Our framework couples convolutional neural networks (CNNs) and a state-of-the-art dense Simultaneous Localization and Mapping (SLAM) system, ElasticFusion (Whelan et al., 2016), to achieve both high-quality semantic reconstruction as well as robust 6D pose estimation for relevant objects. We leverage the pipeline of ElasticFusion as a backbone, and propose a joint geometric and photometric error function with per-pixel adaptive weights. While the main trend in CNN-based 6D pose estimation has been to infer object?s position and orientation from single views of the scene, our approach explores performing pose estimation from multiple viewpoints, under the conjecture that combining multiple predictions can improve the robustness of an object detection system. The resulting system is capable of producing high-quality instance-aware semantic reconstructions of room-sized environments, as well as accurately detecting objects and their 6D poses. The developed method has been verified through extensive experiments on different datasets. Experimental results confirmed that the proposed system achieves improvements over state-of-the-art methods in terms of surface reconstruction and object pose prediction. Our code and video are available at https://sites.google.com/view/object-rpe.","Object pose estimation, 3D reconstruction, Semantic mapping, 3D registration",Dinh-Cuong Hoang and Achim J. Lilienthal and Todor Stoyanov,https://www.sciencedirect.com/science/article/pii/S0921889020304723,https://doi.org/10.1016/j.robot.2020.103632,0921-8890,2020,103632,133,Robotics and Autonomous Systems,Object-RPE: Dense 3D reconstruction and pose estimation with convolutional neural networks,article,HOANG2020103632
"This paper introduces a mobile robot with a new type of transformable wheel legs that can be used for flat and rough terrain. It integrates the stability and maneuverability of a wheeled robot and the legged robot?s obstacle climbing capacity using a transformable mechanism with wheel legs. With a transformation structure based on a four-bar mechanism, these two modes can be easily changed. This paper analyzes the movements for the proposed robot in wheeled and legged mode. Dynamic modeling and design of a control system were obtained. Then, the obstacle climbing strategies under legged modes were carried out. Finally, on the basis of the simulation, a prototype of the proposed robot was designed and produced. The results from the experiments validate the efficiency of the designed hybrid mobile robot.","Mobile robot, Transformable wheel-legged robot, Motion analysis, Obstacle avoidance, Dynamic model",?rem Mertyüz and Alper K. Tany?ld?z? and Beyda Ta?ar and Ahmet B. Tatar and O?uz Yakut,https://www.sciencedirect.com/science/article/pii/S092188902030467X,https://doi.org/10.1016/j.robot.2020.103627,0921-8890,2020,103627,133,Robotics and Autonomous Systems,FUHAR: A transformable wheel-legged hybrid mobile robot,article,MERTYUZ2020103627
"This paper presents a fully hardware synchronized mapping robot with support for a hardware synchronized external tracking system, for super-precise timing and localization. Nine high-resolution cameras and two 32-beam 3D Lidars were used along with a professional, static 3D scanner for ground truth map collection. With all the sensors calibrated on the mapping robot, three datasets are collected to evaluate the performance of mapping algorithms within a room and between rooms. Based on these datasets we generate maps and trajectory data, which is then fed into evaluation algorithms. We provide the datasets for download and the mapping and evaluation procedures are made in a very easily reproducible manner for maximum comparability. We have also conducted a survey on available robotics-related datasets and compiled a big table with those datasets and a number of properties of them.","Mobile robot, Sensor synchronization, Sensor calibration, Robotic datasets, Simultaneous Localization and Mapping (SLAM)",Hongyu Chen and Zhijie Yang and Xiting Zhao and Guangyuan Weng and Haochuan Wan and Jianwen Luo and Xiaoya Ye and Zehao Zhao and Zhenpeng He and Yongxia Shen and Sören Schwertfeger,https://www.sciencedirect.com/science/article/pii/S0921889020303997,https://doi.org/10.1016/j.robot.2020.103559,0921-8890,2020,103559,131,Robotics and Autonomous Systems,Advanced mapping robot and high-resolution dataset,article,CHEN2020103559
"This paper proposes a new compliance control strategy on a robot-assisted bilateral upper limb rehabilitation system. The robotic compliance regulation was achieved by modifying predefined training trajectories in real time, based on measured human?robot interaction force and human users? position within subject-specific workspace. Experimental data were collected from healthy subjects, and indicate that human users can follow predefined training trajectories well under real-time compliance variation, with the maximum normalized root mean square error (NRMSE) value no greater than 1.44%. Preliminary findings are encouraging, which demonstrates the availability of the proposed subject-specific compliance adaptation strategy, and the potential with enhanced training safety and efficacy. Future work will consider conducting a direct comparison between a bilateral upper limb rehabilitation device (BULReD)-assisted compliance training with or without subject-specific adaptation on a large sample of participants with upper limb disabilities.","Compliance control, Subject-specific workspace, Upper-limb robotics, Bilateral",Qing Miao and Yuxin Peng and Li Liu and Andrew McDaid and Mingming Zhang,https://www.sciencedirect.com/science/article/pii/S092188901930898X,https://doi.org/10.1016/j.robot.2020.103478,0921-8890,2020,103478,126,Robotics and Autonomous Systems,Subject-specific compliance control of an upper-limb bilateral robotic system,article,MIAO2020103478
"The navigation of autonomous, mobile multi-robot systems in changing environments is a challenging problem investigated over the past years. Cooperative, multiple robots are employed for many different tasks to increase the efficiency and success of a mission. However, many of the existing collective path planning approaches do not guarantee a reliable escape in environments with complex, non-convex obstacles without any prior knowledge. In this study, we developed a navigation framework for multi-robot systems in unknown areas that solely exploit the sensing information and shared data among the agents. The key contribution of this paper is the simultaneous, collision-free motion planning for fully autonomous robots in a collective manner. Furthermore, our communication architecture enables the robots to find an appropriate path to a desired, joint target position, despite the limited sensing and communication range.","Swarm intelligence, Cooperative control, Autonomous systems, Collective navigation",Ertug Olcay and Fabian Schuhmann and Boris Lohmann,https://www.sciencedirect.com/science/article/pii/S0921889020304449,https://doi.org/10.1016/j.robot.2020.103604,0921-8890,2020,103604,132,Robotics and Autonomous Systems,Collective navigation of a multi-robot system in an unknown environment,article,OLCAY2020103604
"The tightness inspection for the slot wedges is significant for the safe operation of large generators. One of the traditional methods is analysis of the acoustic signals of knocking on the surface of the slot wedge by inspection experts. Nowadays the slot wedge inspecting robot is an effective way to measure the tightness of the slot wedges and classify the level of the slot wedges into different groups. However, there are many types of generators and the precision cannot be guaranteed if the model of one type of generators is applied to another. Although the machine learning methods such as CNN (Convolutional Neural Networks) and RNN (Recurrent Neural Networks) are widely used for classification, they are not suitable for model transfer between different generators. In this paper, a transfer learning based structure is introduced to solve the problem and also the mixture of RNN and CNN is designed to fulfill the system. The structure is tested to transfer models with the acoustic signal sampled by the inspecting robot between the 500 MW and 600 MW generators. Experiment results show that the transfer learning structure can transfer models from one type of generators to another. Compared with the state-of-the-art methods, the proposed structure can improve the inspection precision by at least 36.7% and obtain the average precision over 79.0%.","Transfer learning, Slot wedge inspection robot, CNN, RNN, Frequency domain feature",Wenbin Yu and Yingjie Zhao and Lu Ding and Lei Song and Dan Huang,https://www.sciencedirect.com/science/article/pii/S0921889019308759,https://doi.org/10.1016/j.robot.2020.103507,0921-8890,2020,103507,128,Robotics and Autonomous Systems,Design of transfer learning structure for slot wedge tightness inspection robot,article,YU2020103507
"The recognition of previously visited places, known as Loop Closure Detection (LCD), composes one of the problems widely studied in robotics: simultaneous localization and mapping (SLAM). In this paper we propose a three level hierarchy based LCD method. In our serialized approach, in the First Level, a sequence of the most recently visited places is used as query to search for candidate sequences in our topological map composed by previously visited places. After that, at the Second Level, the method selects the most similar sequence to the query among all candidate sequences which is temporally consistent with the previous LCD method response. Then, at the Third Level, we match the image sequences belonging to the query sequence to the candidate sequence selected in the Second Level. The method is evaluated in different and challenging public datasets, and presents expressive results that overcome the LCD state-of-the-art methods.","Loop Closure Detection, SLAM, Mobile robotics",Fernanda Rodrigues and Renata Neuland and Mathias Mantelli and Diego Pittol and Renan Maffei and Edson Prestes and Mariana Kolberg,https://www.sciencedirect.com/science/article/pii/S0921889020304607,https://doi.org/10.1016/j.robot.2020.103620,0921-8890,2020,103620,133,Robotics and Autonomous Systems,Three level sequence-based Loop Closure Detection,article,RODRIGUES2020103620
"The consensus of multi-agent dynamic systems is a metaphor for many different tasks involving group agreement. However, ensuring consensus in real-world scenarios, with non-convex obstacles and kinodynamic motion constraints, proves to be a hard task, since it is quite difficult to model such a problem analytically. Therefore, this paper studies the problem of state agreement for Multi-Robot Systems (MRS) in unknown cluttered complex environments. Here, we propose and analyze a distributed consensus algorithm combined with a Rapidly-exploring Random Tree-based planner, which allows linear and nonlinear systems to reach a common target on their states inside bi- or three-dimensional spaces filled with static obstacles. We demonstrate that, with enough time, our planning strategy ensures probabilistic completeness convergence independently of the topological communication network employed, since some connectivity constraints are observed. Simulated results with linear and nonlinear models are provided, showing the effectiveness of our proposed method in comparison with the state-of-the-art literature for the specific case of position consensus (rendezvous) missions.","Multi-agent consensus, Rapidly-exploring random trees, Probabilistic completeness, Rendezvous",Armando {Alves Neto} and Leonardo A. Mozelli and Douglas G. Macharet,https://www.sciencedirect.com/science/article/pii/S0921889020304474,https://doi.org/10.1016/j.robot.2020.103607,0921-8890,2020,103607,132,Robotics and Autonomous Systems,On the consensus of nonlinear agents in unknown cluttered environments using random planning,article,ALVESNETO2020103607
"This paper presents a multi-task instance segmentation neural network able to provide both road lane and road participants detection. The multi-task approach, ERFNet-based, allows feature sharing and reduces the computational requirements of the overall detection architecture, allowing real time performance even in configurations with limited hardware. The proposed method includes an ad-hoc training procedure and automatic dataset creation mechanism that is also introduced in this paper. The proposed solution has been tested and validated through a newly generated public dataset derived from the BDD100K of 19K images, and in real scenarios. The results obtained prove the viability of the work for road application and its real time performance.","Semantic segmentation, Neural networks, Lane segmentation, Object segmentation",Leonardo Cabrera {Lo Bianco} and Jorge Beltrán and Gerardo Fernández López and Fernando García and Abdulla Al-Kaff,https://www.sciencedirect.com/science/article/pii/S0921889020304632,https://doi.org/10.1016/j.robot.2020.103623,0921-8890,2020,103623,133,Robotics and Autonomous Systems,Joint semantic segmentation of road objects and lanes using Convolutional Neural Networks,article,LOBIANCO2020103623
"This paper is concentrated on path planning for robots working in a dynamic environment to satisfy real-time needs. An efficient bias-goal factor RRT (EBG-RRT), which is multiple-query sampling-based replanning algorithm, is proposed with rapid response and high success rate. Specifically, a relay node method is proposed to get a position where the robot and dynamic obstacles will be no-collision and help robots to move without suspended. Based on the relay node method, Connection strategy performs minimal modifications to maintain the interrupted path. In order to overcome the short of Waypoint Cache method, an efficient and optimal Waypoint Cache (EOWC) method is proposed to make use of potential cache information and find an optimal path to repair. The EOWC method is combined with the BG-RRT algorithm according to the iterative characteristics. Finally, the EBG-RRT algorithm is verified on ROS with Aubo-i5 manipulator. Simulation results provide the EBG-RRT algorithm is outperformed both in static and dynamic environments.","Dynamic obstacle avoidance, Path planning, Multiple-query, Cache information, ROS",Chengren Yuan and Guifeng Liu and Wenqun Zhang and Xinglong Pan,https://www.sciencedirect.com/science/article/pii/S0921889020304358,https://doi.org/10.1016/j.robot.2020.103595,0921-8890,2020,103595,131,Robotics and Autonomous Systems,An efficient RRT cache method in dynamic environments for path planning,article,YUAN2020103595
"Wall-climbing robots have been widely applied in the inspection of smooth walls. However, only a few adhesion methods have been developed for robots that will allow them to climb cliffs and dusty, high-altitude, rough walls (constructed using coarse concrete, bricks, and stones, etc.) that may be subjected to vibrations. This paper proposes a suitable adhesion method that employs grappling-hook-like claws arranged in a cross shape. First, we address the implementation mechanism required. Then, a method of extracting the characteristic parameter is revealed rough wall was devised, 3D profiles of rough walls were simulated, and the discriminant conditions necessary for the claws to stably grasp the wall were provided. A method of triangulation is proposed to judge which regions of a 3D wall can be gripped, and we subsequently present a grasping discrimination algorithm for the interaction between the miniature claws and 3D wall profile. Finally, a prototype of the grappling-hook-like claw system was fabricated. A test platform was built to test the robot which incorporates an electromagnetic vibration shaker to simulate a vibrating wall. Experiments were then carried out on the robot using the vibrating wall and a random outdoor wall. The results verified the feasibility of the proposed claws and the validity of the discriminant algorithm for gripping 3D walls. Compared with traditional adhesion approaches, the proposed method (based on hook-like claws) is more adaptable to suit various types of wall. It also has higher resistance to disturbances and so provides a more reliable method of adhesion for robots on rough walls.","Flexible grasping claw, Grasping discrimination algorithm, 3D wall, Asperity of rough wall surfaces",Fengyu Xu and Fanchang Meng and Quansheng Jiang and Gaoliang Peng,https://www.sciencedirect.com/science/article/pii/S0921889018310091,https://doi.org/10.1016/j.robot.2020.103501,0921-8890,2020,103501,128,Robotics and Autonomous Systems,"Grappling claws for a robot to climb rough wall surfaces: Mechanical design, grasping algorithm, and experiments",article,XU2020103501
"So far, gas leakage caused by natural or human factors has led to serious consequences in terms of social security. Previous strategies for locating the odor sources appear to be either defective or incomplete. For enhancing the success rate and rapidity, this paper aims to present a novel and complete strategy in search of lurking gas sources. Particle filtering and information entropy are both employed to track the plume information. To improve the tracking efficiency in this process, a novel objective function is designed by considering the entropy gains of the suspected targets as well as the repeated exploration scores. Considering the pseudo sourced caused by obstacles, a statistics-based source determine algorithm is proposed to confirm the source?s authenticity, while the artificial potential field method is subsequently applied to eliminate the distractions introduced by the pseudo sources. Simulations and on-site tests are both carried out while results showed that the proposed scheme is competent to complete sources localization task in the scene that contains randomly distributed obstacles and pseudo source.","Source localization, Particle filtering, Information entropy, Pseudo source filtering, Artificial potential field",Hongbiao Zhu and Yibo Wang and Chengjin Du and Quan Zhang and Weidong Wang,https://www.sciencedirect.com/science/article/pii/S0921889020304590,https://doi.org/10.1016/j.robot.2020.103619,0921-8890,2020,103619,132,Robotics and Autonomous Systems,A novel odor source localization system based on particle filtering and information entropy,article,ZHU2020103619
"Due to its vast applicability, the semantic interpretation of regions or entities increasingly attracts the attention of scholars within the robotics community. The paper at hand introduces a novel unsupervised technique to semantically identify the position of an autonomous agent in unknown environments. When the robot explores a certain path for the first time, community detection is achieved through graph-based segmentation. This allows the agent to semantically define its surroundings in future traverses even if the environment?s lighting conditions are changed. The proposed semantic clustering technique exploits the Louvain community detection algorithm, which constitutes a novel and efficient method for identifying groups of measurements with consistent similarity. The produced communities are combined with metric information, as provided by the robot?s odometry through a hierarchical agglomerative clustering method. The suggested algorithm is evaluated in indoors and outdoors datasets creating topological maps capable of assisting semantic localization. We demonstrate that the system categorizes the places correctly when the robot revisits an environment despite the possible lighting variation.","Topological mapping, Illumination invariance, Community detection, Robot localization",Vasiliki Balaska and Loukas Bampis and Moses Boudourides and Antonios Gasteratos,https://www.sciencedirect.com/science/article/pii/S0921889020304073,https://doi.org/10.1016/j.robot.2020.103567,0921-8890,2020,103567,131,Robotics and Autonomous Systems,Unsupervised semantic clustering and localization for mobile robotics tasks,article,BALASKA2020103567
"For mobile robots to operate autonomously in general environments, perception is required in the form of a dense metric map. For this purpose, we present the stochastic triangular mesh (STM) mapping technique: a 2.5-D representation of the surface of the environment using a continuous mesh of triangular surface elements, where each surface element models the mean plane and roughness of the underlying surface. In contrast to existing mapping techniques, an STM map models the structure of the environment by ensuring a continuous model, while also being able to be incrementally updated with linear computational cost in the number of measurements. We reduce the effect of uncertainty in the robot pose (position and orientation) by using landmark-relative submaps. The uncertainty in the measurements and robot pose are accounted for by the use of Bayesian inference techniques during the map update. We demonstrate that an STM map can be used with sensors that generate point measurements, such as stochastic triangular mesh (LiDAR) sensors and stereo cameras. We show that an STM map is a more accurate model than the only comparable online surface mapping technique ? a standard elevation map ? and we also provide qualitative results on practical datasets.","Dense mapping, Submapping, Perception, Triangular mesh, Probabilistic graphical model, Stereo cameras, LiDAR",Clint D. Lombard and Corné E. {van Daalen},https://www.sciencedirect.com/science/article/pii/S092188901930805X,https://doi.org/10.1016/j.robot.2020.103449,0921-8890,2020,103449,127,Robotics and Autonomous Systems,Stochastic triangular mesh mapping: A terrain mapping technique for autonomous mobile robots,article,LOMBARD2020103449
"This article deals with the development of a simulator that recreates, in virtual reality, a team of Selectively Compliance Assembly Robot Arms (SCARA). This team works cooperatively to fulfill the task of stacking rectangular objects coordinated through a strategy that includes a cloud server responsible for communication between the robots. The execution of the task is based on a leader/follower configuration. In this configuration, the leader performs a computed trajectory constantly reporting its position to the remote server. The remote server, in turn, sends this information back to the follower so this can follow the leader. The application combines MatLab® and Java. The latter is specifically used for communication routines, since its versatility makes it easy to be incorporated into any type of machine. This paper seeks to demonstrate the advantages of incorporating cloud resources into a multi-robot system and how its performance can be tested by means of the application developed.","Cloud, Services, Collaborative, Cooperative, Coordination, Virtual reality",Claudio Urrea and Rodrigo Matteoda,https://www.sciencedirect.com/science/article/pii/S0921889019307651,https://doi.org/10.1016/j.robot.2020.103447,0921-8890,2020,103447,126,Robotics and Autonomous Systems,Development of a virtual reality simulator for a strategy for coordinating cooperative manipulator robots using cloud computing,article,URREA2020103447
"Currently, most social robots interact with their surroundings and humans through sensors that are integral parts of the robots, which limits the usability of the sensors, human?robot interaction, and interchangeability. A wearable sensor garment that fits many robots is needed in many applications. This article presents an affordable wearable sensor vest, and an open-source software architecture with the Internet of Things (IoT) for social humanoid robots. The vest consists of touch, temperature, gesture, distance, vision sensors, and a wireless communication module. The IoT feature allows the robot to interact with humans locally and over the Internet. The designed architecture works for any social robot that has a general-purpose graphics processing unit (GPGPU), I2C/SPI buses, Internet connection, and the Robotics Operating System (ROS). The modular design of this architecture enables developers to easily add/remove/update complex behaviors. The proposed software architecture provides IoT technology, GPGPU nodes, I2C and SPI bus mangers, audio-visual interaction nodes (speech to text, text to speech, and image understanding), and isolation between behavior nodes and other nodes. The proposed IoT solution consists of related nodes in the robot, a RESTful web service, and user interfaces. We used the HTTP protocol as a means of two-way communication with the social robot over the Internet. Developers can easily edit or add nodes in C, C++, and Python programming languages. Our architecture can be used for designing more sophisticated behaviors for social humanoid robots.","Social robot, Internet of Things, GPGPU, Human?robot interaction, Software architecture, Senor vest",Mohsen Jafarzadeh and Stephen Brooks and Shimeng Yu and Balakrishnan Prabhakaran and Yonas Tadesse,https://www.sciencedirect.com/science/article/pii/S0921889019306323,https://doi.org/10.1016/j.robot.2020.103536,0921-8890,2021,103536,139,Robotics and Autonomous Systems,"A wearable sensor vest for social humanoid robots with GPGPU, IoT, and modular software architecture",article,JAFARZADEH2021103536
"Limited communication range, together with mobility of robots, makes it crucial to design the control plans such that connectivity of a multi-robot network is maintained. Recently, many local and global connectivity maintenance schemes have been proposed to preserve connectivity of a robotic network. The traditional local connectivity maintenance method (LCM) is known to preserve every existing link, even though some of the existing connections might not be necessary for maintaining a path between each pair of robots, which is the aim of global connectivity maintenance (GCM) methods. However, the flexibility of movement provided by the global method costs restriction on speed and bandwidth. In this paper, a modified local connectivity maintenance method is provided to gain more flexibility of movement, while preserving the properties and simplicity of a local method. The proposed method is based on traditional local connectivity maintenance equipped with a basic operation to exchange the neighbors between two adjacent robots. Permutation of robots could be beneficial in many robotic applications such as exchanging the leader role in a V-formed robotic group or providing a path for a robot to reach its desired position while preserving the networks connectivity.","Connectivity maintenance, Local connectivity, Multi-robot network, Potential function",Koresh Khateri and Mahdi Pourgholi and Mohsen Montazeri and Lorenzo Sabattini,https://www.sciencedirect.com/science/article/pii/S0921889019309959,https://doi.org/10.1016/j.robot.2020.103540,0921-8890,2020,103540,129,Robotics and Autonomous Systems,A connectivity preserving node permutation local method in limited range robotic networks,article,KHATERI2020103540
"In this paper, we developed an underactuated robotic finger with three joints having a branching tendon mechanism and a sensing system to estimate the wrench applied to the fingertip based on the moment-equivalent point (MEP). We proposed the design to combine the branching tendon mechanism and the principle of wrench sensing based on the MEP. The proposed system realized the measurement of the wrench applied to the fingertip using a simple force sensor and a wire-driven system. Furthermore, we experimentally confirmed their functioning.","Wire-driven robotic finger, Branching tendon mechanism, Force sensing, Moment-equivalent point",Shouhei Shirafuji and Jun Ota,https://www.sciencedirect.com/science/article/pii/S0921889019302908,https://doi.org/10.1016/j.robot.2020.103538,0921-8890,2020,103538,129,Robotics and Autonomous Systems,Development of a robotic finger with a branching tendon mechanism and sensing based on the moment-equivalent point,article,SHIRAFUJI2020103538
"The paper presents a novel path planning methodology based on the directional graph search and the geometry curve for the Automated Valet Parking (AVP) system. The whole path planning methodology is divided into three parts including the global path planning, the path coordination strategy and the parking path planning. Firstly, the global path planning is triggered to find a path from the parking slot entrance to the rough location of the assigned parking spot. A novel directional Hybrid A* algorithm is proposed to generate the global path efficiently without redundant searches, such as the dead end. Afterwards, the path coordination strategy gives a transitional path to connect the end node of the global path to the parking planning start node. The transitional path is composed of geometry curves including arcs and line segments based on the optimal parking start node. Finally, the parking path planning generates a parking path to guide the vehicle from parking start node to the parking space. A modified C-type vertical parking path planning algorithm is utilized to generate the parking path, offering flexibility for choosing the parking start node. Simulation results based on Matlab and PreScan show that it takes less time for the proposed path planning algorithm to generate a feasible path for the AVP system compared with the general planning algorithm. The novel AVP path planning algorithm also has the potential for practical use.","AVP, Path planning, Path coordination, Directional graph search, Geometry curve",Zhaobo Qin and Xin Chen and Manjiang Hu and Liang Chen and Jingjing Fan,https://www.sciencedirect.com/science/article/pii/S0921889020304462,https://doi.org/10.1016/j.robot.2020.103606,0921-8890,2020,103606,132,Robotics and Autonomous Systems,A novel path planning methodology for automated valet parking based on directional graph search and geometry curve,article,QIN2020103606
"Mobile service robots possess high potential of providing numerous assistances in the working areas. In an attempt to develop a mobile service robot which is dynamically balanced for faster movement and taller manipulation capability, we designed and prototyped J4.alpha, which is intended for swift navigation and nimble manipulation. Previously, we devised a pure visual method based on a supervised deep learning model for real-time recognition of nodal locations. Four low-resolution RGB cameras are installed around J4.alpha to capture the surrounding visual features for training and detection. As the method is developed for ease of implementation, fast real-time application, accurate detection, and low cost, we further improve the accuracy and the practicality of the method in this study. Specifically, a set of expectation rules are introduced to reject outlier detections, and a scheme of training renewal is devised to effectively react to environmental modifications. In our previous tests, precision and recall rates of the location coordinate detection by the ConvNet models were generally between 0.78 and 0.91; by introducing the expectation rules, precision and recall are improved by approximately 10%. A large scale field test is also carried out here for both corridor and factory scenarios; the performance of the proposed method was tested for detection accuracy and verified for 2 m and 0.5 m nodal intervals. The scheme of training renewal designed for capturing and reflecting environmental modifications was also proved to be effective.",,Chih-Hung G. Li and Yi-Feng Hong and Po-Kai Hsu and Thavida Maneewarn,https://www.sciencedirect.com/science/article/pii/S0921889020304188,https://doi.org/10.1016/j.robot.2020.103578,0921-8890,2020,103578,131,Robotics and Autonomous Systems,Real-time topological localization using structured-view ConvNet with expectation rules and training renewal,article,LI2020103578
"Exploration is a task in which autonomous mobile robots incrementally discover features of interest in initially unknown environments. We consider the problem of exploration for map building, in which a robot explores an indoor environment in order to build a metric map. Most of the current exploration strategies used to select the next best locations to visit ignore prior knowledge about the environments to explore that, in some practical cases, could be available. In this paper, we present an exploration strategy that evaluates the amount of new areas that can be perceived from a location according to a priori knowledge about the structure of the indoor environment being explored, like the floor plan or the contour of external walls. Although this knowledge can be incomplete and inaccurate (e.g., a floor plan typically does not represent furniture and objects and consequently may not fully mirror the structure of the real environment), we experimentally show, both in simulation and with real robots, that employing prior knowledge improves the exploration performance in a wide range of settings.","Robot exploration, Floor plan, Exploration strategy, Prior knowledge",Matteo Luperto and Michele Antonazzi and Francesco Amigoni and N. Alberto Borghese,https://www.sciencedirect.com/science/article/pii/S0921889020304620,https://doi.org/10.1016/j.robot.2020.103622,0921-8890,2020,103622,133,Robotics and Autonomous Systems,Robot exploration of indoor environments using incomplete and inaccurate prior knowledge,article,LUPERTO2020103622
"Rapidly-exploring Randomized Trees (RRT) is a kind of probabilistically complete exploration algorithm based on the tree structure. It has been widely used in the robotic navigation since it guarantees the complete discovery and the exploration of environment maps through robots. In the present study, the RRT algorithm is extended to propose an optimization-based map exploration strategy for multiple robots to actively explore and build environment maps. The present study adopts a market-based task allocation strategy, which to maximize the profit, for the coordination between robots. In the extension of the RRT, the cost function consists the unknown region and the passed unknown region. The unknown region is explored for a given frontier point, while the passed unknown region is the area, where the robot moves towards the target frontier point. When the robot moves from the start position to the target frontier point, the trajectory length is defined as a constraint for the optimization. The main contributions of the present study can be summarized in optimizing the frontier points, defining a new task allocation strategy and applying different evaluation rules, including the running time and the trajectory length. These rules are applied to explore the multi-robot map in simulated and practical environments. Then the Robot Operating System (ROS) is utilized to evaluate the application of the proposed exploration strategy on Turtlebots in a 270 m2 room. Obtained results from the simulation and the experiment demonstrate that the proposed method outperforms the Umari?s approach from both the running time and the trajectory length aspects.","Rapidly-exploring Randomized Trees, Multiple robots, Map exploration, Optimization framework",Liwei Zhang and Zhibin Lin and Jie Wang and Bingwei He,https://www.sciencedirect.com/science/article/pii/S092188902030405X,https://doi.org/10.1016/j.robot.2020.103565,0921-8890,2020,103565,131,Robotics and Autonomous Systems,Rapidly-exploring Random Trees multi-robot map exploration under optimization framework,article,ZHANG2020103565
"In a typical operation mode, a wheel loader frequently accelerates and decelerates, and the curvature of the driving path is inconsistent. In the past, autonomous vehicle trajectory planning has not considered the related changes in the velocity of the vehicle. Therefore, the trajectory tracking control process has seldom considered the impact of curving paths on the trajectory tracking performance. To address these problems, this study evaluated an autonomous wheel loader based on the trajectory of its non-uniform driving motion and constructed an adaptive model predictive control (AMPC) trajectory tracking system that considers disturbances in the path curvature. The trajectory of the autonomous wheel loader was then tracked using the proposed AMPC system with a planned non-uniform motion trajectory as the target. Its performance was then compared with that of a conventional model predictive control (MPC) trajectory tracking system that does not consider any path curvature disturbances. The maximum displacement error and heading error obtained by the proposed AMPC system were found to be 65.7% and 60%, respectively, smaller than those obtained by the MPC system. The desired trajectory can also be tracked well under different curvature amplitudes using the AMPC trajectory tracking system, ensuring active safety performance of an autonomous wheel loader in the process of trajectory tracking.","Automatic drive, Wheel loader, Trajectory planning, Trajectory tracking, Model predictive control",Junren Shi and Dongye Sun and Datong Qin and Minghui Hu and Yingzhe Kan and Ke Ma and Ruibo Chen,https://www.sciencedirect.com/science/article/pii/S0921889020304103,https://doi.org/10.1016/j.robot.2020.103570,0921-8890,2020,103570,131,Robotics and Autonomous Systems,Planning the trajectory of an autonomous wheel loader and tracking its trajectory via adaptive model predictive control,article,SHI2020103570
"High dimensional robot motion planning has recently been approached with trajectory optimization methods that efficiently minimize a suitable objective function in order to generate robot trajectories that are both optimal and feasible. However, finding a globally optimal solution is often an insurmountable problem in practice and state-of-the-art trajectory optimization methods are thus prone to local minima, mainly in cluttered environments. In this paper, we propose a novel trajectory planning algorithm that employs stochastic optimization in order to find a collision-free trajectory generated from a continuous-time Gaussian process (GP). The contributions of the proposed motion planning method stem from introducing the heteroscedasticity of the GP, together with exploited sparsity for efficient covariance estimation, and a cross-entropy based stochastic optimization for importance sampling based trajectory optimization. We evaluate the proposed method on three simulated scenarios: a maze benchmark, a 7DOF robot arm planning benchmark and a 10DOF mobile manipulator trajectory planning example and compare it to a state-of-the-art GP trajectory optimization method, namely the Gaussian process motion planner 2 algorithm (GPMP2). Our results demonstrate the following: (i) the proposed method yields a more thorough exploration of the solution space in complex environments than GPMP2, while having comparable execution time, (ii) the introduced heteroscedasticity generates GP priors better suited for collision avoidance and (iii) the proposed method has the ability to efficiently tackle high-dimensional trajectory planning problems.","Robot motion planning, Trajectory optimization, Continuous-time Gaussian processes, Stochastic optimization, Cluttered environments",Luka Petrovi? and Juraj Per?i? and Marija Seder and Ivan Markovi?,https://www.sciencedirect.com/science/article/pii/S0921889020304589,https://doi.org/10.1016/j.robot.2020.103618,0921-8890,2020,103618,133,Robotics and Autonomous Systems,Cross-entropy based stochastic optimization of robot trajectories using heteroscedastic continuous-time Gaussian processes,article,PETROVIC2020103618
"Fixed-Wing UAVs (Unmanned Aerial Vehicles) flocking is still a challenging problem due to the kinematics complexity and environmental dynamics. In this paper, we solve the leader?followers flocking problem using a novel deep reinforcement learning algorithm that can generate roll angle and velocity commands by training an end-to-end controller in continuous state and action spaces. Specifically, we choose CACLA (Continuous Actor?Critic Learning Automation) as the base algorithm and we use the multi-layer perceptron to represent both the actor and the critic. Besides, we further improve the learning efficiency by using the experience replay technique that stores the training data in the experience memory and samples from the memory as needed. We have compared the performance of the proposed CACER (Continuous Actor?Critic with Experience Replay) algorithm with benchmark algorithms such as DDPG and double DQN in numerical simulation, and we have demonstrated the performance of the learned optimal policy in semi-physical simulation without any parameter tuning.","Fixed-wing UAV, Flocking, Reinforcement learning, Actor?critic",Chao Yan and Xiaojia Xiang and Chang Wang,https://www.sciencedirect.com/science/article/pii/S0921889020304346,https://doi.org/10.1016/j.robot.2020.103594,0921-8890,2020,103594,131,Robotics and Autonomous Systems,Fixed-Wing UAVs flocking in continuous spaces: A deep reinforcement learning approach,article,YAN2020103594
"This paper presents a rapid (real time) solution to the minimum-time path planning problem for Dubins vehicles under environmental currents (wind or ocean currents). Real-time solutions are essential in time-critical situations (such as replanning under dynamically changing environments or tracking fast moving targets). Typically, Dubins problem requires to solve for six path types; however, due to the presence of currents, four of these path types require to solve the root-finding problem involving transcendental functions. Thus, the existing methods result in high computation times and their applicability for real-time applications is limited. In this regard, in order to obtain a real-time solution, this paper proposes a novel approach where only a subset of two Dubins path types (LSL and RSR) are used which have direct analytical solutions in the presence of currents. However, these two path types do not provide full reachability. We show that by extending the feasible range of circular arcs in the LSL and RSR path types from 2? to 4?: (1) full reachability of any goal pose is guaranteed, and (2) paths with lower time costs as compared to the corresponding 2?-arc paths can be produced. Theoretical properties are rigorously established, supported by several examples, and evaluated in comparison to the Dubins solutions by extensive Monte-Carlo simulations.","Dubins paths, Path planning, Environmental currents, Curvature-constrained vehicles",Khushboo Mittal and Junnan Song and Shalabh Gupta and Thomas A. Wettergren,https://www.sciencedirect.com/science/article/pii/S0921889020304863,https://doi.org/10.1016/j.robot.2020.103646,0921-8890,2020,103646,134,Robotics and Autonomous Systems,Rapid path planning for Dubins vehicles under environmental currents,article,MITTAL2020103646
"We present a motion planner for the autonomous navigation of UAVs that manages motion and sensing uncertainty at planning time. By doing so, optimal paths in terms of probability of collision, traversal time and uncertainty are obtained. Moreover, our approach takes into account the real dimensions of the UAV in order to reliably estimate the probability of collision from the predicted uncertainty. The motion planner relies on a graduated fidelity state lattice and a novel multi-resolution heuristic which adapt to the obstacles in the map. This allows managing the uncertainty at planning time and yet obtaining solutions fast enough to control the UAV in real time. Experimental results show the reliability and the efficiency of our approach in different real environments and with different motion models. Finally, we also report planning results for the reconstruction of 3D scenarios, showing that with our approach the UAV can obtain a precise 3D model autonomously.","Autonomous navigation, Motion planning, Motion uncertainty, UAVs, Scene reconstruction",Adrián González-Sieira and Daniel Cores and Manuel Mucientes and Alberto Bugarín,https://www.sciencedirect.com/science/article/pii/S0921889019307080,https://doi.org/10.1016/j.robot.2020.103455,0921-8890,2020,103455,126,Robotics and Autonomous Systems,Autonomous navigation for UAVs managing motion and sensing uncertainty,article,GONZALEZSIEIRA2020103455
"The interaction between robots and humans is of great relevance for the field of neurorobotics as it can provide insights on how humans perform motor control and sensor processing and on how it can be applied to robotics. We propose a spiking neural network (SNN) to trigger finger motion reflexes on a robotic hand based on human surface Electromyography (sEMG) data. The first part of the network takes sEMG signals to measure muscle activity, then classify the data to detect which finger is being flexed in the human hand. The second part triggers single finger reflexes on the robot using the classification output. The finger reflexes are modeled with motion primitives activated with an oscillator and mapped to the robot kinematic. We evaluated the SNN by having users wear a non-invasive sEMG sensor, record a training dataset, and then flex different fingers, one at a time. The muscle activity was recorded using a Myo sensor with eight different channels. The sEMG signals were successfully encoded into spikes as input for the SNN. The classification could detect the active finger and trigger the motion generation of finger reflexes. The SNN was able to control a real Schunk SVH 5-finger robotic hand online. Being able to map myo-electric activity to functions of motor control for a task, can provide an interesting interface for robotic applications, and a platform to study brain functioning. SNN provide a challenging but interesting framework to interact with human data. In future work the approach will be extended to control also a robot arm at the same time.","Neurorobotics, Human?robot-interaction, Neural control system, Humanoid robot, Motion representation, sEMG classification, Spiking neural networks, Anthropomorphic robot hand",J. Camilo Vasquez Tieck and Sandro Weber and Terrence C. Stewart and Jacques Kaiser and Arne Roennau and Rüdiger Dillmann,https://www.sciencedirect.com/science/article/pii/S0921889020304061,https://doi.org/10.1016/j.robot.2020.103566,0921-8890,2020,103566,131,Robotics and Autonomous Systems,A spiking network classifies human sEMG signals and triggers finger reflexes on a robotic hand,article,TIECK2020103566
"Action recognition plays an important role in human?robot cooperation and interaction. By recognizing human actions, robots can imitate or reproduce human actions and obtain skills. Recently, convolutional neural networks (CNNs) have been widely used to recognize actions based on 3D skeleton. Good performance has been achieved due to the approximation capability gained from the depth of the model. Unfortunately, in the mainstream deep structures, dropout and fully connected layers are usually used to classify actions. That is to say, ensemble is used to guarantee the recognition performance, which decreases the computational efficiency. In order to improve the computational efficiency, we propose in this paper a deep-wide network (DWnet) to recognize human actions based on 3D skeleton. Specifically, we modify the decision-making mechanism of the deep CNN with a shallow structure, which improves the computational efficiency. The state-of-the-art deep CNN is used to extract spatial?temporal features from the skeletal sequence. Then features are transformed into a higher dimensional feature space to obtain global information and classified by the modified decision making mechanism. Experiments on two skeletal datasets demonstrate the advantage of the proposed model on testing efficiency and the effectiveness of the novel model to recognize the action. The code has been publicly available at https://github.com/YHDang/DWnet.","Action recognition, Deep structure, 3D skeleton, Human?robot cooperation",Yonghao Dang and Fuxing Yang and Jianqin Yin,https://www.sciencedirect.com/science/article/pii/S0921889019308176,https://doi.org/10.1016/j.robot.2020.103441,0921-8890,2020,103441,126,Robotics and Autonomous Systems,DWnet: Deep-wide network for 3D action recognition,article,DANG2020103441
"This paper presents an optimal communication relay positioning method to improve the communication performance of mobile multi-node networks in complex environments. The communication channel quality prediction between nodes is of primary concern to find the optimal relay node positions while considering the uncertain and dynamic nature of environments. To this end, the learning-based or the distance model-based method is used for the channel prediction depending on the mobility of the communication nodes of interest. The global message connectivity and the worst case connectivity are introduced as the communication performance metric of networked agents. The optimal relay positions are found by maximizing the performance with respect to the relay positions through a heuristic optimization technique. This algorithm outperforms a recently-developed relay positioning algorithm in the simulations. The indoor experiments are conducted to show that the proposed approach using mobile relays improves the communication performance of the complex network significantly with the accurate channel prediction.","Communication relay, Gaussian process regression, Indoor communication model, Wireless mesh network",Jongyun Kim and Pawel Ladosz and Hyondong Oh,https://www.sciencedirect.com/science/article/pii/S0921889019309145,https://doi.org/10.1016/j.robot.2020.103517,0921-8890,2020,103517,129,Robotics and Autonomous Systems,Optimal communication relay positioning in mobile multi-node networks,article,KIM2020103517
"Learning from human skills has become one of the popular inspirations in grasp prediction and evaluation, but lack of effective methods on groups of grasp points for multi-fingered dexterous hands yields an open challenge. When facing an object, humans firstly predict a variety of options for grasps, which can be concerned as a complex multi-valued problem. After prediction, humans evaluate grasps and then choose the optimal one. Inspired by human skills, we propose Grasp Prediction Networks (GPNs) based on Convolutional Neural Networks (CNNs) and Mixture Density Networks (MDNs). The proposed GPNs map from a depth image to a set of parameters for Gaussian Mixture Model (GMM), from which candidate groups of grasp points can be sampled for prediction. Besides, we also propose Grasp Evaluation Networks (GENs) to evaluate candidate groups and then choose the optimal group of grasp points. The proposed GENs consider force-closure metric as grasp quality for evaluation. Different from other related work, our method (1) utilizes a probabilistic model to predict multiple groups of grasp points from a monocular depth image and (2) evaluates grasp quality with force-closure metric given a monocular depth image and a group of grasp points. Furthermore, we built a grasp dataset which consists of depth images, groups of grasp points and each group?s grasp quality. Herein, three different experiments were designed to validate our approach. The first one was a comparative experiment and revealed that GPNs show equivalent performance as GraspIt! in terms of high-quality grasp planning. The second one was also a comparative experiment, which validated that GENs can evaluate grasps as precisely as GraspIt!. Moreover, the last one was an actual experiment implemented on Shadow Hand Lite, and experimental results indicated that our approach achieved finely grasp of novel objects.","Grasp prediction, Grasp evaluation, Multi-fingered dexterous hands, Convolutional neural networks, Mixture density networks",Zengzhi Zhao and Weiwei Shang and Haoyuan He and Zhijun Li,https://www.sciencedirect.com/science/article/pii/S0921889019309947,https://doi.org/10.1016/j.robot.2020.103550,0921-8890,2020,103550,129,Robotics and Autonomous Systems,Grasp prediction and evaluation of multi-fingered dexterous hands using deep learning,article,ZHAO2020103550
"This paper presents a novel challenging dataset that offers a new landscape of testing material for mobile robotics, autonomous driving research, and forestry operation. In contrast to common urban structures, we explore an unregulated natural environment to exemplify sub-urban and forest environment. The sequences provide two-natured data where each place is visited in summer and winter conditions. The vehicle used for recording is equipped with a sensor rig that constitutes four RGB cameras, an Inertial Measurement Unit, and a Global Navigation Satellite System receiver. The sensors are synchronized based on non-drifting timestamps. The dataset provides trajectories of varying complexity both for the state of the art visual odometry approaches and visual simultaneous localization and mapping algorithms. The full dataset and toolkits are available for download at: http://urn.fi/urn:nbn:fi:att:9b8157a7-1e0f-47c2-bd4e-a19a7e952c0d. As an alternative, you can browse for the dataset using the article title at: http://etsin.fairdata.fi.","Forest, Dataset, SLAM, Visual odometry, Navigation, Localization, Mapping, Stereo, Autonomous driving, Mobile robotics, Field robotics, Computer vision",Ihtisham Ali and Ahmed Durmush and Olli Suominen and Jari Yli-Hietanen and Sari Peltonen and Jussi Collin and Atanas Gotchev,https://www.sciencedirect.com/science/article/pii/S0921889020304504,https://doi.org/10.1016/j.robot.2020.103610,0921-8890,2020,103610,132,Robotics and Autonomous Systems,FinnForest dataset: A forest landscape for visual SLAM,article,ALI2020103610
"The goal of this research is to develop a ?Selective Grasp? system with which robots can grasp and identify the target object even in occluded environments. In pursuit of this goal, we first develop a robot hand on which proximity sensors are mounted all around. In addition to the development, we propose a sensor model of the robot hand. By using the sensor model, robots can estimate the distance to the object and calibrate the sensors. With our robot hand, robots can accurately recognize their surroundings without touch. Secondly, we propose an approach in which robots can memorize spatial information of surroundings by building an environment map. The building map motion is generated by a combination of manipulation primitives based on proximity sensors. Thirdly, we propose a grasp planning method and an object shape classification method based on the environment map. By these methods, robots can grasp objects and classify shapes of the objects in occluded spaces. Lastly, we conduct real robot experiments, through which we validate the effectiveness of our proposed Selective Grasp system.","Proximity sensor, Robot hand, Environment map, Grasp, Shape classification",Naoya Yamaguchi and Shun Hasegawa and Masaki Murooka and Kei Okada and Masayuki Inaba,https://www.sciencedirect.com/science/article/pii/S092188901930274X,https://doi.org/10.1016/j.robot.2020.103464,0921-8890,2020,103464,127,Robotics and Autonomous Systems,Selective grasp in occluded space by all-around proximity perceptible finger,article,YAMAGUCHI2020103464
"Vision-based self-localization methods are key functionalities for various research topics. Recent research results on related fields have catalyzed several accurate, versatile and reliable real-time Visual SLAM systems suitable for self-localization under a wide variety of environmental preconditions. These methods extend their functionalities from being only a good camera tracker to being able to recursively build up camera?s surroundings. The fast development of Visual SLAM research has proposed demands on innovating evaluation methods for Visual SLAM systems. However, retrieving images and ground truth from various kinds of environments, estimating calibration parameters between several sensors and annotating useful labels all require cumbersome human labor and will introduce inevitable errors. In this paper, we propose a method that uses virtually established models to automatically generate photorealistic images with accurate ground truth and several kinds of pixel-level annotations useful for Visual SLAM development and evaluation. We build and render a challenging dataset in low-texture environments with large scale camera movement, multiple moving objects and varying luminance status. We also propose several new evaluation criteria that can fully take advantage of ground truth and annotations from synthetic datasets. Experiments are conducted using the proposed datasets and criteria with several state-of-the-art Visual SLAM methods to demonstrate the functionality of our datasets.","Synthetic dataset, Computer graphic, Visual SLAM, Algorithm validation, Evaluation criteria",Senbo Wang and Jiguang Yue and Yanchao Dong and Shibo He and Haotian Wang and Shaochun Ning,https://www.sciencedirect.com/science/article/pii/S0921889019301009,https://doi.org/10.1016/j.robot.2019.103336,0921-8890,2020,103336,124,Robotics and Autonomous Systems,A synthetic dataset for Visual SLAM evaluation,article,WANG2020103336
"A traveling wave rectilinear gait for elongated, continuous bodies is modeled as a cyclically-varying backbone curve. The gait shapes are represented as planar deviations relative to an average body curve and an associated, rigidly-attached body frame. Body-ground contact patterns and other geometric properties integral to computation of external forcing are conveniently defined with respect to this average body curve. Introducing a body-ground rolling friction model permits the controlled equations of motion to be derived in closed form. Incorporating a constant curvature into the average body realizes turning movements, and hence turning control. Repeated numerical integration of the system dynamics facilitates construction of a control-to-action mapping, characterizing steady system behavior with respect to the gait?s parameter space. The control-to-action map reduces this complex dynamical system to a kinematic unicycle model for which feedback tracking strategies are well understood. To illustrate its utility, it is applied in a trajectory planning and tracking framework for locomotion around obstacles. Using the framework, a robotic snake exercising the traveling wave rectilinear gait successfully plans feasible trajectories and traverses non-trivial obstacle arrangements to reach specified goal positions.","Snake-like robot, Rectilinear, Dynamics, Trajectory planning, Control",Alexander H. Chang and Patricio A. Vela,https://www.sciencedirect.com/science/article/pii/S0921889019300831,https://doi.org/10.1016/j.robot.2019.103406,0921-8890,2020,103406,124,Robotics and Autonomous Systems,Shape-centric modeling for control of traveling wave rectilinear locomotion on snake-like robots,article,CHANG2020103406
"In this paper, we present an effective online planning solution for autonomous vehicles that aims at improving the computational load while preserving high levels of performance in racing scenarios. The method follows the structure of the model predictive (MP) optimal strategy where the main objective is to maximize the velocity while smoothing the dynamic behavior and fulfilling varying constraints. We focus on reformulating the non-linear original problem into a pseudo-linear problem by convexifying the objective function and reformulating the non-linear vehicle equations to be expressed in a Linear Parameter Varying (LPV) form. In addition, the ability of avoiding obstacles is introduced in a simple way and with reduced computational cost. We test and compare the performance of the proposed strategy against its non-linear approach through simulations. We focus on testing the performance of the trajectory planning approach in a racing scenario. First, the case of free obstacles track and afterwards a scenario including static obstacles. Simulation results show the effectiveness of the proposed strategy by reducing the algorithm elapsed time while finding appropriate trajectories under several input/state constraints.","Autonomous driving, Racing planning, MPC, LPV, Obstacle avoidance",Eugenio Alcalá and Vicenç Puig and Joseba Quevedo,https://www.sciencedirect.com/science/article/pii/S0921889019304877,https://doi.org/10.1016/j.robot.2019.103392,0921-8890,2020,103392,124,Robotics and Autonomous Systems,LPV-MP planning for autonomous racing vehicles considering obstacles,article,ALCALA2020103392
"Active compliant control enables to quickly and freely adjust the properties and dynamic behavior of interactions of mechanisms within certain limits. According to the emerging applications in many robotic fields and related areas, the number of publications has also strongly increased. This paper meets the need for a recent comprehensive review, including a profound and concise characterization and classification of compliant control approaches extending the basic concepts, hybrid and parallel force/position, impedance and admittance control, by a survey of their variants and combinations. It mainly focuses on individually operating, stiff, non-redundant systems. Unlike previous reviews, this work is based on a transparent and systematic literature search methodology, which can easily be adapted or updated by any reader, hence remaining enduringly up-to-date over time. Also, a novel selection scheme is proposed, which facilitates the choice of appropriate control approaches for given requirements, particularly for newcoming researchers to the field.","Compliant control, Impedance control, Admittance control, Hybrid force/position control, Parallel force/position control, Force control",Marie Schumacher and Janis Wojtusch and Philipp Beckerle and Oskar {von Stryk},https://www.sciencedirect.com/science/article/pii/S0921889018307772,https://doi.org/10.1016/j.robot.2019.06.009,0921-8890,2019,185--200,119,Robotics and Autonomous Systems,An introductory review of active compliant control,article,SCHUMACHER2019185
"This paper presents a kind of complex virtual fixture (VF) to help space robots perform on-orbit operations in complex environments while ensuring operations safety. The main purpose of the VF is to provide virtual force feedback to adjust the manners of the operator throughout the remote operation process. The complex VF is comprised of a tube-type VF and a velocity-based VF. The tube-type VF ensures that the end effector approaches the target safely and at high speeds over long distances, and the velocity-based VF enables the end of the robot to observe the target within a safe and short distance near the target. Combined with dynamic prediction and path planning, the complex VF can improve the flexibility and efficiency of the operation, and avoid collisions in dynamic environments. The proposed methods are verified by several typical space manipulation tasks, the virtual experiment environment of which is built in CHAI3D. The comparative results indicate that the complex VF can reduce operation time and improve efficiency and accuracy.","Space teleoperation, Virtual tube, Velocity-based VF, Compound VFs, Haptic feedback",Zhengxiong Liu and Zhenyu Lu and Yang Yang and Panfeng Huang,https://www.sciencedirect.com/science/article/pii/S0921889018307930,https://doi.org/10.1016/j.robot.2019.103268,0921-8890,2019,103268,121,Robotics and Autonomous Systems,Teleoperation for space manipulator based on complex virtual fixtures,article,LIU2019103268
"This paper presents a literature survey and a comparative study of Bug Algorithms, with the goal of investigating their potential for robotic navigation. At first sight, these methods seem to provide an efficient navigation paradigm, ideal for implementations on tiny robots with limited resources. Closer inspection, however, shows that many of these Bug Algorithms assume perfect global position estimate of the robot which in GPS-denied environments implies considerable expenses of computation and memory ? relying on accurate Simultaneous Localization And Mapping (SLAM) or Visual Odometry (VO) methods. We compare a selection of Bug Algorithms in a simulated robot and environment where they endure different types noise and failure-cases of their on-board sensors. From the simulation results, we conclude that the implemented Bug Algorithms? performances are sensitive to many types of sensor-noise, which was most noticeable for odometry-drift. This raises the question if Bug Algorithms are suitable for real-world, on-board, robotic navigation as is. Variations that use multiple sensors to keep track of their progress towards the goal, were more adept in completing their task in the presence of sensor-failures. This shows that Bug Algorithms must spread their risk, by relying on the readings of multiple sensors, to be suitable for real-world deployment.","Bug algorithms, Robotic navigation, Comparative study, Limited sensing, Indoor navigation",K.N. McGuire and G.C.H.E. {de Croon} and K. Tuyls,https://www.sciencedirect.com/science/article/pii/S0921889018306687,https://doi.org/10.1016/j.robot.2019.103261,0921-8890,2019,103261,121,Robotics and Autonomous Systems,A comparative study of bug algorithms for robot navigation,article,MCGUIRE2019103261
"This paper presents the design of DCBot, a hot-line working robot that can replace workers to assemble and disassemble the connect fittings of the disconnecting circuit breaker (DCB) in 110 kV substations without needing to be powered off. Robotic assembly in electrical substations requires a robot system with high flexibility and the capability to deal with uncertainties. A robust mobile manipulation system is a new and promising technology that could overcome these challenges. The highlights of our work include (1) a reference for designing hot-line working robots, which can not only guarantee the electrical safety clearance but also minimize the robots? influence on the electric field; (2) an electromagnetic shielding method applicable to the electrical components on the equipotential operation platform; (3) a method for precise outdoor visual positioning for objects with worn surfaces in outdoor environments; (4) a control strategy for hole-searching on complex contact surfaces during the assembly of connect fittings; and (5) a method of planning the safe working space of the hot-line working robot. The experiments and the field tests carried out in 110 kV energized substation environments show that the electrical safety of the substation was guaranteed during the whole process of operation. The success rate of 3 times assembly and 3 times disassembly is 100%.","Hot-line working robotics, Extreme environments, Machine vision, Manipulator",Mingdong Tang and Youlin Gu and Shigang Wang and Qinghua Liang,https://www.sciencedirect.com/science/article/pii/S0921889018308340,https://doi.org/10.1016/j.robot.2019.07.008,0921-8890,2019,247--262,119,Robotics and Autonomous Systems,DCBot: An autonomous hot-line working robot for 110 kV substation,article,TANG2019247
"A new vision in human?robot collaboration has allowed to place robots nearby human operators, working close to each other in industrial environments. As a consequence, human safety has become a dominant issue, together with production efficiency. In this paper we propose an optimization-based control algorithm that allows robots to avoid obstacles (like human operators) while minimizing the difference between the nominal acceleration input and the commanded one. Control Barrier Functions are exploited to build safety barriers around each robot link, to guarantee collision-free trajectories along the whole robot body. Human accelerations and velocities are computed by means of a bank of Kalman filters. To solve obstruction problems, two RGB-D cameras are used and the measured skeleton data are processed and merged using the mentioned bank of Kalman filters. The algorithm is implemented on an Universal Robots UR5 in order to validate the proposed approach.","Human?robot interaction, Collision avoidance, Control barrier function",Federica Ferraguti and Chiara {Talignani Landi} and Silvia Costi and Marcello Bonfè and Saverio Farsoni and Cristian Secchi and Cesare Fantuzzi,https://www.sciencedirect.com/science/article/pii/S0921889019306426,https://doi.org/10.1016/j.robot.2019.103388,0921-8890,2020,103388,124,Robotics and Autonomous Systems,Safety barrier functions and multi-camera tracking for human?robot shared environment,article,FERRAGUTI2020103388
"In this work we present an interactive system capable of producing realistic artworks with acrylic paint based on a cartesian robot. This system focuses on painting artworks by regions, and can be applied for example in the painting of objects such as fruits, flowers, leaves and other individual objects. We have divided the development of the proposed system in three interactive stages: (1) interactive segmentation of work regions, (2) interactive designing of the field for orienting the brush strokes by tracing curves manually in each region and interpolating the curves to generate the vector field, and (3) painting by regions with the field. With our system it is possible to reproduce interactively an image producing pleasant results. The experimental results are presented by painting an apple with three main regions, for this we have utilized a realistic pictorial style and a monochromatic palette of 5 colors.","Bézier curve, Robotic artwork, Scattered interpolation, Interactive painting",Otoniel Igno-Rosario and Claudia Hernandez-Aguilar and Alfredo Cruz-Orea and Arturo Dominguez-Pacheco,https://www.sciencedirect.com/science/article/pii/S0921889019304907,https://doi.org/10.1016/j.robot.2019.103263,0921-8890,2019,103263,121,Robotics and Autonomous Systems,Interactive system for painting artworks by regions using a robot,article,IGNOROSARIO2019103263
"The progress in the development of anthropomorphic hands for robotic and prosthetic applications has not been followed by a parallel development of objective methods to evaluate their performance. The need for benchmarking in grasping research has been recognized by the robotics community as an important topic. In this study we present the Anthropomorphic Hand Assessment Protocol (AHAP) to address this need by providing a measure for quantifying the grasping ability of artificial hands and comparing hand designs. To this end, the AHAP uses 25 objects from the publicly available Yale-CMU-Berkeley Object and Model Set thereby enabling replicability. It is composed of 26 postures/tasks involving grasping with the eight most relevant human grasp types and two non-grasping postures. The AHAP allows to quantify the anthropomorphism and functionality of artificial hands through a numerical Grasping Ability Score (GAS). The AHAP was tested with different hands, the first version of the hand of the humanoid robot ARMAR-6 with three different configurations resulting from attachment of pads to fingertips and palm as well as the two versions of the KIT Prosthetic Hand. The benchmark was used to demonstrate the improvements of these hands in aspects like the grasping surface, the grasp force and the finger kinematics. The reliability, consistency and responsiveness of the benchmark have been statistically analyzed, indicating that the AHAP is a powerful tool for evaluating and comparing different artificial hand designs.","Assessment, Benchmark, Grasping, Prosthetic hand, Robotic hand, Test protocol",Immaculada Llop-Harillo and Antonio Pérez-González and Julia Starke and Tamim Asfour,https://www.sciencedirect.com/science/article/pii/S0921889019300946,https://doi.org/10.1016/j.robot.2019.103259,0921-8890,2019,103259,121,Robotics and Autonomous Systems,The Anthropomorphic Hand Assessment Protocol (AHAP),article,LLOPHARILLO2019103259
"Wrist rehabilitation robots are essential for assisting patients with stoke or wrist injuries. Such devices compensate for deficiencies in manual rehabilitation training, and reduce the workload of rehabilitation physicians. A parallel wrist rehabilitation robot (PWRR) driven by two pneumatic actuators is developed in this paper, consisting of two rotational degrees of freedom for the movements of flexion/extension (F/E) and radial/ulnar deviation (R/U). All components connected to the forearm or the wrist adopt an open structure to improve the wearable convenience, and the PWRR is suitable for most patients, especially those with hypertonia. To determine the PWRR range of motion, the physiological motion space (PMS) of the wrist joint in autonomous and boundary elliptical movements is measured with the help of a VICON motion capture system. The PMS in boundary motions processes an elliptical shape, and the ulnar deviations occupy the most range of motion. The theoretical workspace (TWS) of PWRR is then calculated and designed based on the kinematic model and the distribution characteristics of PMS. In addition, two indices are introduced to evaluate the kinematic performance of PWRR. A PWRR prototype is developed based on the optimal geometrical parameters and detailed structures. Its effective workspace (EWS), which has more clinical significance, is acquired by measuring the F/E and R/U movements during autonomic movements. The EWS, is smaller than TWS due to the physical structure, volume, and interference of mechanical elements. Besides, EWS can nearly encircle PMS, and satisfies all single-axis rehabilitations and compound motions of the wrist complex. The two indices, motion isotropy da and condition number ?, within TWS change smoothly with no mutation, suggesting that PWRR is sufficiently kinematically isotropic, and has no singularity configuration. The analysis shows that the developed PWRR can be applied widely in the wrist rehabilitation.","Wrist rehabilitation, Parallel mechanism, Velocity Jacobian matrices, Workspace analysis, Wearable convenience",Leiyu Zhang and Jianfeng Li and Ying Cui and Mingjie Dong and Bin Fang and Pengfei Zhang,https://www.sciencedirect.com/science/article/pii/S0921889019300843,https://doi.org/10.1016/j.robot.2019.103390,0921-8890,2020,103390,125,Robotics and Autonomous Systems,Design and performance analysis of a parallel wrist rehabilitation robot (PWRR),article,ZHANG2020103390
"The vehicles used for transportation and logistics in the factories usually perceive their surroundings with range sensors. Today, 2D LIDARs are used as range sensors, and 3D LIDARs are becoming widespread with the developments of autonomous vehicle technology. Therefore, Self Adaptive Monte Carlo Localization, abbreviated as SA-MCL, is improved in this study to make the algorithm suitable for autonomous guided vehicles (AGVs) equipped with 2D or 3D LIDARs. Moreover, the traditional SA-MCL algorithm has a constraint that the range sensors on the robot are uniformly placed, and ellipse based energy model is proposed in this study to remove the constraint. This model can compute the energy value regardless of the robot orientation since it considers offsets due to the asymmetric placement of range sensors on the robot. The importance of localization increases since it is aimed that AGVs to be used in smart factories are able to use entire free space on the map in order to provide energy efficiency and time saving, and perform tasks that can vary at anytime instead of routine. SA-MCL algorithm is preferred in this study since traditional SA-MCL can overcome global localization, position tracking and kidnapping sub-problems of localization. The algorithm proposed in this study is verified to demonstrate its performance and effectiveness both in simulation and experimental studies using MATLAB and robot operating system (ROS).","AGV, SA-MCL, 2D and 3D LIDARs, Localization",Abdurrahman Yilmaz and Hakan Temeltas,https://www.sciencedirect.com/science/article/pii/S0921889019302106,https://doi.org/10.1016/j.robot.2019.103285,0921-8890,2019,103285,122,Robotics and Autonomous Systems,Self-adaptive Monte Carlo method for indoor localization of smart AGVs using LIDAR data,article,YILMAZ2019103285
"The TERMES system is a robot collective capable of autonomous construction of 3D user-specified structures. A key component of the framework is an off-line compiler which takes in a structure blueprint and generates a directed map, in turn permitting an arbitrary number of robots to perform decentralized construction in a provably correct manner. In past work, this compiler was limited to a non-optimized search approach which scaled poorly with the structure size. Here, we first recast the process as a constraint satisfaction problem (CSP) to apply well-known optimizations for solving CSP and present new scalable compiler schemes and the ability to quickly generate provably correct maps (or find that none exist) of structures with up to 1 million bricks. We compare the performance of the compilers on a range of structures, and show how the completion time is related to the inter-dependencies between built locations. Second, we show how the transition probability between locations in the structure affect assembly time. While the exact solution for the expected completion time is difficult to compute, we evaluate different objective functions for the transition probabilities and show that these optimizations can drastically improve overall efficiency. This work represents an important step towards collective robotic construction of real-world structures.","Multi-robot systems, Assembly, Construction, Autonomy, Compiler",Yawen Deng and Yiwen Hua and Nils Napp and Kirstin Petersen,https://www.sciencedirect.com/science/article/pii/S0921889019301897,https://doi.org/10.1016/j.robot.2019.07.010,0921-8890,2019,103240,121,Robotics and Autonomous Systems,A Compiler for Scalable Construction by the TERMES Robot Collective,article,DENG2019103240
"We present a construction model that allows robots with different construction capabilities, using materials of different physical properties and sizes, to modify unstructured environments in a distributed system. Building steps are computed reactively so that they can respond to changes in the environment and imperfect assembly. The reactive approach allows robots to coordinate and add material to the same structure. Each robotic agent uses an abstract model of the environment to compute a set of legal construction steps based on its current knowledge of the world, and we show that in this setting more knowledge results in more legal moves. We exploit this capability by letting the system use a variety of materials and choose the most appropriate material given its current knowledge of the state of the structure. We demonstrate the approach by running the system on a variety of terrains and with mixed materials, including both deformable and rigid components.","Autonomous construction, Collective robotic construction, Multi-material, Partial functions, Local sensing",Maira Saboia and Vivek Thangavelu and Nils Napp,https://www.sciencedirect.com/science/article/pii/S0921889019302064,https://doi.org/10.1016/j.robot.2019.07.009,0921-8890,2019,103239,121,Robotics and Autonomous Systems,Autonomous multi-material construction with a heterogeneous robot team,article,SABOIA2019103239
"Achieving precise parameters of multi-joints actuators for Hip?Knee Exoskeleton (HKE) is a crucial process due to its non-linear characteristics. In this paper, a Genetic Algorithm (GA) based optimization is used for parameter estimation of the mathematical model for a four-Degree of Freedom (DoF) multi-joint HKE, which is a type of Lower Limb Exoskeleton (LLE). Mathematical model for electro-mechanical, mechanical, and electrical components of the HKE has been formulated, and its parameters are estimated using GA and experimental method. An objective function is determined based on the difference between the simulated and actual angular trajectory for each joint. The performance of the mathematical model is examined with different voltages under the range of 4 V to 8 V for hip and knee, respectively. Furthermore, the performance of the estimated model is compared with Particle Swarm Optimization (PSO). The results and numerical analysis demonstrated that the estimated model by GA and PSO with varying voltages predicted the actual angular trajectory with acceptable error, while GA provides the more accurate model. It can be ascertained that the proposed method of estimation for mathematical model of the HKE is applicable to identify its parameters, and useful for designing a control system.","Parameter estimation, Lower Limb Exoskeleton, Optimization, Genetic algorithm",Mohammad Soleimani Amiri and Rizauddin Ramli and Mohd Faisal Ibrahim,https://www.sciencedirect.com/science/article/pii/S0921889019307584,https://doi.org/10.1016/j.robot.2020.103425,0921-8890,2020,103425,125,Robotics and Autonomous Systems,Genetically optimized parameter estimation of mathematical model for multi-joints hip?knee exoskeleton,article,AMIRI2020103425
"The focus of this study is to design individual control laws that segregate multiple groups of mobile heterogeneous robots. Our approach is based on the use of abstractions to represent each group of robots and an artificial potential function to segregate the groups. Different from other works in the literature, we prove that with our controller the system will always converge to a state where robots of the same group will be together while separated from robots of different groups. We also propose a collision avoidance scheme which does not interfere in the segregation controller. Furthermore, our controller has a local property, meaning that the controller might not require global information of the whole swarm to converge to the segregated state. The approach is validated with simulations varying the number of robots and groups and experiments with real robots.","Robot swarms, Heterogeneous swarms, Segregation behavior, Abstractions",Edson B. Ferreira-Filho and Luciano C.A. Pimenta,https://www.sciencedirect.com/science/article/pii/S0921889018310042,https://doi.org/10.1016/j.robot.2019.103295,0921-8890,2019,103295,122,Robotics and Autonomous Systems,Abstraction based approach for segregation in heterogeneous robotic swarms,article,FERREIRAFILHO2019103295
"Internet of Things (IoT) has recently become the key for innovation and progress in many industrial sectors and scientific areas. However, it brings many challenges and issues, such as growing number of connected devices, heterogeneity, amount of generated data, security and privacy issues, interoperability and many others. Since devices not only collect data, but also take actions that affect the environment, device coordination in the context of IoT systems is becoming more and more important, especially if the IoT convergence with robotics, known as ?Internet of Robotic Things? (RIoT), is taken into consideration. In novel cyber?physical systems coordination is very important for situations when many devices working parallel have higher potential to achieve the given task more effectively, than a single device operating independently. RIoT experimentation testbeds facilitate development of such cyber?physical systems where devices need to be aware of the environment while interacting with other devices in order to achieve a common goal. In this paper, we propose a semantic-driven framework for automated autonomous robots coordination in the context of RIoT-based experimentation testbeds. Framework for automatic coordinated mission generation within the robotics experimentation platform testbed is evaluated. Results of evaluation are presented and discussed.","Coordination, Autonomous robots, Internet of Things, Ontology, Robot sensing systems, Semantic technology, Testbeds",Valentina Nejkovic and Nenad Petrovic and Milorad Tosic and Nenad Milosevic,https://www.sciencedirect.com/science/article/pii/S0921889019306414,https://doi.org/10.1016/j.robot.2020.103438,0921-8890,2020,103438,126,Robotics and Autonomous Systems,Semantic approach to RIoT autonomous robots mission coordination,article,NEJKOVIC2020103438
"We present a method for a collaborative team of pursuing robots to contain and capture a single evading robot. We address the practical case in which the pursuers do not know the exact location of the evader but rather must localize the evader with noisy on-board sensors. Under our policy, the pursuers move to maximally reduce the area of space reachable by the evader despite the uncertainty in the evader?s position estimate. Our pursuit policy is distributed in the sense that each pursuer only needs to broadcast its position and estimate to its closest neighbors. The policy guarantees that the evader?s reachable area is non-increasing between measurement updates regardless of the evader?s policy. Furthermore, we show in simulations and hardware that the pursuers capture the evader in spite of the position uncertainty provided that the pursuer?s measurement noise decreases with the distance to the evader.","Multi-agent pursuit-evasion, Reachability methods, Game theoretic control",Kunal Shah and Mac Schwager,https://www.sciencedirect.com/science/article/pii/S0921889019301927,https://doi.org/10.1016/j.robot.2019.07.016,0921-8890,2019,103246,121,Robotics and Autonomous Systems,GRAPE: Geometric Risk-Aware Pursuit-Evasion,article,SHAH2019103246
"Motion mapping is an important part in human?robot cooperation. In this paper, a novel concept of virtual-joint based similarity criteria is proposed for flexible and efficient kinematics mapping between dissimilar embodiments, including different degrees of freedom (DOFs), different body morphology, and so on. Virtual joints are defined respectively in both the demonstrator and the imitator, with the same number. In virtual joints, the neglecting, re-ordering and repetitive usage of DOFs could be realized through the virtual decomposing matrices. Each virtual joint of the demonstrator and the corresponding one of the imitator formed a virtual joint pair. The Total Metric of Motion Similarity is the weighted sum of the metrics defined for each virtual joint pairs. Unlike traditional joint-space or Cartesian-space based metrics describing motion similarity solely at the DOF kinematic mode level, virtual-joint-based metrics can be adopted to describe different aspects of motion similarity between dissimilar agents, both in joint space and in Cartesian space. Two experiments are conducted to illustrate the effectiveness of the proposed approach.","Robotic imitation, Kinematics mapping, Motion similarity, Dissimilar embodiments, Human?robot cooperation",Zhang Chen and Ziwei Wang and Rongjian Liang and Bin Liang and Tao Zhang,https://www.sciencedirect.com/science/article/pii/S0921889019305329,https://doi.org/10.1016/j.robot.2019.103412,0921-8890,2020,103412,125,Robotics and Autonomous Systems,Virtual-joint based motion similarity criteria for human?robot kinematics mapping,article,CHEN2020103412
"Inertial parameters characterise an object?s motion under applied forces, and can provide strong priors for planning and control of robotic actions to manipulate the object. However, these parameters are not available a-priori in situations where a robot encounters new objects. In this paper, we describe and categorise the ways that a robot can identify an object?s inertial parameters. We also discuss grasping and manipulation methods in which knowledge of inertial parameters is exploited in various ways. We begin with a discussion of literature which investigates how humans estimate the inertial parameters of objects, to provide background and motivation for this area of robotics research. We frame our discussion of the robotics literature in terms of three categories of estimation methods, according to the amount of interaction with the object: purely visual, exploratory, and fixed-object. Each category is analysed and discussed. To demonstrate the usefulness of inertial estimation research, we describe a number of grasping and manipulation applications that make use of the inertial parameters of objects. The aim of the paper is to thoroughly review and categorise existing work in an important, but under-explored, area of robotics research, present its background and applications, and suggest future directions. Note that this paper does not examine methods of identification of the robot?s inertial parameters, but rather the identification of inertial parameters of other objects which the robot is tasked with manipulating.","Robot identification, Inertial parameters, Object dynamics, Robot grasping and manipulation",Nikos Mavrakis and Rustam Stolkin,https://www.sciencedirect.com/science/article/pii/S0921889019302313,https://doi.org/10.1016/j.robot.2019.103374,0921-8890,2020,103374,124,Robotics and Autonomous Systems,Estimation and exploitation of objects ? inertial parameters in robotic grasping and manipulation: A survey,article,MAVRAKIS2020103374
"Quadrotors are increasingly expected to perform a wide variety of tasks that put them in close proximity to other objects and surfaces in the environment (including other quadrotors), where they are often subject to significant external forces and torques resulting from aerodynamic effects. We present an algorithm ? based on an Unscented Kalman Filter ? that estimates such forces and torques without making assumptions about their source, allowing us to bypass much of the complexity involved in modeling how wind currents interact with quadrotor dynamics. Furthermore, our algorithm does not rely on special sensors, making it suitable for commercial systems where payload and add-on capabilities are limited. Via experiment we show that the estimation algorithm can be used in conjunction with controls and machine learning for detecting and avoiding downwash and walls, and for tracking wind from a fan. We also show that the algorithm is sensitive enough to measure even small changes in force and torque.","Force estimation, Machine learning, Quadrotors",Christopher D. McKinnon and Angela P. Schoellig,https://www.sciencedirect.com/science/article/pii/S0921889018307917,https://doi.org/10.1016/j.robot.2019.103314,0921-8890,2020,103314,123,Robotics and Autonomous Systems,Estimating and reacting to forces and torques resulting from common aerodynamic disturbances acting on quadrotors,article,MCKINNON2020103314
"Most of the existing studies investigate the robot selection problem (RSP) in a multiple criteria decision making (MCDM) manner, from the viewpoint of a single person. This contradicts the reality that the robot selection decision is usually made by a committee or a group of experts with different expertise and concerns. For this reason, this paper proposes a group decision making (GDM) methodology for handling multiple criteria robot selection problem (MCRSP), the working process of which is (i) identifying experts, (ii) implementing the standard MCDM process and (iii) achieving a group consensus. Four objective weight determination methods, namely, Shannon entropy, CRITIC, ideal point and distance-based, are proposed to represent four experts. Experts play the role of think tank in supporting the decision maker who is responsible for MCRSP. In light of that the preference among different experts is uncertain, stochastic multicriteria acceptability analysis is then applied to achieve a holistic evaluation results for identifying good compromise choices. Two illustrative examples are presented to demonstrate the effectiveness and validity of our methodology, and compare the results with those obtained through VIKOR and ELECTRE II.","Robot selection, Multiple criteria decision making, Stochastic multicriteria acceptability analysis, Group consensus",Yelin Fu and Ming Li and Hao Luo and George Q. Huang,https://www.sciencedirect.com/science/article/pii/S0921889018309898,https://doi.org/10.1016/j.robot.2019.103304,0921-8890,2019,103304,122,Robotics and Autonomous Systems,Industrial robot selection using stochastic multicriteria acceptability analysis for group decision making,article,FU2019103304
"Among the different functional movements can be carried out by humanoid biped robots, stair climbing is considered an important functional activity. Although many papers have been published on the planning and executing walking gaits for humanoid robots, most of them were concerned with walking on level ground. This is because the fundamental mechanisms that are needed to fulfill these requirements are still scarcely understood. Thus, in this research, we focused on another perspective of this problem and are inspired by the human control system. The proposed hypotheses were to develop an innovative bio-inspired model based on human dynamic during stair ascent. The model has been established as a reference trajectory model representing the desired coordination pattern between the ankle, knee and hip joints during human stair ascending. An intermittent controller devised such that it keeps the system?s dynamic in a close neighborhood of the desired dynamic and become on/off based on the distance between the model output and the reference trajectory of each joint. The evaluation was carried out through some computer simulation studies on a five-link biped robot. Results show that the reference model follows the desired synergy pattern of lower extremities joints and coordinates joints such that the postural stability is achieved. It has been also proved that the proposed intermittent controller successfully maintains the balance of the robot during movement and can simulate the human ascending stair behavior steadily. It also supports the biped in DSP, SSP and impact phases very well.","Stair ascent, Intermittent control system, Motion stability, Poincare theory",Maryam Vatankhah and Hamid R. Kobravi and Arthur Ritter,https://www.sciencedirect.com/science/article/pii/S0921889018308601,https://doi.org/10.1016/j.robot.2019.103255,0921-8890,2019,103255,121,Robotics and Autonomous Systems,Intermittent control model for ascending stair biped robot using a stable limit cycle model,article,VATANKHAH2019103255
"This paper proposes a new propulsion mechanism for a passive-wheeled robot. By applying the propulsion principle of a two-wheeled skateboard, or ?snakeboard,? a mobile robot with a rotor is constructed. Although the robot moves based on the counter force of the rotor rotation, the timely alternation of the orientations of the front and rear wheels is required. The mechanism proposed herein drives the rotor and the wheel orientations simultaneously using a single motor. Simulation analyses based on a dynamical model confirmed the desired temporal relation in motion between the rotor and wheel orientation, and evaluated the effect of some mechanical parameters to the traveling distance of the robot. Some experiments conducted using the robot demonstrated not only straight-line propulsion, as expected, but also controlled curved motion. Finally, by providing feedback of the positional information, the robot was able to autonomously arrive at a goal position by driving itself with its single motor.","Wheeled mobile robot, Mechanism design, Single motor actuation, Autonomous propulsion, Motion control",Satoshi Ito and Kosuke Niwa and Shoya Sugiura and Ryosuke Morita,https://www.sciencedirect.com/science/article/pii/S0921889019300090,https://doi.org/10.1016/j.robot.2019.103310,0921-8890,2019,103310,122,Robotics and Autonomous Systems,An autonomous mobile robot with passive wheels propelled by a single motor,article,ITO2019103310
"The ability to avoid collisions with each other is one of the fundamental requirements for autonomous unmanned aerial vehicles (UAVs) to be safely integrated into the civilian airspace, and for the viability of multi-UAV operations. This paper introduces a new approach for online cooperative collision avoidance between quadcopters, involving reciprocal maneuvers, i.e., coherent maneuvers without requiring any real-time consensus. Two maneuver strategies are presented, where UAVs respectively change their speed or heading to avoid a collision. A learning-based framework that trains these reciprocal actions for collision evasion (called TRACE) is developed. The primary elements of this framework include: 1) designing simulated experiments that cover a variety of UAV?UAV approach scenarios; 2) performing optimization to identify speed/heading change actions that satisfy safety constraints while minimizing the energy cost of the maneuver; and 3) using the offline optimization outcomes to train classifier (via ensemble bagged tree) and function approximation (via neural networks and Kriging) models for respectively selecting and encoding the avoidance actions. Trajectory generation and dynamics/controls are incorporated in the simulation environment used for training and testing. Over 90% accuracy in action prediction and over 95% success in avoiding collisions is observed when the trained models are applied to simulated unseen test scenarios.","Bio-inspired, Collision avoidance, Learning, Optimization, Unmanned Aerial Vehicle (UAV)",Amir Behjat and Steve Paul and Souma Chowdhury,https://www.sciencedirect.com/science/article/pii/S0921889019301617,https://doi.org/10.1016/j.robot.2019.103270,0921-8890,2019,103270,121,Robotics and Autonomous Systems,Learning reciprocal actions for cooperative collision avoidance in quadrotor unmanned aerial vehicles,article,BEHJAT2019103270
"Human?robot collision avoidance is a key in collaborative robotics and in the framework of Industry 4.0. It plays an important role for achieving safety criteria while having humans and machines working side-by-side in unstructured and time-varying environment. This study introduces the subject of manipulator?s on-line collision avoidance into a real industrial application implementing typical sensors and a commonly used collaborative industrial manipulator, KUKA iiwa. In the proposed methodology, the human co-worker and the robot are represented by geometric primitives (capsules). The minimum distance and relative velocity between them is calculated, when human/obstacles are nearby the concept of hypothetical repulsion and attraction vectors is used. By coupling this concept with a mathematical representation of robot?s kinematics, a task level control with collision avoidance capability is achieved. Consequently, the off-line generated nominal path of the industrial task is modified on-the-fly so the robot is able to avoid collision with the co-worker safely while being able to fulfill the industrial operation. To guarantee motion continuity when switching between different tasks, the notion of repulsion-vector-reshaping is introduced. Tests on an assembly robotic cell in automotive industry show that the robot moves smoothly and avoids collisions successfully by adjusting the off-line generated nominal paths.","Collision avoidance, Collaborative robotics, Industry, Assembly",Mohammad Safeea and Pedro Neto and Richard Bearee,https://www.sciencedirect.com/science/article/pii/S0921889019300648,https://doi.org/10.1016/j.robot.2019.07.013,0921-8890,2019,278--288,119,Robotics and Autonomous Systems,On-line collision avoidance for collaborative robot manipulators by adjusting off-line generated paths: An industrial use case,article,SAFEEA2019278
"Due to the nonholonomic constraints, it is challenging to asymptotically stabilize a differential-drive robot at an arbitrary pose with desirable transient response. In this paper, an advanced parking system is introduced to tackle the problem of nonholonomic stabilization from an arbitrary starting position. The overall parking process is composed of two stages: a reference tracking stage and an asymptotically stabilization one. In the tracking stage, a reference trajectory is carefully generated by taking the robot kinematic constraints into consideration. An existing reference tracking controller is adopted to drive the robot to follow the prescribed route. In the second stage, a parking controller is switched on and is able to asymptotically stabilize the robot by taking advantage of straight and smooth motions in a ?singularity line?. The overall performance of the parking system has been validated through simulation and real experiments.","Asymptotic parking, Nonholonomic systems, Singularity line, Parking controller, Tracking controller",Zhengguo Li and Wenchao Gao and Jiawei Ong,https://www.sciencedirect.com/science/article/pii/S0921889019304749,https://doi.org/10.1016/j.robot.2019.103365,0921-8890,2020,103365,124,Robotics and Autonomous Systems,A dual-stage parking system for differential-drive robots,article,LI2020103365
"Domestic chores, such as laundry tasks, are dull and repetitive. These tasks consume a significant amount of daily time, and are however unavoidable. Additionally, a great portion of elder and disabled people require help to perform them due to lack of mobility. In this work we present advances towards a Robot Household Companion (RHC), focusing on the performance of two particular laundry tasks: unfolding and ironing garments. Unfolding is required to recognize the garment prior to any later folding operation. For unfolding, we apply an interactive algorithm based on the analysis of a colored 3D reconstruction of the garment. Regions are clustered based on height, and a bumpiness value is computed to determine the most suitable pick and place points to unfold the overlapping region. For ironing, a custom Wrinkleness Local Descriptor (WiLD) descriptor is applied to a 3D reconstruction to find the most significant wrinkles in the garment. These wrinkles are then ironed using an iterative path-following control algorithm that regulates the amount of pressure exerted on the garment. Both algorithms focus on the feasibility of a physical implementation in real unmodified environments. A set of experiments to validate the algorithms have been performed using a full-sized humanoid robot.","Robotics, Computer vision, Ironing, Garments, Deformable objects, Force/torque control",David Estevez and Juan G. Victores and Raul Fernandez-Fernandez and Carlos Balaguer,https://www.sciencedirect.com/science/article/pii/S0921889017307479,https://doi.org/10.1016/j.robot.2019.103330,0921-8890,2020,103330,123,Robotics and Autonomous Systems,Enabling garment-agnostic laundry tasks for a Robot Household Companion,article,ESTEVEZ2020103330
"This paper examines the important problem of cooperative localization in robot swarms, in the presence of unmodeled errors experienced by real sensors in hardware platforms. Many existing methods for cooperative swarm localization rely on approximate distance metric heuristics based on properties of the communication graph. We present a new cooperative localization method that is based on a rigorous and scalable treatment of estimation errors generated by peer-to-peer sharing of relative robot pose information. Our approach blends Covariance Intersection and Covariance Union techniques from distributed sensor fusion theory in a novel way, in order to maintain statistical estimation consistency for cooperative localization errors. Experimental validation results show that this approach provides both reliable and accurate state estimation results for Droplet swarms in scenarios where other existing swarm localization methods cannot.","Swarm robots, Cooperative localization, State estimation, Sensor fusion",John Klingner and Nisar Ahmed and Nikolaus Correll,https://www.sciencedirect.com/science/article/pii/S092188901930243X,https://doi.org/10.1016/j.robot.2019.103306,0921-8890,2019,103306,122,Robotics and Autonomous Systems,Fault-tolerant Covariance Intersection for localizing robot swarms,article,KLINGNER2019103306
"It is significant to know the information of the contact force for the control of the flying?perching quadrotor when it is switching from flying state to perching state. The triaxial force sensor is not only difficult to install but also increases the weight and cost of the flying?perching quadrotor. To overcome these limits, this paper presents a force observer to estimate the contact force. We first build a detailed model of the flying?perching quadrotor in free space and when it gets into contact with the perching surface. The model is modified by considering the proximity effect. According to the model, a force observer was proposed. To demonstrate the performance of the proposed observer, simulations are carried out in ideal environment and with consideration of sensor noises. Moreover, we built an experimental platform and carried out experiments to verify the effectiveness of the designed observer in practical situations.","Flying-perching quadrotor, Force observer",Chengwei Huang and Yong Liu and Xi Ye,https://www.sciencedirect.com/science/article/pii/S0921889018308716,https://doi.org/10.1016/j.robot.2019.07.007,0921-8890,2019,103237,120,Robotics and Autonomous Systems,"Design, simulation and experimental study of a force observer for a flying?perching quadrotor",article,HUANG2019103237
"A learning framework is proposed to solve the inverse kinematic problems of a highly redundant mobile manipulator designed to traverse on rough terrains. The problem is not trivial to solve and there does not exist a closed form solution. The learning framework is designed based on the Kohonen Self Organizing Map (KSOM) to establish the mapping between the task-space and joint-space while resolving redundancy exist in the system. The standard KSOM learning architecture is modified to ensure proper coordination between the mobile base and arm satisfying multiple constraints such as wheels of the mobile robot always remain in contact with the terrain and maximize the manipulability for the robot arm while solving inverse kinematics. The network is trained for 14 DoF mobile manipulator traverse on uneven terrain. This method can be extended to other types of robot, such as high degrees of the manipulator. To validate the proposed network architecture several simulations have been performed and experimented on a mobile manipulator considering robot traverse on different types of terrains. The results show the effectiveness of the proposed framework.","Kohonen self organizing map, Redundancy resolution, Mobile manipulators, Rough terrain, Manipulability",R. Raja and A. Dutta and B. Dasgupta,https://www.sciencedirect.com/science/article/pii/S0921889018306778,https://doi.org/10.1016/j.robot.2019.07.015,0921-8890,2019,103245,120,Robotics and Autonomous Systems,Learning framework for inverse kinematics of a highly redundant mobile manipulator,article,RAJA2019103245
"Network topology plays a critical role in enabling a multi-agent system to adapt to environment changes and achieve desired objectives. This paper presents distributed topology manipulation schemes for a group of mobile agents. The agents have limited heterogeneous communication ranges, and connections among them are directional. The topology is established from the overlapping communication ranges. The admissible space is partitioned into enclosed areas by connectivity among the agents based on their communication ranges. Each agent occupies an enclosed area, and its decision-making manipulates the topology by guiding itself to an adjacent enclosed area. Both independent and coordinated decision-making approaches are provided. A guidance algorithm is designed to drive the vehicles to a flexible formation, in which the robustness of the network topology is enhanced.","Network topology, Space partitioning, Decision-making, Limited ranges",Hongjun Yu and Cheng-Chew Lim and Robert Hunjet and Peng Shi,https://www.sciencedirect.com/science/article/pii/S0921889019301873,https://doi.org/10.1016/j.robot.2019.103328,0921-8890,2020,103328,124,Robotics and Autonomous Systems,Flocking and topology manipulation based on space partitioning,article,YU2020103328
"In this paper, a set-point regulation scheme for flexible joint robot (FJR) with link side energy (LSE) feedback is introduced. The drawbacks of traditional PD-type control laws are analyzed first. On this basis, a nonlinear regulator is designed by combining proxy based sliding mode control with LSE feedback, which is targeted at enhancement of vibration suppression. Asymptotic stability of the closed-loop system as well as boundedness of each signal are guaranteed with Lyapunov analysis. Furthermore, vibration suppression ability and robustness against external disturbances of the proposed method is validated on a self-built FJR platform.","Flexible joint robot, Position control, Energy feedback, Proxy-based sliding mode control",Lei Sun and Wen Zhao and Wei Yin and Ning Sun and Jingtai Liu,https://www.sciencedirect.com/science/article/pii/S0921889019301356,https://doi.org/10.1016/j.robot.2019.103272,0921-8890,2019,103272,121,Robotics and Autonomous Systems,Proxy based position control for flexible joint robot with link side energy feedback,article,SUN2019103272
"Nonprehensile rearrangement is the problem of controlling a robot to interact with objects through pushing actions in order to reconfigure the objects into a predefined goal pose. In this work, we rearrange one object at a time in an environment with obstacles using an end-to-end policy that maps raw pixels as visual input to control actions without any form of engineered feature extraction. To reduce the amount of training data that needs to be collected using a real robot, we propose a simulation-to-reality transfer approach. In the first step, we model the nonprehensile rearrangement task in simulation and use deep reinforcement learning to learn a suitable rearrangement policy, which requires in the order of hundreds of thousands of example actions for training. Thereafter, we collect a small dataset of only 70 episodes of real-world actions as supervised examples for adapting the learned rearrangement policy to real-world input data. In this process, we make use of newly proposed strategies for improving the reinforcement learning process, such as heuristic exploration and the curation of a balanced set of experiences. We evaluate our method in both simulation and real setting using a Baxter robot to show that the proposed approach can effectively improve the training process in simulation, as well as efficiently adapt the learned policy to the real world application, even when the camera pose is different from simulation. Additionally, we show that the learned system not only can provide adaptive behavior to handle unforeseen events during executions, such as distraction objects, sudden changes in positions of the objects, and obstacles, but also can deal with obstacle shapes that were not present in the training process.","Nonprehensile rearrangement, Deep reinforcement learning, Transfer learning",Weihao Yuan and Kaiyu Hang and Danica Kragic and Michael Y. Wang and Johannes A. Stork,https://www.sciencedirect.com/science/article/pii/S0921889018304913,https://doi.org/10.1016/j.robot.2019.06.007,0921-8890,2019,119--134,119,Robotics and Autonomous Systems,End-to-end nonprehensile rearrangement with deep reinforcement learning and simulation-to-reality transfer,article,YUAN2019119
"This paper focuses on the development of a crop edge detection algorithm based on the point cloud produced by a stereo camera system using the GPU for fast matching of the camera images. The approach utilizes the 3D characteristics of the transition between the crop and the stubbles or the ground. Therefore, the point cloud is sorted into a grid of cells to create an elevation map. A segmentation in crop and ground is obtained using the Expectation?Maximization algorithm with a Gaussian Mixture Model to represent the distribution of the cell?s heights. This segmentation is Bayesian filtered over a short time frame to create a more robust segmentation result. Afterward, the resulting potential crop edge locations are processed using robust linear regression to come up with an overall linear crop edge model. The implemented system has been tested in a series of experiments with detailed results stated at the end of this work.","Agricultural automation, Computer vision for automation, Visual-based navigation, Advanced driver-assistance systems (ADAS)",Johannes Kneip and Patrick Fleischmann and Karsten Berns,https://www.sciencedirect.com/science/article/pii/S0921889019303410,https://doi.org/10.1016/j.robot.2019.103323,0921-8890,2020,103323,123,Robotics and Autonomous Systems,Crop edge detection based on stereo vision,article,KNEIP2020103323
"We propose a methodology for enforcing a set of coordination rules onto a multi-robot system, based on the use of Petri nets to model the team of robots, safe linear temporal logic to specify a set of coordination rules to be enforced, and supervisory control theory to synthesise a supervisor that enforces the coordination rules. We introduce a composition algorithm that allows us to build a Petri net that represents the largest restriction of the team behaviour that still satisfies the specification. Such a Petri net can be interpreted as a candidate for a supervisor, for which one needs to verify admissibility. We present a general verification procedure for this problem. We also present a syntactic restriction to safe linear temporal logic that guarantees admissibility of the composition a priori. We finish by providing an illustrative example, where we show how the use of temporal logic allows the designer to write the specifications intuitively, and the use of Petri nets allows us to tackle the large state spaces and high concurrency associated with multi-robot systems.","Multi-robot coordination, Linear temporal logic, Supervisory control, Petri nets",Bruno Lacerda and Pedro U. Lima,https://www.sciencedirect.com/science/article/pii/S0921889019302441,https://doi.org/10.1016/j.robot.2019.103289,0921-8890,2019,103289,122,Robotics and Autonomous Systems,Petri net based multi-robot task coordination from temporal logic specifications,article,LACERDA2019103289
"Assistive torque control is important for people who cannot fully accomplish sit-to-stand and stand-to-sit (STS) transitions. In this paper, we proposed a three-level control strategy for a bionic knee exoskeleton based on real-time STS transition recognition. Motion features were obtained from one potentiometer and two inertial measurement units integrated in the exoskeleton. A multi-class support vector classifier was utilized to infer the subject?s real-time motion intent. Twelve able-bodied subjects were recruited in experiments. Mean accuracy across subjects was 97.63%±0.01%. Once STS transition was detected, the proposed control system could add assistive torque in time to assist the subject to accomplish the transition.","STS transitions, Knee exoskeleton, Mode recognition, Real-time, Assistive torque control",Xiuhua Liu and Zhihao Zhou and Jingeng Mai and Qining Wang,https://www.sciencedirect.com/science/article/pii/S092188901830705X,https://doi.org/10.1016/j.robot.2019.06.008,0921-8890,2019,209--220,119,Robotics and Autonomous Systems,Real-time mode recognition based assistive torque control of bionic knee exoskeleton for sit-to-stand and stand-to-sit transitions,article,LIU2019209
"This paper introduces a novel passive type upper arm exoskeletal vest for assisting overhead jobs in industrial environment such as automotive manufacturing centers. The developed upper arm exoskeleton named as Hyundai Vest Exoskeleton (H-VEX) proposes two key mechanical structural elements: (1) an energy-storage multi-linkage mechanism dissipating spring-loaded energy according to angle-increment of a wearer?s upper arm, and (2) a poly-centric shoulder joint mechanism on the transverse plane for its proper alignment with a wearer?s shoulder joint movement. Based on the proposed mechanical structures, H-VEX has effective ergonomic properties which enable it to provide a smooth-increasing upper arm assistive torque according to increment in a wearer?s arm angle up to its target angle without impeding movements in large ranges of motion (RoM). Especially, the critical design parameters of the energy-storage multi-linkage are able to be adjusted to generate customized assistive torque responses, and additionally, this mechanism can be covered in a thin cover frame for beneficial ergonomic & cosmetic reasons. Furthermore, industrial-purposed requirements such as mechanical endurance and cost-effectiveness can be achieved taking advantages of key structures. To verify the effectiveness of H-VEX on overhead works, activation signals of electromyography (EMG) on main corresponding muscles of ten subjects carrying out overhead manipulation tasks were measured and compared with cases without wearing the exoskeletal vest. The statistical analysis on acquired EMG signal indicates that assistive torque provided by H-VEX was shown to significantly decrease activation of the shoulder-related muscles during target tasks.","H-VEX, Upper-limb assistive exoskeleton, Multi-linkage spring-energy storage mechanism, Poly-centric exoskeletal joint",Dong Jin Hyun and KiHyeon Bae and KyuJung Kim and Seungkyu Nam and Dong-hyun Lee,https://www.sciencedirect.com/science/article/pii/S0921889019304464,https://doi.org/10.1016/j.robot.2019.103309,0921-8890,2019,103309,122,Robotics and Autonomous Systems,A light-weight passive upper arm assistive exoskeleton based on multi-linkage spring-energy dissipation mechanism for overhead tasks,article,HYUN2019103309
"Inferring and representing three-dimensional shapes is an important part of robotic perception. However, it is challenging to build accurate models of novel objects based on real sensory data, because observed data is typically incomplete and noisy. Furthermore, imperfect sensory data suggests that uncertainty about shapes should be explicitly modeled during shape estimation. Such uncertainty models can usefully enable exploratory action planning for maximum information gain and efficient use of data. This paper presents a probabilistic approach for acquiring object models, based on visual and tactile data. We study Gaussian Process Implicit Surface (GPIS) representation. GPIS enables a non-parametric probabilistic reconstruction of object surfaces from 3D data points, while also providing a principled approach to encode the uncertainty associated with each region of the reconstruction. We investigate different configurations for GPIS, and interpret an object surface as the level-set of an underlying sparse GP. Experiments are performed on both synthetic data, and also real data sets obtained from two different robots physically interacting with objects. We evaluate performance by assessing how close the reconstructed surfaces are to ground-truth object models. We also evaluate how well objects from different categories are clustered, based on the reconstructed surface shapes. Results show that sparse GPs enable a reliable approximation to the full GP solution, and the proposed method yields adequate surface representations to distinguish objects. Additionally the presented approach is shown to provide computational efficiency, and also efficient use of the robot?s exploratory actions.","Tactile sensing, Shape modeling, Implicit surface, 3D reconstruction, Gaussian process, Regression",Gabriela Zarzar Gandler and Carl Henrik Ek and Mårten Björkman and Rustam Stolkin and Yasemin Bekiroglu,https://www.sciencedirect.com/science/article/pii/S0921889019303495,https://doi.org/10.1016/j.robot.2020.103433,0921-8890,2020,103433,126,Robotics and Autonomous Systems,"Object shape estimation and modeling, based on sparse Gaussian process implicit surfaces, combining visual data and tactile exploration",article,GANDLER2020103433
"Eating is an essential activity of daily living (ADL) for staying healthy and living at home independently. Although numerous assistive devices have been introduced, many people with disabilities are still restricted from independent eating due to the devices? physical or perceptual limitations. In this work, we present a new meal-assistance system and evaluations of this system with people with motor impairments. We also discuss learned lessons and design insights based on the evaluations. The meal-assistance system uses a general-purpose mobile manipulator, a Willow Garage PR2, which has the potential to serve as a versatile form of assistive technology. Our active feeding framework enables the robot to autonomously deliver food to the user?s mouth, reducing the need for head movement by the user. The user interface, visually-guided behaviors, and safety tools allow people with severe motor impairments to successfully use the system. We evaluated our system with a total of 10 able-bodied participants and 9 participants with motor impairments. Both groups of participants successfully ate various foods using the system and reported high rates of success for the system?s autonomous behaviors. In general, participants who operated the system reported that it was comfortable, safe, and easy-to-use.","Assistive robots, Manipulation, Assistive feeding, Meal assistance",Daehyung Park and Yuuna Hoshi and Harshal P. Mahajan and Ho Keun Kim and Zackory Erickson and Wendy A. Rogers and Charles C. Kemp,https://www.sciencedirect.com/science/article/pii/S0921889018307061,https://doi.org/10.1016/j.robot.2019.103344,0921-8890,2020,103344,124,Robotics and Autonomous Systems,"Active robot-assisted feeding with a general-purpose mobile manipulator: Design, evaluation, and lessons learned",article,PARK2020103344
"In real life, providing security for a set of large areas by covering the areas with Unmanned Aerial Vehicles (UAVs) is a difficult problem that consists of multiple objectives. These difficulties are even greater if the area coverage has to be sustained through a specific time window. We address this by considering a Vehicle Routing Problem with a Time Windows (VRPTW) variation in which the capacity of agents is counted as one and each customer (target area) is to be supplied with more than one vehicle simultaneously and without violating time windows. In this problem, our aim is to find a way to cover all areas with the necessary number of UAVs during the time windows, while minimizing the total distance traveled, and providing a fast solution by satisfying the additional constraint that each agent has limited fuel. We present a novel algorithm that relies on clustering the target areas according to their time windows, and then incrementally generating transportation problems with each cluster and the ready UAVs. We then solve the transportation problems with a simplex algorithm. The performance of the proposed algorithm and other algorithms implemented in order to compare the solution quality is evaluated through example scenarios with practical problem sizes.","Vehicle routing problem, Unmanned aerial vehicle, VRPTW, Transportation problem, Simplex algorithm",Fatih Semiz and Faruk Polat,https://www.sciencedirect.com/science/article/pii/S0921889019306475,https://doi.org/10.1016/j.robot.2020.103435,0921-8890,2020,103435,126,Robotics and Autonomous Systems,Solving the area coverage problem with UAVs: A vehicle routing with time windows variation,article,SEMIZ2020103435
"An exoskeleton robot is a mechanical structure that integrates with the exterior of the human body to improve the wearer?s muscular power. The key to ensure performances and comfort of the system is human?robot cooperation. This paper proposes a human?robot cooperative control method based on sEMG (surface Electromyography) signals to drive a pneumatic upper limb exoskeleton to act in accordance with the wearer?s motion intentions. The intended movement information of the human is estimated by combining the regression method with the classification method. Based on the joint torque estimation model which is originated from the Hill-type musculoskeletal model, the regression method is used to estimate the joint?s desired torque by merging the sEMG signal with the joint angle. To avoid shaking and keep the robot?s limbs in the static condition, a classification method with the support vector machine is developed to find out the joint state that the human intends to keep. It was then applied to the exoskeleton?s elbow joint flexion and extension movement experiments to verify the controller?s effectiveness. The experimental results demonstrate that the controller can estimate human?s motion intention accurately and is appropriate for the human?robot collaboration.","Human?robot cooperative control, Exoskeleton robot, Wearable robot, Surface electromyography(sEMG), Joint torque estimation, Joint state detector",Hao Liu and Jun Tao and Pan Lyu and Fang Tian,https://www.sciencedirect.com/science/article/pii/S0921889018307462,https://doi.org/10.1016/j.robot.2019.103350,0921-8890,2020,103350,125,Robotics and Autonomous Systems,Human-robot cooperative control based on sEMG for the upper limb exoskeleton robot,article,LIU2020103350
"Multi-robot systems (MRS) are a reference solution for many prominent real-world applications, e.g. management of warehouses or exploration of unknown environments. One of the most fundamental computational problems in MRS is that of planning the assignment of tasks to robots when such tasks have deadlines, i.e. constraints on when the execution must take place. The problem, when multiple objective functions of interest need to be optimized, is both NP-Hard and hard to approximate, and few heuristics are known in the literature to handle it. Unfortunately, none of them guarantees that the trajectories used by the robots when moving between tasks? locations are collision-free at planning time. Rather, they implement a reactive behavior, i.e. they abort the execution of a planned task whenever something goes wrong, e.g. trajectories of robots intersect or a deadline is missed due to some obstacle. This approach induces negative effects on the global performance of the system in the form of waste of energy, due to high distances traveled by the fleet members, or in the form of high convergence time to execute tasks. Therefore, planning the assignments of temporally constrained tasks with the guarantee of avoiding collisions can be a desirable feature for multi-robot systems. In this paper, we present CFAT-D (Collision-Free Allocation of Tasks having Deadlines), a new algorithm that can allocate temporally constrained tasks while guaranteeing that used trajectories are collision-free at planning time. We prove CFAT-D to be correct and showcase its effectiveness through an extensive experimental evaluation. Finally, we provide a roadmap toward the practical implementation of the new strategy in real-world environments.","Multi-robot systems, Distributed algorithms, Task allocation, Path planning, Algorithm engineering, Scheduling",Mattia D?Emidio and Imran Khan,https://www.sciencedirect.com/science/article/pii/S0921889018306493,https://doi.org/10.1016/j.robot.2019.07.002,0921-8890,2019,151--172,119,Robotics and Autonomous Systems,Collision-free allocation of temporally constrained tasks in multi-robot systems,article,DEMIDIO2019151
"This paper addresses the modeling of an autonomous underwater vehicle using quaternion formulation for angular position description and Lagrange method to compute the equations of motion. As the four parameters are dependent and generate a constraint, Lagrange multipliers are used with Baumgarte method to solve and stabilize the system. The dynamic model includes underwater effects like added mass and inertia, hydrodynamic damping, buoyancy and propeller forces. Moreover, a quaternion-based line of sight guidance algorithm is derived to avoid any use of trigonometric function and compute directly the orientation error of the underwater vehicle and the desired attitude in terms of quaternions. Motion control is achieved with a quaternion-based adaptive sliding mode controller rejecting model uncertainties and water current. The simulation results, where the vehicle follows a sequence of way-points including vertical diving motion demonstrate that the proposed guidance algorithm and motion control are deeply relevant both in terms of effectiveness and robustness for this particular type of vehicle and orientation formulation.","Underwater vehicle, Dynamic model, Lagrange, Quaternions, Adaptive sliding mode control",Jonathan Rodriguez and Herman Castañeda and J.L. Gordillo,https://www.sciencedirect.com/science/article/pii/S0921889019307444,https://doi.org/10.1016/j.robot.2019.103408,0921-8890,2020,103408,124,Robotics and Autonomous Systems,Lagrange modeling and navigation based on quaternion for controlling a micro AUV under perturbations,article,RODRIGUEZ2020103408
"Failure detection of high facilities always presents a tremendous challenge. Climbing-wall robot with detection capacity has become a main approach. But owing to their limitations in overcoming obstacles and complicated wall situation, reliable wall-climbing property and precise detection abilities are the most basic demand for achieving this function. Hence, further research is required to enhance robot capabilities in overcoming obstacles and accurate detection signal. The paper presents a new climbing-wall detection robot mechanism. The wall-climbing robot consists of two climbing modules. The two climbing modules are connected by anti-overturning mechanism to provide a capacity of anti-overturning during overcoming obstacle. The detection mechanism is installed at the bottom of the robot. Detailed design issues are presented with analyses of the design parameters. Transition displacement of anti-overturning mechanism and force transfer equation are derived, and stable operating conditions are verified. The abilities of flat surface locomotion, anti-overturning, preload and detection capacity are validated by using experiments. Experiment results show that the prototype achieves 10kg payload capacity on vertical surfaces and can overcome 10mm obstacle. 1mm×1mm circular groove can be found.","Climbing robot, Overcoming obstacles, Nondestructive testing, High payload",Fumin Gao and JianChun Fan and Laibin Zhang and Jiankang Jiang and Shoujie He,https://www.sciencedirect.com/science/article/pii/S0921889019305664,https://doi.org/10.1016/j.robot.2020.103439,0921-8890,2020,103439,125,Robotics and Autonomous Systems,Magnetic crawler climbing detection robot basing on metal magnetic memory testing technology,article,GAO2020103439
"Effective exchange of information in multi-robot systems is one of the grand challenges of today?s robotics. Here, we address the problem of simultaneously maximizing the (i) resilience to faults and (ii) area coverage of dynamic multi-robot topologies. We want to avoid the onset of single points of failure, i.e., situations in which the failure of a single robot causes the loss of connectivity in the overall network. Our methodology is based on (i) a three-fold control law and (ii) a distributed online optimization strategy that computes the optimal choice of control parameters for each robot. By doing so, connectivity is not only preserved, but also made resilient to failures as the network topology evolves. To assess the effectiveness of our approach, we ran experiments with a team of eight two-wheeled robots and we evaluated it against the injection of two separate classes of faults: communication and hardware failures. Results show that the proposed approach continues to perform as intended, even in the presence of these hazards.","Fault-tolerance, Resilience, Multi-robot systems, Connectivity, Graph theory, Control, Online optimization, Robotic hardware",Marco Minelli and Jacopo Panerati and Marcel Kaufmann and Cinara Ghedini and Giovanni Beltrame and Lorenzo Sabattini,https://www.sciencedirect.com/science/article/pii/S0921889019301903,https://doi.org/10.1016/j.robot.2019.103384,0921-8890,2020,103384,124,Robotics and Autonomous Systems,Self-optimization of resilient topologies for fallible multi-robots,article,MINELLI2020103384
"This paper presents a study on a point cloud analysis captured by a robot navigating in a shopping mall environment. It investigates the type and how much information the robot could extract from the environment. For this purpose, information regarding environmental changes and the number of people in shops was extracted and analyzed. First, the robot was manually controlled to collect data in a typical shopping mall having different types of shops and a food court. As the robot navigated thoroughly around the environment, seven data recordings of data obtained from various onboard sensors were recorded during afternoon hours over three consecutive days. We built a composite map by overlaying 3D point clouds for each recording sharing the same coordinate frame, which reveals the changes in the environment?s static objects. The number of humans at each shop in each recording was computed using a human tracker. Then, we computed a fourteen-dimensional vector for each shop: seven dimensions for environmental changes and seven for human density. Experimental results show that the environmental changes and the human density at each shop are consistent with the visual changes that occurred in the shops and the number of people who visited the shops. Correlation analysis was done among shop changes, shop open space, and human density where results suggest that change in shop configurations are often done in smaller shops and shops with larger open space tend to attract larger number of customers. Finally, information extracted from shops was used to categorize the shops according to similarity.","Human tracking, Point cloud data, Data analysis",Deneth Karunarathne and Yoichi Morales and Takayuki Kanda and Hiroshi Ishiguro,https://www.sciencedirect.com/science/article/pii/S0921889019300934,https://doi.org/10.1016/j.robot.2020.103443,0921-8890,2020,103443,126,Robotics and Autonomous Systems,Understanding a public environment via continuous robot observations,article,KARUNARATHNE2020103443
"Vibration decreases operational accuracy and productivity of flexible manipulators, and trajectory planning is an effective way to suppress vibration. However, the existing trajectory planning methods can only suppress vibration of planar flexible manipulators. In this paper, a trajectory planning method is proposed to suppress vibration of spatial flexible manipulators. Firstly, the dynamic models of each link of the flexible manipulator are established separately. Then with the constraint equations, the dynamic model of the flexible manipulator is established as a Differential Algebraic Equation (DAE). Secondly, the trajectory functions are designed as quintic polynomials, and the conditions are deduced to satisfy acceleration limits of each joint. Finally, the trajectory planning problem is transferred to an optimal problem. Particle Swam Optimization (PSO) is adopted to solve the optimal problem. Numerical simulation is conducted to demonstrate the good performance of the proposed method.","Flexible manipulator, Trajectory planning, Vibration suppression, Particle swam optimization",Leilei Cui and Hesheng Wang and Weidong Chen,https://www.sciencedirect.com/science/article/pii/S092188901930288X,https://doi.org/10.1016/j.robot.2019.103316,0921-8890,2020,103316,123,Robotics and Autonomous Systems,Trajectory planning of a spatial flexible manipulator for vibration suppression,article,CUI2020103316
"This paper studies a tunneling-based reconfiguration algorithm for cubic modular robots. Tunneling-based reconfiguration is a promising approach for cubic modular robot reconfiguration in severe space requirements. This is because a tunneling modular robot only uses spaces occupied by the start and goal configurations. However, previously proposed methods have a limitation on the arrangement of the start and goal configurations, in which the overlapped part between them must be connected. We propose a tunneling reconfiguration algorithm that removes the limitation and is available for cases with multi-overlapped parts between the start and goal configurations. It is often the case that a tunneling-based reconfiguration assumes the use of a meta-module-based structure to maintain the connectivity and mobility of the robot structure. However, in previous methods, the meta-modules often come apart during the tunneling process, and each module belongs to a different meta-module before and after the reconfiguration. The proposed algorithm also solves this problem. We implement the algorithm in a distributed form and prove its completeness for assumed robot structures. We examine the proposed tunneling algorithm by simulation.","Cubic modular robots, Reconfiguration algorithm, Distributed robots",Hiroshi Kawano,https://www.sciencedirect.com/science/article/pii/S0921889019301447,https://doi.org/10.1016/j.robot.2019.103369,0921-8890,2020,103369,124,Robotics and Autonomous Systems,Distributed tunneling reconfiguration of cubic modular robots without meta-module?s disassembling in severe space requirement,article,KAWANO2020103369
"Obtaining inverse kinematics and dynamics of a robotic manipulator is often crucial for robot control. Analytical models are typically used to approximate real robot systems, and various controllers have been designed on top of the analytical model to compensate for the approximation error. Recently, machine learning techniques have been developed for error compensation, resulting in better performance. Unfortunately, combining a learned compensator with an analytical model makes the designed controller redundant and computationally expensive. Also, general machine learning techniques require a lot of data to perform the training process and approximation, especially in solving high dimensional problems. As a result, state-of-the-art machine learning applications are either expensive in terms of computation and data collection, or limited to a local approximation for a specific task or routine. In order to address the high dimensionality problem in learning inverse kinematics and dynamics, as well as to make the training process more data efficient, this paper presents a novel approach using a series of modified Generative Adversarial Networks (GANs). Namely, we use Conditional GANs (CGANs), Least Squares GANs (LSGANs), Bidirectional GANs (BiGANs) and Dual GANs(DualGANs). We trained and tested the proposed methods using real-world data collected from two types of robotic manipulators, a MICO robotic manipulator and a Fetch robotic manipulator. The data input to the GANs was obtained using a sampling method applied to the real data. The proposed approach enables approximating the real model using limited data without compromising the performance and accuracy. The proposed methods were tested in real-world experiments using unseen trajectories to validate the ?learned? approximate inverse kinematics and inverse dynamics as well as to demonstrate the capability and effectiveness of the proposed algorithm over existing analytical models.","Inverse kinematics, Inverse dynamics, Generative adversarial networks",Hailin Ren and Pinhas Ben-Tzvi,https://www.sciencedirect.com/science/article/pii/S0921889019303501,https://doi.org/10.1016/j.robot.2019.103386,0921-8890,2020,103386,124,Robotics and Autonomous Systems,Learning inverse kinematics and dynamics of a robotic manipulator using generative adversarial networks,article,REN2020103386
"Waterline detection from images taken by cameras mounted on low-cost autonomous surface vehicles (ASVs) is a key process for obtaining a fast obstacle detection. Achieving an accurate waterline prediction is difficult due to the instability of the ASV on which the camera is mounted and the presence of reflections, illumination changes, and waves. In this work, we present a method for waterline and obstacle detection designed for low-cost ASVs employed in environmental monitoring. The proposed approach is made of two steps: (1) a pixel-wise segmentation of the current image is used to generate a binary mask separating water and non-water regions, (2) the mask is analyzed to infer the position of the waterline, which in turn is used for detecting obstacles. Experiments were carried out on two publicly available datasets containing floating obstacles such as buoys, sailing and motor boats, and swans moving near the ASV. Quantitative results show the effectiveness of the proposed approach with 98.8% pixel-wise segmentation accuracy running at 10 frames per second on an embedded GPU board.","Water detection, Autonomous surface vessels, Robotic boats, Robot vision, Water quality monitoring",L. Steccanella and D.D. Bloisi and A. Castellini and A. Farinelli,https://www.sciencedirect.com/science/article/pii/S0921889019302775,https://doi.org/10.1016/j.robot.2019.103346,0921-8890,2020,103346,124,Robotics and Autonomous Systems,Waterline and obstacle detection in images from low-cost autonomous boats for environmental monitoring,article,STECCANELLA2020103346
"In this paper, the modeling, control design, and trajectory planning for inherently safe robots with variable stiffness links (VSL) are investigated. Firstly, a dynamic model of VSL robots is developed using the pseudo-rigid-body model (PRBM). Based on PRBM, a feedback-linearization based controller is proposed. Extended state observer and deflection feedback are designed to improve the robustness and vibration suppression. To keep the inherent safety, a safe trajectory planning problem is formulated and the safety criterion is converted to a velocity constraint. With constraints on the jerk, acceleration, and velocity, the trajectory-planning problem is formulated as a time-optimal problem. The analytical solution of this problem is derived by optimal control theory. Experiments show the performances of motion control and vibration suppression of the proposed controller. The impact test results indicate the potential of VSL robots for applications with physical human?robot interaction.","Variable stiffness link, Physical human?robot interaction, Robust control, Vibration suppression, Safe trajectory planning, Impact test",Siyang Song and Xianpai Zeng and Yu She and Junmin Wang and Hai-Jun Su,https://www.sciencedirect.com/science/article/pii/S0921889019300752,https://doi.org/10.1016/j.robot.2019.07.017,0921-8890,2019,103247,120,Robotics and Autonomous Systems,Modeling and control of inherently safe robots with variable stiffness links,article,SONG2019103247
"This paper presents a new person tracking and identification framework based on solely a monocular camera. In this framework, we first track persons in the robot coordinate space using Unscented Kalman filter with the ground plane information and human height estimation. Then, we identify the target person to be followed with the combination of Convolutional Channel Features (CCF) and online boosting. It allows us to take advantage of deep neural network-based feature representation while adapting the person classifier to a specific target person depending on the circumstances. The entire system can be run on a recent embedded computation board with a GPU (NVIDIA Jetson TX2), and it can easily be reproduced and reused on a new mobile robot platform. Through evaluations, we validated that the proposed method outperforms existing person identification methods for mobile robots. We applied the proposed method to a real person following robot, and it has been shown that CCF-based person identification realizes robust person following in both indoor and outdoor environments.","Person tracking, Person identification, Mobile robot",Kenji Koide and Jun Miura and Emanuele Menegatti,https://www.sciencedirect.com/science/article/pii/S0921889019302891,https://doi.org/10.1016/j.robot.2019.103348,0921-8890,2020,103348,124,Robotics and Autonomous Systems,Monocular person tracking and identification with on-line deep feature selection for person following robots,article,KOIDE2020103348
"Human motor performance is a key area of investigation in both biomechanics and robotics. In robotics, understanding human muscular control is important to synthesize prosthetic motions and ensure safe human?robot interaction. Building controllable biomechanical models can help in quantifying the characteristics of a subject?s motion and in designing effective treatments, like motion training. This paper presents the task-based motion analysis of muscular effort using an upper-body musculoskeletal model, validated through motion capture experiments and dynamic simulations. To study the contribution of robotic assistance in improving human motor skills, the muscular effort of the task of reaching with and without robotic assistance was investigated for 10 subjects. Reduction of 21.4% in the arm muscular effort was observed for the tasks with robotic assistance.","Human performance augmentation, Rehabilitation robotics, Dynamics",Emel Demircan and Stephanie Yung and Mathew Choi and Jon Baschshi and Brian Nguyen and Javier Rodriguez,https://www.sciencedirect.com/science/article/pii/S0921889017303846,https://doi.org/10.1016/j.robot.2020.103429,0921-8890,2020,103429,125,Robotics and Autonomous Systems,Operational space analysis of human muscular effort in robot assisted reaching tasks,article,DEMIRCAN2020103429
"This paper presents a new formulation of a reactive obstacle avoidance algorithm, in the Task-Priority framework, delivering a practical solution for obstacle avoidance between vehicle-manipulator systems and complex environments. The presented concepts were implemented on an intervention autonomous underwater vehicle (I-AUV) and tested in an underwater pipe structure inspection and valve turning scenario, in a test tank, using GIRONA500 with an ECA 5E Micro manipulator. The obstacle avoidance is treated as an inequality (set-based) task, which takes into account all obstacles that are interacting with the robot links. Both the robot and the obstacles are represented by spheres to allow for analytical formulation. However, the environment is wrapped with spheres based on its actual geometry stored as an Octomap, hence it can be represented at different resolutions. Depending on the type of the mission performed by the robot we defined two modes of operation: (1) Navigation and Inspection, and (2) Intervention. For each mode, the algorithm takes into account different number of key points at the I-AUV and a different resolution of the environment representation. Typically, for the Intervention mode the resolution is higher, to allow for more precise motion. We also present an escape point strategy in case of the robot getting stuck between obstacles.","I-AUV, Set-based Task-Priority, Obstacle avoidance, Robot control, Valve turning",Patryk Cie?lak and Roberto Simoni and Pere {Ridao Rodríguez} and Dina Youakim,https://www.sciencedirect.com/science/article/pii/S0921889019306104,https://doi.org/10.1016/j.robot.2019.103396,0921-8890,2020,103396,124,Robotics and Autonomous Systems,Practical formulation of obstacle avoidance in the Task-Priority framework for use in robotic inspection and intervention scenarios,article,CIESLAK2020103396
"While researchers envision exciting applications for metamorphic systems like programmable matter, current solutions to the shape formation problem are still a long way from meeting their requirements. To dive deeper into this issue, we propose an extensive survey of the current state of the art of self/reconfiguration algorithms and underlying models in modular robotic and self-organizing particle systems. We identify three approaches for solving this problem and we compare the different solutions using a synoptic graphical representation. We then close this survey by confronting existing methods to our vision of programmable matter, and by discussing a number of future research directions that would bring us closer to making it a reality.","Self-reconfiguration, Modular robots, Programmable matter, Distributed algorithms, Self-organizing particle systems",Pierre Thalamy and Benoît Piranda and Julien Bourgeois,https://www.sciencedirect.com/science/article/pii/S0921889019301459,https://doi.org/10.1016/j.robot.2019.07.012,0921-8890,2019,103242,120,Robotics and Autonomous Systems,A survey of autonomous self-reconfiguration methods for robot-based programmable matter,article,THALAMY2019103242
"Grasp quality metrics aim at quantifying different aspects of a grasp configuration between a specific robot hand and object. They produce a numerical value that allows to rank grasp configurations and optimize based on them. Grasp quality metrics are a key part of most analytical grasp-planning approaches. Additionally, they are often used to generate ground-truth labels for synthetically generated grasp exemplars required for learning-based approaches. Recent studies have highlighted the limitations of grasp quality metrics when used to predict the outcome of a grasp execution on a real robot. In this paper, we systematically study how well seven commonly-used grasp quality metrics perform in the real world. To this end, we generated two datasets of grasp candidates in simulation, each one for a different robotic system. The quality of these synthetic grasp candidates is quantified by the aforementioned metrics. For validation, we developed an experimental procedure to accurately replicate grasp candidates on two real robotic systems and to evaluate the performance of each grasp. Given the resulting datasets, we trained different classifiers to predict grasp success using only grasp quality metrics as input. Our results show that combinations of quality metrics can achieve up to a 85% classification accuracy for real grasps.","Grasping, Grasp simulation, Machine learning, Prediction model, Real grasp execution",Carlos Rubert and Daniel Kappler and Jeannette Bohg and Antonio Morales,https://www.sciencedirect.com/science/article/pii/S0921889019300247,https://doi.org/10.1016/j.robot.2019.103274,0921-8890,2019,103274,121,Robotics and Autonomous Systems,Predicting grasp success in the real world - A study of quality metrics and human assessment,article,RUBERT2019103274
"This paper presents a novel approach toward representing human whole-body motions with fingers and classification of human motions while performing tasks that require delicate finger movements, such as holding or grasping. Human whole-body motions are recorded using an optical motion capture system that measures positions of markers attached to a performer. Additionally, the performer wears data gloves with strain gauges fixed at the finger joints to measure flexions and extensions. Combining whole-body motion with finger motions forms a representation of integrated motion, which is subsequently encoded into a probabilistic model whose parameters are optimized such that the model most likely generates the training data for the integrated motion. Observations of integrated motion are classified into the relevant probabilistic model with the largest probability of generating the observation. Synchronous measurements of human whole-body and finger motions created a dataset of integrated human motions. We tested our proposed approach on this dataset, thereby demonstrating that representations of whole-body motion integrated with finger motions improved classification of human motions while manipulating objects.","Motion primitive, Motion classification, Stochastic model",Wataru Takano and Yusuke Murakami and Yoshihiko Nakamura,https://www.sciencedirect.com/science/article/pii/S0921889019304841,https://doi.org/10.1016/j.robot.2019.103378,0921-8890,2020,103378,124,Robotics and Autonomous Systems,Representation and classification of whole-body motion integrated with finger motion,article,TAKANO2020103378
"Similar to humans, robots benefit from interacting with their environment through a number of different sensor modalities, such as vision, touch, sound. However, learning from different sensor modalities is difficult, because the learning model must be able to handle diverse types of signals, and learn a coherent representation even when parts of the sensor inputs are missing. In this paper, a multimodal variational autoencoder is proposed to enable an iCub humanoid robot to learn representations of its sensorimotor capabilities from different sensor modalities. The proposed model is able to (1) reconstruct missing sensory modalities, (2) predict the sensorimotor state of self and the visual trajectories of other agents actions, and (3) control the agent to imitate an observed visual trajectory. Also, the proposed multimodal variational autoencoder can capture the kinematic redundancy of the robot motion through the learned probability distribution. Training multimodal models is not trivial due to the combinatorial complexity given by the possibility of missing modalities. We propose a strategy to train multimodal models, which successfully achieves improved performance of different reconstruction models. Finally, extensive experiments have been carried out using an iCub humanoid robot, showing high performance in multiple reconstruction, prediction and imitation tasks.","Multimodal learning, Autonomous learning, Variational autoencoder",Martina Zambelli and Antoine Cully and Yiannis Demiris,https://www.sciencedirect.com/science/article/pii/S0921889019301575,https://doi.org/10.1016/j.robot.2019.103312,0921-8890,2020,103312,123,Robotics and Autonomous Systems,Multimodal representation models for prediction and control from partial information,article,ZAMBELLI2020103312
"A neuromorphic control architecture is introduced to govern the motion of a lightweight humanoid robot. The reference trajectories necessary to perform stable gaits are generated by neural modules represented by Chaotic Recurrent Neural Networks CRNN organized in a hierarchical fashion. In the higher layer a body-coordination module generates the trajectories for the central parts of the robot body, in the middle layer the limb-coordination modules generate the Cartesian trajectories for the end effector of each limb, finally in the lower layer the limb modules control the position of the robot joints. Each neural module consists of a reservoir of N=200 leaky-integrator neurons randomly and sparsely connected with fixed synapses. The adaptation occurs in the synapses of readout units by online learning techniques like the delta rule and the Recursive Least Square algorithm RLS. It is demonstrated that the neural modules can learn and reproduce with enough accuracy the trajectories acquired from the simulation of a humanoid robot in V-REP software. With an optimal initialization of the reservoir connection matrix and by using a low computationally expensive learning algorithm such as the delta rule, ?(N), the average of MSE over all lower limbs joints is in the order of 0.1. For the lower-limbs-coordination-module the MSE drops to 0.004 by using the more computational expensive RLS, ?(N2). In case the neural module needs to learn how to adapt the trajectories according to a specific step length and frequency the MSE is 0.06. A comparison between different learning algorithms applied on the CRNN showed better performances by using RLS. This result is confirmed also by a direct comparison with a different neural architecture, the PCPG, however at the expense of a bigger computational complexity. A real test conducted on a small computational unit (Raspberry Pi2) demonstrated that the CRNN can be executed at a frequency of 142 Hz which suffices to feed a PID feedback control loop at the joint level.","Neuromorphic controller, Real time trajectory generation, Chaotic Recurrent Neural Network, Humanoid robotics, Biped robot, Neurodynamics",Michele Folgheraiter and Amina Keldibek and Bauyrzhan Aubakir and Giuseppina Gini and Alessio Mauro Franchi and Matteo Bana,https://www.sciencedirect.com/science/article/pii/S0921889017301793,https://doi.org/10.1016/j.robot.2019.07.014,0921-8890,2019,103244,120,Robotics and Autonomous Systems,A neuromorphic control architecture for a biped robot,article,FOLGHERAITER2019103244
"Mission planning for Autonomous Marine Vehicles (AMVs) is non-trivial because significant uncertainty is present when profiling the operating environment, especially for underwater missions. Mission complexity is compounded for each vehicle added to the mission. In practice, fleet operations are formulated as separate temporal problems by the operator and solved using a temporal planner. This paper proposes a planning method that uses energy as the base planning resource instead of time. Unlike temporal planners, energy planners account for physical loads endured by the vehicles. The extent of uncertainty in the vehicle loads is clarified by using the vehicle dynamics model and Monte Carlo simulation on the model parameters. The planning method is a multistage procedure to decompose operator specified task, obstacle, and vehicle data into an energy formulation of the Team Orienteering Problem (TOP) which is then solved using Discrete Strengthened PSO (DStPSO). The DStPSO algorithm has been modified to include a selective swarm size decay method that allows for larger initial swarm sizes to promote early exploration and preserves a percentage of the best performing particles on each iteration to save computational resources. The planner produces near-optimal routes containing feasible trajectories for individual vehicles that maximise tasks completed according to individual vehicle energy constraints. A case-study mission for long-term, large-scale, underwater inspection of a wind turbine array was converted into input data to evaluate the planner. Energy planning presents the opportunity for vehicles to actively monitor the feasibility of their individual plan against their current energy consumption, allowing for advanced reasoning and fault handling to occur in situ without operator assistance.","Planning AI, Multi-robot systems, Marine robotics",Fletcher Thompson and Roberto Galeazzi,https://www.sciencedirect.com/science/article/pii/S0921889019303355,https://doi.org/10.1016/j.robot.2019.103404,0921-8890,2020,103404,124,Robotics and Autonomous Systems,Robust mission planning for Autonomous Marine Vehicle fleets,article,THOMPSON2020103404
"In this work, the H? control for mechanical systems and its application in Robotics is discussed. The controller is designed in discrete time and it is synthesized for mechanical systems that are modeled by means of the Euler?Lagrange formulation. Making use of the discrete Hamilton?Jacobi?Isaacs equation the control law is derived. The discrete control law is then applied to a continuous-time 6-DoF bipedal robot model in order to track the walking pattern references for each link. The system along with the control law is simulated, with the system subjected to an external disturbance that emulates the action of a group of unknown bounded forces over the links of the bipedal robot. Furthermore, an algorithm to diminish the effect of the disturbance is proposed such that the full knowledge of the plant is not needed but only the linear part of the mass and inertia matrix; this algorithm is combined with the H? controller and applied to a robotic arm. Finally, this work is compared to a similar approach that uses H? technique in continuous time.","Robotics, Discrete-time systems, Mechanical systems,  controller, Tracking control",L. Osuna-Ibarra and H. Caballero-Barragán and A.G. Loukianov and E. Bayro-Corrochano,https://www.sciencedirect.com/science/article/pii/S0921889017302920,https://doi.org/10.1016/j.robot.2019.07.005,0921-8890,2019,201--208,119,Robotics and Autonomous Systems,Tracking control using optimal discrete-time H? for mechanical systems: Applied to Robotics,article,OSUNAIBARRA2019201
"We present a robust scene-matching (SM) algorithm using time-invariant features that are propagated and bounded by a model propagator and pixel boundary. The SM based absolute navigation has the advantage that the position of the vehicle can be independently calculated without external information, making it possible to calculate a stable navigation solution without cumulative errors. However, SM-based absolute localization has a mismatching problem, this is due to the difference between the reference for the matching and the input image, and the more the change, the higher the probability of mismatching. In this paper we propose an algorithm that can mitigate the mismatching problem with a model-based propagator and time-invariant features. The propagator is based on a relative velocity of the inertial navigation system (INS) model, which is very accurate for a short time. Also the propagated feature points have pixel boundaries, which considers not only INS model uncertainty but also distortion of the aerial images caused by various terrain characteristics. The proposed algorithm is verified by simulation using real experimental data. Consequently we can found the proposed algorithm is very effective in mitigating the mismatching problem in urban areas.","Scene matching, Feature points, Aerial image, Inertial navigation system, Horizontal pixel boundary",Sung Hyuk Choi and Chan Gook Park,https://www.sciencedirect.com/science/article/pii/S0921889019302660,https://doi.org/10.1016/j.robot.2019.103372,0921-8890,2020,103372,124,Robotics and Autonomous Systems,Robust aerial scene-matching algorithm based on relative velocity model,article,CHOI2020103372
"This article comprehends the design of a Brain-Based Robot (BBR) using hybrid techniques that incorporate both Brain-Based Device (BBD) and computational algorithms. BBDs are biologically inspired machines which have its behavior guided by a simulated nervous system. This nervous system follows detailed neuroanatomy of different brain areas. BBDs tend to have a nervous system with a large number of neurons and synapses. Thus, a huge computational power is required to simulate the nervous system of a BBD. Nevertheless, some of the tasks carried out by the simulated nervous system can be accomplished using computational algorithms which can help reducing the required computational power greatly. In this article, a BBR is built which combines some subsystems from BBD with computer vision algorithms. Computer vision algorithms are applied using OpenCV to extract some features from images, while neuronal-areas are connected together based on a detailed neuroanatomical structure to mimic the human learning process. Nengo python package is used for simulating neuronal areas in the system and monitoring activities of neuronal units. Moreover, the successful integration of the BBD?s subsystems with computer vision leads to the perceptual categorization based on invariant object-recognition of various visual cues. To make a fair comparison with BBD, the nervous system of a BBD is built on the same computer used to build the hybrid brain for the proposed BBR. The proposed hybrid brain is then applied to a Nao humanoid robot in V-REP simulation environment to test it. The results obtained through this article prove that the proposed hybrid brain possesses the same intelligence of the BBD and requires much less computational power that it can run on an on-board computer of a robot, which makes it plausible for engineering applications.","Computer vision, Invariant object-recognition, Brain-Based Device, Perceptual categorization, Neural simulation",Omar Zahra and Mohamed Fanni and Abdelfatah M. Mohamed,https://www.sciencedirect.com/science/article/pii/S0921889017307819,https://doi.org/10.1016/j.robot.2019.05.006,0921-8890,2019,135--150,119,Robotics and Autonomous Systems,Synthesis of a hybrid brain for a humanoid robot,article,ZAHRA2019135
"This paper presents the robust controller design for an indoor blimp robot to achieve application such as the surveillance. The commonly used 6 degrees of freedom dynamic model is simplified under reasonable assumptions and decoupled into two independent parts. The blimp simplified horizontal plane movement model is complemented with disturbance terms to ensure the modeling accuracy, then it is transformed to a simpler form for the ease of controller design. Next, the disturbance terms are evaluated by the designed real-time estimator, and the perturbation estimates are compensated in the conceived motion controller for cancellation of the influence of disturbances. The performance and robustness of the disturbance compensation-based controller are verified by both simulations and experiments on the developed blimp robot. Finally, the results prove the feasibility of the blimp robot in indoor surveillance application by stabilizing itself at a fixed position or patrolling along a predefined path.","Blimp robot, Navigation, Estimation, Uncertainty compensation, Robust control",Yue Wang and Gang Zheng and Denis Efimov and Wilfrid Perruquetti,https://www.sciencedirect.com/science/article/pii/S0921889019304683,https://doi.org/10.1016/j.robot.2019.103402,0921-8890,2020,103402,124,Robotics and Autonomous Systems,Disturbance compensation based controller for an indoor blimp robot,article,WANG2020103402
"A muscle tension training device that contains series elastic actuators (SEAs) has high safety and control performance in human?machine interaction equipment. Based on the cascade impedance controller and the electromyographic (EMG) sensor signal, this paper proposes a self-adaptive gain-scheduled algorithm. The algorithm automatically adjusts the stiffness gain value according to the muscle force. Simultaneously the stable gain function of the passivity condition can ensure the interaction stability. A cascade impedance controller is the basis for ensuring the stiffness of the port and the stability of the interaction; the gain-scheduled function is derived based on the acquired EMG signal and the pre-set muscle exercise mode. Therefore, the control structure is highly efficient, safe to use and offers diverse strength training modes. The simulation and experimental results show that the stiffness gain-scheduled controller can accurately achieve matching of the force and port stiffness. Furthermore, the interaction process ensures precise stability. The gain-scheduled method can adjust the contact stiffness in real time according to the needs of the experimenter. It changes the way muscles exercise under the original constant stiffness. This method that has a personalized exercise feature provides a new solution for improving dynamic training.","Series elastic actuator, Gain-scheduled, Muscle tension training",Jian Li and Siqi Li and Guihua Tian and Hongcai Shang,https://www.sciencedirect.com/science/article/pii/S0921889019303197,https://doi.org/10.1016/j.robot.2019.103253,0921-8890,2019,103253,121,Robotics and Autonomous Systems,Muscle tension training method for series elastic actuator (SEA) based on gain-scheduled method,article,LI2019103253
"In contexts such as teleoperation, robot reprogramming, human?robot-interaction, and neural prosthetics, conveying movement commands to a robotic platform is often a limiting factor. Currently, many applications rely on joint-angle-by-joint-angle prescriptions. This inherently requires a large number of parameters to be specified by the user that scales with the number of degrees of freedom on a platform, creating high bandwidth requirements for interfaces. This paper presents an efficient representation of high-level, spatial commands that specifies many joint angles with relatively few parameters based on a spatial architecture that is judged favorably by human viewers. In particular, a general method for labeling connected platform linkages, generating a databank of user-specified poses, and mapping between high-level spatial commands and specific platform static configurations are presented. Thus, this architecture is ?platform-invariant? where the same high-level, spatial command can be executed on any platform. This has the advantage that our commands have meaning for human movers as well. In order to achieve this, we draw inspiration from Laban/Bartenieff Movement Studies, an embodied taxonomy for movement description. The architecture is demonstrated through implementation on 26 spatial directions for a Rethink Robotics Baxter, an Aldebaran NAO, and a KUKA youBot. User studies are conducted to validate the claims of the proposed framework.",,A. {Jang Sher} and U. Huzaifa and J. Li and V. Jain and A. Zurawski and A. LaViers,https://www.sciencedirect.com/science/article/pii/S0921889017301835,https://doi.org/10.1016/j.robot.2019.07.006,0921-8890,2019,263--277,119,Robotics and Autonomous Systems,"An embodied, platform-invariant architecture for connecting high-level spatial commands to platform articulation",article,JANGSHER2019263
"Since state of the art simultaneous localization and mapping (SLAM) algorithms are not constant time, it is often necessary to reduce the problem size while keeping as much of the original graph?s information content. In graph SLAM, the problem is reduced by removing nodes and rearranging factors. This is normally faced locally: after selecting a node to be removed, its Markov blanket sub-graph is isolated, the node is marginalized and its dense result is sparsified. The aim of sparsification is to compute an approximation of the dense and non-relinearizable result of node marginalization with a new set of factors. Sparsification consists on two processes: building the topology of new factors, and finding the optimal parameters that best approximate the original dense distribution. This best approximation can be obtained through minimization of the Kullback?Liebler divergence between the two distributions. Using simple topologies such as Chow?Liu trees, there is a closed form for the optimal solution. However, a tree is oftentimes too sparse and produces bad distribution approximations. On the contrary, more populated topologies require nonlinear iterative optimization. In the present paper, the particularities of pose-graph SLAM are exploited for designing new informative topologies and for applying the novel factor descent iterative optimization method for sparsification. Several experiments are provided comparing the proposed topology methods and factor descent optimization with state-of-the-art methods in synthetic and real datasets with regards to approximation accuracy and computational cost.","Mobile robotics, SLAM, Sparsification, Factor recovery, Topology",Joan Vallvé and Joan Solà and Juan Andrade-Cetto,https://www.sciencedirect.com/science/article/pii/S0921889018303002,https://doi.org/10.1016/j.robot.2019.06.004,0921-8890,2019,108--118,119,Robotics and Autonomous Systems,Pose-graph SLAM sparsification using factor descent,article,VALLVE2019108
"This paper proposes a new robot-assisted bilateral upper limb training strategy, focusing on the bilateral coordination of users? upper limbs. The strategy is implemented and evaluated on a bilateral upper limb rehabilitation device (BULReD) that is an H-bot mechanism actuated by two Maxon DC motors. The control system consists of a position controller, an admittance controller and an adaptive algorithm, where the BULReD stiffness is modified session by session based on training performance. This strategy is also integrated with subject-specific workspace for enhanced training safety. Experiments were carried out with five subjects through active reaching tasks. Results indicate that the proposed training strategy requires significant coordination of bilateral upper limbs for task completion, and is able to tune control parameters to an appropriate difficulty level based on participants? training performance. Future work will focus on its clinical evaluation on patients with upper limb disabilities.","Robot-assisted, Bilateral, Upper limb, Training strategy, Subject-specific workspace",Qing Miao and Mingming Zhang and Andrew McDaid and Yuxin Peng and Sheng Q. Xie,https://www.sciencedirect.com/science/article/pii/S0921889018308777,https://doi.org/10.1016/j.robot.2019.103334,0921-8890,2020,103334,124,Robotics and Autonomous Systems,A robot-assisted bilateral upper limb training strategy with subject-specific workspace: A pilot study,article,MIAO2020103334
"To effectively leverage the spatio-temporal sensing capabilities of the team searching for a signal-emitting source, this paper presents a collaborative search method, in which each robot employs the weighted social Bayesian estimation and executes the distributed infotaxis search for the source. Cognition difference between robots, measuring the dissimilarity of probability maps, is specially introduced to obtain the heterogeneous weights of Bayesian estimation. However, the requirement of exchanging the whole probability map presents additional challenges in computation and communication for real-time applications. In this work, a solution for fast low-cost collaborative infotaxis method based on a combination of particle filter and Gaussian fitting is proposed. A particle filter is first employed for the representation of the source probability distribution, which makes the infotaxis strategy computationally tractable for large complex spaces using the limited and tractable amount of randomly drawn particles. By fitting a Gaussian density to the particles, each robot obtains the likelihood weight for social Bayesian estimation by only reporting the mean and the covariance matrix of Gaussian distribution rather than exchanging the whole probability maps. The simulation shows the proposed collaborative infotaxis can achieve an efficient search behavior in complex environments using a small number of particles and a lower communication bandwidth.","Cognition difference, Bayesian estimation, Collaborative infotaxis, Particle filter, Gaussian fitting",Cheng Song and Yuyao He and Branko Ristic and Xiaokang Lei,https://www.sciencedirect.com/science/article/pii/S0921889019306451,https://doi.org/10.1016/j.robot.2019.103414,0921-8890,2020,103414,125,Robotics and Autonomous Systems,Collaborative infotaxis: Searching for a signal-emitting source based on particle filter and Gaussian fitting,article,SONG2020103414
"In this paper, the mathematical expressions of a second-order matrix sensitivity analysis (SOMSA) is derived. This method has higher accuracy and requires less calculation works than previous analysis methods. Based on the SOMSA, when the traditional force-based impedance control is applied in leg hydraulic drive system (LHDS) of legged robots, the effects of parameter variations on control performance are studied by sensitivity dynamic analysis under nine working conditions. Then, combined with two measurable sensitivity indexes, the results of the sensitivity dynamic analysis are studied quantitatively. Finally, the above results are verified experimentally by using LHDS test platform. The conclusions contribute to the optimization of the LHDS structure and provide theoretical references for compensation control strategies of the traditional force-based impedance control.","Leg hydraulic drive system (LHDS), Hydraulic drive unit (HDU), Second order matrix sensitivity analysis (SOMSA), Force-based impedance control",Kaixian Ba and Bin Yu and Qixin Zhu and Zhengjie Gao and Guoliang Ma and Zhengguo Jin and Xiangdong Kong,https://www.sciencedirect.com/science/article/pii/S0921889019301290,https://doi.org/10.1016/j.robot.2019.103265,0921-8890,2019,103265,121,Robotics and Autonomous Systems,Second order matrix sensitivity analysis of force-based impedance control for leg hydraulic drive system,article,BA2019103265
"Exoskeleton devices are used to assist joint motion of subjects suffering from mobility deficiencies. Controlling an exoskeleton subjects to high nonlinearities, which are mainly due to the mechanical coupling, external disturbances, parameter uncertainties, and modeling errors. Keeping in view the requirement of a relatively accurate movement tracking while reducing the disturbances effects, there is a need for a robust controller. In this paper, an adaptive RISE (Robust Integral of Sign Error) controller is developed and implemented on the EICoSI (Exoskeleton Intelligently Communicating and Sensitive to Intention) knee exoskeleton. RISE has an advantage over standard controllers that it achieves semi-global asymptotic tracking even in the presence of unstructured disturbances. But to achieve this tracking, high control gains are required. Thus, to limit such high gains, RISE control strategy is combined with an adaptive controller, which has the advantage of improving the tracking performance while reducing the eventual overshoots. The stability of the coupled human/ exoskeleton system is analyzed based on Lyapunov theory and the system has shown semi-global asymptotic stability. The adaptive RISE controller gives better SNR (signal to noise ratio) by 11% and 2% as compared with adaptive and RISE controller respectively. In terms of tracking error, the adaptive RISE controller shows 9% more RMSE than adaptive controller but 41% less when compared with RISE controller Three experimental scenarios are analyzed to validate the proposed controller, namely (i) external disturbances, that could come from the ground during walking; (ii) induced payload, that could come from the resistive/assistive torque from the muscles and (iii) payload with external disturbances. The system is found to be robust and efficient in tracking the reference trajectories while maintaining limited error and high signal to noise ratio.","Adaptive controller, Asymptotic stability, RISE feedback, Knee exoskeleton",Kashif I.K. Sherwani and Neelesh Kumar and Ahmed Chemori and Munna Khan and Samer Mohammed,https://www.sciencedirect.com/science/article/pii/S0921889019303070,https://doi.org/10.1016/j.robot.2019.103354,0921-8890,2020,103354,124,Robotics and Autonomous Systems,RISE-based adaptive control for EICoSI exoskeleton to assist knee joint mobility,article,SHERWANI2020103354
"Humanoid robots are anticipated to work like humans in unstructured environments, and in such cases, falling over is inevitable due to the inherent postural instabilities and external disturbances arising from the environments. Since falling over may annihilate both the robot and its surroundings, we introduce in this work a generic method to predict the falling over of humanoid robots in a reliable, robust, and agile manner across various terrains, and also amidst arbitrary disturbances. The aforementioned characteristics have been strived to attain by proposing a prediction principle inspired by the human balance sensory systems. Accordingly, the fusion of multiple sensors such as inertial measurement unit and gyroscope (IMU), foot pressure sensor (FPS), joint encoders, and stereo vision sensor, which are equivalent to the human?s vestibular, proprioception, and vision systems are considered. For the prediction process, we first define a set of feature-based fall indicator variables (FIVs) from the different sensors, introduce prediction window parameters, and the thresholds for the FIVs are extracted using those parameters for four major disturbance scenarios. Further, an online threshold interpolation technique and an impulse adaptive counter limit are proposed to manage more generic disturbances. Finally, an instantaneous integer value is computed for each FIVs using their respective thresholds and the cumulative sum of them are normalized to predict the fall over by setting a suitable value as the critical limit. To determine the best combination and the usefulness of multiple sensors, the prediction performance is evaluated on four different types of terrains, in three unique combinations: first, each feature individually with their respective FIVs; second, an intuitive performance-based (PF); and finally, Kalman filter based (KF) techniques, which involve the usage of multiple features. For PF and KF techniques, prediction performance evaluations are carried out with and without adding noise to ascertain the influence of sensor noise. Overall, it is reported that KF performed better than PF and individual sensor features under different conditions. Also, the method?s ability to predict fall overs during the robot?s simple dynamic motion is also tested and verified through simulations. Experimental verification of the proposed prediction method on flat and uneven terrains is carried out with the WALK-MAN humanoid robot.","Humanoid robots, Fall prediction, Multi-sensor fusion",Rajesh Subburaman and Dimitrios Kanoulas and Luca Muratore and Nikos G. Tsagarakis and Jinoh Lee,https://www.sciencedirect.com/science/article/pii/S0921889018309187,https://doi.org/10.1016/j.robot.2019.103257,0921-8890,2019,103257,121,Robotics and Autonomous Systems,Human inspired fall prediction method for humanoid robots,article,SUBBURAMAN2019103257
"Robotics and automation in the food industry is not as widely applied as in other industries, such as automotive and electrical industries, due to the large variations in the shape and properties of food materials and the frequent alterations of food products. Robotic end effectors that can adapt to these variations and handle multiple types of food materials are in high demand. Therefore, we propose a dual-mode soft gripper made of rubber material that can grasp and suck different types of objects. The gripper consists of four soft fingers, fabricated with rubber material using casting process, each of which is designed as a combination of a PenuNet bending actuator and a suction pad located at the fingertip. We introduce a new design for the air paths, which play an important role in the proper function of the soft finger. Finite element (FE) simulations were performed to confirm the finger design. Experimental tests were conducted to evaluate single finger bending, gripper lifting force, and grasping and sucking actions for various types of food materials. Results show that the soft gripper can lift a 273.97-g hot dog in the grasping mode, as well as a 512.62-g bagged Kernel corn and a 1072.65-g Macbook Air in the suction mode. It can adapt to approximately circular and square targets, such as a piece of fried chicken and an orange, when the soft fingers are in a perpendicular configuration. While in a parallel configuration, the gripper can successfully handle elongated targets, such as a hot dog. An experiment is also presented to demonstrate the automatic packaging of a Japanese boxed lunch, which requires both grasping and suction modes to be employed.","Soft gripper, Grasping, Suction, Food packaging, Automation",Zhongkui Wang and Keung Or and Shinichi Hirai,https://www.sciencedirect.com/science/article/pii/S0921889019300879,https://doi.org/10.1016/j.robot.2020.103427,0921-8890,2020,103427,125,Robotics and Autonomous Systems,A dual-mode soft gripper for food packaging,article,WANG2020103427
"This work is concerned with targeted drug delivery inside the human body using magnetic microrobots. It proposes a vision-based magnetic platform for guiding microrobots in both open-loop/closed-loop schemes. The open-loop scheme can be used for example in the case of the inner ear, where the microrobots cannot be localized in real time. On the other hand, for more accuracy, closed-loop scheme can be used for organs as the human eye since microrobots can be localized using a vision sensor. For both schemes, the platform is designed to compensate for human body movements. It is composed of a new magnetic actuator mounted on a robot end-effector and a hybrid vision system. The latter consists of a camera and two microscopes, while the newly proposed magnetic actuator is built using four permanent magnets. The proposed actuator has been designed to create a local maximum of the magnetic field magnitude in a planar workspace. This results in a convergence point for magnetic microrobots that are in its influence zone, making possible open-loop control with a satisfactory accuracy. The procedures for calibrating each component of the proposed platform are described and validated. Finally, several experiments have been carried out to validate the modeling part and to show the feasibility of the concept. The obtained experimental results show that using such platform, the microrobots guiding can be achieved in open-loop under reasonable perturbations and in closed-loop with an accuracy of 200 ?m.",,Azaddien Zarrouk and Karim Belharet and Omar Tahri,https://www.sciencedirect.com/science/article/pii/S0921889019303604,https://doi.org/10.1016/j.robot.2019.103366,0921-8890,2020,103366,124,Robotics and Autonomous Systems,Vision-based magnetic actuator positioning for wireless control of microrobots,article,ZARROUK2020103366
"In collective robotic systems, the automatic generation of controllers for complex tasks is still a challenging problem. Open-ended evolution of complex robot behaviors can be a possible solution whereby an intrinsic driver for pattern formation and self-organization may prove to be important. We implement such a driver in collective robot systems by evolving prediction networks as world models in pair with action?selection networks. Fitness is given for good predictions which causes a bias towards easily predictable environments and behaviors in the form of emergent patterns, that is, environments of minimal surprise. There is no task-dependent bias or any other explicit predetermination for the different qualities of the emerging patterns. A careful configuration of actions, sensor models, and the environment is required to stimulate the emergence of complex behaviors. We study self-assembly to increase the scenario?s complexity for our minimal surprise approach and, at the same time, limit the complexity of our simulations to a grid world to manage the feasibility of this approach. We investigate the impact of different swarm densities and the shape of the environment on the emergent patterns. Furthermore, we study how evolution can be biased towards the emergence of desired patterns. We analyze the resilience of the resulting self-assembly behaviors by causing damages to the assembled pattern and observe the self-organized reassembly of the structure. In summary, we evolved swarm behaviors for resilient self-assembly and successfully engineered self-organization in simulation. In future work, we plan to transfer our approach to a swarm of real robots.","Self-assembly, Evolutionary swarm robotics, Pattern formation, Self-organization",Tanja Katharina Kaiser and Heiko Hamann,https://www.sciencedirect.com/science/article/pii/S0921889019300855,https://doi.org/10.1016/j.robot.2019.103293,0921-8890,2019,103293,122,Robotics and Autonomous Systems,Engineered self-organization for resilient robot self-assembly with minimal surprise,article,KAISER2019103293
"We present a robust Global Matching technique focused on 3D mapping applications using laser range-finders. Our approach works under the assumption that places can be recognized by analyzing the projection of the observed points along the gravity direction. Relative poses between pairs of 3D point clouds are estimated by aligning their 2D projective representations and benefiting from the corresponding dimensional reduction. We present the complete processing pipeline for two different applications that use the global matcher as a core component: First, the global matcher is used for the registration of static scan sets where no a-priori information of the relative poses is available. It is combined with an effective procedure for validating the matches that exploits the implicit empty space information associated to single acquisitions. In the second use case, the global matcher is used for the loop detection required for 3D SLAM applications. We use an Extended Kalman Filter to obtain a belief of the map poses, which allows to validate matches and to execute hierarchical overlap tests, which reduce the number of potential matches to be evaluated. Additionally, the global matcher is combined with a fast local technique. In both use cases, the global reconstruction problem is modeled as a sparse graph, where scan poses (nodes) are connected through matches (edges). The graph structure allows formulating a sparse global optimization problem that optimizes scan poses, considering simultaneously all accepted matches. Our approach is being used in production systems and has been successfully evaluated on several real and publicly available datasets.","Global registration, Loop detection, Place recognition, SLAM",Carlos Sánchez-Belenguer and Simone Ceriani and Pierluigi Taddei and Erik Wolfart and Vítor Sequeira,https://www.sciencedirect.com/science/article/pii/S0921889019302635,https://doi.org/10.1016/j.robot.2019.103324,0921-8890,2020,103324,123,Robotics and Autonomous Systems,Global matching of point clouds for scan registration and loop detection,article,SANCHEZBELENGUER2020103324
"In this paper, we investigate an effective control strategy for a cane-type assistive mobile robot toward clinical gait training. Assistive robots are expected to provide aid in order to reduce the burden of caregivers and physical therapists, e.g., in gait rehabilitation of elderly people. Our group has been developing a series of cane-type walking assistive robots named Intelligent Cane as a mobile hand-holding device based on admittance control to provide safe and efficient gait training. This paper explores a systematic design methodology of the admittance control model in order to provide suitable walking load during gait training. We first conduct a pilot experiment to investigate the relationship between the physiological cost of user?s walking and the coefficients in the admittance control model of the cane robot. Then, we present a clinical gait training study conducted in a hospital to evaluate the feasibility in practical use of the proposed control strategy of our cane robot in gait rehabilitation. These experimental results suggest the effectiveness of the proposed gait rehabilitation strategy with our robot.","Rehabilitation robotics, Human?robot interaction, Assistive robots, Gait analysis",Shunki Itadera and Jun Nakanishi and Yasuhisa Hasegawa and Toshio Fukuda and Masanori Tanimoto and Izumi Kondo,https://www.sciencedirect.com/science/article/pii/S0921889018306900,https://doi.org/10.1016/j.robot.2019.103326,0921-8890,2020,103326,123,Robotics and Autonomous Systems,Admittance control based robotic clinical gait training with physiological cost evaluation,article,ITADERA2020103326
"We propose an approach that considers controlling contact between a robot and the environment during physical interactions. Current physical interaction control approaches are limited in terms of the range of tasks that can be performed. To allow robots to perform more tasks, we derive tactile features representing deformations of the mechanically compliant sensing surface of a tactile sensor and incorporate these features to a robot controller, akin to a visual servo, via touch- and task-dependent tactile feature mapping matrices. As a first contribution, we derive tactile features to localize a contact coordinate frame between an object and an array of pressure sensing elements, with a mechanically compliant surface, attached onto a robot arm end-effector interacting with the object. As a second contribution, we propose tactile projection matrices to design a tactile servoing controller that combines these tactile features with a Cartesian impedance controller of the robot arm. These matrices convert the proposed tactile features to balance not only normal forces but also torques about the sensor?s axes. It allows the end-effector to steer the contact frame in a desired manner by regulating errors in the tactile features to address several common issues in robotics: exploration and co-manipulation.","Robot Arm control, Physical interaction, Tactile sensing arrays, Tactile servoing, Manipulation, Haptic exploration",Zhanat Kappassov and Juan-Antonio Corrales and Véronique Perdereau,https://www.sciencedirect.com/science/article/pii/S0921889019300697,https://doi.org/10.1016/j.robot.2019.103332,0921-8890,2020,103332,123,Robotics and Autonomous Systems,Touch driven controller and tactile features for physical interactions,article,KAPPASSOV2020103332
"In learning by demonstration, the generalization of motion trajectories far away from the set of demonstrations is often limited by the dependency of the learned models on arbitrary coordinate references. Trajectory shape descriptors have the potential to remove these dependencies by representing demonstrated trajectories in a coordinate-free way. This paper proposes a constraint-based optimization framework to generalize demonstrated rigid-body motion trajectories to new situations starting from the shape descriptor of the demonstration. Experimental results indicate excellent generalization capabilities showing how, starting from only a single demonstration, new trajectories are easily generalized to novel situations anywhere in task space, such as new initial or target positions and orientations, while preserving similarity with the demonstration. The results encourage the use of trajectory shape descriptors in learning by demonstration to reduce the number of required demonstrations.","Learning from demonstration, Trajectory generalization, Invariant shape descriptors, Constraint-based optimization",Maxim Vochten and Tinne {De Laet} and Joris {De Schutter},https://www.sciencedirect.com/science/article/pii/S0921889019303288,https://doi.org/10.1016/j.robot.2019.103291,0921-8890,2019,103291,122,Robotics and Autonomous Systems,Generalizing demonstrated motion trajectories using coordinate-free shape descriptors,article,VOCHTEN2019103291
"In this paper we propose a new method for solving the path planning problem in a static environment to find an optimal collision-free path between starting and goal points. First, the grid model of the robot?s working environment is constructed, and then the potential value of the grid cells is calculated based on the new proposed potential function. This function is used to guide the robot to move toward the desired goal, it has the lowest value at the goal position and the value is increased as the robot moves further away. Second, we developed an efficient method, called the Boundary Node Method, to find the initial feasible path. In this method, the robot is simulated by a nine-node quadrilateral element, where the centroid node represents the robot?s position. The robot moves in the working environment toward the goal with eight-boundary nodes based on the potential value of the boundary nodes. The initial feasible path is generated from a sequence of waypoints that the robot has to traverse as it moves toward the goal point without colliding with any obstacles. However, the proposed method can generate the path safely and efficiently, but the path is not optimal in terms of the total path length. Therefore, in order to construct an optimal or near-optimal collision-free path, an additional method, called the Path Enhancement Method, is developed. Finally, the cubic spline interpolation is adopted to generate a continuous smooth path that connects the starting point to the goal point. The proposed method has been tested in several working environments with different degrees of complexities. The results demonstrated that the proposed method is able to generate near-optimal collision-free path efficiently. Moreover, we compared the performance of the proposed methods with the other path planning methods in terms of path length and computational time. The results revealed that the proposed method can solve the robot path planning problem more efficiently. Finally, in order to verify the performance of the developed method for generating a collision-free path, experimental studies were carried out on the real robot.","Robot path planning, Path optimization, Simulation model, Autonomous mobile robot, Potential function, Boundary Node Method, Path Enhancement Method",R.A. Saeed and Diego Reforgiato Recupero and Paolo Remagnino,https://www.sciencedirect.com/science/article/pii/S0921889018307310,https://doi.org/10.1016/j.robot.2019.103320,0921-8890,2020,103320,123,Robotics and Autonomous Systems,A Boundary Node Method for path planning of mobile robots,article,SAEED2020103320
"Self-assembling robotic systems form a subclass of distributed robotic systems that undertake the fundamental task of structure formation. These systems build desired target structures by putting their constituting robotic modules together in a distributed and stochastic fashion, i.e., through a self-assembly process. The use of self-assembly as the underpinning coordination mechanism provides powerful means for structure formation across a variety of length scales as well as media. In particular, fluidic media have been shown to be very efficient enablers for small-scale self-assembly. In this paper, we consider a distributed robotic system consisting of multiple miniature robotic modules performing self-assembly in 2D, at the water?air interface. The course of the assembly process in the system culminating in a predefined target structure is shaped by the ruleset controllers programmed on the individual robotic modules, allowing only certain formations and ruling out others throughout the process. Designing control strategies relies heavily on accurate models of the system dynamics. Faithfully modeling such systems and their inter-module interactions involves capturing the hydrodynamic forces acting on the modules using typically computationally expensive fluid dynamic modeling tools. Such computational cost restricts the usability of the resulting models, particularly for the purpose of designing optimized controllers. In this paper, we present a new modeling approach and proceed by employing the resulting model for optimizing ruleset controllers. First, we show how the hardware and firmware of the robotic platform can be faithfully modeled in a high-fidelity robotic simulator. Second, we develop a physics plugin to recreate the hydrodynamic forces acting on the modules and propose a trajectory-based method for calibrating the plugin model parameters. Finally, we employ the resulting model and obtain automatically optimized ruleset controllers for given target structures.","Programmable self-assembly, Model-based design, Physics-based models, Ruleset controllers, Distributed robotic systems",Bahar Haghighat and Hala Khodr and Alcherio Martinoli,https://www.sciencedirect.com/science/article/pii/S0921889019302350,https://doi.org/10.1016/j.robot.2019.07.011,0921-8890,2019,103241,121,Robotics and Autonomous Systems,Lightweight physics-based models for the control of fluid-mediated self-assembly of robotic modules,article,HAGHIGHAT2019103241
"Bootstrapped Neuro-Simulation (BNS) is a method of concurrent simulator and robot controller evolution. The algorithm requires little domain knowledge and no pre-investigation data gathering. Additionally, it bridges the reality gap effectively, rapidly evolves functional controllers, and recovers from damage automatically. In this paper, the first evidence of the ability of BNS to evolve closed-loop controllers is shown; in this case to solve a light-following problem. The algorithm is then evaluated for its damage recovery ability for these closed-loop controllers and shown to be very effective, with only minor adaptations.","Evolutionary robotics, Evolutionary computation, Machine learning",Brydon A. Leonard and Mathys C. {du Plessis} and Grant W. Woodford,https://www.sciencedirect.com/science/article/pii/S0921889018305256,https://doi.org/10.1016/j.robot.2019.103398,0921-8890,2020,103398,124,Robotics and Autonomous Systems,Bootstrapped Neuro-Simulation as a method of concurrent neuro-evolution and damage recovery,article,LEONARD2020103398
"As demands on pragmatic solutions of robotics technology increase in the manufacturing industry, deep affinities between research experts and industry users are required. The European Robotics Challenges (EuRoC) research project has proposed a scientific competition and matched up research labs with industrial end users to establish challenger teams to develop and test solutions that will be applied in the real context of the industrial end-users. The paper reports the result of TIMAIRIS who is one of 6 challenger teams to advance to the final stage out of 103 teams and technical details used in the Challenge 2 - Shop Floor Logistics and Manipulation. To address the requirements and achieve the objectives of the challenge, a skill-based anytime agent architecture has been developed and extended to make the team focus on the challenging research that addresses real issues in the user environments. Finally, shop floor logistics and manipulation scenarios have been developed and demonstrated in a realistic environment for autonomous packaging.","Skill-based, Anytime agent architecture, Mobile manipulation, Autonomous packaging, European robotics challenges (EuRoC)",Gi Hyun Lim and Eurico Pedrosa and Filipe Amaral and Artur Pereira and Nuno Lau and José Luís Azevedo and Bernardo Cunha and Simone Badini,https://www.sciencedirect.com/science/article/pii/S0921889017307947,https://doi.org/10.1016/j.robot.2019.06.006,0921-8890,2019,103227,120,Robotics and Autonomous Systems,"Skill-based anytime agent architecture for European Robotics Challenges in realistic environments: EuRoC Challenge 2, Stage II ? realistic labs",article,LIM2019103227
"A simple, short and efficient chaotic path planning algorithm is proposed for autonomous mobile robots, with the aim of covering a given terrain using chaotic, unpredictable motion. The proposed technique utilizes the logistic map with a chaotic tactic that utilizes a modulo function to produce a sequence of directions for a robot that can move in eight different directions on a grid. Extensive simulations are performed, and the results show a fast and efficient scanning of the given area. In addition, the proposed algorithm is further enhanced with a pheromone inspired memory technique, with good improvements in efficiency.","Autonomous mobile robot, Path planning, Terrain coverage, Chaos, Logistic map",Lazaros Moysis and Eleftherios Petavratzis and Christos Volos and Hector Nistazakis and Ioannis Stouboulos,https://www.sciencedirect.com/science/article/pii/S0921889019305871,https://doi.org/10.1016/j.robot.2019.103377,0921-8890,2020,103377,124,Robotics and Autonomous Systems,A chaotic path planning generator based on logistic map and modulo tactics,article,MOYSIS2020103377
"This paper presents a novel approach toward synthesizing whole-body motions from visual perception and reaction force for a humanoid robot that maintains a suitable physical interaction with an environment. A behavior containing a whole-body motion, reaction force, and visual perception is encoded into a probabilistic model referred to as a ?motion symbol?. The humanoid robot selects a motion symbol appropriate to the current situation and computes references for joint angles and reaction forces according to the selected symbol. The robot subsequently modifies these references to satisfy a desired impedance relating the robot whole-body positions and forces. This computation builds visual and physical feedback loops with knowledge about the behaviors, making it possible for a humanoid robot to not only perform human-like motion behaviors similar to training behaviors, but to also physically adapt to the immediate environment. We applies this proposed framework only to controlling the upper-body motion for a humanoid robot. Experiments demonstrate that the proposed method allows a humanoid robot to control its upper-body motion in response to visual perception and reaction forces acting on its hands to achieve five tasks while controlling its lower-body motion for its balance.","Impedance control, Probabilistic model, Humanoid robot",Wataru Takano and Hiroki Kanayama and Taro Takahashi and Tomohisa Moridaira and Yoshihiko Nakamura,https://www.sciencedirect.com/science/article/pii/S0921889019305354,https://doi.org/10.1016/j.robot.2019.103353,0921-8890,2020,103353,124,Robotics and Autonomous Systems,A data-driven approach to probabilistic impedance control for humanoid robots,article,TAKANO2020103353
"Making robots know people?s place concepts has attracted researchers for decades. People believe that this capability will firmly benefit not only robot?human interaction but also reasonable and social robot behaviors, or even traditional problems in robot research such as object detection. Focusing on place classification, this paper builds a kind of native pure 3D geometric description to capture place layouts based on common point clouds. This perspective enables our method to naturally accommodate various illuminations, including extremely bad lighting for which traditional image methods cannot work properly. The space of a place is first divided into 3D voxels. The cardinal orientations of this space are then extracted, and the geometric attributes of the voxels are subsequently represented based on the cardinal orientations. The voxels with geometric attributes are defined as the cardinal-direction prototyping blocks (CDPBs). Next, the CDPB distribution for a scene is calculated by qualitative spatial description technology, thereby obtaining the complete place description. Given the sparse description, the sparse random forest (SRF) is used for learning. The experiments indicate that the CDPB-based method outperforms the current 3D geometric method and its mixed method, and it has good time performance. The main advantages of our method are that it does not require any strict hypotheses on surfaces, such as planar surfaces, it requires smaller fusion windows to attain satisfactory classification rates, it can be used in extreme lighting environments, and its parameter selection is easy.","Indoor place classification, Scene geometry, Place perception, Place description, Semantic cognition",Bo Zhu and Xiang Gao and Guozheng Xu and Yi Wang and Youqi Zheng,https://www.sciencedirect.com/science/article/pii/S0921889018308121,https://doi.org/10.1016/j.robot.2019.103318,0921-8890,2020,103318,123,Robotics and Autonomous Systems,Indoor place classification by building cardinal-direction prototyping blocks on point clouds,article,ZHU2020103318
"Despite extensive studies on cyclic tasks in robotics, definitive solutions for the problem of trajectory generation for periodic motions have not been achieved so far. In this paper, we present an approach for online trajectory generation from a library of desired periodic trajectories. The proposed approach consists of a Central Pattern Generator (CPG) architecture ensuring entrainment of any periodic trajectory, smooth motion modulation and observing position and velocity limits of the robot. The proposed CPG is composed of a synchronized network of novel bounded output oscillatory systems. Every oscillatory system is a three-dimensional dynamical system encoding a one-dimensional periodic function as a stable limit cycle. We also use the state transformation method to bound the oscillator?s output and its first time derivative. Finally, we present a synchronization technique to construct a synchronized network of the proposed oscillators for generating multi dimensional periodic functions. Using Lyapunov based arguments, we prove that the proposed CPG ensures stability, convergence, and synchronization of the desired trajectory. The soundness of the proposed oscillator and the resulting CPG are validated both in simulations and experiments on the humanoid robot iCub.","Online trajectory generation, Central pattern generator, Oscillator synchronization, Bounded output oscillator",Venus Pasandi and Aiko Dinale and Mehdi Keshmiri and Daniele Pucci,https://www.sciencedirect.com/science/article/pii/S0921889019305998,https://doi.org/10.1016/j.robot.2020.103423,0921-8890,2020,103423,125,Robotics and Autonomous Systems,A programmable central pattern generator with bounded output,article,PASANDI2020103423
"This paper presents a real-time game theoretic motion planning approach that enables an autonomous drone to race competitively against an arbitrary number of opponent drones along a 2D or 3D racecourse. Our method computes an approximate Nash equilibrium in the space of robot trajectories to maximally advance the ego robot while taking into account the opponents? intentions and responses. The core of our solution is a ?sensitivity enhanced? iterative best response algorithm that the ego robot uses to repeatedly plan its own trajectory and infer opponents? trajectories, ultimately seeking a Nash equilibrium in the joint space of trajectories for all the drones. The algorithm includes a term that allows the ego vehicle to gain advantage by exploiting the influence of the ego drone?s trajectory on the adversaries? objectives through the shared collision avoidance constraints among the vehicles. We also propose two methods for accelerating this computationally intensive iterative algorithm using (i) parallel computing with multiple CPU cores, and (ii) a neural network model that learns to predict trajectories close to the Nash equilibrium through offline training examples. Extensive simulation studies are conducted to benchmark the performance of our game theoretic planner and the statistical results show that our approach largely outperforms a baseline model predictive control algorithm that does not account for the opponents? reactions. Hardware experiments with 4 quadrotor robots on a 3D racecourse are performed to show the applicability of our method in real-time robotic systems.","Game theoretic motion planning, Nash equilibrium, Multi-robot systems",Zijian Wang and Tim Taubner and Mac Schwager,https://www.sciencedirect.com/science/article/pii/S0921889019301939,https://doi.org/10.1016/j.robot.2019.103410,0921-8890,2020,103410,125,Robotics and Autonomous Systems,Multi-agent sensitivity enhanced iterative best response: A real-time game theoretic planner for drone racing in 3D environments,article,WANG2020103410
"A strategy based on stigmergy mechanism for swarm robots interaction is proposed in this paper. The stigmergy mechanism refers to an interactive method in which robots communicate indirectly through the pheromone left in the environment by robots. The proposed stigmergic strategy that uses a vectorial pheromone model is applied for swarm robots to search and track a dynamic target. Some simulations and experiments are implemented to observe the performance of the strategy. In these investigations, RFID tags which are very cheap and convenient are arranged in the environment as carriers of the pheromones for indirect communication among robots. Robots read and write the vectorial pheromones while moving in the environment, and determine their behaviors through the vectorial pheromones. The results from simulations and experiments of using different numbers of robots show the swarm robots are able to find a dynamic target quickly and then keep a close track to the target, which demonstrates the feasibility and scalability of this strategy.","Stigmergy, Swarm robots, Indirect communication, Vectorial pheromone, Dynamic target",Qirong Tang and Zhipeng Xu and Fangchao Yu and Zhongqun Zhang and Jingtao Zhang,https://www.sciencedirect.com/science/article/pii/S0921889019301538,https://doi.org/10.1016/j.robot.2019.103251,0921-8890,2019,103251,120,Robotics and Autonomous Systems,Dynamic target searching and tracking with swarm robots based on stigmergy mechanism,article,TANG2019103251
"This paper proposes a Learning Kalman Network (LKN) based monocular visual odometry (VO), i.e. LKN-VO, for on-road driving. Most existing learning-based VO focus on ego-motion estimation by comparing the two most recent consecutive frames. By contrast, the LKN-VO incorporates a learning ego-motion estimation through the current measurement, and a discriminative state estimator through a sequence of previous measurements. Superior to the model-based monocular VO, a more accurate absolute scale can be learned by LKN without any geometric constraints. In contrast to the model-based Kalman Filter (KF), the optimal model parameters of LKN can be obtained from dynamic and deterministic outputs of the neural network without elaborate human design. LKN is a hybrid approach where we achieve the non-linearity of the observation model and the transition model though deep neural networks, and update the state following the Kalman probabilistic mechanism. In contrast to the learning-based state estimator, a sparse representation is further proposed to learn the correlations within the states from the car?s movement behaviour, thereby applying better filtering on the 6DOF trajectory for on-road driving. The experimental results show that the proposed LKN-VO outperforms both model-based and learning state-estimator-based monocular VO on the most well-cited on-road driving datasets, i.e. KITTI and Apolloscape. In addition, LKN-VO is integrated with dense 3D mapping, which can be deployed for simultaneous localization and mapping in urban environments.","Monocular visual odometry, Learning Kalman Filter, Vehicle driving",Cheng Zhao and Li Sun and Zhi Yan and Gerhard Neumann and Tom Duckett and Rustam Stolkin,https://www.sciencedirect.com/science/article/pii/S092188901930154X,https://doi.org/10.1016/j.robot.2019.07.004,0921-8890,2019,103234,121,Robotics and Autonomous Systems,Learning Kalman Network: A deep monocular visual odometry for on-road driving,article,ZHAO2019103234
"We present a control design for N unmanned aerial vehicles (UAVs) tasked with an inspection of M ground moving vehicles. The location of each ground vehicle is known to each UAV, but the navigation and intent of each ground vehicle are unknown, therefore, this uncertainty has to be anticipated in each UAV?s navigation. We use the minimum time stochastic optimal control to navigate each UAV towards the inspection of each ground vehicle. Based on this control, we formulate assignments of ground vehicles to be inspected by UAVs as an optimization problem to inspect all ground vehicles in the minimum expected time. Accounting for ground vehicle uncertain trajectories, we update the optimal assignment by a Markov inequality rule. The rule prevents the possibility of indefinite updating of assignments without finishing the inspection of all vehicles. On the other hand, it updates an assignment if it leads to a statistically significant improvement of the inspection expected time. The presented approach is illustrated with numerical examples.",,Alexey A. Munishkin and Dejan Milutinovi? and David W. Casbeer,https://www.sciencedirect.com/science/article/pii/S0921889019301952,https://doi.org/10.1016/j.robot.2019.103370,0921-8890,2020,103370,125,Robotics and Autonomous Systems,Min?max time efficient inspection of ground vehicles by a UAV team,article,MUNISHKIN2020103370
"Automatic optimization of robotic behavior has been the long-standing goal of Evolutionary Robotics. Allowing the problem at hand to be solved by automation often leads to novel approaches and new insights. A common problem encountered with this approach is that when this optimization occurs in a simulated environment, the optimized policies are subject to the reality gap when implemented in the real world. This often results in sub-optimal behavior, if it works at all. This paper investigates the automatic optimization of neurocontrollers to perform quick but safe landing maneuvers for a quadrotor micro air vehicle using the divergence of the optical flow field of a downward looking camera. The optimized policies showed that a piece-wise linear control scheme is more effective than the simple linear scheme commonly used, something not yet considered by human designers. Additionally, we show the utility in using abstraction on the input and output of the controller as a tool to improve the robustness of the optimized policies to the reality gap by testing our policies optimized in simulation on real world vehicles. We tested the neurocontrollers using two different methods to generate and process the visual input, one using a conventional CMOS camera and one a dynamic vision sensor, both of which perform significantly differently than the simulated sensor. The use of the abstracted input resulted in near seamless transfer to the real world with the controllers showing high robustness to a clear reality gap.","Evolutionary robotics, Bio-inspired landing, Reality gap, High speed flight",Kirk Y.W. Scheper and Guido C.H.E. {de Croon},https://www.sciencedirect.com/science/article/pii/S0921889019302404,https://doi.org/10.1016/j.robot.2019.103380,0921-8890,2020,103380,124,Robotics and Autonomous Systems,Evolution of robust high speed optical-flow-based landing for autonomous MAVs,article,SCHEPER2020103380
"In several applications, a robot moving from a start to a goal location is required to gather data along its path (e.g., a video feed in a monitoring scenario). The robot can have at its disposal only a limited amount of memory to store the collected data, in order to contain costs or to avoid that sensitive data fall into the hands of an attacker. This poses the need of periodically delivering the data to a Base Station (BS) through a deployed communication infrastructure that, in general, is not available everywhere. In this paper, we study this scenario by considering a variant of the shortest path problem (which we prove to be NP-hard) where the robot acquires information along its path, stores it into a limited memory buffer, and ensures that no information is lost by periodically communicating data to the BS. We present and evaluate an optimal exponential-time algorithm, an efficient feasibility test, and a polynomial-time heuristic algorithm.","Path planning, Communication constraints, Limited memory",Alessandro Riva and Arlind Rufi and Jacopo Banfi and Francesco Amigoni,https://www.sciencedirect.com/science/article/pii/S0921889018303865,https://doi.org/10.1016/j.robot.2019.06.005,0921-8890,2019,221--230,119,Robotics and Autonomous Systems,Algorithms for limited-buffer shortest path problems in communication-restricted environments,article,RIVA2019221
"Imagining the consequences of one?s own actions, before and during their execution, allows the agents to choose actions based on their simulated performance, and to monitor the progress by comparing observed to simulated behavior. In this study, we propose a deep model that enables a robot to learn to predict the consequences of its manipulation actions from its own interaction experience on objects of various shapes. Given the top-down image of the object, the robot learns to predict the movement trajectory of the object during execution of a lever-up action performed with a screwdriver in a physics-based simulator. The prediction is realized in two stages; the system first computes a number of features from the object and then generates the complete motion trajectory of the center of mass of the object using Long Short Term Memory (LSTM) models. In the first step, we investigated use of various feature descriptors such as shape context that encodes a distributed representation of positions of the object boundary points, unsupervised features that are extracted from autoencoders, Convolutional Neural Network (CNN) based features that are conjointly trained with the LSTMs, and finally task-specific supervised features that are engineered to well-encode the underlying dynamics of the lever-up action. The models are trained in simulation with objects of varying edge numbers and tested in the simulated and the real world. Our deep and generic CNN-based LSTM model outperformed the predictors that use unsupervised representations such as shape descriptors or autoencoder features in the simulated test set. Additionally, it was shown to generalize well to novel object shapes that were not experienced during model training. Finally, our model was shown to perform well in predicting the consequences of lever-up actions generated by a screwdriver that was attached to the gripper of the real UR10 robot. We further showed that our system can predict qualitatively different trajectories of objects that roll off the table or tumble over as the result of lever-up action.","Robot learning, Predictive models, Long short term memory, Shape context, Manipulation, Convolutional neural networks",M. Yunus Seker and Ahmet E. Tekden and Emre Ugur,https://www.sciencedirect.com/science/article/pii/S0921889019300740,https://doi.org/10.1016/j.robot.2019.07.003,0921-8890,2019,173--184,119,Robotics and Autonomous Systems,Deep effect trajectory prediction in robot manipulation,article,SEKER2019173
"In the last two decades, the Visual?Inertial Odometry (VIO) has recently received much attention for efficient and accurate ego-motion estimation of unmanned vehicle systems. In particular, the VIO includes only an Inertial Measurement Unit (IMU) and a camera. In this paper, we present a novel calibration approach for accurate deployment of monocular VIO. For this purpose, the hybrid optimization algorithm is used for calibrating the camera intrinsic and camera?IMU extrinsic calibration, automatically and without knowing the mechanical configuration. It is a professional work to carefully calibrate the intrinsic and extrinsic parameters, and it is required to repeat this work when the mechanical configuration of the sensor suite changes. Quantitative comparisons our method with the offline conventional calibration method on the KITTI dataset verify the efficacy and accuracy of the proposed method. We also demonstrate the performance of the proposed approach in large scale outdoor experiments.","Visual?inertial odometry, Sensor fusion, Sensors calibration, State estimation, Optimization",Mohammadvali Arbabmir and Masoud Ebrahimi,https://www.sciencedirect.com/science/article/pii/S0921889019300466,https://doi.org/10.1016/j.robot.2019.103249,0921-8890,2019,103249,120,Robotics and Autonomous Systems,Visual?inertial state estimation with camera and camera?IMU calibration,article,ARBABMIR2019103249
"Cooperative manipulation and transportation by means of multi-robot systems is a subject that has received an increased interest in the last few years. In this work, a task priority approach is first recalled from the authors previous works as framework for the control of a single mobile manipulator, to manage all its control objectives, including set membership ones and a proper coordination between the manipulator and its supporting vehicle. The approach is then extended, through a novel coordination policy, to execute a cooperative transportation of a common load by means of two (or more) mobile manipulators, via an explicit but limited information exchange, without modifying the individual controllers. Experimental results with two YouBot mobile manipulators are shown to demonstrate the effectiveness of the approach.","Cooperative mobile manipulation, Task priority framework, Mobile manipulators",E. Simetti and G. Casalino and F. Wanderlingh and M. Aicardi,https://www.sciencedirect.com/science/article/pii/S0921889019302763,https://doi.org/10.1016/j.robot.2019.103287,0921-8890,2019,103287,122,Robotics and Autonomous Systems,A task priority approach to cooperative mobile manipulation: Theory and experiments,article,SIMETTI2019103287
"Local reactive behaviors endow animals the ability to exhibit agile and dexterous performance when traversing challenging terrains. This paper presents a novel locomotion control method based on the central pattern generator (CPG) concept for hexapod walking robot with local reactive behavior to cope with terrain irregularities. Firstly, a two-layered CPG-based single-leg controller is developed to generate the rhythmical movement for each leg executing tripod walking. The Van der Pol oscillator is employed on the high-layer to construct a coupled CPG network which serves as a phase regulator (PR) to produce rhythmic signals with prescribed phase relations amongst neurons. On the low-layer, an auxiliary linear converter (LC) transforms these signals into the desired joint trajectories. Subsequently, by embodying the proprioceptive sensing and external tactile information as the sensory feedback, two typical local reactive mechanisms including the elevator reflex and searching reflex are achieved by virtue of on-line adjusting the coupling scheme of the PR and the coefficients of the LC. A locomotion control framework for hexapod walking robot is further established by combining the single-leg controller with a finite state machine to allocate swing/stance commands for individual joints in dealing with terrain perturbations. The effectiveness of the proposed method has been verified through both virtual model simulation and experiments on a physical hexapod platform.","Hexapod walking robot, Legged locomotion, Local reactive behavior, Central pattern generator (CPG)",Haitao Yu and Haibo Gao and Zongquan Deng,https://www.sciencedirect.com/science/article/pii/S0921889019304142,https://doi.org/10.1016/j.robot.2019.103401,0921-8890,2020,103401,124,Robotics and Autonomous Systems,Enhancing adaptability with local reactive behaviors for hexapod walking robot via sensory feedback integrated central pattern generator,article,YU2020103401
"Autonomous underwater vehicles (AUVs) are increasingly being used for underwater survey and exploration missions. The expanding mission scope for AUVs highlights the need for a long-endurance operational capability, which mainly depends on propulsion system efficiency and battery capacity. The use of submerged docking stations permitting battery recharge and data download/upload offers a means of enabling persistence without compromising propulsion and payload power budgets, while also reducing associated deployment/recovery costs and risks. Autonomous docking with an underwater station is, however, complicated by the presence of currents and obstacles in the water, and by the relative dynamic differences in pose between the dock and the vehicle. A robust docking guidance system is identified as a core and crucial component for ensuring successful AUV docking. This paper presents a detailed literature review summarizing the current state-of-the-art in AUV docking guidance methodologies, identifying their relative merits and shortcomings, and revealing the docking guidance methodologies that seems to be the most prominent.","Autonomous underwater vehicles, Autonomous docking, Universal docking guidance framework",A.M. Yazdani and K. Sammut and O. Yakimenko and A. Lammas,https://www.sciencedirect.com/science/article/pii/S0921889019300181,https://doi.org/10.1016/j.robot.2019.103382,0921-8890,2020,103382,124,Robotics and Autonomous Systems,A survey of underwater docking guidance systems,article,YAZDANI2020103382
"This paper proposes a resident autonomous underwater vehicle (AUV) system for monitoring around an underwater infrastructure using an AUV and a seafloor station (SS), where the SS serves as the positioning reference and a battery charging station for the AUV. Docking to the SS is a key technology in the system. The proposed method utilizes acoustic and visual positioning based on the SS. To increase the robustness of the method, further methods for visual positioning using limited information and autonomous judging of docking success are implemented. After completing docking, the AUV charges its batteries wirelessly. The process of balancing battery consumption and the amount of charge is formulized to enable prolonged and continuous surveying. The proposed system was evaluated in sea and tank environments using the AUV Tri-TON 2 (TT2) and a test-bed SS. In the sea experiments, TT2 succeeded in docking to the SS under the condition of low visibility which was within 2 m and complicated sea current induced by waves which was around 0.5 m/s. To enhance the success rate of docking, a control method considering the resistance due to sea currents is formulated. It was verified that this control method can ensure a position of TT2 maintained with 0.1 m vibration throughout the control simulation using the velocity of sea currents obtained in the sea experiments. In the tank trials, TT2 succeeded in operating continuously during three days while performing autonomous docking to the SS and charging its batteries.","Autonomous underwater vehicle (AUV), Docking, Resident AUV, Underwater monitoring, Wireless charging",Takumi Matsuda and Toshihiro Maki and Kotohiro Masuda and Takashi Sakamaki,https://www.sciencedirect.com/science/article/pii/S0921889018310029,https://doi.org/10.1016/j.robot.2019.07.001,0921-8890,2019,103231,120,Robotics and Autonomous Systems,Resident autonomous underwater vehicle: Underwater system for prolonged and continuous monitoring based at a seafloor station,article,MATSUDA2019103231
"This paper presents a method that fuses a 1D laser range finder and monocular camera to restore unknown 3D structure and 6 degree-of-freedom camera poses. This method can overcome a known deficiency of the absolute scale of monocular cameras and avoid the baseline limitation of stereo vision to obtain a more robust result. The theoretical logic of the fusion of the two sensors is analyzed in detail, and the effectiveness of our method is demonstrated by simulation and experiments. The influential factors related to the measurement and reconstruction accuracy are analyzed through simulation, and the validity of the proposed method is verified by comparing the monocular and RGBD methods on open datasets and observational experiments.",,Zhuang Zhang and Rujin Zhao and Enhai Liu and Kun Yan and Yuebo Ma and Yunze Xu,https://www.sciencedirect.com/science/article/pii/S092188901830873X,https://doi.org/10.1016/j.robot.2019.03.010,0921-8890,2019,181--191,116,Robotics and Autonomous Systems,A fusion method of 1D laser and vision based on depth estimation for pose estimation and reconstruction,article,ZHANG2019181
"Autonomous systems for monitoring and surveying are increasingly used in retail stores, since they improve the overall performance of the store and reduce the manpower cost. Moreover, an automated system improves the accuracy of collected data by avoiding human-related factors. This paper presents ROCKy, a mobile robot for data collection and surveying in a retail store that autonomously navigates and monitors store shelves based on real-time store heat maps; ROCKy is designed to automatically detect Shelf Out of Stock (SOOS) and Promotional Activities (PA) based on Deep Convolutional Neural Networks (DCNNs). The deep learning approach evaluates visual and textual content of an image simultaneously to classify and map SOOS and PA events during working hours. The proposed approach was applied and tested on several real scenarios, presenting a new public dataset with more than 14.000 annotated shelves images. Experimental results confirmed the effectiveness of the approach, showing high accuracy (up to 87%) in comparison with the existing state of the art SOOS and PA monitoring solutions, and a signification reduction of retail surveying time (45%).","Robotic vision, Shelf out of stock, Deep learning, Real time localisation system, Autonomous store mapping",Marina Paolanti and Luca Romeo and Massimo Martini and Adriano Mancini and Emanuele Frontoni and Primo Zingaretti,https://www.sciencedirect.com/science/article/pii/S0921889018304548,https://doi.org/10.1016/j.robot.2019.01.021,0921-8890,2019,179--188,118,Robotics and Autonomous Systems,Robotic retail surveying by deep learning visual and textual data,article,PAOLANTI2019179
"During multi-robot exploration, the calculation cost of the target assignment increases significantly with an increase in the map size and number of robots. In this study, a target elimination method is proposed to overcome this challenge. The benefit of the proposed method increases as the map size and number of robots increase, which is demonstrated both empirically and theoretically. Moreover, it is established that the proposed method does not rely on a specific map representation or robot?target assignment method.","Exploration, Multi-robot, Multi-target, Assignment, Target elimination",Salih Marangoz and Mehmet Fatih Amasyal? and Erkan Uslu and Furkan Çakmak and Nihal Altunta? and S?rma Yavuz,https://www.sciencedirect.com/science/article/pii/S0921889018301830,https://doi.org/10.1016/j.robot.2019.01.005,0921-8890,2019,174--185,113,Robotics and Autonomous Systems,More scalable solution for multi-robot?multi-target assignment problem,article,MARANGOZ2019174
"This paper presents a general and systematic approach to automating a variety of agile maneuvers with a small fixed-wing unmanned aerial vehicle. The methodology begins by numerically solving optimal control problems off-line to generate a small set of reference trajectories and feedforward control inputs for maneuvers. A dynamic time warping-based interpolation process parametrizes these solutions, adding robustness to the maneuver, whilst allowing the on-board library of state and control time histories to remain compact. To handle errors, inaccuracies, noise, and disturbances that are not accounted for by feedforward control, feedback control laws stabilize about the reference trajectories. The work focuses mainly on one agile maneuver: an aggressive turn-around, in which the aircraft undergoes a rapid 180 degree heading reversal, beginning and ending in straight and level flight. To establish the generality of the methodology, it is also applied to transition maneuvers between straight and level flight, and a nose-up hover. The proposed automation scheme is computationally light during flight, consisting of a simple feedforward/feedback controller coupled to a compact library of maneuvers that are optimized over the full flight envelope. The methodology is validated in simulations and flight tests. The automation scheme is implemented successfully on a small fixed-wing unmanned aerial vehicle.","Fixed-wing, Trajectory generation, Unmanned aerial vehicles, Optimal control, Dynamic time warping",Joshua M. Levin and Aditya A. Paranjape and Meyer Nahon,https://www.sciencedirect.com/science/article/pii/S0921889018304305,https://doi.org/10.1016/j.robot.2019.03.004,0921-8890,2019,148--161,116,Robotics and Autonomous Systems,Agile maneuvering with a small fixed-wing unmanned aerial vehicle,article,LEVIN2019148
"In order to improve road safety, many advanced driver assist systems (ADAS) have been developed to support human-decision making and reduce driver workload. Currently, the majority of ADAS employ a single, often very simple, driver model to predict human-driver interaction in the immediate future (e.g., next few seconds). However, there is tremendous variability in how each individual drives, necessitating personalized driver models, based on data collected from observed actual driver actions. Yet, because we currently lack sufficient knowledge of the high-level cognitive brain functions, traditional control-theoretic driver models have difficulty accurately predicting driver actions. Recently, machine-learning algorithms have been utilized to predict future driver control actions. We compare several of these algorithms used to predict the lateral control actions of human drivers. Specifically, we compare these algorithms in terms of their suitability to develop haptic-shared ADAS, which share the control force with the human driver. To this end, we need to know how the steering torque is provided by the driver. However, low-cost driving simulators typically measure steering angle but not steering torque. Thus, this work also proposes a methodology to estimate the steering-wheel torque. Using the estimated steering torque, we train several machine learning driver control models and compare the performance using both simulated and real human-driving data sets.","Advanced driver assist system, Human driver control model, Driving simulator study, Driver?vehicle interaction, Unknown parameter and input estimation",Kazuhide Okamoto and Panagiotis Tsiotras,https://www.sciencedirect.com/science/article/pii/S0921889018302008,https://doi.org/10.1016/j.robot.2019.01.020,0921-8890,2019,155--171,114,Robotics and Autonomous Systems,Data-driven human driver lateral control models for developing haptic-shared control advanced driver assist systems,article,OKAMOTO2019155
"Desert ants use the polarization of skylight and a combination of stride and ventral optic flow integration processes to track the nest and food positions when traveling, achieving outstanding performances. Navigation sensors such as global positioning systems and inertial measurement units still have disadvantages such as their low resolution and drift. Taking our inspiration from ants, we developed a 2-pixel celestial compass which computes the heading angle of a mobile robot in the ultraviolet range. The output signals obtained with this optical compass were investigated under various weather and ultraviolet conditions and compared with those obtained on a magnetometer in the vicinity of our laboratory. After being embedded on-board the robot, the sensor was first used to compensate for random yaw disturbances. We then used the compass to keep the Hexabot robot?s heading angle constant in a straight forward walking task over a flat terrain while its walking movements were imposing yaw disturbances. Experiments performed under various meteorological conditions showed the occurrence of steady state heading angle errors ranging from 0.3? (with a clear sky) to 2.9? (under changeable sky conditions). The compass was also tested under canopies and showed a strong ability to determine the robot?s heading while most of the sky was hidden by the foliage. Lastly, a waterproof, mono-pixel version of the sensor was designed and successfully tested in a preliminary underwater benchmark test. These results suggest this new optical compass shows great precision and reliability in a wide range of outdoor conditions, which makes it highly suitable for autonomous robotic outdoor navigation tasks. A celestial compass and a minimalistic optic flow sensor called M2APix (based on Michaelis?Menten Auto-adaptive Pixels) were therefore embedded on-board our latest insectoid robot called AntBot, to complete the previously mentioned ant-like homing navigation processes. First the robot was displaced manually and made to return to its starting-point on the basis of its absolute knowledge of the coordinates of this point. Lastly, AntBot was tested in fully autonomous navigation experiments, in which it explored its environment and then returned to base using the same sensory modes as those on which desert ants rely. AntBot produced robust, precise localization performances with a homing error as small as 0.7% of the entire trajectory.","Non-conventional vision, Optic flow, Hexapod, Homing, Odometry, Multiple sensory fusion, Bio-inspiration, Biomimetics, Bionics, Biorobotics",Julien Dupeyroux and Stéphane Viollet and Julien R. Serres,https://www.sciencedirect.com/science/article/pii/S092188901830263X,https://doi.org/10.1016/j.robot.2019.04.007,0921-8890,2019,40--56,117,Robotics and Autonomous Systems,An ant-inspired celestial compass applied to autonomous outdoor robot navigation,article,DUPEYROUX201940
"This paper considers the motion planning problem for multiple tethered planar mobile robots. Each robot is attached to a fixed base by a flexible cable. Since the robots share a common workspace, the interactions amongst the robots, cables, and obstacles pose significant difficulties for planning. Previous works have studied the problem of detecting whether a target cable configuration is intersecting (or entangled). Here, we are interested in the motion planning problem: how to plan and coordinate the robot motions to realize a given non-intersecting target cable configuration. We identify four possible modes of motion, depending on whether (i) the robots move in straight lines or following their cable lines; (ii) the robots move sequentially or concurrently. We present an in-depth analysis of Straight/Concurrent, which is the most practically-interesting mode of motion. In particular, we propose algorithms that (a) detect whether a given target cable configuration is realizable by a Straight/Concurrent motion, and (b) return a valid coordinated motion plan. The algorithms are analyzed in detail and validated in simulations and in a hardware experiment.","Multi-robot motion planning, Tethered robots",Xu Zhang and Quang-Cuong Pham,https://www.sciencedirect.com/science/article/pii/S0921889018309710,https://doi.org/10.1016/j.robot.2019.05.008,0921-8890,2019,189--203,118,Robotics and Autonomous Systems,Planning coordinated motions for tethered planar mobile robots,article,ZHANG2019189
"Image understanding using deep convolutional network has reached human-level performance, yet the closely related problem of video understanding, especially action recognition, has not reached the same required level of maturity. As a solution we propose two independent architectures for action recognition using meta-classifiers ? the first is based on combining kernels of support-vector-machines (SVM) and the second is based on distributed Gaussian Processes (GP). Both receive features that are computed using a multi-stream deep convolutional neural network, enabling the achievement of state-of-the-art performance on a 51 and a 101-class action recognition problem (HMDB-51/UCF-101 dataset). We have named the resulting architecture ?pillar networks? as each (very) deep neural network acts as a pillar for the meta-classifiers. In addition, we illustrate that hand-crafted features such as the improved dense trajectories (iDT) and Multi-skip Feature Stacking (MIFS), when used as additional pillars, can further supplement the performance.","Action recognition, dCNN, Multi-kernel SVM, Gaussian process",Yu Qian and Biswa Sengupta,https://www.sciencedirect.com/science/article/pii/S0921889018302483,https://doi.org/10.1016/j.robot.2019.04.005,0921-8890,2019,47--54,118,Robotics and Autonomous Systems,Pillar Networks: Combining parametric with non-parametric methods for action recognition,article,QIAN201947
"This paper presents a novel distributed and parallel self-assembly approach, which uses the lattice system as a systematic structure and homogeneous robots as shaping carriers to form a two-dimensional user-specified shape autonomously. Given a desired shape to be formed, the initial shape matches with it to execute the initialization of all individuals to allow each of them gets its location and status. Based on that, with the stratified mechanism, the macro-level behavior of large-scale group formation in swarm robotics is transformed to local formation action of individuals within the edge layers of the current aggregate, which makes complex shape formation possible. Then two motion-chains, a collection of individuals that have priority to move currently, are autonomously planning in parallel through local interaction and collaboration. Once all robots within a motion-chain are activated, each of them will move along the outer edge of the current aggregate orderly to fill the edge-filling layer efficiently. The motion-chains will be iteratively generated until the desired shape is formed. We evaluate the feasibility and scalability of this novel approach in simulation-based experiments, and implement the self-assembly algorithm on the Rubik robot, a hardware system developed in our lab.","Swarm robotics, Self-assembly, Stratified mechanism, Motion-chain, Parallel planning",Hong-an Yang and Shuai Cao and Luoyu Bai and Zhaoqi Zhang and Jie Kong,https://www.sciencedirect.com/science/article/pii/S0921889018307899,https://doi.org/10.1016/j.robot.2019.04.011,0921-8890,2019,80--92,118,Robotics and Autonomous Systems,A distributed and parallel self-assembly approach for swarm robotics,article,YANG201980
"This paper attempts to address the problem of online modulation of virtual impedance for an assistive robot based on real-time gait and activity measurements to personalize the assistance for different users at different states. In this work, smart shoes and inertial sensors are introduced to measure ground contact forces and knee joint kinematics, respectively. An automatic impedance tuning (AIT) approach is presented for a knee assistive device (KAD) based on real-time activity recognition and gait phase detection. The activities considered in this paper are level, uphill, and downhill walking. A Gaussian mixture model (GMM) is employed to map the fuzzy likelihood of various activities and gait phases to the desired virtual impedance of the KAD. The prior estimate of virtual impedance is defined using human knee impedance identified with the walking data collected on different users. The AIT approach is integrated into the high-level impedance-based controller of the KAD for assistance during the stance phase. Finally, to evaluate the benefit of the proposed algorithm in stance phase, an EMG sensor is placed on the vastus medialis muscle group of three participants. The proposed approach is compared with two baseline approaches: constant impedance and finite state machine, and the results demonstrate that the profiles of impedance parameters and robot assistive torque are smoother and the muscle activity of vastus medialis is reduced. It is also noticed that the participants reduce their step lengths and increase walking cadence with assistance from the KAD.","Wearable sensors, Assistive robotics, Human intention estimation, Impedance control, Rehabilitation",Prudhvi Tej Chinimilli and Zhi Qiao and Seyed Mostafa {Rezayat Sorkhabadi} and Vaibhav Jhawar and Iat Hou Fong and Wenlong Zhang,https://www.sciencedirect.com/science/article/pii/S092188901830558X,https://doi.org/10.1016/j.robot.2019.01.013,0921-8890,2019,66--76,114,Robotics and Autonomous Systems,Automatic virtual impedance adaptation of a knee exoskeleton for personalized walking assistance,article,CHINIMILLI201966
"We propose a new distributed method for coverage of a moving deformable convex region with a team of robots in a communication network. Robots execute a distributed self-deployment strategy based on Centroidal Voronoi Tessellations (CVT) to cover the region evenly while preventing collisions. The main contribution is the addition of a feedforward action to overcome the well-known slow convergence issue of the basic CVT algorithms. This action is derived by each robot from the information about the region that floods through the network from a few selected leaders. The method allows to quickly adapt to the fastly changing working area in spite of the light communication requirements, and it is well suited for large teams of expendable robots.","Autonomous robots, Swarm, Coverage, Tracking",Enrique Teruel and Rosario Aragues and Gonzalo López-Nicolás,https://www.sciencedirect.com/science/article/pii/S0921889018309436,https://doi.org/10.1016/j.robot.2019.06.002,0921-8890,2019,51--63,119,Robotics and Autonomous Systems,A distributed robot swarm control for dynamic region coverage,article,TERUEL201951
"This paper considers the task allocation problems in a distributed multi-robot system under critical time constraints. Considering the requirement of distributed computing, many existing distributed heuristic task allocation approaches tend to trap in local optimal and cannot obtain high-quality solutions. For a dynamic task allocation problem in a multi-robot system, not only the task information and the robot state may be subject to changes, but also the network status. That is, robots that each robot can communicate with may change over time, and sometimes there may even be no robots that it can communicate with. To solve these problems, a dynamic grouping allocation method is proposed. It builds upon the state-of-the-art consensus-based auction algorithms, extending them in both task inclusion phase and consensus phase. First, a cluster-first strategy and a task inclusion procedure that can be easily applied to the task inclusion phase of the algorithms are proposed, so that the solution quality of each iteration of the algorithms are significantly improved with a reasonable amount of computation. In addition, to increase the exploration capabilities, a proportional selection method is used in the task inclusion procedure when it is likely to trap in a local optimal. Second, the block-information-sharing strategy is used to avoid the possible conflicts that dynamic changes may bring. Numerical simulations demonstrate that the proposed method can provide conflict-free solutions in dynamic environments and can achieve outstanding performance in comparison with the state-of-the-art algorithms.","Adaptive system, Distributed task allocation, Multi-robot system, Overall objective",Xinye Chen and Ping Zhang and Guanglong Du and Fang Li,https://www.sciencedirect.com/science/article/pii/S0921889018308182,https://doi.org/10.1016/j.robot.2019.04.012,0921-8890,2019,31--46,118,Robotics and Autonomous Systems,A distributed method for dynamic multi-robot task allocation problems with critical time constraints,article,CHEN201931
"In this work, we introduce Ubiquitous Supercomputing for robotics with the objective of opening our imagination to the development of new powerful heterogeneous multi-robot systems able to perform all kind of missions. Supercomputing, also known as High Performance computing (HPC) is the tool that allows us to predict the weather, understand the origins of the universe, create incredibly realistic fantasy movies, send personalized advertisement to millions of users worldwide and much more. Robotics has been mostly absent in its use of HPC but some previous works have lightly flirted with it. With the findings presented in here, we propose a ubiquitous supercomputing ontology, which allows describing systems made up of robots, traditional HPC infrastructures, sensors, actuators and people and exhibiting scalability, user-transparency and ultimately higher computing efficiency. Moreover, we present a technology called The ARCHADE, which facilitates the development, implementation and operation of such systems, and we propose a mechanism to define and automatize missions carried out by ubiquitous supercomputing systems. As a proof of concept, we present a system depicted as Tigers VS Hunters, which illustrates the potential of this technology. The results presented in here are part of a two series work introducing The ARCHADE. This first delivery presents its philosophy and main features. Correspondingly the second part will present a set of use cases and a complete performance benchmark. Supercomputing is part of our lives and it can be found in many research and industrial endeavors. With the ubiquitous supercomputing ontology and The ARCHADE, supercomputing will become part of robotics as well, bringing it therefore everywhere.","Ubiquitous supercomputing, The ARCHADE, Ubiquitous supercomputing ontology, High performance robotic computing - HPRC, HPRC cluster, Parallel robotic computing node - PRCN, General-purpose computing mission",Leonardo Camargo-Forero and Pablo Royo and Xavier Prats,https://www.sciencedirect.com/science/article/pii/S0921889018305190,https://doi.org/10.1016/j.robot.2019.01.006,0921-8890,2019,187--198,114,Robotics and Autonomous Systems,The ARCHADE: Ubiquitous Supercomputing for robotics. Part I: Philosophy,article,CAMARGOFORERO2019187
"The ability of mobile service robots to efficiently search for a person is needed in a vast domain of applications. The search problem is especially challenging when the user is freely moving across the environment, the robot has only a constrained field of view, and visibility constraints arise from the environment. We propose in this article a novel approach that simulates the user?s presence at different locations in the environment based on a hidden Markov model (HMM). The HMM predicts the user?s motion and computes the observability likelihood at the different locations given the predictions. Our approach then selects effective search locations that maximize the user?s expected observability. The selection criterion hereby considers the visibility constraints along the robot?s path as well as the robot?s travel time to reach the search location. We performed both real-world and extensive simulated experiments to evaluate our method. In comparison to a greedy maximum coverage approach as well as to a greedy strategy that uses background information, we show that our framework leads to a significant reduction of the time needed to find the user.","Modeling human motion, Motion prediction, Hidden Markov models, Information gain based search",AbdElMoniem Bayoumi and Philipp Karkowski and Maren Bennewitz,https://www.sciencedirect.com/science/article/pii/S0921889018306043,https://doi.org/10.1016/j.robot.2019.02.001,0921-8890,2019,40--48,115,Robotics and Autonomous Systems,Speeding up person finding using hidden Markov models,article,BAYOUMI201940
"This paper addresses the problem of minimizing the uncertainty through motion planning in a globally exponentially stable sensor-based simultaneous localization and mapping algorithm, with the objective of performing active exploitation. This is done by designing an optimization problem that weighs the final uncertainty, the overall uncertainty in the horizon considered, and the cost of the control. Using the Pontryagin minimum principle and building on the derivation of the Kalman filter by Athans and Tse as well as on Hussein?s extension for motion planning, the optimization problem is transformed into a two-point boundary value problem that encodes necessary conditions for the input that minimizes the uncertainty. A strategy is proposed to solve this problem numerically, and particular examples are analysed. Following the shortcomings identified in this procedure, the original optimization problem is modified assuming that the input velocities are piecewise constant functions. A direct approach is used to solve this new optimization problem, allowing the in-depth analysis of more realistic scenarios.","Simultaneous localization and mapping, Optimal control, Uncertainty optimization",Pedro Lourenço and Pedro Batista and Paulo Oliveira and Carlos Silvestre,https://www.sciencedirect.com/science/article/pii/S0921889018303841,https://doi.org/10.1016/j.robot.2018.12.005,0921-8890,2019,38--55,113,Robotics and Autonomous Systems,Strategies for uncertainty optimization through motion planning in GES sensor-based SLAM,article,LOURENCO201938
"Rehabilitation robots have shown a high potential for improving the patients? mobility, improving their functional movements and assisting in daily activities. However, this technology is still an emerging field and suffers from several challenges like compliance control and dynamic uncertain caused by the human?robot collaboration. The main challenge addressed in this paper is to ensure that the exoskeleton robot provides a suitable compliance control that allows it to cooperate perfectly with humans even if the dynamic model of the exoskeleton robot is uncertain. To achieve that, an adaptive tracking controller based on Modified Function Approximation Technique (FAT) is proposed to approximate the dynamic model of the exoskeleton robot. Unlike a conventional FAT, the required use of basis functions in estimations law of dynamic model and the acceleration feedback is eliminated in the proposed modified FAT. Additionally, the desired trajectory is designed based on the designer?s prediction of the motion intention of the human, using the Damped Least Square method in order to reduce the error between the actual position of the robot and the motion intention of the human which help the subject move the exoskeleton arm easily in active rehabilitation tasks. The stability analysis is formulated and demonstrated based on Lyapunov function. An experimental physiotherapy session and comparison study with a healthy subject was performed to test the effectiveness and robustness of the proposed adaptive control.","Rehabilitation robots, Function Approximation Technique, Active assistive motion, Human inverse kinematics",Brahim Brahmi and Mohamed Hamza Laraki and Maarouf Saad and M.H. Rahman and Cristobal Ochoa-Luna and Abdelkrim Brahmi,https://www.sciencedirect.com/science/article/pii/S0921889018307802,https://doi.org/10.1016/j.robot.2019.02.017,0921-8890,2019,92--102,117,Robotics and Autonomous Systems,Compliant adaptive control of human upper-limb exoskeleton robot with unknown dynamics based on a Modified Function Approximation Technique (MFAT),article,BRAHMI201992
"This paper presents a robust method for generic obstacle detection and collision warning in Advanced Driver Assistance Systems (ADAS). The highlight of our method is the ability to detect all obstacles without prior knowledge and detect partially occluded obstacles including the obstacles that have not completely appeared in the frame (truncated obstacles). Our results show an improvement of 90% more true positives per frame compared to one of the state-of-the-art methods. Our proposed method is robust to variations in illumination and to a wide variety of vehicles and obstacles that are encountered while driving. Distortions are introduced when Inverse Perspective Mapping (IPM) projects the camera image onto the road surface plane. In this paper, we first show that the angular distortion in the IPM domain belonging to obstacle edges varies as a function of their corresponding 2D location in the camera plane. We use this information to perform proposal generation. We propose a novel proposal assessment method based on fusing statistical properties from both the IPM image and the camera image to perform robust outlier elimination and false positive reduction. We also present an annotated obstacle detection dataset derived from various source videos that can serve as a benchmark for the evaluation of future obstacle detection algorithms. The source videos containing diverse illumination and traffic conditions are derived from multiple publicly available datasets.","Obstacle detection, Inverse Perspective Mapping (IPM), Selective Edge Filtering (SEF), Proposal assessment, Fused statistical properties, Occlusion, Advanced Driver Assistance Systems (ADAS)",Charan D. Prakash and Farshad Akhbari and Lina J. Karam,https://www.sciencedirect.com/science/article/pii/S0921889018301787,https://doi.org/10.1016/j.robot.2018.12.004,0921-8890,2019,172--186,114,Robotics and Autonomous Systems,Robust obstacle detection for advanced driver assistance systems using distortions of inverse perspective mapping of a monocular camera,article,PRAKASH2019172
"This paper deals with the stable navigation of up to eight articulated vehicles, coupled together to form a road-train. Based on kinematic and dynamic models, three control approaches are proposed for dynamic stabilization in road-train configuration, as well as a methodology for setting control gains, using three possible actuators: damper at the vehicle articulation, front steering or rear drive wheels. Implementation on a 3D simulator, representative of the dynamics of the real system with a high degree of fidelity, demonstrates the controller?s performance and robustness in critical scenario conditions. Tests are then conducted in real conditions to validate the new strategy.","Articulated vehicle road-train, Linear quadratic regulator, Dynamic stabilization, ELK-test",Eric Lucet and Alain Micaelli,https://www.sciencedirect.com/science/article/pii/S092188901730893X,https://doi.org/10.1016/j.robot.2019.01.016,0921-8890,2019,106--123,114,Robotics and Autonomous Systems,Stabilization of a road-train of articulated vehicles,article,LUCET2019106
"In this paper, we discuss the omni-directional gait of a passive-spine hexapod robot, which consists of three body segments connected by passive body joints. To design the turning and rotating gaits for this robot, firstly, we analyze a geometric model to demonstrate how segment rotation can result from abduction of the legs. Next, we obtain the principle of the rotation and direction of the body segments, which are analyzed by determining the geometric features of different configurations. The turning and rotating gaits are then attained by varying only the duration of the transition sequence of the passive-spine hexapod robot. The capability of sideways motion is also given in this paper. Finally, this proposed method for designing the omni-directional gait of a passive-spine hexapod is demonstrated by simulations and experiments.","Multi-legged robot, Passive-spine hexapod robot, Passive body segment joint, Geometric analysis, Omni-directional gait",Yongchen Tang and Guoteng Zhang and Dingxin Ge and Shugen Ma,https://www.sciencedirect.com/science/article/pii/S0921889018309667,https://doi.org/10.1016/j.robot.2019.06.001,0921-8890,2019,231--246,119,Robotics and Autonomous Systems,Omni-directional gait of a passive-spine hexapod,article,TANG2019231
"The extrinsic and intrinsic calibration of light detection and ranging (LiDAR) and inertial measurement unit (IMU) system is an essential prerequisite for its using in robots navigation or localization tasks. However, the existing LiDAR-IMU calibration method usually based on either point or planar features and existed adjustment parameter correlation limitations, which great restrict the extrinsic?intrinsic calibration flexibility and versatility. For this reason, a novel calibration technique that incorporates cone and cylinder features is proposed to overcome these drawbacks. The basic principle of our proposed method is that, first of all, we establish the transformation relationship between LiDAR and IMU coordinate frame, the LiDAR-IMU system calibration parameters and cone-cylinder geometric constrained. Secondly, the LiDAR extrinsic parameters are calibrated by estimating the pose of each scanned point datasets lies on the cone-cylinder surface and then solving the cone-cylinder geometric constrained optimization problem. Thirdly, the restricted maximum likelihood estimation (RMLE) algorithm is used to solve the optimization of IMU intrinsic parameters calibration Finally, intensive experimental studies are conducted to check the validity of our proposed method, the experimental results are presented that validate the proposed method and demonstrate the overall performances of LiDAR-IMU system obviously improved compared to plane based calibration method.","Error modeling, LiDAR-IMU, Extrinsic?intrinsic calibration, Cone-cylinder feature",W.I. Liu and Yunwang Li,https://www.sciencedirect.com/science/article/pii/S092188901730636X,https://doi.org/10.1016/j.robot.2019.01.010,0921-8890,2019,124--133,114,Robotics and Autonomous Systems,Error modeling and extrinsic?intrinsic calibration for LiDAR-IMU system based on cone-cylinder features,article,LIU2019124
"This paper presents modeling and model predictive control (MPC) of a hybrid cable-driven robot (HCDR). First of all, a whole-body model is developed for the HCDR. To simplify the system modeling in practical applications, a decoupled model is then proposed to divide the whole system into two subsystems: in-plane and out-plane systems, where the former indicates a kinematic constraint vibration model and the latter indicates an underactuated dynamic model. Control design, simulations and experiments are developed to validate the models and control strategies. To overcome the inaccurate limitation of Inertial Measurement Unit (IMU) to observe states, new in-plane and out-plane state estimation methods are also proposed. Based on these state observers, experiments are implemented in different cases (e.g., no-load and 6 kg load) to evaluate control performance, and results are satisfactory.","Hybrid cable-driven robot, Dynamics, Control, Vibration",Ronghuai Qi and Mitchell Rushton and Amir Khajepour and William W. Melek,https://www.sciencedirect.com/science/article/pii/S0921889019300533,https://doi.org/10.1016/j.robot.2019.04.013,0921-8890,2019,1--12,118,Robotics and Autonomous Systems,Decoupled modeling and model predictive control of a hybrid cable-driven robot (HCDR),article,QI20191
"In this paper, we present a motion planning framework for humanoid robots that combines whole-body motions as well as footsteps under a quasi-static flat ground plane assumption. Traditionally, these two have been treated as separate research domains. One of the major challenges behind whole-body motion planning is the high DoF (Degrees of Freedom) nature of the problem, in addition to strict constraints on obstacle avoidance and stability. On the other hand footstep planning on its own is a comparatively simpler problem due to the low DoF search space, but coalescing it into a larger framework that includes whole-body motion planning adds further complexity in reaching a solution within a suitable time frame that satisfies all the constraints. In this work, we treat motion planning as a graph search problem, and employ Shared Multi-heuristic A* (SMHA*) to generate efficient, stable and collision-free motion plans given only the starting state of the robot and the desired end-effector pose.","Robotic motion planning, Humanoid robots, Multi-heuristic A*, Graph search",Rizwan Asif and Ali Athar and Faisal Mehmood and Fahad Islam and Yasar Ayaz,https://www.sciencedirect.com/science/article/pii/S0921889018306547,https://doi.org/10.1016/j.robot.2019.03.007,0921-8890,2019,51--63,116,Robotics and Autonomous Systems,Whole-body motion and footstep planning for humanoid robots with multi-heuristic search,article,ASIF201951
"This paper presents the semantic-reasoning module of VIRBOT, our proposed architecture for service robots. We show that by combining symbolic AI with digital-signal processing techniques this module achieves competitive performance. Our system translates a voice command into an unambiguous representation that helps an inference engine, built around an expert system, to perform action and motion planning. First, in the natural-language interpretation process, the system generates two outputs: (1) conceptual dependence, expressing the linguistic meaning of the statement, and (2) verbal confirmation, a paraphrase in natural language that is repeated to the user to confirm that the command has been correctly understood. Then, a conceptual-dependency interpreter extracts semantic role structures from the input sentence and looks for such structures in a set of known interpretation patterns. We evaluate this approach in a series of skill-specific semantic-reasoning experiments. Finally, we demonstrate our system in the general-purpose service robot test of the RoboCup-at-Home international competition, where incomplete information is given to a robot and the robot must recognize and request the missing information, and we compare our results with a series of baselines from the competition where our proposal performed best.","Service robots, Semantic reasoning, Knowledge representation",Jesus Savage and David A. Rosenblueth and Mauricio Matamoros and Marco Negrete and Luis Contreras and Julio Cruz and Reynaldo Martell and Hugo Estrada and Hiroyuki Okada,https://www.sciencedirect.com/science/article/pii/S0921889018302501,https://doi.org/10.1016/j.robot.2019.01.007,0921-8890,2019,77--92,114,Robotics and Autonomous Systems,Semantic reasoning in service robots using expert systems,article,SAVAGE201977
"Due to high degrees-of-freedom of humanoids and induced redundancy, there are multiple ways of performing a given manipulation task. Finding optimal ways of performing tasks is one desirable property of any motion planning framework. This includes optimizing both the path with respect to a certain objective function and also the final pre-grasp or goal position. Additionally, a variety of constraints need to be satisfied such as stability, self-collision and collision with objects in the environment and also kinematic loop-closure formed during the task. In this paper, an asymptotically optimal sampling based approach for generating motion plans is presented. A novel constraint solver extension to the bidirectional Fast Marching Trees (BFMT*) algorithm in the form of a way-point generator is proposed such that it can be applied for whole-body motion planning of humanoids. Moreover, a comparison of the performance of the proposed extension of BFMT* and the state-of-art RRT* based motion planner is shown. A gradient based inverse kinematics solver has also been implemented in combination with an optimization technique to generate goal configurations in order to ensure optimality in the pre-grasp position. The efficacy of the proposed approach is evaluated in a simulation environment on Hubo+ robot model. The results show a significant improvement in path costs, as well as overall optimality of given tasks for the proposed approach. Additionally, rigorous analysis over the choice of planning algorithms considered in this paper is present for the considered scenarios.","Optimal motion planning, Humanoid, Sampling-based motion planning, Task solver, Inverse kinematics, Closed kinematic loops",Hari Teja K. and Abhilash Balachandran and S.V. Shah,https://www.sciencedirect.com/science/article/pii/S0921889017307108,https://doi.org/10.1016/j.robot.2019.04.004,0921-8890,2019,263--277,118,Robotics and Autonomous Systems,Optimal whole-body motion planning of humanoids in cluttered environments,article,K2019263
"As autonomous service robots become more affordable and thus available for the general public, there is a growing need for user-friendly interfaces to control these systems. Control interfaces typically get more complicated with increasing complexity of robotic tasks and environments. Traditional control modalities such as touch, speech or gesture are not necessarily suited for all users. While some users can make the effort to familiarize themselves with a robotic system, users with motor disabilities may not be capable of controlling such systems even though they need robotic assistance most. In this paper, we present a novel framework that allows these users to interact with a robotic service assistant in a closed-loop fashion, using only thoughts. The system is composed of several interacting components: a brain?computer interface (BCI) that uses non-invasive neuronal signal recording and co-adaptive deep learning, high-level task planning based on referring expressions, navigation and manipulation planning as well as environmental perception. We extensively evaluate the BCI in various tasks, determine the performance of the goal formulation user interface and investigate its intuitiveness in a user study. Furthermore, we demonstrate the applicability and robustness of the system in real-world scenarios, considering fetch-and-carry tasks, close human?robot interactions and in presence of unexpected changes. As our results show, the system is capable of adapting to frequent changes in the environment and reliably accomplishes given tasks within a reasonable amount of time. Combined with high-level task planning based on referring expressions and an autonomous robotic system, interesting new perspectives open up for non-invasive BCI-based human?robot interactions.","EEG, Co-adaptive brain?computer-interface, Realtime deep learning, Autonomous robotics, Referring expression generation, High-level task planning, Computer vision",D. Kuhner and L.D.J. Fiederer and J. Aldinger and F. Burget and M. Völker and R.T. Schirrmeister and C. Do and J. Boedecker and B. Nebel and T. Ball and W. Burgard,https://www.sciencedirect.com/science/article/pii/S0921889018302227,https://doi.org/10.1016/j.robot.2019.02.015,0921-8890,2019,98--113,116,Robotics and Autonomous Systems,"A service assistant combining autonomous robotics, flexible goal formulation, and deep-learning-based brain?computer interfacing",article,KUHNER201998
"In this work, a complete solution is provided for detecting and identifying cylindrical shapes, which are commonly found in household and industrial environments, using consumer-grade RGB-D cameras. Most standard approaches to detect and identify cylinders are not robust to outliers (e.g. points on other objects in the scene), which limits their applicability in realistic scenes. In addition, these methods fail to benefit from environmental constraints, e.g. the fact that cylinders often lie or stand on flat surfaces. To tackle the aforementioned limitations, we introduce three main novelties: (i) a point cloud soft voting scheme with curvature information that reduces the influence of outliers and noise, (ii) a selective sampling of the orientation space that favorsorientations known a priori, and (iii) a deep-learning based classifier to filter out objects with non-cylindrical appearance in the 2D images, thus further improving robustness to outliers. A set of experiments with synthetically generated data are used to assess the robustness of our fitting method to different levels of outliers and noise. The results demonstrate that incorporating the principal curvature direction within the orientation voting process allows for large improvements on cylinders parameters estimation. Furthermore, we demonstrate that combining the 2D deep-learning cylinder classifier with the 3D orientation voting scheme allows for large speed-up and accuracy improvements on cylinder identification. The qualitative and quantitative results with real data acquired from a consumer RGB-D camera, confirm the advantages of the proposed framework.",,Rui Figueiredo and Atabak Dehban and Plinio Moreno and Alexandre Bernardino and José Santos-Victor and Helder Araújo,https://www.sciencedirect.com/science/article/pii/S0921889017308710,https://doi.org/10.1016/j.robot.2019.04.002,0921-8890,2019,17--28,117,Robotics and Autonomous Systems,A robust and efficient framework for fast cylinder detection,article,FIGUEIREDO201917
"We introduce new auction bidding and resolution algorithms to improve multi-robot sequential single-item auctions for heterogeneous systems. We consider two objectives, minimising the energy usage and time required to complete all tasks. Sequential single-item auctions are computationally inexpensive while producing efficient task allocations for homogeneous robots, but produce less efficient allocations for heterogeneous robots. Our algorithms provide consistent and significant (up to 20%) improvements for both objectives for a number of scenarios relative to the standard auction process, as tested in MATLAB simulations. Interestingly, our algorithms produce faster task completion even in homogeneous systems. We also introduce a new algorithm for sequential single-item auctions when robots have partial knowledge of their environment. We illustrate its improved performance and analyse its sensitivity, showing that precise tuning is not essential for faster and more efficient task completion. These improvements can reduce energy usage and task completion times for both indoor and outdoor robots in a variety of fields.","Multi-robot, Path planning, Routing, Sequential auction",Nick Sullivan and Steven Grainger and Ben Cazzolato,https://www.sciencedirect.com/science/article/pii/S0921889018306663,https://doi.org/10.1016/j.robot.2019.02.016,0921-8890,2019,130--142,115,Robotics and Autonomous Systems,Sequential single-item auction improvements for heterogeneous multi-robot routing,article,SULLIVAN2019130
"Autonomous robots that work in the same environment as humans are preferred to ensure mechanical safety with respect to soft contact with their surroundings and adaptivity to handle various tools and to manage partial malfunctions. To ensure that these requirements for robots are satisfied, this study proposes an approach for obtaining a robot structure and its application to building controller for dynamic motion of a robot. It is assumed that the physical relations between the sensor variables are unknown. On the basis of dependency network construction using mutual information, controllers are generated and tested by finding appropriate causal chains of the sensor variables. The proposed controller generation methods were tested using the control tasks of a musculoskeletal robotic arm. Thus, the proposed controller generation algorithm finds appropriate controllers, and the framework of this generation is robust to the changes in the body of the body.","Adaptivity, Control, Mutual information, Structure estimation",Yuichi Kobayashi and Kentaro Harada and Kentaro Takagi,https://www.sciencedirect.com/science/article/pii/S0921889018307474,https://doi.org/10.1016/j.robot.2019.04.010,0921-8890,2019,55--65,118,Robotics and Autonomous Systems,Automatic controller generation based on dependency network of multi-modal sensor variables for musculoskeletal robotic arm,article,KOBAYASHI201955
"Common coding theory posits there are cycles between perceptions and actions at the fundamental logic of the nervous system. An action performed by an agent modifies its external environment and/or internal states. The agent is able to complete a given goal by performing a sequence of actions. In this work, shared representations for both perception and action and their processing algorithm are presented that suggest goal-oriented alternative actions even with incomplete information. The alternative actions provide more opportunities for a service robot to achieve goals. Knowledge plays significant roles to successfully complete service tasks. Most knowledge inference mechanisms assume complete and correct knowledge about the environment. Real world environments are often uncertain and only partially observable. Thus, intelligent service robots may have an incomplete knowledge base which includes false negatives and false positives as well as true positives. False negatives and false positives can prevent service robots from completing their service tasks. A case study reveals that the proposed method has proved valuable to suggest alternatives for false information as well as to build reactive plans with customary efficiency.","Alternative actions, Weighted semantic networks, Incomplete knowledge, Robot knowledge representation, Spreading activation",Gi Hyun Lim,https://www.sciencedirect.com/science/article/pii/S0921889018303397,https://doi.org/10.1016/j.robot.2019.02.005,0921-8890,2019,38--50,116,Robotics and Autonomous Systems,Shared representations of actions for alternative suggestion with incomplete information,article,LIM201938
"Finger design automation is highly demanded from robot industries to fulfill the requirements of the agile market. Nevertheless, literature lacks a promising approach to automate the design process of reliable fingers for industrial robots. Hence, this work proposes the generic optimized finger design (GOFD) method which automates the design process of single- and multi-function finger grippers. The proposed method includes an optimization algorithm to minimize the design process time. The method is utilized to generate fingers for several groups of objects. Results show that the GOFD method outperforms existing methods and is able to reduce the design time by an average of 16,600 s. While the proposed method substantially reduces the design process time of fingers, the quality of grasps is comparable to the traditional exhaustive search method. The grasp quality of GOFD deviates only 0.47% from the absolute best grasp known from the exhaustive search method in average. The designed fingers are lastly manufactured and experimentally verified.","Design automation, Fingers design, Multi-function fingers, Industrial grippers, Optimization, Robotics",Mohammadali Honarpardaz and Johan Ölvander and Mehdi Tarkian,https://www.sciencedirect.com/science/article/pii/S0921889018304123,https://doi.org/10.1016/j.robot.2018.12.011,0921-8890,2019,120--131,113,Robotics and Autonomous Systems,Fast finger design automation for industrial robots,article,HONARPARDAZ2019120
"In this paper we propose a novel actuation concept, consisting of a conventional DC motor in series with a compliant element having multiple configurations of equilibrium. The proposed device works similarly to a traditional series elastic actuator, where the elasticity increases safety and force control accuracy, but presents the possibility of achieving higher efficiency and releasing energy at a higher bandwidth. An introduction on the mechanical properties of the multistable element explains its working principle and provides simple model-based guidelines to its design. We characterize the actuator and propose a robust algorithm to control both storage and rate of release of its elastic energy. Using only an incremental encoder on the motor?s axis, we show that we can reliably control the position of the actuator and its convergence towards a state of stable equilibrium. The proposed robust control architecture sensibly improves the tracking accuracy with respect to conventional PID controllers. Once reconfigured, no additional energy from the motor is required to hold the position, making the actuator appealing for energy-efficient systems. We conclude with a discussion on the limitations and advantages of such technology, suggesting avenues for its application in the field of assistive robotics.","Series elastic actuators, Multistability, System identification, Robust position control, Linear Kalman filter",Leonardo Cappello and Michele Xiloyannis and Binh Khanh Dinh and Alberto Pirrera and Filippo Mattioni and Lorenzo Masia,https://www.sciencedirect.com/science/article/pii/S092188901830900X,https://doi.org/10.1016/j.robot.2019.04.014,0921-8890,2019,167--178,118,Robotics and Autonomous Systems,Multistable series elastic actuators: Design and control,article,CAPPELLO2019167
"Advanced cognitive capabilities enable humans to solve even complex tasks by representing and processing internal models of manipulation actions and their effects. Consequently, humans are able to plan the effect of their motions before execution and validate the performance afterwards. In this work, we derive an analog approach for robotic wiping actions which are fundamental for some of the most frequent household chores including vacuuming the floor, sweeping dust, and cleaning windows. We describe wiping actions and their effects based on a qualitative particle distribution model. This representation enables a robot to plan goal-oriented wiping motions for the prototypical wiping actions of absorbing, collecting and skimming. The particle representation is utilized to simulate the task outcome before execution and infer the real performance afterwards based on haptic perception. This way, the robot is able to estimate the task performance and schedule additional motions if necessary. We evaluate our methods in simulated scenarios, as well as in real experiments with the humanoid service robot Rollin? Justin.","AI reasoning methods, Action and effect representation, Compliant manipulation, Service robotics",Daniel Leidner and Georg Bartels and Wissam Bejjani and Alin Albu-Schäffer and Michael Beetz,https://www.sciencedirect.com/science/article/pii/S0921889018303312,https://doi.org/10.1016/j.robot.2018.11.018,0921-8890,2019,199--216,114,Robotics and Autonomous Systems,"Cognition-enabled robotic wiping: Representation, planning, execution, and interpretation",article,LEIDNER2019199
"Surface descriptors, which represent the surface characteristics of an image numerically, are the fundamental elements in many vision applications. Although traditional surface descriptors that are handcrafted or learned using machine learning techniques have been applied in many different vision applications, some difficulty remains in handling large amounts of noise and variance in 3D data. To resolve this difficulty, recent studies have applied deep learning techniques for the development of surface descriptors. Unlike other techniques based on the complete 3D CAD model or pre-known mesh information of the object, we consider the constraint of the robotic applications in which the information mentioned above is difficult to preload. In this paper, we propose a new 3D surface descriptor that does not require any pre-loaded topological information of the objects or a mesh construction, which may occasionally fail with new or previously unknown objects. Further, we propose a voxel representation that is adaptive to the density of the points, resolving the problem of varying densities of the point cloud data. Finally, we adopt domain-adversarial learning that leads a network to learn the features discriminative for similarity measurements while remaining invariant to different point densities. We gathered approximately 5,000 point-cloud images of objects along with their position and orientation information. We then constructed approximately half a million pairs of point clouds indicating the identical and different parts of the objects, which are labeled as true and false, respectively. The dataset of constructed pairs was used for the learning of 3D surface descriptors using a Siamese convolutional neural network (SCNN) with a domain-adversarial characteristic. The results indicate that the proposed descriptor outperforms other descriptors.","3D local surface descriptor, RGB-D sensor, Point cloud, Convolutional neural network",Ju-Hwan Seo and Dong-Soo Kwon,https://www.sciencedirect.com/science/article/pii/S0921889018307231,https://doi.org/10.1016/j.robot.2019.03.009,0921-8890,2019,64--79,116,Robotics and Autonomous Systems,Learning 3D local surface descriptor for point cloud images of objects in the real-world,article,SEO201964
"Q-learning, a type of reinforcement learning, has gained increasing popularity in autonomous mobile robot path planning recently, due to its self-learning ability without requiring a priori model of the environment. Yet, despite such advantage, Q-learning exhibits slow convergence to the optimal solution. In order to address this limitation, the concept of partially guided Q-learning is introduced wherein, the flower pollination algorithm (FPA) is utilized to improve the initialization of Q-learning. Experimental evaluation of the proposed improved Q-learning under the challenging environment with a different layout of obstacles shows that the convergence of Q-learning can be accelerated when Q-values are initialized appropriately using the FPA. Additionally, the effectiveness of the proposed algorithm is validated in a real-world experiment using a three-wheeled mobile robot.","Flower pollination algorithm, Obstacle avoidance, Path planning, Robot, Q-learning, Robot navigation",Ee Soong Low and Pauline Ong and Kah Chun Cheah,https://www.sciencedirect.com/science/article/pii/S0921889018308285,https://doi.org/10.1016/j.robot.2019.02.013,0921-8890,2019,143--161,115,Robotics and Autonomous Systems,Solving the optimal path planning of a mobile robot using improved Q-learning,article,LOW2019143
"In this paper, an enhanced visual place recognition system is proposed aiming to improve the localization performance of a mobile platform. Our technique takes full advantage of the continuous input image stream in order to provide additional knowledge to the matching functionality. The well-established Bag-of-Visual-Words model is adapted into a hierarchical design that derives the visual information from the full entity of a natural scene into the description, while it additionally preserves the geometric structure of the explored world. Our approach is evaluated as part of a state-of-the-art Simultaneous-Localization-and-Mapping algorithm, and parallelization techniques are exploited utilizing every available hardware module in a low-power device. The implemented algorithm has been tested on several publicly available datasets offering consistently accurate localization results and preventing the majority of redundant computations that the additional geometrical verifications can induce.","Localization, Visual place recognition, Mobile systems, Parallel programming",Loukas Bampis and Antonios Gasteratos,https://www.sciencedirect.com/science/article/pii/S0921889018305293,https://doi.org/10.1016/j.robot.2019.01.004,0921-8890,2019,104--119,113,Robotics and Autonomous Systems,Revisiting the Bag-of-Visual-Words model: A hierarchical localization architecture for mobile systems,article,BAMPIS2019104
"This paper assesses some of the key legal and regulatory questions arising from the integration of physical robotic systems with cloud-based services, also called ?cloud robotics.? The literature on legal and ethical issues in robotics has a strong focus on the robot itself, but largely ignores the background information processing. Conversely, the literature on cloud computing rarely addresses human?machine interactions, which raise distinctive ethical and legal concerns. In this paper, we investigate, from a European legal and regulatory perspective, the growing interdependence and interactions of tangible and virtual elements in cloud robotics environments. We highlight specific problems and challenges in regulating such complex and dynamic ecosystems and explore potential solutions. To illustrate practical challenges, we consider several examples of cloud robotics ecosystems involving multiple parties, various physical devices, and various cloud services. These examples illuminate the complexity of interactions between relevant parties. By identifying pressing legal and regulatory issues in relation to cloud robotics, we hope to inform the policy debate and set the scene for further research.","Cloud, Cloud computing, Cloud robotics, Robots, Cyber?physical system, Law, Technology, Policy, Human?robot interaction, Privacy, Data protection, Product safety",Eduard Fosch-Villaronga and Christopher Millard,https://www.sciencedirect.com/science/article/pii/S092188901930051X,https://doi.org/10.1016/j.robot.2019.06.003,0921-8890,2019,77--91,119,Robotics and Autonomous Systems,Cloud robotics law and regulation: Challenges in the governance of complex and dynamic cyber?physical ecosystems,article,FOSCHVILLARONGA201977
"Battery Electric Vehicle (BEV) has one of the most promising drivetrain technology. However, the BEVs are facing the limited cruising range which generally reduces their share in the automotive market. Velocity profile, acceleration characteristics, road gradients, and drive techniques around curves have significant impacts on the energy consumption of the BEVs. A semi-autonomous ecological driver assistance system to regulate the velocity with energy-efficient techniques is proposed to address the limitation. The main contribution of this paper is the design of a real-time nonlinear model predictive controller with improved inequality constraints handling and economic penalty function to plan the online cost-effective cruising velocity. This system is based on the extended cruise control driver assistance system which controls the longitudinal velocity of the BEV in a safe and energy efficient manner by taking advantage of road slopes, effective drive around curves, and respecting the traffic regulation. A real-time optimisation algorithm is adapted and extended with economic objective function. Instead of the conventional Euclidean norms, deadzone penalty functions are proposed to achieve the economic objectives. In addition, the states inequality constraints are handled based on the proposed soft nonlinear complementarity function aimed to preserve the relaxed complementary slackness to enhance the Pontryagin?s Minimum Principle (PMP) method. Obtained numerical simulation and field experimental results demonstrate the effectiveness of the proposed method for a semi-autonomous electric vehicle in terms of real-time energy-efficient velocity regulation and constraints satisfaction intended to improve the cruising range capability of the BEVs.","Nonlinear Model Predictive Control, Ecological Driver Assistance Systems, Electric vehicles, Optimal Energy Management, Real-time Systems",Seyed Amin Sajadi-Alamdari and Holger Voos and Mohamed Darouach,https://www.sciencedirect.com/science/article/pii/S092188901830191X,https://doi.org/10.1016/j.robot.2018.12.001,0921-8890,2019,291--303,112,Robotics and Autonomous Systems,Nonlinear Model Predictive Control for Ecological Driver Assistance Systems in Electric Vehicles,article,SAJADIALAMDARI2019291
"In off-road environments, energy costs are highly uncertain and variable due to unknown terrains. To plan missions for robots with limited energy storage capacity, a robot?s reachable set must be determined. This work presents a novel approach for learning reachable sets based on data collected during a mission. Leveraging the authors? previous work, a spatial energy map of an unknown environment, built with data collected by a robot, can be used to compute a chance constrained reachable set (CCRS) based on a user-defined confidence level. Simulations demonstrate that as a robot collects more data on an energy map, the true positive rate of a computed CCRS improves significantly while the false positive rate remains low, implying that a robot?s reachability can be robustly determined for use in future missions.","Reachability, Spatial energy mapping, Gaussian process regression, Planning under uncertainty",Michael Quann and Lauro Ojeda and William Smith and Denise Rizzo and Matthew Castanier and Kira Barton,https://www.sciencedirect.com/science/article/pii/S0921889018310212,https://doi.org/10.1016/j.robot.2019.05.009,0921-8890,2019,1--12,119,Robotics and Autonomous Systems,Chance constrained reachability in environments with spatially varying energy costs,article,QUANN20191
"The global localization problem concerns situations when a map of the environment is known but there is no initial guess of the agent position. Whereas the ability to perform global localization is required in many practical situations, it is still an open problem, particularly if the agent requires to find an accurate estimate of its 3-D pose. In this article, we describe PlaneLoc, a novel probabilistic approach to 3-D global localization, which integrates multiple local cues to construct a probability distribution that describes the likelihood of the agent pose. This framework enables to incorporate various types of localization cues but we demonstrate its feasibility using segmented planes abstracted from RGB-D data. We use multiple triplets of planar segments to generate candidate probability distribution and employ it to find the most probable pose with respect to a global map of planar segments. The PlaneLoc implementation uses the ORB-SLAM2 system that serves as visual odometry and makes it possible to generate observation in a form of sets of local segments online. The proposed approach can be used for global localization with a known map or for loop closing and re-localization in Simultaneous Localization and Mapping. The implemented system is validated in experiments using publicly available RGB-D data sets, including our own data set acquired specifically for testing localization methods based on planar features.","Global localization, SLAM, Planar segments, RGB-D data",Jan Wietrzykowski and Piotr Skrzypczy?ski,https://www.sciencedirect.com/science/article/pii/S0921889018303701,https://doi.org/10.1016/j.robot.2019.01.008,0921-8890,2019,160--173,113,Robotics and Autonomous Systems,PlaneLoc: Probabilistic global localization in 3-D using local planar features,article,WIETRZYKOWSKI2019160
"Scene modeling is very crucial for robots that need to perceive, reason about and manipulate the objects in their environments. In this paper, we adapt and extend Boltzmann Machines (BMs) for contextualized scene modeling. Although there are many models on the subject, ours is the first to bring together objects, relations, and affordances in a highly-capable generative model. For this end, we introduce a hybrid version of BMs where relations and affordances are incorporated with shared, tri-way connections into the model. Moreover, we introduce a dataset for relation estimation and modeling studies. We evaluate our method in comparison with several baselines on object estimation, out-of-context object detection, relation estimation, and affordance estimation tasks. Moreover, to illustrate the generative capability of the model, we show several example scenes that the model is able to generate, and demonstrate the benefits of the model on a humanoid robot. The code and the dataset are publicly made available at: https://github.com/bozcani/COSMO.","Scene modeling, Context, Boltzmann Machines",?lker Bozcan and Sinan Kalkan,https://www.sciencedirect.com/science/article/pii/S0921889018303427,https://doi.org/10.1016/j.robot.2018.12.009,0921-8890,2019,132--148,113,Robotics and Autonomous Systems,COSMO: Contextualized scene modeling with Boltzmann Machines,article,BOZCAN2019132
"This paper addresses the problem of Human-Aware Navigation (HAN), using multi camera sensors to implement a vision-based person tracking system. The main contributions of this paper are as follows: a novel and efficient Deep Learning person detection and a standardization of human-aware constraints. In the first stage of the approach, we propose to cascade the Aggregate Channel Features (ACF) detector with a deep Convolutional Neural Network (CNN) to achieve fast and accurate Pedestrian Detection (PD). Regarding the human awareness (that can be defined as constraints associated with the robot?s motion), we use a mixture of asymmetric Gaussian functions, to define the cost functions associated to each constraint. Both methods proposed herein are evaluated individually to measure the impact of each of the components. The final solution (including both the proposed pedestrian detection and the human-aware constraints) is tested in a typical domestic indoor scenario, in four distinct experiments. The results show that the robot is able to cope with human-aware constraints, defined after common proxemics and social rules.","Pedestrian detection, Convolutional Neural Network, Human-Aware Navigation",André Mateus and David Ribeiro and Pedro Miraldo and Jacinto C. Nascimento,https://www.sciencedirect.com/science/article/pii/S0921889017306784,https://doi.org/10.1016/j.robot.2018.12.007,0921-8890,2019,23--37,113,Robotics and Autonomous Systems,Efficient and robust Pedestrian Detection using Deep Learning for Human-Aware Navigation,article,MATEUS201923
"In this work we propose an online trajectory planner for humanoid walking. It is based on the observer trajectory planning problem where the moving observer (humanoid) should maneuver optimally to better estimate the position of the target (door). Thus, the uncertainty of the door location within the humanoid?s field of view is considered. In particular, we propose a terminal stochastic controller that recursively applies the Unscented Kalman Filter (UKF) over a time horizon for evaluating a set of objective functions. The aim is to minimize the estimation error of the door location while maintaining it inside the humanoid?s field of view, and avoiding collisions between the humanoid and the door frame. The output is the sequence of walking velocity references. In addition, we compute the humanoid?s odometric localization based on the UKF to provide the instantaneous humanoid location, which is an input to the trajectory planner. We validate the stochastic controller with a set of experiments in a scenario with doors using a real humanoid NAO, equipped with an RGB-D sensor mounted on its head.1 1The source code in ROS C++ is available at: https://sites.google.com/site/gustavoarechavaleta/sochum.","Humanoid walking, Optimal observer planning, Stochastic optimal control",Alvaro Paz and Gustavo Arechavaleta,https://www.sciencedirect.com/science/article/pii/S0921889018306377,https://doi.org/10.1016/j.robot.2019.01.014,0921-8890,2019,61--72,115,Robotics and Autonomous Systems,Online optimization of humanoid walking trajectories for passing through a door,article,PAZ201961
"This paper aims at proposing a comprehensive control framework designed for cooperative transportation of a heavy load by two humanoid robots. First, a simplified dynamic model of the cooperative task is developed and the system stability is rigorously analyzed. Next, a centralized controller is formulated, this formulation provides an optimal control of the system by considering the robots dynamical stability while satisfying the robot?object?robot constraints. Finally, the controller is integrated with an arm controller and a local planner module forming a complete framework for cooperative transportation tasks. The approach is thoroughly analyzed and validated in simulation, and experiments are carried out on a team of two Nao humanoid robots transporting a range of objects placed on a small table. The experimental results pointed out the robustness of the approach as the robots successfully accomplished the transportation tasks in a stable way, moreover the transported objects masses were up to half the mass of one of the robot. Besides increasing the robot payload, some of the transported objects are relatively large and it is simply impossible for a single robot to transport them.","Humanoid robot, Control, Legged locomotion, Robot?robot cooperation",Louis Hawley and Wael Suleiman,https://www.sciencedirect.com/science/article/pii/S0921889018303543,https://doi.org/10.1016/j.robot.2019.02.003,0921-8890,2019,1--16,115,Robotics and Autonomous Systems,Control framework for cooperative object transportation by two humanoid robots,article,HAWLEY20191
"Robotic applications are commonly used in industrial automation systems. Such systems are often comprised of a series of equipment, including robotic arms, conveyors, a workspace, and fixtures. While each piece of equipment may be calibrated with the highest precision, their alignment in relation to each other is an important issue in defining the accuracy of the system. Currently, a variety of complex automated and manual methods are used to align a robotic arm to a workspace. These methods often use either expensive equipment or are slow and skill-dependent. This paper presents a novel low-cost method for aligning an industrial robot to its workcell at 6 degrees of freedom (DoF). The solution is new, simple and easy to use and intended for the SMEs dealing with low volume, high complexity automated systems. The proposed method uses three dial indicators mounted to a robot end effector and a fixed measurement cube, positioned on a workcell. The robot is pre-programmed for a procedure around the cube. The changes on the dial indicators are used to calculate the misalignment between the robot and the workcell. Despite simplicity of the design, the solution is supported with complex real-time mathematical calculations and proven to identify and eliminate misalignment up to 3 mm and 5 degrees to an accuracy of 0.003 mm and 0.002 degrees: much higher than the precision required for a conventional industrial robot. In this article, the authors describe a proposed solution, validate the computation both theoretically and through a laboratory test rig and simulation.","Robot alignment, Automated systems, Robot calibration, Forward and inverse modelling",Joseph Millington and Radmehr P Monfared and Daniel Vera,https://www.sciencedirect.com/science/article/pii/S092188901830527X,https://doi.org/10.1016/j.robot.2019.01.015,0921-8890,2019,144--154,114,Robotics and Autonomous Systems,Innovative mechanism to identify robot alignment in an automation system,article,MILLINGTON2019144
"Generally, most grasp detection models follow the similar frameworks as that in object detection, which use the convolutional neural network to regress the grasp parameters directly. However, grasp detection and object detection are actually different, for the ground truths in object detection are unique while that in grasp detection are not exhaustive. A predicted grasp could still be applicable despite it does not coincide well with ground truth. In this paper, a novel grasp detection model is constructed to make a fairer evaluation on grasp candidate. Instead of using isolated ground truths, the grasp path is introduced to reveal the possible consequent distribution of ground truths. The grasp candidate is first mapped to grasp path, generating the mapped grasp, and the bias between them works as the estimated error for back-propagation. Experiments deployed on grasping dataset as well as real-world scenarios show that our proposed method could improve the detection accuracy. In addition, it can be well-generalized to detect unseen objects.","Multi-grasp detection, Grasp path, Convolutional neural network",Lu Chen and Panfeng Huang and Zhongjie Meng,https://www.sciencedirect.com/science/article/pii/S0921889018307346,https://doi.org/10.1016/j.robot.2019.01.009,0921-8890,2019,94--103,113,Robotics and Autonomous Systems,Convolutional multi-grasp detection using grasp path for RGBD images,article,CHEN201994
"Sampling gas distributions by robotic platforms in order to find gas sources is an appealing approach to alleviate threats for a human operator. Different sampling strategies for robotic gas exploration exist. In this paper we investigate the benefit that could be obtained by incorporating physical knowledge about the gas dispersion. By exploring a gas diffusion process using a multi-robot system. The physical behavior of the diffusion process is modeled using a Partial Differential Equation (PDE) which is integrated into the exploration strategy. It is assumed that the diffusion process is driven by only a few spatial sources at unknown locations with unknown intensity. The objective of the exploration strategy is to guide the robots to informative measurement locations and by means of concentration measurements estimate the source parameters, in particular, their number, locations and magnitudes. To this end we propose a probabilistic approach towards PDE identification under sparsity constraints using factor graphs and a message passing algorithm. Moreover, message passing schemes permit efficient distributed implementation of the algorithm, which makes it suitable for a multi-robot system. We designed an experimental setup that allows us to evaluate the performance of the exploration strategy in hardware-in-the-loop experiments as well as in experiments with real ethanol gas under laboratory conditions. The results indicate that the proposed exploration approach accelerates the identification of the source parameters and outperforms systematic sampling.","Robotic exploration, Gas source localization, Multi-agent-system, Partial differential equation, Mobile robot olfaction, Sparse Bayesian learning, Factor graph, Message passing",Thomas Wiedemann and Dmitriy Shutin and Achim J. Lilienthal,https://www.sciencedirect.com/science/article/pii/S0921889018303816,https://doi.org/10.1016/j.robot.2019.03.014,0921-8890,2019,66--79,118,Robotics and Autonomous Systems,Model-based gas source localization strategy for a cooperative multi-robot system?A probabilistic approach and experimental validation incorporating physical knowledge and model uncertainties,article,WIEDEMANN201966
"We present a robot vision approach to deformable object classification, with direct application to autonomous service robots. Our approach is based on the assumption that continuous perception provides robots with greater visual competence for deformable objects interpretation and classification. Our approach classifies the category of clothing items by continuously perceiving the dynamic interactions of the garment?s material and shape as it is being picked up. For this, we extract continuously visual features of a RGB-D video sequence and we fuse features by means of the Locality Constrained Group Sparse Representation (LGSR) algorithm. To evaluate the performance of our approach, we created a fully annotated database featuring 150 garment videos in random configurations. Experiments demonstrate that by continuously observing an object deform, our approach achieves a classification score of 66.7%, outperforming state-of-the-art approaches by a ?27.3% increase.","Deformable object classification, Continuous perception, Robot vision",Luz Martínez and Javier Ruiz-del-Solar and Li Sun and J. Paul Siebert and Gerardo Aragon-Camarasa,https://www.sciencedirect.com/science/article/pii/S0921889019300417,https://doi.org/10.1016/j.robot.2019.05.010,0921-8890,2019,220--230,118,Robotics and Autonomous Systems,Continuous perception for deformable objects understanding,article,MARTINEZ2019220
"In order to synthesize controllers for wheeled mobile robots (WMRs), some design techniques are usually based on the assumption that the set of kinematic constraints are fully satisfied. Nevertheless, when a WMR moves on a trajectory, phenomena such as slipping, skidding and deformability (also related to flexibility) can cause violation of kinematic constraints as well as system instability. Previous research has shown that to make the tracking error converge toward a small neighborhood containing the origin, in WMRs that moving at different speeds, it can be used an outer closed-loop scheme based on an auxiliary control law with aid of estimations of the slipping and skidding variations. But, although these previous works use slipping/skidding variations, the flexibility parameter is not taken into account to compute the auxiliary control law, making the outer closed-loop less robust for different flexibility values in the dynamic. The work reported here proposes a control scheme fully influenced by the flexibility parameter and whose robustness will be based on an auxiliary control law that uses a nonlinear function in terms of flexibility and slipping/skidding variations. The results obtained from experimental and simulations tests will show that the flexible auxiliary control law not only ensures that the error converges to a small neighborhood close to origin but also it is more insensitive to the speed increasing of the WMR.","Slipping, Skidding, Flexibility, Singular perturbation, Wheeled mobile robots, Trajectory tracking",C.A. {Peña Fernández} and J.J.F. Cerqueira and A.M.N. Lima,https://www.sciencedirect.com/science/article/pii/S0921889018304986,https://doi.org/10.1016/j.robot.2019.05.007,0921-8890,2019,231--250,118,Robotics and Autonomous Systems,Nonlinear trajectory tracking controller for wheeled mobile robots by using a flexible auxiliary law based on slipping and skidding variations,article,PENAFERNANDEZ2019231
"In this paper, a hybrid Voronoi-based ant colony optimization (V-ACO) technique for multiple autonomous marine vehicles (AMVs) is proposed to solve adaptive ocean sampling problem. The Voronoi-based scheme utilizes Voronoi partition with tournament selection method that enables more Voronoi edges lie in higher scientific interest regions. This scheme is then combined with ant colony optimization (ACO) using modified heuristic function, to find collision-free optimal trajectories for multiple AMVs to collect ocean measurements. For comparison, conventional ACO, rapidly-exploring random tree star (RRT*) and Dijkstra?s algorithm are also applied and tested for adaptive ocean sampling. Results of simulation tests specifically highlight the effectiveness and robustness of the proposed V-ACO path planner in generating trajectories of multi-AMVs that maximize data collection for adaptive ocean sampling in high scientific interest areas while considering specified mission time, inter-vehicle and obstacles avoidance constraints. Furthermore, field experiments validate the capability of the proposed V-ACO path planner in finding optimal solutions for adaptive ocean sampling.","Path planning, Multiple autonomous marine vehicles, Adaptive ocean sampling, Voronoi diagram, Ant colony optimization",Chengke Xiong and Danfeng Chen and Di Lu and Zheng Zeng and Lian Lian,https://www.sciencedirect.com/science/article/pii/S0921889018304469,https://doi.org/10.1016/j.robot.2019.02.002,0921-8890,2019,90--103,115,Robotics and Autonomous Systems,Path planning of multiple autonomous marine vehicles for adaptive sampling using Voronoi-based ant colony optimization,article,XIONG201990
"Autonomous navigation of mobile robots is often based on information from a variety of heterogeneous sensors; hence, extrinsic sensor calibration is a fundamental step in the fusion of such information. In this paper, we address the problem of extrinsic calibration of a radar?LiDAR?camera sensor system. This problem is primarily challenging due to sparse informativeness of radar measurements. Namely, radars cannot extract rich structural information about the environment, while their lack of elevation resolution, that is nevertheless accompanied by substantial elevation field of view, introduces uncertainty in the origin of the measurements. We propose a novel calibration method which involves a special target design and two-step optimization procedure to solve the aforementioned challenges. First step of the optimization is minimization of a reprojection error based on an introduced point?circle geometric constraint. Since the first step is not able to provide reliable estimates of all the six extrinsic parameters, we introduce a second step to refine the subset of parameters with high uncertainty. We exploit a pattern discovered in the radar cross section estimation that is correlated to the missing elevation angle. Additionally, we carry out identifiability analysis based on the Fisher Information Matrix to show minimal requirements on the dataset and to verify the method through simulations. We test the calibration method on a variety of sensor configurations and address the problem of radar vertical misalignment. In the end, we show via extensive experiment analysis that the proposed method is able to reliably estimate all the six parameters of the extrinsic calibration.","Sensor calibration, Radar, LiDAR, Camera, Radar cross section",Juraj Per?i? and Ivan Markovi? and Ivan Petrovi?,https://www.sciencedirect.com/science/article/pii/S0921889018301994,https://doi.org/10.1016/j.robot.2018.11.023,0921-8890,2019,217--230,114,Robotics and Autonomous Systems,Extrinsic 6DoF calibration of a radar?LiDAR?camera system enhanced by radar cross section estimates evaluation,article,PERSIC2019217
"This paper presents semantic-based methods for the understanding of human movements in robotic applications. To understand human movements, robots need to first, recognize the observed or demonstrated human activities, and secondly, learn different parameters to execute an action or robot behavior. In order to achieve that, several challenges need to be addressed such as the automatic segmentation of human activities, identification of important features of actions, determine the correct sequencing between activities, and obtain the correct mapping between the continuous data and the symbolic and semantic interpretations of the human movements. This paper aims to present state-of-the-art semantic-based approaches, especially the new emerging approaches that tackle the challenges of finding generic and compact semantic models for the robotics domain. Finally, we will highlight potential breakthroughs and challenges for the next years such as achieving scalability, better generalization, compact and flexible models, and higher system accuracy.","Semantic representations, Understanding human movements, Human activity recognition, Robot action execution, Intelligent systems",Karinne Ramirez-Amaro and Yezhou Yang and Gordon Cheng,https://www.sciencedirect.com/science/article/pii/S0921889018303932,https://doi.org/10.1016/j.robot.2019.05.013,0921-8890,2019,31--50,119,Robotics and Autonomous Systems,A survey on semantic-based methods for the understanding of human movements,article,RAMIREZAMARO201931
"In this paper, a voltage-based sliding mode control (SMC) is presented to control the position of n rigid-link flexible-joint (RLFJ) serial robot manipulator in the presence of structured and unstructured uncertainties. In addition to good performance, the proposed method has three attracting properties: First, it has been developed for a class of RLFJ robot manipulators with a n degree of freedom (DOF). Second, the design process includes all the manipulator dynamical equations, the mechanical and the electrical part of the actuator. Third, the simple structure and low volume of computing make practical implementation possible. Using the idea of the independent joint control strategy, the system dynamic equations are decomposed into n independent subsystems. For each subsystem, three sliding surfaces are defined. Then using these sliding surfaces, control input laws are designed for all subsystems simultaneously. It is proved that the proposed method can guarantee the asymptotic stability of each subsystems and the global asymptotic stability of the closed-loop system in the presence of uncertainties. The results of simulations, as well as experimental results produced using MATLAB/Simulink external mode control on a flexible-joint electrically driven robot manipulator, illustrate high efficiency of the proposed control schemes.","Robot manipulator, Joint flexibility, Sliding mode control, Voltage-based, Structured uncertainty, Unstructured uncertainty",Saeed zaare and Mohammad Reza Soltanpour and Mazda Moattari,https://www.sciencedirect.com/science/article/pii/S0921889018309916,https://doi.org/10.1016/j.robot.2019.05.014,0921-8890,2019,204--219,118,Robotics and Autonomous Systems,Voltage based sliding mode control of flexible joint robot manipulators in presence of uncertainties,article,ZAARE2019204
"Target searching in an unknown environment is a traditional research issue in the multiagent area. In some real cases, the agents do not only discover the targets; instead, they have subsequent tasks that must be completed before a deadline. In this paper, these cases are abstracted as the agents searching for target locations in an unknown environment and then occupying these target locations within a limited time. The agents can obtain rewards by occupying the target locations, and the goal of this problem is to maximize net income, defined as total reward minus the moving cost of the agents. This problem can be transformed into the traditional problems, and then be solved by previous related algorithms. However, this approach is not optimal. In this paper, we present a method that combines previous algorithms and a decision-making algorithm. The experiments demonstrate that the method containing our decision-making algorithm can lead to higher net income than simply using previous algorithms.","Multiagent, Target searching and occupancy, Decision-making, Unknown environment",Fuhan Yan and Kai Di and Jiuchuan Jiang and Yichuan Jiang and Hui Fan,https://www.sciencedirect.com/science/article/pii/S0921889018306882,https://doi.org/10.1016/j.robot.2019.01.017,0921-8890,2019,41--56,114,Robotics and Autonomous Systems,Efficient decision-making for multiagent target searching and occupancy in an unknown environment,article,YAN201941
"This paper presents an innovative application of the hybrid model predictive control (HMPC) scheme to optimally regulate the intelligent vehicle longitudinal velocity. For autonomous velocity regulation, the intelligent vehicle needs to be operated in two distinct modes (drive and brake) and because of the mode-dependent constraints on accelerations and decelerations by considering the comfort of passengers, the intelligent vehicle longitudinal dynamics control process can be regarded as a constrained hybrid dynamical system. Thus, in this study, the intelligent vehicle longitudinal dynamics is approximated as a two-mode discrete-time mixed logical dynamical (MLD) system. Using this approximation, a hybrid model predictive controller, which allows us to optimize the switching sequences of the operation modes (binary control inputs) and the torques acted on the wheels (continuous control inputs), is tuned based on online mixed-integer quadratic programming. Numerical simulation analysis is conducted for a sport utility vehicle to demonstrate the effectiveness of the proposed control method. Finally, the explicit representation of the HMPC is computed to control the intelligent vehicle in real-time, and the experimental results are presented to show the applicability of the proposed controller.","Intelligent vehicle, Longitudinal dynamics, Hybrid system, Mixed logical dynamical model, Experimental tests",Xiaoqiang Sun and Yingfeng Cai and Shaohua Wang and Xing Xu and Long Chen,https://www.sciencedirect.com/science/article/pii/S0921889018306122,https://doi.org/10.1016/j.robot.2018.11.020,0921-8890,2019,190--200,112,Robotics and Autonomous Systems,Optimal control of intelligent vehicle longitudinal dynamics via hybrid model predictive control,article,SUN2019190
"Olfactory telerobotics consists in augmenting the sensing capabilities of a conventional teleoperated mobile-robot to acquire information about the surrounding air (i.e. smell, wind-speed, etc.) in addition to the usual audio and video streams. Conceptually, this allows for new and improved applications, among which the most relevant are those related to gas-source localization (GSL). That is, searching through telerobotics for one or multiple gas-emission sources, such as hazardous gas-leaks in industrial facilities or the CO2 signature of trapped survivors in collapsed buildings. Notwithstanding, both the needed sensing-technology for the robot as well as the olfactory feedback-interfaces for the human operator are relatively recent, and might still not meet all the requirements of such applications. This work is therefore meant to assess the current feasibility of olfactory telerobotics to address real-world GSL problems, and accordingly, to determine which aspects play the most important role for its success, or otherwise, might be constraining its usefulness. We have collected to this end a dataset composed of 60 experiments where volunteer operators had to locate and identify hidden gas-source among several identical candidates with an olfaction-enabled robot and under realistic environmental conditions (i.e. uncontrolled and natural gas-distributions). We analyse this data to determine the overall search accuracy and intuitiveness of the system, considering that none of the operators had any prior experience with it, and study the importance of the employed sensory-feedback and how they were employed during the experiments. We finally report different findings, from which we highlight that the tested telerobotics system allowed the operators to correctly identify the source in 3 out of 4 attempts, and that the underlying human search-strategy appears to be a probabilistic-driven behaviour that favours semantic and visual information over the robot?s gas and wind measurements.","Mobile robotics, Telerobotics, Artificial olfaction, Gas source localization, Electronic nose",Andres Gongora and Javier Gonzalez-Jimenez,https://www.sciencedirect.com/science/article/pii/S0921889018306523,https://doi.org/10.1016/j.robot.2018.12.008,0921-8890,2019,1--9,113,Robotics and Autonomous Systems,Olfactory telerobotics. A feasible solution for teleoperated localization of gas sources?,article,GONGORA20191
"This paper is about detecting and counting the passengers of a tracking vehicle using on-car monocular vision. By having a model of nearby vehicle occupants, intelligent reasoning systems of autonomous cars will be provided with this additional knowledge needed in emergency situations such as those that many philosophers have recently raised. The on-road Vehicle PassengEr Detection (ViPED) system is based on the human perception model in terms of spatio-temporal reasoning, namely the slight movements of passenger shape silhouettes inside the cabin. The main challenges we face are the low light conditions of the cabin (no feature points), the subtle non-rigid motions of the occupants (possible artifactual transitions), and the puzzling discrimination problem of back or front seat occupants (lack of depth information inside the cabin). To overcome these challenges, we first track the detected car windshield and find the optimal affine warp. The registered windshield images are preprocessed in order to extract a feature matrix, which serves as input to a Convolutional Neural Network (CNN) for inferring the number and position of passengers. We demonstrate that our low-cost sensor system is able to detect in most cases successfully all the passengers in preceding moving vehicles at various distances and occupancies. Metrics and datasets are included for possible community future work on this new challenging task.","Autonomous vehicles, Safety systems, Driver information systems, ADAS",Angelos Amanatiadis and Evangelos Karakasis and Loukas Bampis and Stylianos Ploumpis and Antonios Gasteratos,https://www.sciencedirect.com/science/article/pii/S0921889018302045,https://doi.org/10.1016/j.robot.2018.12.002,0921-8890,2019,282--290,112,Robotics and Autonomous Systems,ViPED: On-road vehicle passenger detection for autonomous vehicles,article,AMANATIADIS2019282
"Visual SLAM is a computationally expensive task, with a complexity that grows unbounded as the size of the explored area increases. This becomes an issue when targeting embedded applications such as on-board localization on Micro Aerial Vehicles (MAVs), where real-time execution is mandatory and computational resources are a limiting factor. The herein proposed method introduces a covisibility-graph based map representation which allows a visual SLAM system to execute with a complexity that does not depend on the size of the map. The proposed structure allows to efficiently select locally relevant portions of the map to be optimized in such a way that the results resemble performing a full optimization on the whole trajectory. We build on S-PTAM (Stereo Parallel Tracking and Mapping), yielding an accurate and robust stereo SLAM system capable to work in real-time under limited hardware constraints such as those present in MAVs. The developed SLAM system in assessed using the EuRoC dataset. Results show that covisibility-graph based map culling allows the SLAM system to run in real-time even on a low-resource embedded computer. The impact of each SLAM task on the overall system performance is analyzed in detail and the SLAM system is compared with state-of-the-art methods to validate the presented approach.","Stereo SLAM, Constrained covisibility, Loop closure, Real-time embedded SLAM, MAVs",Gastón Castro and Matías A. Nitsche and Taihú Pire and Thomas Fischer and Pablo {De Cristóforis},https://www.sciencedirect.com/science/article/pii/S0921889018304500,https://doi.org/10.1016/j.robot.2019.03.015,0921-8890,2019,192--205,116,Robotics and Autonomous Systems,Efficient on-board Stereo SLAM through constrained-covisibility strategies,article,CASTRO2019192
"When working in dynamic environment, traditional SLAM framework performs poorly due to interference from dynamic objects. By taking advantages of deep learning in object detection, a semantic simultaneous localization and mapping framework named Dynamic-SLAM is proposed, in order to solve the problem of SLAM in dynamic environment. First, based on the convolutional neural network, an SSD object detector which combines prior knowledge is constructed to detect dynamic objects in the newly detection thread at semantic level. Then, in view of low recall rate of the existing SSD object detection network, a missed detection compensation algorithm based on the speed invariance in adjacent frames is proposed, which greatly improves the recall rate of detection. Finally, a feature-based visual SLAM system is constructed, which processes the feature points of dynamic objects through a selective tracking algorithm in the tracking thread, to significantly reduce the error of pose estimation caused by incorrect matching. The recall rate of the system is increased from 82.3% to 99.8% compared with the original SSD network. Several experiments show that the localization accuracy of Dynamic-SLAM is higher than the state-of-the-art systems. The system successfully localizes and constructs an accurate environmental map in real-world dynamic environment by using a mobile robot. In sum, our experimental demonstrations verify that Dynamic-SLAM shows improved accuracy and robustness in robot localization and mapping comparing to the state-of-the-art SLAM system in dynamic environment.","Simultaneous localization and mapping (SLAM), Semantics, Object detection, Dynamic environment",Linhui Xiao and Jinge Wang and Xiaosong Qiu and Zheng Rong and Xudong Zou,https://www.sciencedirect.com/science/article/pii/S0921889018308029,https://doi.org/10.1016/j.robot.2019.03.012,0921-8890,2019,1--16,117,Robotics and Autonomous Systems,Dynamic-SLAM: Semantic monocular visual localization and mapping based on deep learning in dynamic environment,article,XIAO20191
"Robots operating in populated environments, such as hospitals, office environments or airports, encounter a large variety of people with some of them having an advanced need for cautious interaction because of their advanced age or motion impairments. To provide appropriate assistance and support robot helpers require the ability to recognize people and their potential requirements. In this article, we present a people detection framework that distinguishes people according to the mobility aids they use. Our framework uses a deep convolutional neural network for detecting people in image data. For human-aware robots it is necessary to know where people are in a 3D world reference frame instead of only locating them in a 2D image, therefore we add a 3D centroid regression output to the network to predict the Cartesian position of people. We further use a probabilistic class, position and velocity tracker to account for false detections and occlusions. Our framework comes in two variants: The depth only variant targets high privacy demands, while the RGB only framework provides improved detection performance for non-critical applications. Both variants do not require additional geometric information about the environment. We demonstrate our approach using a dedicated dataset acquired with the support of a mobile robotic platform. The dataset contains five classes: pedestrian, person in wheelchair, pedestrian pushing a person in a wheelchair, person using crutches and person using a walking frame. Our framework achieves an mAP of 0.87 for RGB and 0.79 for depth images at a detection distance threshold of 0.5m on our dataset, with a runtime of 53ms per image. The annotated dataset is publicly available and our framework is made open source as a ROS people detector.","Mobile robot, Service robotics, Convolutional neural networks, Object detection, Object tracking, People detection, Multi-class detection",Marina Kollmitz and Andreas Eitel and Andres Vasquez and Wolfram Burgard,https://www.sciencedirect.com/science/article/pii/S0921889018303257,https://doi.org/10.1016/j.robot.2019.01.011,0921-8890,2019,29--40,114,Robotics and Autonomous Systems,Deep 3D perception of people and their mobility aids,article,KOLLMITZ201929
"Affordances play a crucial role in robotics since they allow developing truly autonomous robots, which can freely explore and interact with the environment. Most of the existing approaches for analyzing affordances in a scene consider only one or few types of affordance, e.g., grasping points, object manipulation or locomotion. In many cases only whole objects are considered. In our study we include in total 12 affordances of object-related, manipulation and locomotion affordances, considering affordances of both objects and/or their parts. We design a system that can densely predict affordances given only a single 2D RGB image. For this, we propose a method that transfers object class labels to affordances. This enables us to train convolutional neural networks, a PSPNet-based network and a U-Net-style network, to directly predict affordances from an image using a selective binary cross entropy loss function. The method is able to handle (potentially multiple) affordances of objects and their parts in a pixel-wise manner even in the case of incomplete data. We perform qualitative as well as quantitative evaluations with simulated and real data including robot experiments. In general, we find that frequent affordances are recognized with a substantial fraction of correctly assigned pixels, while this is harder for infrequent affordances and small objects. In addition, we demonstrate that our method performs better than a recent competitive approach. As the proposed method operates on 2D images, it is easier to implement than competing 3D methods and it could therefore more easily provide useful affordance estimates for robotic actions as demonstrated experimentally.",,Timo Lüddecke and Tomas Kulvicius and Florentin Wörgötter,https://www.sciencedirect.com/science/article/pii/S0921889018309990,https://doi.org/10.1016/j.robot.2019.05.005,0921-8890,2019,92--107,119,Robotics and Autonomous Systems,Context-based affordance segmentation from 2D images for robot actions,article,LUDDECKE201992
"Control of a robotic arm using a brain?computer interface (BCI) for reach and grasp activities is one of the most fascinating applications for some severely disabled people, which is especially challenging for the non-invasive BCIs based on electroencephalography (EEG). In this paper, shared control is applied to realize the control of a dexterous robotic arm with a motor imagery-based (MI-based) BCI and computer vision guidance. With the utilization of the shared control, the subjects just need to move the robotic arm by performing only two different mental tasks to the surrounding area of the target. The accurate pose of the target is estimated by a depth camera equipped in the robot system. Once the endpoint of the robotic arm enters the pre-defined vision-guided region, the robotic arm will grasp the target autonomously. Five healthy and inexperienced subjects participated in the online experiments and the average success rate is above 70% even with no specific user training. The results show that the shared control can make the robotic arm accomplish the complex tasks (reach and grasp) with the simple two-class MI-based BCIs.","Brain?computer interface, Motor imagery, Computer vision, Shared control, Robotic arm",Yang Xu and Cheng Ding and Xiaokang Shu and Kai Gui and Yulia Bezsudnova and Xinjun Sheng and Dingguo Zhang,https://www.sciencedirect.com/science/article/pii/S0921889018306080,https://doi.org/10.1016/j.robot.2019.02.014,0921-8890,2019,121--129,115,Robotics and Autonomous Systems,Shared control of a robotic arm using non-invasive brain?computer interface and computer vision guidance,article,XU2019121
"This paper investigates cooperative control of vehicle platoons, focusing on the effect of medium access control (MAC) protocol and unreliable measurement on acceleration information. A Markov chain is used to describe the randomness in vehicular network access under a MAC protocol; a reduced-order observer is proposed to estimate the relative acceleration of neighboring vehicles. Based on stochastic system techniques, a series of sufficient conditions for the existence of the observer-based controller are given in the form of backward recursive Riccati Difference Equations (RDE). A controller?estimator design algorithm is derived to determine the controller and observer gains with which the disturbance of the preceding vehicle acceleration can be eliminated and string stability and zero steady-state velocity error performance can be guaranteed. Both numerical simulations and experiments with laboratory-scale Arduino cars are given to verify the effectiveness and practicability of the proposed algorithm.","Vehicle platoons control, Vehicular ad hoc networks, Markov MAC protocol, Observer-based control, String stability, Zero steady-state velocity errors",Shixi Wen and Ge Guo,https://www.sciencedirect.com/science/article/pii/S0921889018300939,https://doi.org/10.1016/j.robot.2019.02.006,0921-8890,2019,28--39,115,Robotics and Autonomous Systems,Observer-based control of vehicle platoons with random network access,article,WEN201928
"The objective of this paper is to present a full-stack, real-time motion planning framework for kinodynamic robots and then show how it is applied and demonstrated on a physical quadrotor system operating in a laboratory environment. The proposed framework utilizes an offline?online computation paradigm, neighborhood classification through machine learning, sampling-based motion planning with an optimal cost distance metric, and trajectory smoothing to achieve real-time planning for aerial vehicles. This framework accounts for dynamic obstacles with an event-based replanning structure and a locally reactive control layer that minimizes replanning events. The approach is demonstrated on a quadrotor navigating moving obstacles in an indoor space and stands as, arguably, one of the first demonstrations of full-online kinodynamic motion planning, with execution cycles of 3 Hz to 5 Hz. For the quadrotor, a simplified dynamics model is used during the planning phase to accelerate online computation. A trajectory smoothing phase, which leverages the differentially flat nature of quadrotor dynamics, is then implemented to guarantee a dynamically feasible trajectory.","Motion planning, Kinodynamic, Real-time, Obstacle avoidance, Quadrotor, Unmanned aerial vehicle, Machine learning, Human?robot interaction",Ross E. Allen and Marco Pavone,https://www.sciencedirect.com/science/article/pii/S0921889017308692,https://doi.org/10.1016/j.robot.2018.11.017,0921-8890,2019,174--193,115,Robotics and Autonomous Systems,A real-time framework for kinodynamic planning in dynamic environments with application to quadrotor obstacle avoidance,article,ALLEN2019174
"In this paper, a complete solution for autonomous landing of a low-cost quadrotor on a moving platform is presented. First, the dynamic model of the quadrotor is described and simplified for landing task. Second, a novel landing pad associated with detection algorithm is designed for robust detection by a low-cost monocular camera. In order to deal with mirror effect and occasional misidentification, a 3D point cluster algorithm for relative position estimation is proposed. Third, using the backstepping approach, an adaptive position controller is designed to calculate the desired attitude for attitude loop. The overall stability of the position loop is proven by a Lyapunov method. Meanwhile, some landing strategies are presented to achieve a safe and stable landing task. Finally, the low-cost system architecture of the quadrotor and the experiment results are both demonstrated to showcase the effectiveness of the proposed method.","Autonomous landing, Low-cost quadrotor, Backstepping method",Yuhua Qi and Jiaqi Jiang and Jin Wu and Jianan Wang and Chunyan Wang and Jiayuan Shan,https://www.sciencedirect.com/science/article/pii/S0921889019300508,https://doi.org/10.1016/j.robot.2019.05.004,0921-8890,2019,64--76,119,Robotics and Autonomous Systems,Autonomous landing solution of low-cost quadrotor on a moving platform,article,QI201964
"This document details the implementation and test of a self-calibrating estimation architecture for the sideslip of a Formula Student prototype. The proposed algorithm fuses several sensors being the most relevant an Inertial Measurement Unit (IMU) and a Global Positioning System (GPS). It is presented a comparison between a linear and a non-linear estimators, and their consequences. The algorithm is tested with real data from a Formula Student vehicle, and validated with a differential GPS. It is also reported an implementation of the proposed algorithm in a micro-controller, and tested with a radio-controlled (RC) vehicle. These results are also validated with the data from a more accurate indoor motion system.","Kalman Filters, Estimation, System implementation, Real-time systems, Vehicle dynamics",André Antunes and Pedro Outeiro and Carlos Cardeira and Paulo Oliveira,https://www.sciencedirect.com/science/article/pii/S0921889018301908,https://doi.org/10.1016/j.robot.2019.01.018,0921-8890,2019,83--89,115,Robotics and Autonomous Systems,Implementation and testing of a sideslip estimation for a formula student prototype,article,ANTUNES201983
"Lower extremity exoskeletons have been developed as a motion assistive technology in recent years. Walking pattern generation is a fundamental topic in the design of these robots. The usual approach with most exoskeletons is to use a pre-recorded pattern as a look-up table. There are some deficiencies with this method, including data storage limitation and poor regulation relating to the walking parameters. In addition, the walking parameters can be taken in hand very hard. Therefore modeling the human walking pattern is required. The few existing models provide piece by piece walking patterns, only generating at the beginning of each stride. In this paper, a real-time walking pattern generation method is provided which enables changing the parameters during the stride. For this purpose, two feedback controlled third order systems are proposed as real-time trajectory planners for generating the trajectories of the x and y components of each joint?s position. The boundary conditions of the trajectories are determined to prevent backward balance loss by appropriate displacement of the center of mass. In addition, a cost function is intended for each trajectory planner in order to increase the smoothness of trajectories. Optimization technique is used to design the feedback controller for tracking the boundary conditions in such a way that the cost function is minimized. Finally, the proper joint angles are generated using inverse kinematics transformation. The performance of the proposed pattern generator is verified via real experiments on the Exoped robot.","Exoskeleton, Walking pattern, Optimal control, Center of mass, Exoped",Jafar Kazemi and Sadjaad Ozgoli,https://www.sciencedirect.com/science/article/pii/S0921889018307966,https://doi.org/10.1016/j.robot.2019.02.012,0921-8890,2019,1--23,116,Robotics and Autonomous Systems,"Real-time walking pattern generation for a lower limb exoskeleton, implemented on the Exoped robot",article,KAZEMI20191
"A crucial requirement for imparting autonomy to the fish-inspired robots is the trajectory planning capability that can generate obstacle-free and optimal trajectories to a commanded goal location. Research in the area of dynamics-aware trajectory planning, especially in the presence of environmental disturbances, for fish-inspired robots is scarce. Trajectory-following for fish-inspired robots, which is different from trajectory planning, has been well explored wherein feedback controllers that reject disturbances are employed to follow the pre-specified waypoints. This paper reports an optimal trajectory planning approach for Anguilliform-inspired robots based on model predictive planning framework. The robot?s dynamics constraints, as well as its interaction with the surrounding flow conditions, are captured via dynamics simulations and are expressed using discretized motion primitives. The motion primitives are then used for generating a search-tree and an A*-based algorithm is used for searching the optimal trajectory. We developed a simulation-based admissible heuristic function that is used for improving the computational performance of the developed trajectory planner. The developed simulation-based heuristic function provided a computational speed-up by a factor of up to 10.3 with respect to that of the Euclidean heuristic for test cases comprising of a variety of obstacle densities, ambient flow conditions, and goal locations. The trajectories generated by the developed approach have been found to be dynamically feasible, collision-free, and optimal for the experiments reported in this paper. We believe that the developed approach can impart autonomy to the Anguilliform-inspired robots that, due to their slender and hyper-redundant structures, can perform autonomous inspection and maintenance of sub-sea structures having narrow regions, obstacles, and ambient flow and can be useful in various civil and defense applications.","Fish-inspired robots, Trajectory planning, Motion planning, Flow, Anguilliform-inspired robot, Heuristic function",Aditi Raj and Atul Thakur,https://www.sciencedirect.com/science/article/pii/S0921889018307565,https://doi.org/10.1016/j.robot.2019.05.001,0921-8890,2019,144--158,118,Robotics and Autonomous Systems,Dynamically feasible trajectory planning for Anguilliform-inspired robots in the presence of steady ambient flow,article,RAJ2019144
"In standard point-based methods, the depth measurements of the point features suffer from noise, which will lead to incorrect global structure of the environment. This paper presents a submap joining based SLAM with an RGB-D camera by introducing planes as well as points as features.This work is consisted of two steps: submap building and submap joining. Several adjacent keyframes, with the corresponding small patches, visual feature points, and planes observed from these keyframes, are used to build a submap. We fuse the submaps into a global map in a sequential fashion, such that, the global structure is recovered gradually through plane feature associations and optimization. We also show that the proposed algorithm can handle plane association problem incrementally in submap level, as the plane covariance can be obtained in each submap. The use of submap significantly reduces the computational cost during the optimization process, while keeping all information about planes. The proposed method is validated using both publicly available RGB-D benchmarks and datasets collected by authors. The algorithm can produce accurate trajectories and high quality 3D models on these challenging datasets, which are difficult for existing RGB-D SLAM or SFM algorithms.","RGB-D, SLAM, 3D reconstruction, Indoor mapping",Jun Wang and Jingwei Song and Liang Zhao and Shoudong Huang and Rong Xiong,https://www.sciencedirect.com/science/article/pii/S0921889018302033,https://doi.org/10.1016/j.robot.2019.05.002,0921-8890,2019,93--111,118,Robotics and Autonomous Systems,A submap joining algorithm for 3D reconstruction using an RGB-D camera based on point and plane features,article,WANG201993
"In recent years, Unmanned Ground Vehicles (UGVs) have been widely used as service robots. Unlike industrial robots, which are situated in fixed and controlled positions, UGVs work in dynamic environments, sharing the environment with other vehicles and humans. These robots should be able to move without colliding with any obstacle, assuring its integrity and the environment safety. In this paper, we propose two adaptations of the classical Dynamic Window algorithm for dealing with dynamic obstacles like Dynamic Window for Dynamic Obstacles (DW4DO) and Dynamic Window for Dynamic Obstacles Tree (DW4DOT). These new algorithms are compared with our previous algorithms based on Curvature Velocity Methods: Predicted Curvature Velocity Method (PCVM) and Dynamic Curvature Velocity Method (DCVM). Proposals have been validated in both simulated and real environment using several robotic platforms.","Dynamic obstacle avoidance, Dynamic window, Mapping",Eduardo J. Molinos and Ángel Llamazares and Manuel Ocaña,https://www.sciencedirect.com/science/article/pii/S0921889018309746,https://doi.org/10.1016/j.robot.2019.05.003,0921-8890,2019,112--130,118,Robotics and Autonomous Systems,Dynamic window based approaches for avoiding obstacles in moving,article,MOLINOS2019112
"Recently, advances in robotics? technology and research focus on complex scenarios. In these scenarios, robots have to act and respond fast to situational demands. First, they require heterogeneous knowledge from various sources. Then, they need to integrate this knowledge with their reasoning methodologies. These reasoning methodologies are typically different for every domain. This paper introduces an integrated knowledge processing methodology. This methodology uses query mechanisms and model-to-model transformations. Combining these two mechanisms enables processing of heterogeneous knowledge bases. The methodology is demonstrated for an outdoor scenario with diverse systems. In this scenario knowledge and reasoning methods from various sources are integrated. This includes static knowledge from. Open Sreet Map and Digital Elevation Models. The Robot Scene Graph tracks changes in the world and provides geometric reasoning. KnowRob with its Sherpa ontology and openEASE provide further reasoning capabilities.","Querying big data, Knowledge sharing, Knowledge management, Knowledge maintenance",Fereshta Yazdani and Sebastian Blumenthal and Nico Huebel and Asil Kaan Bozcuo?lu and Michael Beetz and Herman Bruyninckx,https://www.sciencedirect.com/science/article/pii/S0921889018303488,https://doi.org/10.1016/j.robot.2019.03.013,0921-8890,2019,80--91,117,Robotics and Autonomous Systems,Query-based integration of heterogeneous knowledge bases for search and rescue tasks,article,YAZDANI201980
"Simultaneous Localization and Mapping (SLAM) is an effective technique in the field of robot location and navigation. However, when the existing SLAM algorithm is applied in harsh terrain, such as the terrain found in coal mines, accuracy suffers, and on-line adaptive adjustment capability is poor. Furthermore, the system suffers from low robustness and is susceptible to random noise. In order to solve these problems, we propose an innovative Strong Tracking Second Order Central Difference SLAM (STSOSLAM) algorithm that combines a Strong Tracking Filter (STF), a Second-Order Central Differential Filter (SOCDF), and a Particle Filter (PF). The new algorithm utilizes the second order sterling interpolation formula to deal with the nonlinear system problem using the Cholesky decomposition technique, which propagates directly by using the covariance square root factor in the SLAM probabilistic estimation. This technique not only guarantees the positive definite property of the covariance matrix, but also reduces the truncation error of local linearization. In addition, STF is introduced into the algorithm. It updates every sigma point using an adaptive algorithm and obtains optimized filter gain through the STF online adjustment factor and suppresses uncertain noise and the influence of initial value selection. Through simulation and experiments, STSOSLAM algorithm shows much better performance in terms of estimation accuracy, robustness and reliability than FastSLAM2.0 and Central Difference FastSLAM (CDFastSLAM) algorithms, establishing the foundation of applying the STSOSLAM algorithm in the harsh terrain of coal mines.","FastSLAM, CDFastSLAM, STSOSLAM, Particle filter, Second order central difference particle filter, Strong tracking filter",Jiahui Dai and Xiaobo Li and Kequan Wang and Yunpei Liang,https://www.sciencedirect.com/science/article/pii/S0921889018305025,https://doi.org/10.1016/j.robot.2019.03.006,0921-8890,2019,114--125,116,Robotics and Autonomous Systems,A novel STSOSLAM algorithm based on strong tracking second order central difference Kalman filter,article,DAI2019114
"This paper introduces an electric Hyundai Medical Exoskeleton (H-MEX). It is specially designed to enable disabled people (e.g. spinal cord injury individuals below T10, stroke patients) to walk again, according to a basic walking control strategy. H-MEX is easily assembled with mechanically/electrically block-by-block connections, and its built-in control framework provides an unique control interface. Through this interface, the H-MEX wearer can customize gait parameters (viz., the step length, step period, and default torso tilt angle). With the proposed framework, trajectories for each active joint are planned for generating propulsion (i.e., angular momentum) in double-stance gait. This facilitates stability and convenience for H-MEX wearers. A dynamic simulation was conducted on a simplified planar model that describes an average human body: the intended propulsion generation during the double-stance phase was verified to lead to angular momentum with respect to a leading stance leg, for more stable and convenient step walking. Also, the degree of propulsion was shown to be adjusted by setting kinematic percentage of intended double-stance motion. The proposed control method was evaluated with five healthy subjects on a treadmill as one of initial performance tests: kinematic data on subjects? torsos given from basic walking at a velocity of 0.7 km/h and 1.2 km/h indicated the effectiveness of the proposed control strategy.","Lower-limb exoskeleton, Impedance control, Gait trajectory planning, Double-stance phase, Human locomotion",Dong Jin Hyun and Hyunseop Lim and SangIn Park and JuYoung Yoon and Kyungmo Jung and KiHyeon Bae and Inju Lee,https://www.sciencedirect.com/science/article/pii/S0921889018306511,https://doi.org/10.1016/j.robot.2019.03.002,0921-8890,2019,24--37,116,Robotics and Autonomous Systems,Walking propulsion generation in double stance by powered exoskeleton for paraplegics,article,HYUN201924
"Accurate geometric and inertial parameter estimates of a modern manipulator are of crucial importance to obtain good performances during a contact task or for obtaining more and more required realistic simulations. CAD data are often provided by the manufacturer, but these are inaccurate and do not take into account eventual end-effector modifications. Fortunately, they can be identified. However, in real industrial applications, dynamic identification is rarely performed because it supposedly requires a cumbersome and long procedure. There is a need of a practical but accurate method to identify dynamics parameters. Thus, this paper proposes a practical framework to identify a Kuka LWR robot in less than 10 s. An experimental comparison between several cost functions showed that log{det(?)} is the best trade-off for getting a good parameters accuracy within a minimal time. The procedure identifies very accurately the inertial parameters of the robot and of its end-effector and recognizes its geometric parameters from a look-up table. When using identified parameters, joint torques were estimated with an RMS difference lower than 1 N m when compared to measured ones. The identified model was then used to generate a contact painting trajectory. During this contact task, the external forces were estimated and controlled without the use of a force sensor. Experimentation showed that the external forces could be identified with an RMS difference lower than 3 N.","Dynamic identification, Force control, Painting task, Kuka LWR",Takuma Katsumata and Benjamin Navarro and Vincent Bonnet and Philippe Fraisse and André Crosnier and Gentiane Venture,https://www.sciencedirect.com/science/article/pii/S0921889017307091,https://doi.org/10.1016/j.robot.2018.11.021,0921-8890,2019,149--159,113,Robotics and Autonomous Systems,Optimal exciting motion for fast robot identification. Application to contact painting tasks with estimated external forces,article,KATSUMATA2019149
"Dual-arm cooperation is considered as an available approach to improve the poor efficiency by autonomous robotic harvesting. While, cooperating arm movements using visual information is a key challenge for harvesting robots working in non-structured environments. In this paper, we develop a dual-arm cooperative approach for a tomato harvesting robot using a binocular vision sensor. Firstly, a tomato detection algorithm combining AdaBoost classifier and color analysis is proposed and employed by the harvesting robot. Then, a fast three-dimensional scene reconstruction method is obtained in the simulation environment by using point clouds acquired from a stereo camera. Integration of tomato detection, target localization, motion planning and real-time control for dual-arm movements, the dual-arm cooperation for robotic harvesting can be implemented. To validate the proposed approach, field experiments were conducted with the potted tomatoes in greenhouse. Over 96% of target tomatoes were correctly detected with the speed of about 10 fps. The positioning error of robot end-point of less than 10 mm was achieved for large scale direct positioning of the harvesting robot. With the vacuum cup grasping and wide-range cutting, the success rate of robotic harvesting achieved 87.5%. Meanwhile, the harvesting cycle time excluding cruise time was less than 30 s. These results indicate that the dual-arm cooperative approach is feasible and practical for robotic harvesting in non-structured environments.","Binocular vision, Dual-arm cooperation, Tomato detection, Three-dimensional scene reconstruction, Harvesting cycle time",Xiao Ling and Yuanshen Zhao and Liang Gong and Chengliang Liu and Tao Wang,https://www.sciencedirect.com/science/article/pii/S092188901830808X,https://doi.org/10.1016/j.robot.2019.01.019,0921-8890,2019,134--143,114,Robotics and Autonomous Systems,Dual-arm cooperation and implementing for robotic harvesting tomato using binocular vision,article,LING2019134
"Human?robot interaction in natural settings requires filtering out the different sources of sounds from the environment. Such ability usually involves the use of microphone arrays to localize, track and separate sound sources online. Multi-microphone signal processing techniques can improve robustness to noise but the processing cost increases with the number of microphones used, limiting response time and widespread use on different types of mobile robots. Since sound source localization methods are the most expensive in terms of computing resources as they involve scanning a large 3D space, minimizing the amount of computations required would facilitate their implementation and use on robots. The robot?s shape also brings constraints on the microphone array geometry and configurations. In addition, sound source localization methods usually return noisy features that need to be smoothed and filtered by tracking the sound sources. This paper presents a novel sound source localization method, called SRP-PHAT-HSDA, that scans space with coarse and fine resolution grids to reduce the number of memory lookups. A microphone directivity model is used to reduce the number of directions to scan and ignore non significant pairs of microphones. A configuration method is also introduced to automatically set parameters that are normally empirically tuned according to the shape of the microphone array. For sound source tracking, this paper presents a modified 3D Kalman (M3K) method capable of simultaneously tracking in 3D the directions of sound sources. Using a 16-microphone array and low cost hardware, results show that SRP-PHAT-HSDA and M3K perform at least as well as other sound source localization and tracking methods while using up to 4 and 30 times less computing resources respectively.","Sound source localization, Sound source tracking, Microphone array, Online processing, Embedded system, Mobile robot, Robot audition",François Grondin and François Michaud,https://www.sciencedirect.com/science/article/pii/S0921889017309399,https://doi.org/10.1016/j.robot.2019.01.002,0921-8890,2019,63--80,113,Robotics and Autonomous Systems,Lightweight and optimized sound source localization and tracking methods for open and closed microphone array configurations,article,GRONDIN201963
"Novelty detection is a very useful function for detecting abnormal data in any application. An expectation-based novelty-detection approach has been introduced that learns the dynamic relationship model among normal data in order to predict the next expected data. Most novelty-detection systems use an offline approach with a fixed structure, a system type that has limitations when the data count in the environment is unknown. A new expectation-based novelty-detection system features an online recurrent neural network approach that learns the data by inserting new nodes or deleting unused nodes from its structure. Generally, to detect novelties, a global novelty threshold is defined to filter out all input data as novel whenever the prediction error of the network exceeds the threshold. However, because a neural network cannot learn to predict all classes of input data perfectly, using a global novelty threshold leads to the misclassification of the insufficiently learned normal data as novel. To overcome this problem, the novelty-detection system has been improved to learn local novelty thresholds alongside its learning to predict expectations. The proposed algorithm is applied to an online novelty detection using colour and depth data obtained from a Kinect sensor on a mobile robot. The performance of the expected novelty detector and its limitations during experiments are analysed and shown. Furthermore, colour and depth data as inputs into the novelty filter are separately analysed and their contributions on the overall novelty detection highlighted. In conclusion, the performance of the novelty filter could further be improved by applying a better feature-selection technique to extract more interesting features from high-dimensional input data.","Online learning, Novelty detection, Robot learning, Mobile robot inspection, Image processing, Neural network",Emre Özbilge,https://www.sciencedirect.com/science/article/pii/S0921889019300636,https://doi.org/10.1016/j.robot.2019.04.003,0921-8890,2019,68--79,117,Robotics and Autonomous Systems,Experiments in online expectation-based novelty-detection using 3D shape and colour perceptions for mobile robot inspection,article,OZBILGE201968
"In the Intelligent Transportation Systems Community, the research interest in intelligent and autonomous vehicles is increasing during the last few years. Accordingly, this paper presents the advances in the development of a ROS-based (Robot Operating System) software architecture for intelligent vehicles. The main contribution of the architecture is its powerfulness (in the aspect of complete architecture managing the navigation, synchronization, communication, cooperation, ground station, web server, sound system), flexibility (due to the fact that autonomous vehicles evolve exponentially where new sensors or algorithms emerge every day), and modularity (in the form of interchangeability and replaceability for new modules), which allow researchers to develop and test different algorithms easily and faster. The architecture has been tested on two real platforms such as the iCab (Intelligent Campus Automobile) and IvvI 2.0 vehicle (Intelligent Vehicle based on Visual Information) The first one is a full y autonomous vehicle and the second one provides Advance Driver Assistance. Additionally, it is shown the use case for the iCab project where the scope is focused on the critical element of navigation. The use case exposed proves the benefits of using this architecture over a centralized one.","Autonomous vehicles, Icab, Ros, Software architecture, Path planning",Pablo Marin-Plaza and Ahmed Hussein and David Martin and Arturo {de la Escalera},https://www.sciencedirect.com/science/article/pii/S092188901830201X,https://doi.org/10.1016/j.robot.2019.04.008,0921-8890,2019,251--262,118,Robotics and Autonomous Systems,iCab Use Case for ROS-based Architecture,article,MARINPLAZA2019251
"This paper addresses planning and control of robot motion under uncertainty that is formulated as a continuous-time, continuous-space stochastic optimal control problem, by developing a topology-guided path integral control method. The path integral control framework, which forms the backbone of the proposed method, re-writes the Hamilton?Jacobi?Bellman equation as a statistical inference problem; the resulting inference problem is solved by a sampling procedure that computes the distribution of controlled trajectories around the trajectory by the passive dynamics. For motion control of robots in a highly cluttered environment, however, this sampling can easily be trapped in a local minimum unless the sample size is very large, since the global optimality of local minima depends on the degree of uncertainty. Thus, a homology-embedded sampling-based planner that identifies many (potentially) local-minimum trajectories in different homology classes is developed to aid the sampling process. In combination with a receding-horizon fashion of the optimal control the proposed method produces a dynamically feasible and collision-free motion plans without being trapped in a local minimum. Numerical examples on a synthetic toy problem and on quadrotor control in a complex obstacle field demonstrate the validity of the proposed method.","Stochastic optimal control, Topological motion planning, Linearly-solvable optimal control, Multi-modality",Jung-Su Ha and Soon-Seo Park and Han-Lim Choi,https://www.sciencedirect.com/science/article/pii/S0921889017308874,https://doi.org/10.1016/j.robot.2019.01.001,0921-8890,2019,81--93,113,Robotics and Autonomous Systems,Topology-guided path integral approach for stochastic optimal control in cluttered environment,article,HA201981
"Learning from demonstration provides an effective method to resolve the problem of teaching robot to execute complex motions without expert knowledge about the robot system. In this paper, we present a novel learning from demonstration method based on multi-stage cost learning. The recorded demonstrations are assumed to be composed of several substages chained together. Leveraging this assumption, a segmentation and cost learning framework is proposed to search for the cutting points that divide the unsegmented demonstrations into multiple substages and retrieve cost function for each substage. To the best of our knowledge, it is the first solution to learn multi-stage cost functions in continuous domain without restricting the possible cost functions into limited numbers or simple forms. To generate new trajectory, a complete objective functional is constructed based on the learned multi-stage cost functions plus other constraints like obstacle avoidance and is optimized with functional gradient method. The generated trajectory can adapt to new environments while maintain the specific properties of each substage as demonstrations. The effectiveness of the proposed method is verified through simulation study and experiments conducted on a real robot manipulator.","Trajectory generation, Learning from demonstration, Cost learning, Dynamic programming",Jin Hu and Rong Xiong,https://www.sciencedirect.com/science/article/pii/S0921889018303075,https://doi.org/10.1016/j.robot.2019.04.006,0921-8890,2019,57--67,117,Robotics and Autonomous Systems,Trajectory generation with multi-stage cost functions learned from demonstrations,article,HU201957
"Autonomous vehicles promise to improve traffic safety while, at the same time, increase fuel efficiency and reduce congestion. They represent the main trend in future intelligent transportation systems. This paper concentrates on the planning problem of autonomous vehicles in traffic. We model the interaction between the autonomous vehicle and the environment as a stochastic Markov decision process (MDP) and consider the driving style of an expert driver as the target to be learned. The road geometry is taken into consideration in the MDP model in order to incorporate more diverse driving styles. The desired, expert-like driving behavior of the autonomous vehicle is obtained as follows: First, we design the reward function of the corresponding MDP and determine the optimal driving strategy for the autonomous vehicle using reinforcement learning techniques. Second, we collect a number of demonstrations from an expert driver and learn the optimal driving strategy based on data using inverse reinforcement learning. The unknown reward function of the expert driver is approximated using a deep neural-network (DNN). We clarify and validate the application of the maximum entropy principle (MEP) to learn the DNN reward function, and provide the necessary derivations for using the maximum entropy principle to learn a parameterized feature (reward) function. Simulated results demonstrate the desired driving behaviors of an autonomous vehicle using both the reinforcement learning and inverse reinforcement learning techniques.","Reinforcement learning, Inverse reinforcement learning, Deep neural-network, Maximum entropy, Path planning, Autonomous vehicle",Changxi You and Jianbo Lu and Dimitar Filev and Panagiotis Tsiotras,https://www.sciencedirect.com/science/article/pii/S0921889018302021,https://doi.org/10.1016/j.robot.2019.01.003,0921-8890,2019,1--18,114,Robotics and Autonomous Systems,Advanced planning for autonomous vehicles using reinforcement learning and deep inverse reinforcement learning,article,YOU20191
"This article surveys 21 studies of how ethologists characterize the environment for arthropods, reptiles, mammals, and birds traversing above ground, below ground, and burrowing in order to provide insights in selecting or designing a robot for a complex work envelope, for example, the 2018 Thailand Cave rescue. Roboticists are currently forced to rely on empirical expertise to select or design robots and to construct ad hoc testbeds for expected environments due to the lack of comprehensive quantitative metrics. Fortunately, ethologists have been grappling with how to quantify environmental factors that impact the traversability of different animals. That community has collectively identified 21 characteristics which this article discusses and groups into a novel taxonomy of three broad categories: local navigational constraints, surface properties, and global layout properties. One conclusion is that the set of appropriate characteristics for a specific environment depends on the scale of the environment to the agent. The article also makes four recommendations to aid roboticists in a) selecting a particular robot suitable for the environmental characteristics, b) building testbeds that are more representative of the target environment or to objectively compare different robotics, and c) collecting data about an environment for use cases or work analyses. It also discusses the limitations of the ethological studies for robotics and the remaining gaps.",,Grant A. Wilde and Robin R. Murphy,https://www.sciencedirect.com/science/article/pii/S0921889018306468,https://doi.org/10.1016/j.robot.2019.04.009,0921-8890,2019,159--166,118,Robotics and Autonomous Systems,A robotics-oriented taxonomy of how ethologists characterize the traversability of animal environments,article,WILDE2019159
"This paper presents a talking gesture generation system based on Generative Adversarial Networks, along with an evaluation of its adequateness. The talking gesture generation system produces a sequence of joint positions of the robot?s upper body which keeps in step with an uttered sentence. The suitability of the approach is demonstrated with a real robot. Besides, the motion generation method is compared with other (non-deep) generative approaches. A two-step comparison is made. On the one hand, a statistical analysis is performed over movements generated by each approach by means of Principal Coordinate Analysis. On the other hand, the robot motion adequateness is measured by calculating the end effectors? jerk, path lengths and 3D space coverage.","Social robotics, Generative learning models, Motion generation, Principal coordinate analysis, Body language expression, Generative adversarial networks",Igor Rodriguez and José María Martínez-Otzeta and Itziar Irigoien and Elena Lazkano,https://www.sciencedirect.com/science/article/pii/S0921889018304445,https://doi.org/10.1016/j.robot.2018.11.024,0921-8890,2019,57--65,114,Robotics and Autonomous Systems,Spontaneous talking gestures using Generative Adversarial Networks,article,RODRIGUEZ201957
"The torque vectoring controller is the electrical substitute of a mechanical differential, with the advantage of improving the stability and handling of the vehicle. This work tackles the design, implementation and testing of a torque vectoring algorithm to be implemented in a Formula Student prototype. First is presented a dynamic test model used for the design and tuning of the controllers, which is then validated with real data from a real vehicle. Secondly, a computation methodology to achieve a reference value is proposed. Two controllers are presented, a PID and a LQR controller, with both being designed and tested in simulation. In a final part, the two controllers are implemented in a Formula Student prototype. The results from the vehicle with and without the controllers are then compared and the performance improvement discussed.","Torque control, Control systems, Optimal control, System implementation",João Antunes and André Antunes and Pedro Outeiro and Carlos Cardeira and Paulo Oliveira,https://www.sciencedirect.com/science/article/pii/S0921889018301970,https://doi.org/10.1016/j.robot.2018.12.010,0921-8890,2019,56--62,113,Robotics and Autonomous Systems,Testing of a torque vectoring controller for a Formula Student prototype,article,ANTUNES201956
"This study proposes a robust humanoid step control algorithm that optimizes ground reaction force, step position and step time. Our method is focused on the robot that has finite size of foot and designed to exploit its advantages. The foot allows for the range of ZMP presence and our algorithm use this ZMP range to absorb sensor noise, modeling error and certain amount of disturbances. Thanks to these effect, our step controller is able to produce new stepping time and the stepping position stably. From quadratic programming (QP) technique, we can consider maximum kinematical foot range and maximum foot velocity in the optimization process by setting inequality constraints. The CoM trajectory is re-planned in each control cycle with a short cycle preview controller. The linear inverted pendulum model (LIPM) simulation and full dynamics simulation shows that our proposing method precisely reflect the advantages of footed robot and significant improvement in walking robustness to strong perturbation.","Biped walking, Step position adjustment, Step time adjustment, Divergent component of motion",Hyobin Jeong and Inho Lee and Okkee Sim and KangKyu Lee and Jun-Ho Oh,https://www.sciencedirect.com/science/article/pii/S0921889018305372,https://doi.org/10.1016/j.robot.2018.12.003,0921-8890,2019,10--22,113,Robotics and Autonomous Systems,A robust walking controller optimizing step position and step time that exploit advantages of footed robot,article,JEONG201910
"Through deep learning and computer vision techniques, driving manoeuvres can be predicted accurately a few seconds in advance. Even though adapting a learned model to new drivers and different vehicles is key for robust driver-assistance systems, this problem has received little attention so far. This work proposes to tackle this challenge through domain adaptation, a technique closely related to transfer learning. A proof of concept for the application of a Domain-Adversarial Recurrent Neural Network (DA-RNN) to multi-modal time series driving data is presented, in which domain-invariant features are learned by maximising the loss of an auxiliary domain classifier. Our implementation is evaluated using a leave-one-driver-out approach on individual drivers from the Brain4Cars dataset, as well as using a new dataset acquired through driving simulations, yielding an average increase in performance of 30% and 114% respectively compared to no adaptation. We also show the importance of fine-tuning sections of the network to optimise the extraction of domain-independent features. The results demonstrate the applicability of the approach to driver-assistance systems as well as training and simulation environments.","Manoeuvre anticipation, ADAS, Deep learning, LSTM, Recurrent neural networks, Domain adaptation",Michele Tonutti and Emanuele Ruffaldi and Alessandro Cattaneo and Carlo Alberto Avizzano,https://www.sciencedirect.com/science/article/pii/S0921889018301209,https://doi.org/10.1016/j.robot.2019.02.007,0921-8890,2019,162--173,115,Robotics and Autonomous Systems,Robust and subject-independent driving manoeuvre anticipation through Domain-Adversarial Recurrent Neural Networks,article,TONUTTI2019162
"One critical aspect of robotic visual learning is to capture the precedence relations among primitive actions from observing human performing manipulation activities. Current state-of-the-art spatial?temporal representations do not fully capture the precedence relations. In this paper, we present a novel activity representation: Manipulation Precedence Graph (MPG) and its associated overall planning module, with the goal to enable robot to learn manipulation activities from human demonstrations with overall planning. Experiments conducted on three publicly available manipulation activity video corpora as well as on a simulation platform validate that (1) the generated MPG from our system is robust given noisy detections from perception modules; (2) the overall planning module is able to generate parallel action sequences for robot to execute them in parallel; (3) the overall system improves robots? manipulation execution efficiency.","Manipulation precedence graph, Understanding human activities, Intelligent systems, AI and robotics",Xin Ye and Zhe Lin and Yezhou Yang,https://www.sciencedirect.com/science/article/pii/S0921889018303622,https://doi.org/10.1016/j.robot.2019.03.011,0921-8890,2019,126--135,116,Robotics and Autonomous Systems,Robot learning of manipulation activities with overall planning through precedence graph,article,YE2019126
"The ankle?foot complex in the human body is one of the major determinants in normal human walking. Most of the research study ankle and foot motion by observing people as they move, measuring desired kinematic and kinetic data indoor or outdoor, and numerical simulations in computer. However, very few studies are able to explore the fundamental mechanical principles underlying human musculoskeletal system. In this paper, we developed a three-dimension (3D) passive dynamic walker with flat feet, toes and ankle springs to investigate the impact of the ankle and toe stiffness in the walking motion. The results suggest that the ankle springs have a main impact on the walking motion, where the anterior spring, over any other position, plays a main role in providing sagittal stability. The springs from the sagittal plane control the pitch angle of the robot which impacts on its velocity and step length. The stability got worse along with the step length and velocity increasing especially when the step length overcame 8 cm. The fact that the best configuration of the ankle joint has stiffer stiffness in the sagittal plane than the coronal plane complies in nature with humans where Tibialis Anterior, Soleus and Gastrocnemius muscles are much stronger than other muscles around the ankle. Furthermore, it can be stated that the medial toe plays a more important role than the lateral one, as blocking the medial toe with the stiffest joint (rigid joint) has a negative effect on walking motion. In conclusion, we show that the ankle stiffness of the robot in anterior?posterior position should be higher than that in medial?lateral position and the stiffness in any position should exceed a minimum level to maintain walking stability. Also, adding toes (medial one should be softer than the lateral) in the foot of the robot may benefit biped locomotion especially when taking longer step length.","Biologically inspired robot, Passive walker, Biomechanics, Ankle, Toe",Kunyang Wang and Pablo Tena Tobajas and Jing Liu and Tao Geng and Zhihui Qian and Lei Ren,https://www.sciencedirect.com/science/article/pii/S0921889018306857,https://doi.org/10.1016/j.robot.2019.02.010,0921-8890,2019,49--60,115,Robotics and Autonomous Systems,Towards a 3D passive dynamic walker to study ankle and toe functions during walking motion,article,WANG201949
"In this paper, we introduce a novel methodology for fusing sensors and improving robustness to sensor failures in end-to-end learning based autonomous navigation of ground vehicles in unknown environments. We propose the first learning based camera?LiDAR fusion methodology for autonomous in-door navigation. Specifically, we develop a multimodal end-to-end learning system, which maps raw depths and pixels from LiDAR and camera, respectively, to the steering commands. A novel gating based dropout regularization technique is introduced which effectively performs multimodal sensor fusion and reliably predicts steering commands even in the presence of various sensor failures. The robustness of our network architecture is demonstrated by experimentally evaluating its ability to autonomously navigate in the indoor corridor environment. Specifically, we show through various empirical results that our framework is robust to sensor failures, partial image occlusions, modifications of the camera image intensity, and the presence of noise in the camera or LiDAR range images. Furthermore, we show that some aspects of obstacle avoidance are implicitly learned (while not being specifically trained for it); these learned navigation capabilities are shown in ground vehicle navigation around static and dynamic obstacles.","Robustness to sensor failures, Deep learning for autonomous navigation, Vision/LiDAR based navigation, Learning from demonstration, Sensor fusion, Autonomous vehicles",Naman Patel and Anna Choromanska and Prashanth Krishnamurthy and Farshad Khorrami,https://www.sciencedirect.com/science/article/pii/S0921889018305645,https://doi.org/10.1016/j.robot.2019.03.001,0921-8890,2019,80--97,116,Robotics and Autonomous Systems,A deep learning gated architecture for UGV navigation robust to sensor failures,article,PATEL201980
"Traversing rough terrains is one of the domains where multi-legged walking robots benefit from their relatively more complex kinematics in comparison to wheeled robots. The complexity of walking robots is usually related not only to mechanical parts but also to servomotors and the necessary electronics to efficiently control such a robotic system. Therefore, large, middle, but even small walking robots capable of traversing rough terrains can be very costly because of all the required equipment. On the other hand, using intelligent servomotors with the position control and feedback, affordable hexapod walking robots are becoming increasingly available. However, additional sensors may still be needed to stabilize the robot motion on rough terrains, e.g., inclinometers or inertial measurement units, force or tactile sensors to detect the ground contact point of the leg foot-tip. In this work, we present a minimalistic approach for adaptive locomotion control using only the servomotors position feedback. Adaptive fine-tuning of the proposed controller is supported by a dynamic model of the robot leg accompanied by the model of the internal servomotor controller. The models enable timely detection of the leg contact point with the ground and reduce developed stress and torques applied to the robot construction and servomotors without any additional sensor feedback. The presented results support that the proposed approach reliably detects the ground contact point, and thus enable traversing rough terrains with small, affordable hexapod walking robot.","Multi-legged robot, Locomotion control, Rough terrains",Jan Faigl and Petr ?í?ek,https://www.sciencedirect.com/science/article/pii/S0921889018306614,https://doi.org/10.1016/j.robot.2019.03.008,0921-8890,2019,136--147,116,Robotics and Autonomous Systems,Adaptive locomotion control of hexapod walking robot for traversing rough terrains with position feedback only,article,FAIGL2019136
"This paper presents a trajectory smoothing approach and corresponding real-time interpolation for the flying robot. To smoothly transit between straight line segments, the Bézier curve is introduced to guarantee continuous curvature. Subsequently, considering the constraints on approximation errors and lengths of the original straight line segments, an optimization problem pursuing maximal curvature radius of the Bézier curves is proposed to reduce the potential fluctuation in the real-time flights. With the established geometric profile of continuous curvature, a fast real-time interpolation approach that ensures smooth acceleration profile in real-time flights is proposed. To verify the effectiveness of this development, extensive simulations and experiments are conducted at last. The results show that the proposed trajectory generation approach can effectively generate reference trajectories in real-time both at two-dimensional and three-dimensional spaces with continuous curvature and smooth acceleration. With well-generated trajectory, the flying robot can closely track the reference with maximum cross-tracking error of 0.05 m.","Trajectory generation, Curvature smoothing, Real-time interpolation, Flying robot",Wei Dong and Ye Ding and Jie Huang and Luo Yang and Xiangyang Zhu,https://www.sciencedirect.com/science/article/pii/S0921889017301173,https://doi.org/10.1016/j.robot.2019.02.004,0921-8890,2019,73--82,115,Robotics and Autonomous Systems,An optimal curvature smoothing method and the associated real-time interpolation for the trajectory generation of flying robots,article,DONG201973
"Structure from Motion (SfM) is an image based method for 3D reconstruction of objects. This method coupled with Dense Multi-View Stereo (DMVS) can be used to generate an accurate point cloud of texture-full objects. Although this process is fully automatic, capturing images in proper locations is hard especially for texture-less objects which need a pattern projection procedure to have a successful matching step in SfM. This study aims to propose an automatic and portable system which can provide a pattern on objects and capture a set of high quality images in a way that a complete and accurate 3D model can be generated by the captured images using SFM and DMVS method. The system consists of three parts including a glassy turntable with a novel pattern projection system, a digital camera located on a mono-pod mounted on a length adjustable bar attached to the box of turntable and a controller system to control two other parts. Given the speed and step parameters for the system in a smart phone as the controller system, the digital camera automatically captures an image after every rotation step of the table. To evaluate the system, five different objects were tested under four criteria including plane fitting, structural resolution test, scale resolving test and comparing with a reference 3D model obtained with a commercial accurate laser scanner known as GOM ATOS Compact laser scanner. The average standard deviation for all the cited criteria was around 0.2 mm which illustrates the ability of the proposed system to capture high quality images for 3D reconstruction of texture-less objects.","Structure from motion (SfM), Dense multi-view stereo (DMVS), 3D reconstruction system, Texture-less objects, Autonomous systems",Ali {Hosseininaveh Ahmadabadian} and Ali Karami and Rouhallah Yazdan,https://www.sciencedirect.com/science/article/pii/S0921889017307431,https://doi.org/10.1016/j.robot.2019.04.001,0921-8890,2019,29--39,117,Robotics and Autonomous Systems,An automatic 3D reconstruction system for texture-less objects,article,HOSSEININAVEHAHMADABADIAN201929
"Within the realm of service robotics, researchers have placed a great amount of effort into learning, understanding, and representing motions as manipulations for task execution by robots. The task of robot learning and problem-solving is very broad, as it integrates a variety of tasks such as object detection, activity recognition, task/motion planning, localization, knowledge representation and retrieval, and the intertwining of perception/vision and machine learning techniques. In this paper, we solely focus on knowledge representations and notably how knowledge is typically gathered, represented, and reproduced to solve problems as done by researchers in the past decades. In accordance with the definition of knowledge representations, we discuss the key distinction between such representations and useful learning models that have extensively been introduced and studied in recent years, such as machine learning, deep learning, probabilistic modeling, and semantic graphical structures. Along with an overview of such tools, we discuss the problems which have existed in robot learning and how they have been built and used as solutions, technologies or developments (if any) which have contributed to solving them. Finally, we discuss key principles that should be considered when designing an effective knowledge representation.","Knowledge representation, Robot learning, Task planning, Domestic robots, Service robotics",David Paulius and Yu Sun,https://www.sciencedirect.com/science/article/pii/S0921889018303506,https://doi.org/10.1016/j.robot.2019.03.005,0921-8890,2019,13--30,118,Robotics and Autonomous Systems,A Survey of Knowledge Representation in Service Robotics,article,PAULIUS201913
"This article proposes a method for sensor fusion between odometers, gyroscope, accelerometer, magnetometer and visual landmark localization system. The method is designed for estimation of all 6 degrees of freedom (both translation and attitude) of a wheeled robot moving in uneven terrain. The fusion method is based on continuous estimation of the mean square error of each estimated value and allows different sampling rates of each sensor. Due to the simple implementation, it is suitable for real-time processing in the low-cost hardware. In order to evaluate the precision of the estimated position, stochastical models of sensors (with parameters matching real hardware sensors) were used and random trajectories were simulated. The virtual experiments showed that the method is resistant to the failure of any sensor except the odometers; however, each sensor provides improvement in the resultant precision.","Localization, Sensor fusion, Odometry, Landmarks, Inertial sensors, Mean square error",Du?an Nemec and Vojtech ?imák and Ale? Janota and Marián Hrubo? and Emília Bubeníková,https://www.sciencedirect.com/science/article/pii/S0921889018300757,https://doi.org/10.1016/j.robot.2018.11.019,0921-8890,2019,168--177,112,Robotics and Autonomous Systems,"Precise localization of the mobile wheeled robot using sensor fusion of odometry, visual artificial landmarks and inertial sensors",article,NEMEC2019168
"In this paper stiffness of cable-driven parallel robots (CDPRs) is analyzed in detail and based on this analysis, the stiffness-feasible workspace is introduced. This workspace includes all stable poses which increasing the internal forces can modify the total stiffness of the robot. It has been shown that in the CDPRs, the concept of the internal forces can be applied for keeping cables in tension and increasing stiffness. However, it should be noted that increasing the internal forces may decrease the overall stiffness of the mechanism and it is only applicable in stabilizable poses of the workspace. Therefore, stiffness-feasible workspace determines the allowable internal forces range which can increase the stiffness and it will guarantee that in this range of the internal forces, the structure of the robot is stable. In this paper, by employing this criterion and evolutionary algorithms, a CDPR is optimally designed, and a set of answers is presented. In this design, in addition to the stiffness-feasible workspace, another criterion as stiffness number is presented which is useful for specifying the distribution of the stiffness and stiffness-feasibility of the robot.","Cable-driven parallel robot, Stiffness, Internal forces, Stiffness-feasible workspace, Optimal design",Javad Bolboli and Mohammad A. Khosravi and Farzaneh Abdollahi,https://www.sciencedirect.com/science/article/pii/S0921889018306572,https://doi.org/10.1016/j.robot.2019.01.012,0921-8890,2019,19--28,114,Robotics and Autonomous Systems,Stiffness feasible workspace of cable-driven parallel robots with application to optimal design of a planar cable robot,article,BOLBOLI201919
"The problem of object localization and recognition on autonomous mobile robots is still an active topic. In this context, we tackle the problem of learning a model of visual saliency directly on a robot. This model, learned and improved on-the-fly during the robot?s exploration provides an efficient tool for localizing relevant objects within their environment. The proposed approach includes two intertwined components. On the one hand, we describe a method for learning and incrementally updating a model of visual saliency from a depth-based object detector. This model of saliency can also be exploited to produce bounding box proposals around objects of interest. On the other hand, we investigate an autonomous exploration technique to efficiently learn such a saliency model. The proposed exploration, called Reinforcement Learning-Intelligent Adaptive Curiosity (RL-IAC) is able to drive the robot?s exploration so that samples selected by the robot are likely to improve the current model of saliency. We then demonstrate that such a saliency model learned directly on a robot outperforms several state-of-the-art saliency techniques, and that RL-IAC can drastically decrease the required time for learning a reliable saliency model.","Visual saliency, Bounding box proposals, Intrinsic motivation, Intelligent adaptive curiosity, Autonomous mobile robots, Incremental learning, Deep learning",Céline Craye and Timothée Lesort and David Filliat and Jean-François Goudou,https://www.sciencedirect.com/science/article/pii/S0921889018304792,https://doi.org/10.1016/j.robot.2018.11.012,0921-8890,2019,244--259,112,Robotics and Autonomous Systems,Exploring to learn visual saliency: The RL-IAC approach,article,CRAYE2019244
This paper presents a method for global localization and tracking of an Unmanned Aerial Vehicle (UAV) over satellite images. We propose a new measurement model based on a novel version of BRIEF descriptor and apply it in a Monte Carlo Localization system that estimates the UAV pose in 4 degrees of freedom. The model is used to compare images obtained from the UAV downward looking camera against patches of satellite images such as the ones available on Google? Earth. The proposed method was validated using real flights sequences and has yield good results with different maps of the same region spawning many years and covering large areas.,"UAV, Localization, abBRIEF, Satellite images",Mathias Mantelli and Diego Pittol and Renata Neuland and Arthur Ribacki and Renan Maffei and Vitor Jorge and Edson Prestes and Mariana Kolberg,https://www.sciencedirect.com/science/article/pii/S092188901830438X,https://doi.org/10.1016/j.robot.2018.12.006,0921-8890,2019,304--319,112,Robotics and Autonomous Systems,A novel measurement model based on abBRIEF for global localization of a UAV over satellite images,article,MANTELLI2019304
"One of the unresolved problems in the field of computer creativity is developing a robot capable of creating full-color images with artistic paints in a human-like manner. While several advanced painting machines have been presented up to date, high-grade color rendition remains one of the main bottlenecks in robotic painting. In this paper, we present a robotic setup for realistic grayscale painting. The key feature of our robot is a special paint mixing device aimed at improving tone rendition in comparison to previously reported approaches. We describe the main algorithmic and hardware solutions implemented in our robot as well as the first experimental results. The robot represents a 3-DoF CNC machine equipped with a brush, the paint mixing device and a syringe pump block for paint supplement. In our study, we focus on monochrome painting with black and white acrylic paints. A mathematical model of primary paint mixing is described. Two realistic artworks have been created during test runs, and their reproductions together with the source images are given. The accuracy of tone rendition was experimentally tested. Further research will be aimed at high-grade color rendition and creating full-color paintings.","Robotics, Robotic art, Painterly rendering, Color rendition, Brushstroke rendering, Computer creativity",Artur I. Karimov and Ekaterina E. Kopets and Vyacheslav G. Rybin and Sergey V. Leonov and Anzhelika I. Voroshilova and Denis N. Butusov,https://www.sciencedirect.com/science/article/pii/S0921889018309321,https://doi.org/10.1016/j.robot.2019.02.009,0921-8890,2019,17--27,115,Robotics and Autonomous Systems,Advanced tone rendition technique for a painting robot,article,KARIMOV201917
"Emerging industrial applications involving mobile manipulation in the presence of humans is driving attention towards steerable wheeled mobile robots (SWMR), since these can perform arbitrary 2D planar trajectories, providing a reasonable compromise between maneuverability (necessary for human avoiding algorithms) and effectiveness. Instantaneous center of rotation (ICR) based kinematic models and controllers are the most suited for such robots, as they assure the existence of a unique ICR point at all times. However, unsatisfactory behavior do exist in numerous applications requiring frequent changes in the sign of the angular velocity command. This is typically the case for robot heading control: moving the ICR point from one border of the 2D ICR space to the other makes it pass by the robot geometric center, where only pure rotations are feasible. This behavior is not desirable and should be avoided. In this paper, we propose a novel complementary route ICR controller, where the ICR can go from one extreme to the other by means of border switching in one sample period. Thanks to this approach, fast response to the velocity commands is achieved with little steering motion. The new algorithm has been tested successfully in simulations and experiments, and is more time efficient with far more satisfactory behavior than the state-of-art direct route based controllers. These results have been also confirmed quantitatively, using a newly developed metric, the command fulfillment index (CFI).","Steerable mobile robot, Pseudo-omni mobile robot, Nonholonomic omnidirectional mobile robot",Mohamed Sorour and Andrea Cherubini and Abdellah Khelloufi and Robin Passama and Philippe Fraisse,https://www.sciencedirect.com/science/article/pii/S0921889018305086,https://doi.org/10.1016/j.robot.2019.02.011,0921-8890,2019,131--143,118,Robotics and Autonomous Systems,Complementary-route based ICR control for steerable wheeled mobile robots,article,SOROUR2019131
"Legged robots need to make contact with irregular surfaces, when operating in unstructured natural terrains. Representing and perceiving these areas to reason about potential contact between a robot and its surrounding environment, is still largely an open problem. This paper introduces a new framework to model and map local rough terrain surfaces, for tasks such as bipedal robot foot placement. The system operates in real-time, on data from an RGB-D and an IMU sensor. We introduce a set of parametrized patch models and an algorithm to fit them in the environment. Potential contacts are identified as bounded curved patches of approximately the same size as the robot?s foot sole. This includes sparse seed point sampling, point cloud neighborhood search, and patch fitting and validation. We also present a mapping and tracking system, where patches are maintained in a local spatial map around the robot as it moves. A bio-inspired sampling algorithm is introduced for finding salient contacts. We include a dense volumetric fusion layer for spatiotemporally tracking, using multiple depth data to reconstruct a local point cloud. We present experimental results on a mini-biped robot that performs foot placements on rocks, implementing a 3D foothold perception system, that uses the developed patch mapping and tracking framework.","Irregular surface modeling, Foothold contact modeling, Bounded curved patch modeling, Curved patch fitting and tracking, 3D perception for bipedal robots, Bipedal robot foot placement, Rough terrain stepping, Legged robot locomotion",Dimitrios Kanoulas and Nikos G. Tsagarakis and Marsette Vona,https://www.sciencedirect.com/science/article/pii/S0921889017308242,https://doi.org/10.1016/j.robot.2019.05.012,0921-8890,2019,13--30,119,Robotics and Autonomous Systems,Curved patch mapping and tracking for irregular terrain modeling: Application to bipedal robot foot placement,article,KANOULAS201913
"This paper presents an approach, using an anticipatory kinodynamic motion planner, for obtaining the best trajectory and velocity profile for autonomous driving in dynamic complex environments, such as driving in urban scenarios. The planner discretizes the road search space and looks for the best vehicle path and velocity profile at each control period of time, assuming that the static and dynamic objects have been detected. The main contributions of the work are in the anticipatory kinodynamic motion planner, in a fast method for obtaining the G2-splines for path generation, and in a method to compute and select the best velocity profile at each candidate path that fulfills the vehicle kinodynamic constraints, taking into account the passenger comfort. The method has been developed and tested in MATLAB through a set of simulations in different representative scenarios, involving fixed obstacles and moving vehicles. The outcome of the simulations shows that the anticipatory kinodynamic planner performs correctly in diverse dynamic scenarios, maintaining smooth accelerations for passenger comfort.","Autonomous driving, ADAS, Urban, Anticipation, Kinodynamic motion planning, Path planning, -splines, Velocity profiles",Jordi Pérez Talamino and Alberto Sanfeliu,https://www.sciencedirect.com/science/article/pii/S0921889018301957,https://doi.org/10.1016/j.robot.2018.11.022,0921-8890,2019,93--105,114,Robotics and Autonomous Systems,Anticipatory kinodynamic motion planner for computing the best path and velocity trajectory in autonomous driving,article,TALAMINO201993
"In this manuscript, we tackle the problem of a continuous localization of a legged robot. We propose a novel, optimization-based procedure for the state estimation of the robot using measurements from internal sensors (legged odometry). Then, we propose the optimization-based integration of the legged odometry and the visual SLAM output. The proposed multi-modal localization system can continuously estimate the pose of the robot in various conditions despite fast motions of the robot, slippages or image motion blur. We provide the results of the real-time implementation of the proposed method on a multi-legged walking robot. We compare the proposed localization method to other state of the art localization systems and provide the dataset for future comparisons.","Walking robot, Legged odometry, SLAM, Mapping, Navigation",Dominik Belter and Micha? R. Nowicki,https://www.sciencedirect.com/science/article/pii/S092188901830126X,https://doi.org/10.1016/j.robot.2018.10.013,0921-8890,2019,110--124,111,Robotics and Autonomous Systems,Optimization-based legged odometry and sensor fusion for legged robot continuous localization,article,BELTER2019110
"This study proposes a mechanism and a methodology for large force input to the environment by a mobile robot. To determine the limits on the force that a mobile robot can apply to a target object, we analyzed the forces between the robot, ground, and object, and the frictional-force limits between any two of these three bodies. To prevent the mobile robot from falling during the large-force application, the manipulator is connected to the robot via a passive rotational joint. This mechanism enables the mobile robot to search the environmental parameters. A new mobile robot fitted with the proposed mechanism, named ARODA, was developed. In a validation experiment, the developed mobile robot successfully tilted a relatively large and heavy object while searching the environmental parameters (the frictional coefficients of the floor and object and the size of the object). Equipped with the proposed mechanism, the mobile robot refrained from falling while applying a large force to the object by trial and error.","Mobile robot, Large force, Nonprehensile manipulation",Shouhei Shirafuji and Yuri Terada and Tatsuma Ito and Jun Ota,https://www.sciencedirect.com/science/article/pii/S0921889017306875,https://doi.org/10.1016/j.robot.2018.09.005,0921-8890,2018,92--101,110,Robotics and Autonomous Systems,"Mechanism allowing large-force application by a mobile robot, and development of ARODA",article,SHIRAFUJI201892
"Maintaining an upright stance is a challenging task in both humans and humanoid robots in that it is complicated by inherently unstable mechanics and requires controlling a noisy, inaccurate, multi-DoF system. Hence, learning and prediction are often involved in humanoid control. This appears to apply similarly in humans where continuous control with sensory feedback avoids falling. This work presents an attempt of integrating a learned predictor into a humanoid posture control. A neurorobotics approach was used, in which the concept of a bio-inspired modular control is tested on a 14 DOF humanoid robot platform. In particular, the paper shows how to address, in a closed loop system, the problem that sensory feedback tends to create a correlation between the state of the system and its controlled inputs. This complicates the training of machine learning models, or identification procedures in general, because the feedback makes the effect of the noise, which is unknown, on the system output dependent on the input. Using a bio-inspired modular control of the robot, a linear predictor based on on-line learning, integrated in the control through a bio-inspired schema, has been compared with the method of a Smith predictor. The on-line predictor compared favorably with the Smith predictor in the task of balancing during voluntary movements.","Bio-inspired, Humanoid posture control, Learning, Prediction, Neurorobotics",Vittorio Lippi,https://www.sciencedirect.com/science/article/pii/S0921889017309107,https://doi.org/10.1016/j.robot.2018.05.012,0921-8890,2018,63--70,107,Robotics and Autonomous Systems,Prediction in the context of a human-inspired posture control model,article,LIPPI201863
"Ever since digital technology entered in the operating theater (OT) surgery has moved out through one of the big transformation on account of medical world and now we are foreseeing the era of digital OT. Robotic assisted surgery (RAS) is a way of technological development in the medical environment that uses robotic structure to assist in surgical measures. RAS was designed to beat the limitations of Minimal Invasive Surgery (MIS) and to improve the ability of medical doctor during surgery. The paper depicts the control methodology for surgical robots based on the combination of fuzzy logic control (FLC) with sliding mode control (SMC). The appreciable features of SMC like simplicity in design and high degree of robustness motivate researchers to employ this methodology in robotics. Nevertheless, the destructive chattering phenomenon is circumvented by espousing FLC in SMC. Additionally, the output gain of fuzzy sliding mode control (FSMC) is online tuned by a supervisory fuzzy logic control (SFLC), which results in chattering diminution. System stability is investigated using Lyapunov theorem. All numerical simulations have been carried out using MATLAB tool for 2 DOF surgical robot manipulator formulated for high speed trajectory tracking and for the typical condition during surgery. Moreover, the performance has been validated in real-time using Opal-RT Lab simulator show the efficacy of the proposed methodology. The simulation as well as real time digital simulator (OP-4500) results of FSMC and supervisory fuzzy logic based sliding mode control (SFSMC) are compared with the conventional SMC which represents the improvement of control law for attainment of optimized results by rejecting perturbations and achieving the desired system performance within a specific band of operation.","Sliding mode control (SMC), Fuzzy sliding mode control (FSMC), Supervisory fuzzy sliding mode control (SFSMC), Surgical robot, Robotic assisted surgery",Mohd Salim Qureshi and Pankaj Swarnkar and Sushma Gupta,https://www.sciencedirect.com/science/article/pii/S0921889017304578,https://doi.org/10.1016/j.robot.2018.08.008,0921-8890,2018,68--85,109,Robotics and Autonomous Systems,A supervisory on-line tuned fuzzy logic based sliding mode control for robotics: An application to surgical robots,article,QURESHI201868
"For robot with flexible bar-groups that comprise flexible link, flexible joint and joint clearance, it is difficult to guarantee highly accurate and efficient work. To address this problem, dynamic models of flexible links and flexible joints are studied in this paper, and a comprehensive dynamics model is established by constraints. Based on this comprehensive dynamics model, the comprehensive dexterity is defined by the index functions of condition number, minimum singular and dynamics operand, which can reflect the actual situation. Taking the comprehensive dexterity as the main basis, the novel idea of workspace lattice is put forward, and based on the Fourier transform and the principles of probability and statistics, the workspace lattice of robot system can be obtained. The proposed method is experimentally applied to a light-weight parallel robot, and its feasibility and effectiveness are verified. Moreover, extensive actual operation is performed by the light-weight parallel robot, which demonstrates the adaptive capability and the robustness of the proposed method.","Flexible bar-group, Trajectory control, Comprehensive dynamics, Comprehensive dexterity, Workspace lattice",Kunming Zheng and Youmin Hu and Bo Wu and Xuexing Guo,https://www.sciencedirect.com/science/article/pii/S0921889018302768,https://doi.org/10.1016/j.robot.2018.10.010,0921-8890,2019,44--61,111,Robotics and Autonomous Systems,New trajectory control method for robot with flexible bar-groups based on workspace lattices,article,ZHENG201944
"This paper deals with EMG-driven torque estimation and optimal adaptive impedance control during robot-aided rehabilitation. In this preliminary and feasibility study, the proposed framework was evaluated considering an active knee orthosis and only healthy subjects. First, a simplified and optimized musculoskeletal model is used to compute the estimate of user?s torque considering electromyographic (EMG) signals taken from selected muscles acting during flexion and extension movements. The model optimization is performed by comparing the estimated torque from EMG with the torque generated by the inverse dynamics tool of the OpenSim software. As an alternative solution, a multilayer perceptron neural network (NN) is proposed to map the EMG signals to the user?s torque. The proposed approaches are evaluated by a set of healthy subjects wearing the knee orthosis and performing a protocol created for user?robot interaction analysis. Then, an EMG-driven adaptive impedance control is proposed to improve the user participation during the rehabilitation session. The approach is based on an optimal solution which considers the position error and the robot assistance level. The experimental results indicate the use of EMG signals is feasible for adaptive control strategies, taking into account the current condition of the user and optimizing the robot assistance.","Robotics rehabilitation, Impedance control, Adaptive controller, EMG-driven controller",Guido G. Peña and Leonardo J. Consoni and Wilian M. {dos Santos} and Adriano A.G. Siqueira,https://www.sciencedirect.com/science/article/pii/S0921889018304263,https://doi.org/10.1016/j.robot.2018.11.011,0921-8890,2019,98--108,112,Robotics and Autonomous Systems,Feasibility of an optimal EMG-driven adaptive impedance control applied to an active knee orthosis,article,PENA201998
"Markov Decision Processes (MDPs) are not able to make use of domain information effectively due to their representational limitations. The lacking of elements which enable the models be aware of context, leads to unstructured representation of that problem such as raw probability matrices or lists. This causes these tools significantly less efficient at determining a useful policy as the state space of a task grows, which is the case for more realistic problems having localized dependencies between states and actions. In this paper, we present a new state machine, called Context-Aware Markov Decision Process (CA-MDP) based on MDP for the purpose of representing Markovian sequential decision making problems in a more structured manner. CA-MDP changes and augments MDP facilities by integrating causal relationships between actions and states thereby enabling structural, hence compact if possible, representation of the tasks. To show the expressive power of CA-MDP, we give the theoretical bounds for complexity of conversion between MDP and CA-MDP to demonstrate the expressive power of CA-MDP. Next, to generate an optimal policy from CA-MDP encoding by exploiting those newly defined facilities, we devised a new solver algorithm based on value iteration (VI), called Context-Aware Value Iteration (CA-VI). Although regular dynamic programming (DP) based algorithms is successful at effectively determining optimal policies, they do not scale well with respect to state?action space, making both the MDP encoding and related solver mechanism practically unusable for real-life problems. Our solver algorithm gets the power of overcoming the scalability problem by integrating the structural information provided in CA-MDP. First, we give theoretical analysis of CA-VI by examining the expected number of Bellman updates being performed on arbitrary tasks. Finally, we present our conducted experiments on numerous problems, with important remarks and discussions on certain aspects of CA-VI and CA-MDP, to justify our theoretical analyses empirically and to assess the real performance of CA-VI with CA-MDP formulation by analysing the execution time by checking how close it gets to the practical minimum runtime bound with respect to VI performance with MDP encoding of the same task.","Markov decision processes, Stochastic planning",Omer Ekmekci and Faruk Polat,https://www.sciencedirect.com/science/article/pii/S0921889018303294,https://doi.org/10.1016/j.robot.2018.11.013,0921-8890,2019,137--153,112,Robotics and Autonomous Systems,A context aware model for autonomous agent stochastic planning,article,EKMEKCI2019137
"Using tools from artificial intelligence, mainly artificial neural networks, this paper presents an walking-engine for humanoid robots. This engine uses dynamic neural networks with feedback for gait generation, a modified Zhang neural network for a singularity-robust inverse kinematics solver, and feedforward neural networks for neuro-adaptive control. The Atlas humanoid robot model in simulation is used to test and verify the capabilities of the neuro-dynamic walking engine. Results show that the engine is capable of generating conventional ZMP stable walking gaits and executing them using the Atlas robot in simulation.","Neural networks, Humanoid robot, ATLAS, Adaptive control",Ghassan Atmeh and Kamesh Subbarao,https://www.sciencedirect.com/science/article/pii/S0921889018301271,https://doi.org/10.1016/j.robot.2018.09.003,0921-8890,2018,124--138,110,Robotics and Autonomous Systems,A neuro-dynamic walking engine for humanoid robots,article,ATMEH2018124
"Existing path and velocity planning methods for car-like vehicles, the paths of which are subject to constraints on the derivative of the curvature in the horizontal plane, do not accurately express the relationships among position, velocity and acceleration in 3D space. Moreover, velocity planning algorithms are efficient only when the curvature and derivative of the curvature have the same velocity demand. As efficiency and comfort are two key issues in promoting planning algorithms, in this paper, the vehicle is allowed to know the nearly shortest-length path and to set a continuous velocity and acceleration profile to track the trajectory reference while taking into account bounds on acceleration (including lateral acceleration) and jerk that are consistent with comfort. First, to construct a nearly shortest path, the 3D path surface is mapped onto the horizontal, profile and frontal planes, and a 2D path smoothing method is applied to solve the 3D path smoothing problem. This method has been used in highway design, but the theoretical understanding of its performance remains limited. This limitation is addressed from the viewpoint of 3D path smoothing in this paper. In addition, the jerk, acceleration, velocity, steering angle and steering angular acceleration profile are merged into a trajectory tracking task to provide a new velocity planning method to find the time-optimal path. Finally, the capabilities of the path and velocity planning methods within general planning schemes are also demonstrated.","Path planning, Velocity planning, 3D space, Car-like vehicle, Highway design",He Zhang and Shaowei Yang,https://www.sciencedirect.com/science/article/pii/S0921889018300502,https://doi.org/10.1016/j.robot.2018.05.013,0921-8890,2018,87--99,107,Robotics and Autonomous Systems,Smooth path and velocity planning under 3D path constraints for car-like vehicles,article,ZHANG201887
"When humans move in a lateral direction (frontal plane), they intuitively understand the motion parallax phenomenon while jointly developing sensory neurons and pursuit eye movements with the help of their life-long learning experiences. At that time, various ranges of motion parallax effects are used to extract meaningful pieces of information such as relative depth of variously positioned objects and the spatial separation between the robot and the fixating object (absolute distance). By mimicking the visual learning in mammals to realize an autonomous robot system, a visual learning framework (Prucksakorn, 2016) was proposed to concurrently develop both visual sensory coding and pursuit eye movement with an addition of depth perception. Within the proposed framework, an artificial neural network was used to learn the relationship between the eye movements and the absolute distance. Nonetheless, the limitation of the proposed framework is that the predefined single lateral body movement cannot fully evoke the motion parallax effect for depth perception. Here, we extend the presented visual learning framework to accurately and autonomously represent the various ranges of absolute distance by using pursuit eye movements from multiple lateral body movements. We show that the proposed model, which is implemented in a HOAP3 humanoid robot simulator, can successfully enhance the smooth pursuit eye movement control with the self-calibrating ability and the distance estimation comparing to the single lateral movement based approach.","Active depth perception, Developmental vision, Motion parallax, Eye pursuit, Sensory-motor coordination",Tanapol Prucksakorn and Sungmoon Jeong and Nak Young Chong,https://www.sciencedirect.com/science/article/pii/S0921889017308539,https://doi.org/10.1016/j.robot.2018.08.009,0921-8890,2018,27--37,109,Robotics and Autonomous Systems,A self-trainable depth perception method from eye pursuit and motion parallax,article,PRUCKSAKORN201827
"Fast and efficient global localization is a critical problem for autonomous systems. Existing sequence-based visual place recognition requires a storage-intensive image database for robust localization, while more storage-efficient odometry-based place recognition approaches can require a long travel distance to obtain an accurate localization. In this paper, we present a novel particle filter-based localization system that adapts to varying degrees of map image densities, road layout ambiguity and visual appearance change. The base system combines a geometric place recognition capability utilizing odometry and roadmaps with a visual place recognition system. When using a sparse image database, particles could exist at visually unknown places, which introduces difficulties in performing sequential visual place recognition. To address this challenge, we propose to make use of effective visual observations to enable the system to accumulate visual belief sequentially, even when reference images are very sparse. Furthermore, we develop a vision reliability estimation method, which analyses the relationship between the visual component and the particle filter convergence, to calibrate the optimal contribution of vision to particle weighting in different visual environments and conditions. To evaluate our approach, we perform extensive experiments using four benchmark localization datasets, and control the reference image density by subsampling these datasets. Results show that the proposed technique is able to consistently and correctly localize the vehicle over a range of reference image densities, and to consistently outperform a particle filter-enhanced version of an existing state-of-the-art SeqSLAM system, which fails when image spacing exceeds 30 m. In particular, for a 600% increase in database image sparsity (from 10 m to 70 m), we show that the proposed method is able to maintain localization performance with only a 40% increase in localization latency (from 250 m to 350 m). We also provide an analysis of the results and a characterization of the system?s computational requirements.","Visual place recognition, Map-based localization, Odometry, Road map, Autonomous vehicles",Jun Mao and Xiaoping Hu and Michael Milford,https://www.sciencedirect.com/science/article/pii/S0921889018300617,https://doi.org/10.1016/j.robot.2018.06.007,0921-8890,2018,246--261,107,Robotics and Autonomous Systems,An adaptive localization system for image storage and localization latency requirements,article,MAO2018246
"Road region extraction is one of the key technologies to support the safe operation of vehicle intelligent system. Aiming at the current demands and difficulties of extracting unstructured roads in the field, a new road extraction algorithm based on vanishing point location is proposed in this paper. Based on the improvement of the vanishing point detection method with road border region estimation, the proposed method comprehends the spatial structure of the road image, and combines the color and edge information of the intrinsic image which extracted based on regression analysis. Then the road region can be extracted. The proposed method makes full use of the intermediate information in calculation process to improve the computational efficiency while ensuring the accuracy of the result. Besides, the algorithm performs well for road images under different environments.","Vanishing point, Intrinsic image, Road extraction, Regression analysis",Yong Li and Guofeng Tong and Anan Sun and Weili Ding,https://www.sciencedirect.com/science/article/pii/S0921889018303609,https://doi.org/10.1016/j.robot.2018.08.011,0921-8890,2018,86--96,109,Robotics and Autonomous Systems,Road extraction algorithm based on intrinsic image and vanishing point for unstructured road image,article,LI201886
"The ability to implement semantic Reach-to-grasp (RTG) tasks successfully is a crucial skill for robots. Given unknown objects in an unstructured environment, finding an feasible grasp configuration and generating a constraint-satisfied trajectory to reach it are challenging. In this paper, a learning framework which combines semantic grasp planning with trajectory generation is presented to implement semantic RTG tasks. Firstly, the object of interest is detected by using an object detection model trained by deep learning. A Bayesian-based search algorithm is proposed to find the grasp configuration with highest probability of success from the segmented image of the object using a trained quality network. Secondly, for robotic reaching movements, a model-based trajectory generation method inspired by the human internal model theory is designed to generate a constraint-satisfied trajectory. Finally, the presented framework is validated both in comparative analysis and on real-world experiments. Experimental results demonstrated that the proposed learning framework enables the robots to implement semantic RTG tasks in unstructured environments.","Semantic reach-to-grasp, Deep learning, Bayesian optimization, Model-based trajectory generation",Zhen Deng and Xiaoxiang Zheng and Liwei Zhang and Jianwei Zhang,https://www.sciencedirect.com/science/article/pii/S092188901730917X,https://doi.org/10.1016/j.robot.2018.08.001,0921-8890,2018,140--152,108,Robotics and Autonomous Systems,A learning framework for semantic reach-to-grasp tasks integrating machine learning and optimization,article,DENG2018140
"The recent increasing demands on accomplishing complicated manipulation tasks necessitate the development of effective task-motion planning techniques. To help understand robot movement intention and avoid causing unease or discomfort to nearby humans toward safe human?robot interaction when these tasks are performed in the vicinity of humans by those robot arms that resemble an anthropomorphic arrangement, a dedicated and unified anthropomorphism-aware task-motion planning framework for anthropomorphic arms is at a premium. A general human-inspired four-level Anthropomorphic Arm Motion Language (A2ML) is therefore proposed for the first time to serve as this framework. First, six hypotheses/rules of human arm motion are extracted from the literature in neurophysiological field, which form the basis and guidelines for the design of A2ML. Inspired by these rules, a library of movement primitives and related motion grammar are designed to build the complete motion language. The movement primitives in the library are designed from two different but associated representation spaces of arm configuration: Cartesian-posture-swivel-angle space and human arm triangle space. Since these two spaces can be always recognized for all the anthropomorphic arms, the designed movement primitives and consequent motion language possess favorable generality. Decomposition techniques described by the A2ML grammar are proposed to decompose complicated tasks into movement primitives. Furthermore, a quadratic programming based method and a sampling based method serve as powerful interfaces for transforming the decomposed tasks expressed in A2ML to the specific joint trajectories of different arms. Finally, the generality and advantages of the proposed motion language are validated by extensive simulations and experiments on two different anthropomorphic arms.","Anthropomorphic arm, Motion language, Task-motion planning, Movement primitive",Cheng Fang and Xilun Ding and Chengxu Zhou and Nikos Tsagarakis,https://www.sciencedirect.com/science/article/pii/S0921889018301829,https://doi.org/10.1016/j.robot.2018.10.006,0921-8890,2019,145--161,111,Robotics and Autonomous Systems,A2ML: A general human-inspired motion language for anthropomorphic arms based on movement primitives,article,FANG2019145
"This paper aims to present a cooperative and distributed navigation strategy, that is an on-line path planner, for an autonomous multi-robot system. The robots are intended to navigate and explore an unknown environment in order to find and reach obligatory passage points or way-points (goals), and then achieve a known final position. All robots in the team are homogeneous, independent and have limited communication skills. However they interact among them and with the environment to autonomously decide about their paths and tasks: if they should explore the environment, or avoid visiting a previously explored region, or to reach a discovered goal. Information sharing is directly carried out when the robots are into a communication area and/or indirectly by stigmergy. In this case, artificial pheromone, as a repulsive field, is used to mark regions that have already been explored by other members of the team, therefore avoiding redundant exploration and time waste. Fuzzy controllers are used for robots? motion. The proposed on line path planner performance is evaluated in different simulated environment scenarios and the main results are presented.","Multi-robot system, Path planning, Indirect communication, Distributed control",João Paulo Lima Silva {de Almeida} and Renan Taizo Nakashima and Flávio Neves-Jr and Lúcia Valéria Ramos {de Arruda},https://www.sciencedirect.com/science/article/pii/S0921889018303567,https://doi.org/10.1016/j.robot.2018.11.005,0921-8890,2019,32--48,112,Robotics and Autonomous Systems,Bio-inspired on-line path planner for cooperative exploration of unknown environment by a Multi-Robot System,article,DEALMEIDA201932
"Qualitative relational maps (QRM) are useful environmental representations for robots that incorporate information about point like and extended landmarks. While several methods for generating QRM exist, no general planning methods for QRM are available. This paper introduces qualitative linking (Q-Link), a general three level planning architecture for use with any type of QRM. Q-Link generates high level plans over ?links? in a QRM and uses local planners to execute trajectories to enable a robot to navigate from a start to a goal. Q-Link is adaptable to any robotic platform, and can plan over deterministic information from a QRM or uncertain information from a probabilistic QRM. Path completion guarantees and distance bounds are provided for environments with point landmarks and no occlusions. The performance of Q-Link is tested in simulation and an in vivo study, where path completion is not guaranteed. The simulation studies show that Q-Link is robust to failure in scenarios where a specific landmark density is guaranteed with minimal occlusions (over 97% path completion rate), but sensitive to environments with insufficient landmark density (up to 74% failure rate) . The in vivo studies show that Q-Link is robust to failure in an outdoor navigation scenario for three different environment types that contain point landmarks and extended landmarks (72% path completion rate).",,Jennifer Padgett and Mark Campbell,https://www.sciencedirect.com/science/article/pii/S0921889017304220,https://doi.org/10.1016/j.robot.2018.07.001,0921-8890,2018,51--65,108,Robotics and Autonomous Systems,Q-Link: A general planning architecture for navigation with qualitative relational information,article,PADGETT201851
"The main focus of this work is the development of a software architecture to autonomously navigate a flying vehicle in an indoor environment in presence of obstacles. The hardware platform used to test the developed algorithms is the AscTec Firefly equipped with a RGB-D camera (Microsoft Kinect): the sensor output is used to incrementally build a map of the environment and generate a collision-free path. Specifically, we introduce a novel approach to analytically compute the path in an efficient and effective manner. An initial path, given by the intersection of two 3D surfaces, is shaped around the obstacles by adding to either of the two surfaces a radial function at every obstacle location. The intersection between the deformed surfaces is guaranteed not to intersect obstacles, hence it is a safe path for the robot to follow. The entire computation runs on-board and the path is computed in real-time. In this article we present the developed algorithms, the software architecture as well as the results of our experiments, showing that the method can adapt in real time the robot?s path in order to avoid several types of obstacles, while producing a map of the surroundings.","UAV, MAV, Flying vehicle, Obstacle avoidance, Path planning",Massimiliano Iacono and Antonio Sgorbissa,https://www.sciencedirect.com/science/article/pii/S0921889018301027,https://doi.org/10.1016/j.robot.2018.04.005,0921-8890,2018,38--46,106,Robotics and Autonomous Systems,Path following and obstacle avoidance for an autonomous UAV using a depth camera,article,IACONO201838
"A world model representing the elements in a robot?s environment needs to maintain a correspondence between the objects being observed and their internal representations, which is known as the anchoring problem. Anchoring is a key aspect for an intelligent robot operation, since it enables high-level functions such as task planning and execution. This work presents an anchoring system that continually integrates new observations from a 3D object recognition algorithm into a probabilistic world model. Our system takes advantage of the contextual relations inherent to human-made spaces in order to improve the classification results of the baseline object recognition system. To achieve that, the system builds a graph-based world model containing the objects in the scene (both in the current and previously perceived observations), which is exploited by a Probabilistic Graphical Model (PGM) in order to leverage contextual information during recognition. The world model also enables the system to exploit information about objects beyond the current field of view of the robot sensors. Most importantly, this is done in an online fashion, overcoming both the disadvantages of single-shot recognition systems (e.g., limited sensor aperture) and offline recognition systems that require prior registration of all frames of a scene (e.g., dynamic scenes, unsuitability for plan-based robot control). We also propose a novel way to include the outcome of local object recognition methods in the PGM, which results in a decrease in the usually high model learning complexity and an increase in the system performance. The system performance has been assessed with a dataset collected by a mobile robot from restaurant-like settings, obtaining positive results for both its data association and object recognition capabilities. The system has been successfully used in the RACE robotic architecture.","Context-aware anchoring, Anchoring, World modeling, Data association, Mobile robotics, Conditional random fields",Martin Günther and J.R. Ruiz-Sarmiento and Cipriano Galindo and Javier González-Jiménez and Joachim Hertzberg,https://www.sciencedirect.com/science/article/pii/S0921889017307856,https://doi.org/10.1016/j.robot.2018.08.016,0921-8890,2018,12--32,110,Robotics and Autonomous Systems,Context-aware 3D object anchoring for mobile robots,article,GUNTHER201812
"RGB-D data-based Simultaneous Localization and Mapping (RGB-D SLAM) aims to concurrently estimate robot poses and reconstruct traversed environments using RGB-D sensors. Many effective and impressive RGB-D SLAM algorithms have been proposed over the past years. However, virtually all the RGB-D SLAM systems developed so far rely on the static-world assumption. This is because the SLAM performance is prone to be degraded by the moving objects in dynamic environments. In this paper, we propose a novel RGB-D data-based motion removal approach to address this problem. The approach is on-line and does not require prior-known moving-object information, such as semantics or visual appearances. We integrate the approach into the front end of an RGB-D SLAM system. It acts as a pre-processing stage to filter out data that are associated with moving objects. Experimental results demonstrate that our approach is able to improve RGB-D SLAM in various challenging scenarios.","Motion removal, Codebook model, Dynamic environments, RGB-D SLAM",Yuxiang Sun and Ming Liu and Max Q.-H. Meng,https://www.sciencedirect.com/science/article/pii/S0921889018300691,https://doi.org/10.1016/j.robot.2018.07.002,0921-8890,2018,115--128,108,Robotics and Autonomous Systems,Motion removal for reliable RGB-D SLAM in dynamic environments,article,SUN2018115
"Human activity understanding has attracted much attention in recent years, because it plays a key role in a wide range of applications such as human?computer interfaces, visual surveillance, video indexing, intelligent humanoids robots, ambient intelligence and more. Activity understanding strongly benefits from fast, predictive action recognition. Here we present a new prediction algorithm for manipulation action classes in natural scenes. Manipulations are first represented by their temporal sequence of changing static and dynamic spatial relations between the objects that take part in the manipulation. This creates a transition matrix, called ?Enriched Semantic Event Chain (ESEC)?. We use these ESECs to classify and predict a large set of manipulations. We find that manipulations can be correctly predicted after only (on average) 45% of their total execution time and that we are almost twice as fast as a standard HMM-based method used for comparison.","Action classification, Action prediction, Symbolic framework",Fatemeh Ziaeetabar and Tomas Kulvicius and Minija Tamosiunaite and Florentin Wörgötter,https://www.sciencedirect.com/science/article/pii/S0921889018303725,https://doi.org/10.1016/j.robot.2018.10.005,0921-8890,2018,173--188,110,Robotics and Autonomous Systems,Recognition and prediction of manipulation actions using Enriched Semantic Event Chains,article,ZIAEETABAR2018173
"This paper presents path following control experiments of a miniature spherical rolling and spinning robot mechanism on three different types of outdoor surfaces. The research is inspired from the efficient locomotory rolling patterns of various insects in unstructured environment. A nonlinear adaptive sliding mode (ASMC) feedback method maintains the robot stability and robustness in the presence of parameter uncertainties and external disturbances. The proposed path following control policy is developed, implemented and tested for the miniature spherical robot on three different types of irregular surfaces in outdoors. Path following accuracy, roll angle stability and wheel velocity response are three parameters measured to evaluate robot performance. ASMC controller capability is compared with an integral sliding mode (ISMC) controller. Experimental results show that proposed nonlinear robust control policy precisely tracks the different paths on these irregular surfaces in practical outdoor conditions.","Spherical robot, Rolling gait, Central pattern generator (), Path following control, Adaptive sliding mode () control",Abhra Roy Chowdhury and G.S. Soh and S.H. Foong and K.L. Wood,https://www.sciencedirect.com/science/article/pii/S0921889017307212,https://doi.org/10.1016/j.robot.2018.05.004,0921-8890,2018,140--151,106,Robotics and Autonomous Systems,Experiments in robust path following control of a rolling and spinning robot on outdoor surfaces,article,CHOWDHURY2018140
"Inspired by human dancers who make a comprehensive aesthetic judgement of their own dance poses by using both visual and non-visual information, this paper presents a novel feature fusion based approach to automatic aesthetics evaluation of robotic dance poses in order to improve the performance of robotic choreography creation. Four kinds of features are extracted, namely kinematic feature, region feature, contour feature, and spatial distribution feature of colour block. Based on different feature combinations, machine learning is deployed to train aesthetics models for the automatic judgement on robotic dance poses. The proposed approach has been implemented on a simulated robot environment, and experimental results are presented to verify its feasibility and good performance.","Robotic dance pose, Feature fusion, Machine learning, Automatic aesthetics estimation",Hua Peng and Jing Li and Huosheng Hu and Liping Zhao and Sheng Feng and Keli Hu,https://www.sciencedirect.com/science/article/pii/S0921889018305220,https://doi.org/10.1016/j.robot.2018.10.016,0921-8890,2019,99--109,111,Robotics and Autonomous Systems,Feature fusion based automatic aesthetics evaluation of robotic dance poses,article,PENG201999
"Public datasets are becoming extremely important for the scientific and industrial community to accelerate the development of new approaches and to guarantee identical testing conditions for comparing methods proposed by different researchers. This research presents the Urban@CRAS dataset that captures several scenarios of one iconic region at Porto Portugal These scenario presents a multiplicity of conditions and urban situations including, vehicle-to-vehicle and vehicle-to-human interactions, cross-sides, turn-around, roundabouts and different traffic conditions. Data from these scenarios are timestamped, calibrated and acquired at 10 to 200 Hz by through a set of heterogeneous sensors installed in a roof of a car. These sensors include a 3D LIDAR, high-resolution color cameras, a high-precision IMU and a GPS navigation system. In addition, positioning information obtained from a real-time kinematic satellite navigation system (with 0.05m of error) is also included as ground-truth. Moreover, a benchmarking process for some typical methods for visual odometry and SLAM is also included in this research, where qualitative and quantitative performance indicators are used to discuss the advantages and particularities of each implementation. Thus, this research fosters new advances on the perception and navigation approaches of autonomous robots (and driving).","Dataset, Autonomous driving, Mobile robots, Odometry, SLAM, Benchmarks, Computer vision, Urban@CRAS",Ana Rita Gaspar and Alexandra Nunes and Andry Maykol Pinto and Aníbal Matos,https://www.sciencedirect.com/science/article/pii/S0921889018301386,https://doi.org/10.1016/j.robot.2018.08.004,0921-8890,2018,59--67,109,Robotics and Autonomous Systems,Urban@CRAS dataset: Benchmarking of visual odometry and SLAM techniques,article,GASPAR201859
"We report on an extensive study of the benefits and limitations of current deep learning approaches to object recognition in robot vision scenarios, introducing a novel dataset used for our investigation. To avoid the biases in currently available datasets, we consider a natural human?robot interaction setting to design a data-acquisition protocol for visual object recognition on the iCub humanoid robot. Analyzing the performance of off-the-shelf models trained off-line on large-scale image retrieval datasets, we show the necessity for knowledge transfer. We evaluate different ways in which this last step can be done, and identify the major bottlenecks affecting robotic scenarios. By studying both object categorization and identification problems, we highlight key differences between object recognition in robotics applications and in image retrieval tasks, for which the considered deep learning approaches have been originally designed. In a nutshell, our results confirm the remarkable improvements yield by deep learning in this setting, while pointing to specific open challenges that need be addressed for seamless deployment in robotics.","Humanoid robotics, Robot vision, Visual object recognition, Machine learning, Deep learning, Transfer learning, Image dataset, Dataset collection, Representation invariance, iCub",Giulia Pasquale and Carlo Ciliberto and Francesca Odone and Lorenzo Rosasco and Lorenzo Natale,https://www.sciencedirect.com/science/article/pii/S0921889018300332,https://doi.org/10.1016/j.robot.2018.11.001,0921-8890,2019,260--281,112,Robotics and Autonomous Systems,Are we done with object recognition? The iCub robot?s perspective,article,PASQUALE2019260
"We propose a model for the allocation of agents to tasks when the tasks have a cost which grows over time. Our model accounts for both the natural growth of tasks and the effort of the agents at containing such growth. The objective is to produce solutions that minimize the growth of tasks (potentially stopping such growth) by efficiently coordinating the operations of the agents. This problem has strong spatial and temporal components, as the agents require time not only to work on the tasks but also to move between tasks and during that time the costs of completing the tasks continue to grow. We propose a novel distributed coordination algorithm, called Lazy max-sum, which works well even when the model of the environment has errors. The algorithm handles homogeneous as well as heterogeneous agents, which can do different amounts of work per time unit and have different travel speeds. We show experimentally that the algorithm outperforms other methods in both a simple simulation and the RoboCup Rescue agent simulation.","Multi-agent, Task allocation, Decentralized methods",James Parker and Alessandro Farinelli and Maria Gini,https://www.sciencedirect.com/science/article/pii/S0921889017307297,https://doi.org/10.1016/j.robot.2018.08.015,0921-8890,2018,44--56,110,Robotics and Autonomous Systems,Lazy max-sum for allocation of tasks with growing costs,article,PARKER201844
"Efficient, cost effective, and fast automated guided vehicles (AGVs) are getting more an more attention day by day. Giant industries and huge businesses has already adopted the AGV technology to boost their profits. In order to make the AGVs more affordable for medium or small businesses, manufacturing costs must be reduced. A line follower AGV is a cost effective solution among the others. A line follower usually follows a painted line on the floor that guides it to its destination. Line followers generally avoid high cost line detection algorithms because of limited computational power. As the processors getting faster, cheaper, and smaller the question arises: is it possible to utilize costly algorithms such as evolutionary algorithms in such a real-time application? In this paper, a novel technique is presented for applying harmony search evolutionary algorithm in real-time line detection vision based and the idea was implemented using a two wheeled robotic platform. Proposed robot detects and follows the path with high levels of accuracy, without the need for edge detection and independent of image resolution.","Harmony search, Line follower, Machine vision, Line detection, Automated guided vehicle",Mahmoud Bakhshinejad Beigzadeh Mahaleh and Seyed Abolghasem Mirroshandel,https://www.sciencedirect.com/science/article/pii/S0921889017308023,https://doi.org/10.1016/j.robot.2018.06.008,0921-8890,2018,156--166,107,Robotics and Autonomous Systems,Harmony search path detection for vision based automated guided vehicle,article,MAHALEH2018156
"This paper reports on the design and development of new cosmetic gloves made of two different superelastic rubbers ? thermoplastic styrene elastomer (TSE) and silicone rubber (TSG silicone) ? and compares them with gloves made of polyvinyl chloride (PVC) for myoelectric prosthetic hands to realize a realistic appearance and flexible motion. The materials are compared in terms of their appearance, material, mechanical, and sensing properties. Appearance properties include the shape, wrinkles, fingerprints, texture, nail, and color of the hand; these properties are designed so as to produce a prosthetic hand that looks similar to a human hand. The material properties are evaluated in terms of adaptability for daily living without preventing finger motions of the powered hand by performing a tear strength test. Mechanical properties are improved by designing the thickness of the palm to grip an object. The sensing properties are essential for acquiring information about the object and the environment. The overall performance is evaluated through a material engineering test and a pick-and-place test with a powered prosthetic hand. Tear strength comparisons showed that TSE and TSG silicone could respectively withstand 5?7 and 3 times the strain that PVC could withstand before breakage. The TSE glove shows the highest stretching length before breaking and shows high flexibility even after breaking. The electric currents during EMG prosthetic hand motion showed that TSE and TSG silicone gloves successfully reduced energy consumption by around one-third for many hand movements. Flexibility test results for the maximum opening posture showed that the PVC glove greatly restricted the hand opening width. However, the differences between the cases without and with TSE gloves were very small; therefore, both cases show the same range of motion. The flexible TSE facilitated easy fitting and therefore had the lowest fitting time; in fact, it can be worn in one-third the time required for wearing PVC or TSG silicone gloves. In pick-and-place experiments, TSG silicone and TSE gloves both showed similar results for successfully grasping objects. The TSE glove is hard to break and has high elasticity; therefore, nails can be added to it. Furthermore, TSG resin is thermosetting and can be processed at room temperature, making it easy to impart conductivity. Therefore, the TSG silicone material is more suitable for implementing a sensor.","Cosmetic gloves, Myoelectric prosthetic hand, Gripping performance, Skin texture, Superelastic rubber, Thermoplastic styrene elastomer, Silicone elastomer",Yoshiko Yabuki and Kazumasa Tanahashi and Yasuhiro Mouri and Yuta Murai and Shunta Togo and Ryu Kato and Yinlai Jiang and Hiroshi Yokoi,https://www.sciencedirect.com/science/article/pii/S0921889017306772,https://doi.org/10.1016/j.robot.2018.09.004,0921-8890,2019,31--43,111,Robotics and Autonomous Systems,Development of new cosmetic gloves for myoelectric prosthetic hand using superelastic rubber,article,YABUKI201931
"This paper presents NAR-RM, a method for learning robot reaching motions from a set of demonstrations using Nonlinear AutoRegressive (NAR) polynomial models. Reaching motions are modeled as solutions to autonomous discrete-time nonlinear dynamical systems, so that the movements started near the data of the demonstrations follow the trained trajectories and always reach and stop at the target. Since NAR models obtained using standard system identification techniques do not always adequately model the reaching motions, in this paper we present a method that uses a least-squares estimator with constraints to impose the location of fixed points in the model. With the imposition of new fixed points it is possible to change the location of the original fixed points of the model, thus allowing the learning of stable reaching motions. We evaluate our method using a library of human handwriting motions, a mobile robot and an industrial manipulator.","Learning by demonstration, Nonlinear autoregressive models, Dynamical systems, Fixed point",Rafael F. Santos and Guilherme A.S. Pereira and L.A. Aguirre,https://www.sciencedirect.com/science/article/pii/S092188901730814X,https://doi.org/10.1016/j.robot.2018.06.006,0921-8890,2018,182--195,107,Robotics and Autonomous Systems,Learning robot reaching motions by demonstration using nonlinear autoregressive models,article,SANTOS2018182
"The motion of a mechanical system can be defined as a path through its configuration space. Computing such a path has a computational complexity scaling exponentially with the dimensionality of the configuration space. We propose to reduce the dimensionality of the configuration space by introducing the irreducible path ? a path having a minimal swept volume. The paper consists of three parts: In part I, we define the space of all irreducible paths and show that planning a path in the irreducible path space preserves completeness of any motion planning algorithm. In part II, we construct an approximation to the irreducible path space of a serial kinematic chain under certain assumptions. In part III, we conduct motion planning using the irreducible path space for a mechanical snake in a turbine environment, for a mechanical octopus with eight arms in a pipe system and for the sideways motion of a humanoid robot moving through a room with doors and through a hole in a wall. We demonstrate that the concept of an irreducible path can be applied to any motion planning algorithm taking curvature constraints into account.","Motion planning, Irreducible paths, Serial kinematic chain, Swept volume",Andreas Orthey and Olivier Roussel and Olivier Stasse and Michel Taïx,https://www.sciencedirect.com/science/article/pii/S0921889018303671,https://doi.org/10.1016/j.robot.2018.08.012,0921-8890,2018,97--108,109,Robotics and Autonomous Systems,Motion planning in Irreducible Path Spaces,article,ORTHEY201897
"This study proposes a biped robot state estimation framework based on a compliant inverted pendulum model and a robust state estimator. A proper model that can express the key physical characteristics while considering limited computing power should be defined for the biped robot state estimation. A biped robot?s limited structural stiffness and relatively long legs compared with the cross section of the body lead to undesired flexibility. However, the models used in previous research are either not suitable for state estimation or too simple to express the essential characteristics of the biped robot. A compliant inverted pendulum model is adopted herein to enhance the estimation accuracy. This model is made by adding a virtual spring and a damper to the conventional inverted pendulum. The additional elements represent the mechanical deformation and the undesired flexible movement. Adopting this model makes it possible to reflect the important characteristics of the biped robot while taking advantage of the merits of the single-mass model. In addition, a robust state estimator that we previously proposed is adopted to compensate for the estimation error caused by the modeling error. Using these two factors, the improved COM-kinematics estimate is obtained with respect to the existing simple-model-based biped state estimators.","Biped robot state estimation, Compliant inverted pendulum model, Robust state estimation, Undesired mechanical deformation",Hyoin Bae and Jun-Ho Oh,https://www.sciencedirect.com/science/article/pii/S0921889018301131,https://doi.org/10.1016/j.robot.2018.06.004,0921-8890,2018,38--50,108,Robotics and Autonomous Systems,Biped robot state estimation using compliant inverted pendulum model,article,BAE201838
"A novel semi-direct monocular visual simultaneous localization and mapping (SLAM) system is proposed to maintain the fast performance of a direct method and the high precision and loop closure capability of a feature-based method. This system extracts and matches Oriented FAST and Rotated BRIEF features in a keyframe and tracks a non-keyframe via a direct method without the requirement of extracting and matching features. A keyframe is used for global or local optimization and loop closure, whereas a non-keyframe is used for fast tracking and localization, thereby combining the advantages of direct and feature-based methods. A monocular visual-inertial SLAM system that fuses inertial measurement data with visual SLAM is also proposed. This system successfully recovers the metric scale successfully. The evaluation on datasets shows that the proposed approach accomplishes loop closure detection successfully and requires less time to achieve accuracy comparable with that of feature-based method. The physical experiment demonstrates the feasibility and robustness of the proposed SLAM. The approach achieves good balance between speed and accuracy and provides valuable references for design and improvement of other SLAM methods.","Robot vision, Simultaneous localization and mapping (SLAM), Loop closure detection",Shao-peng Li and Tao Zhang and Xiang Gao and Duo Wang and Yong Xian,https://www.sciencedirect.com/science/article/pii/S0921889018301374,https://doi.org/10.1016/j.robot.2018.11.009,0921-8890,2019,201--210,112,Robotics and Autonomous Systems,Semi-direct monocular visual and visual-inertial SLAM with loop closure detection,article,LI2019201
"A novel transformable wheel-legged robot, namely Land Devil Ray (LDR), is proposed for search and rescue mission in complex terrains. Inspired from spatial folding mechanism and metamorphic mechanism, a multi-four-bar linkage transformable wheel-legged locomotion mechanism is proposed for LDR, which can transform from circle-wheeled mobility to wheel-legged mobility, or vice versa, for adaptability of different terrains. Aimed to minimize the robot actuators, the wheel-legged transformation is designed to be triggered passively when contacting the obstacles, or be actively driven without extra actuator by active triggering mechanism. The parameters of wheel-legged structure are optimized as well for an optimal transformation success rate and better obstacle-negotiation capability. A prototype of LDR robot is conducted, and its experiment results show that the proposed robot integrates the advantages of both wheeled and legged mobility, and has excellent performance in maneuverability, stability, maximum obstacle-negotiation height and mode switch process, such as transformation ratio as 1.88, transformation success rate as 100%, and ability to over obstacles 2.8 times as tall as its wheel radius. Lessons learned from the proposed robotic mobility and its results have general applicability to search / rescue robots, and other types of mobile robots as well.","Rescue robot, Mobile robot, Wheel-legged mobility, Transformable wheel, Obstacle negotiation",Long Bai and Jian Guan and Xiaohong Chen and Junzhan Hou and Wenbo Duan,https://www.sciencedirect.com/science/article/pii/S0921889018301891,https://doi.org/10.1016/j.robot.2018.06.005,0921-8890,2018,145--155,107,Robotics and Autonomous Systems,An optional passive/active transformable wheel-legged mobility concept for search and rescue robots,article,BAI2018145
"Tracked vehicles have inherent advantages over wheeled vehicles, as the former provide stable locomotion on loose and uneven terrain. However, compared with the latter, the slippage generated due to the complex, nonlinear track-terrain interactions during skid-steering to follow a curve, brings about difficulties preventing the accurate prediction of their motions. The key to improving the accuracy of trajectory-following is the ?proper? motion control methodology that can accurately factor-in the slippage behavior. In this paper, the authors propose a novel approach to the dynamic modeling and motion control of tracked vehicles undergoing skid-steering on horizontal, hard terrain, under nonholonomic constraints. Due to the skew-symmetry property of nonholonomic mechanical systems, the control methodology is established using the backstepping method based on a modified Proportional?Integral?Derivative (PID) computed-torque control. A key element in the control strategy proposed here is the reliable estimation of the pose ? position and orientation ? of the vehicle platform and its twist?point velocity and angular velocity. It is assumed that the vehicle is suitably instrumented to allow for accurate-enough pose and twist estimates. Validated via a numerical example, the proposed controller is proven to be effective in controlling an unmanned tracked vehicle.","Tracked vehicle, Skew-symmetry property, Trajectory tracking control, Planar kinematics, Nonholonomic constraint",Ting Zou and Jorge Angeles and Ferri Hassani,https://www.sciencedirect.com/science/article/pii/S0921889018300319,https://doi.org/10.1016/j.robot.2018.09.008,0921-8890,2018,102--111,110,Robotics and Autonomous Systems,Dynamic modeling and trajectory tracking control of unmanned tracked vehicles,article,ZOU2018102
"Both scientists and roboticists widely agree that the musculoskeletal system of the human foot plays an important role in locomotion. Nevertheless, the contribution of the foot musculoskeletal system has not been fully uncovered because currently it is impossible to modify and evaluate musculoskeletons in living animals. Here, to understand the effects of foot windlass mechanism, we construct a bipedal robot, which has similar musculoskeleton and dynamics to those of human. By implementing experiments on this robot, we investigate the effects (e.g. jumping height) of foot windlass mechanism on drop jumping, a simple and representative bouncing gait comprising landing and push-off. Through a significant number of drop jumping trials, the results demonstrated that (1) the windlass mechanism is passively activated in the push-off phase and that (2) it contributes to the height of jumping. Our results suggest that the foot windlass mechanism contributes to the energy efficiency and performance in locomotion.","Foot windlass mechanism, Musculoskeletal robot, Locomotion efficiency, Jumping height, Drop jumping/bouncing",Xiangxiao Liu and Yu Duan and Arne Hitzmann and Yuntong Xu and Tsungyuan Chen and Shuhei Ikemoto and Koh Hosoda,https://www.sciencedirect.com/science/article/pii/S0921889017307182,https://doi.org/10.1016/j.robot.2018.09.006,0921-8890,2018,85--91,110,Robotics and Autonomous Systems,Using the foot windlass mechanism for jumping higher: A study on bipedal robot jumping,article,LIU201885
"Articulated and flexible objects constitute a challenge for robot manipulation tasks but are present in different real-world settings, including home and industrial environments. Current approaches to the manipulation of articulated and flexible objects employ ad hoc strategies to sequence and perform actions on them depending on a number of physical or geometrical characteristics related to those objects, as well as on an a priori classification of target object configurations. In this paper, we propose an action planning and execution framework, which (i) considers abstract representations of articulated or flexible objects, (ii) integrates action planning to reason upon such configurations and to sequence an appropriate set of actions with the aim of obtaining a target configuration provided as a goal, and (iii) is able to cooperate with humans to collaboratively carry out the plan. On the one hand, we show that a trade-off exists between the way articulated or flexible objects are perceived and how the system represents them. Such a trade-off greatly impacts on the complexity of the planning process. On the other hand, we demonstrate the system?s capabilities in allowing humans to interrupt robot action execution, and ?in general ?to contribute to the whole manipulation process. Results related to planning performance are discussed, and examples with a Baxter dual-arm manipulator performing actions collaboratively with humans are shown.","Planning, Knowledge representation, Software architecture, Articulated object",Alessio Capitanelli and Marco Maratea and Fulvio Mastrogiovanni and Mauro Vallati,https://www.sciencedirect.com/science/article/pii/S0921889018300034,https://doi.org/10.1016/j.robot.2018.08.003,0921-8890,2018,139--155,109,Robotics and Autonomous Systems,On the manipulation of articulated objects in human?robot cooperation scenarios,article,CAPITANELLI2018139
"This paper describes the pulling and steering of magnetic therapeutic microparticles for drug delivery based on a macro?micromanipulator system. The macromanipulation system is composed of a 6 Degree Of Freedom (6 DOF) serial manipulator while a linear permanent-based actuator (1 DOF) is equipped at the end-effector as a micropart to precisely steer and pull magnetic microparticles. Using the classical mathematical tools of robotics, we developed the global kinematic model of the robot-device assembly, thus defining a reference trajectory to propel the microparticles. A novel actuator-based permanent magnet has been designed and realized as a robot micro end-effector to control the trajectory of a microparticle along a millimeter-sized workspace. Simulations and experiments were conducted to show the ability of the macro?micromanipulator system to steer particles on a viscous fluid simulating a biological media.","Inner ear, Drug delivery, Serial manipulator, Microrobots, Permanent magnets",W. Amokrane and K. Belharet and M. Souissi and A. Bozorg Grayeli and A. Ferreira,https://www.sciencedirect.com/science/article/pii/S0921889017307996,https://doi.org/10.1016/j.robot.2018.05.002,0921-8890,2018,10--19,107,Robotics and Autonomous Systems,Macro?micromanipulation platform for inner ear drug delivery,article,AMOKRANE201810
"Robust and fast motion estimation and mapping is a key prerequisite for autonomous operation of mobile robots. The goal of performing this task solely on a stereo pair of video cameras is highly demanding and bears conflicting objectives: on one hand, the motion has to be tracked fast and reliably, on the other hand, high-level functions like navigation and obstacle avoidance depend crucially on a complete and accurate environment representation. In this work, we propose a two-layer approach for visual odometry and SLAM with stereo cameras that runs in real-time and combines feature-based matching with semi-dense direct image alignment. Our method initializes semi-dense depth estimation, which is computationally expensive, from motion that is tracked by a fast but robust keypoint-based method. Experiments on public benchmark and proprietary datasets show that our approach is faster than state-of-the-art methods without losing accuracy and yields comparable map building capabilities. Moreover, our approach is shown to handle large inter-frame motion and illumination changes much more robustly than its direct counterparts.","Visual simultaneous localization and mapping, Visual odometry, Feature-based SLAM, Semi-dense SLAM",Nicola Krombach and David Droeschel and Sebastian Houben and Sven Behnke,https://www.sciencedirect.com/science/article/pii/S0921889017308205,https://doi.org/10.1016/j.robot.2018.08.002,0921-8890,2018,38--58,109,Robotics and Autonomous Systems,Feature-based visual odometry prior for real-time semi-dense stereo SLAM,article,KROMBACH201838
"This paper presents extensions and practical realization of a previously proposed novel approach to navigation and sensor integration for small unmanned aerial vehicles (UAV). The proposed approach employs vehicle dynamic model (VDM) as process model within navigation system, and treats data from other sensors such as inertial measurement unit (IMU), barometric altimeter, and global navigation satellite system (GNSS) receiver as observations within the system. In comparison to conventional approach that employs inertial navigation system (INS) as process model, employing VDM requires no added hardware, yet significantly improves navigation performance, especially in case of GNSS outages. Experimental results from a real flight on a custom made fixed-wing UAV, as well as Monte Carlo simulation results, reveal improvements of 1 to 2 orders of magnitude in navigation accuracy during GNSS outages of 3 minutes? duration. This is a prerequisite for safer navigation without exteroceptive sensors. Uncertainty levels are predicted consistently within the filter, and a discussion on observability based on covariance matrix analysis is presented. Computation time is also compared to conventional INS-based approach.","UAV, Autonomous navigation, Vehicle dynamic model, GNSS outage, Inertial navigation",Mehran Khaghani and Jan Skaloud,https://www.sciencedirect.com/science/article/pii/S0921889017303792,https://doi.org/10.1016/j.robot.2018.05.007,0921-8890,2018,152--164,106,Robotics and Autonomous Systems,Assessment of VDM-based autonomous navigation of a UAV under operational conditions,article,KHAGHANI2018152
"The estimation of the internal model of a robotic system results from the interaction of its morphology, sensors and actuators, with a particular environment. Model learning techniques, based on supervised machine learning, are widespread for determining the internal model. An important limitation of such approaches is that once a model has been learnt, it does not behave properly when the robot morphology is changed. From this it follows that there must exist a relationship between them. We propose a model for this correlation between the morphology and the internal model parameters, so that a new internal model can be predicted when the morphological parameters are modified. Different neural network architectures are proposed to address this high dimensional regression problem. A case study is analyzed in detail to illustrate and evaluate the performance of the approach, namely, a pan?tilt robot head executing saccadic movements. The best results are obtained for an architecture with parallel neural networks. Our results can be instrumental in state-of-the-art trends such as self-reconfigurable robots, reproducible research, cyber?physical robotic systems or cloud robotics, in which internal models would available as shared knowledge, so that robots with different morphologies can readily exhibit a particular behavior in a given environment.","Model learning, Internal model, Morphology, Neural networks, Visual learning",Angel J. Duran and Angel P. {del Pobil},https://www.sciencedirect.com/science/article/pii/S0921889017306942,https://doi.org/10.1016/j.robot.2018.08.014,0921-8890,2018,33--43,110,Robotics and Autonomous Systems,Predicting the internal model of a robotic system from its morphology,article,DURAN201833
"A new reactive collision avoidance method for navigation of aerial robots (such as unmanned aerial vehicles (UAVs)) in unstructured urban/suburban environments is presented. Small form-factor aerial robots, such as quadcopters, often have limited payload capacity, flight time, processing power, and sensing capabilities. To enhance the capabilities of such vehicles without increasing weight or computing power, a reactive collision avoidance method based on open sectors is described. The method utilizes information from a two-dimensional laser scan of the environment and a short-term memory of past actions and can rapidly circumvent obstacles in outdoor urban/suburban environments. With no map required, the method enables the robot to react quickly and navigate even when the enivornment changes. Furthermore, the low computational requirement of the method allows the robot to quickly react to unknown obstacles that may be poorly represented in the scan, such as trees with branches and leaves. The method is validated in simulation results and through physical experiments on a prototype quadcopter system, where results show the robot flying smoothly around obstacles at a relatively high speed (3 m/s).",,Jake A. Steiner and Xiang He and Joseph R. Bourne and Kam K. Leang,https://www.sciencedirect.com/science/article/pii/S0921889018303944,https://doi.org/10.1016/j.robot.2018.11.016,0921-8890,2019,211--220,112,Robotics and Autonomous Systems,Open-sector rapid-reactive collision avoidance: Application in aerial robot navigation through outdoor unstructured environments,article,STEINER2019211
"In distance-based localization, estimating the position of a network of wireless sensors is not an easy task. The problem increases when dealing with moving nodes and cluttered indoor environments. Many algorithms have been proposed in the literature and, among them, the Multidimensional Scaling (MDS) technique gained a lot of interest due to its resilience to flips ambiguities and easiness of use. Many variants of MDS have been proposed to overcome issues such as partial connectivity or distributed computation. In this context, it is common to place some anchors nodes to help in estimating the coordinates of the network correctly. However, instead of using the anchor?s positions directly during the minimization of the MDS cost function, most approaches act on the estimated coordinates at the end of the MDS computation without fully utilizing the knowledge about anchors. In this work, the classic MDS and Dynamic MDS have been reformulated to utilize the anchor?s position inside the minimization function. A set of real experiments in 3D with Ultrawide-band devices show that our approach considerably improves the accuracy of localization with respect to the usual MDS techniques.","Multidimensional scaling, Anchors, Distance-based localization, Mobile nodes, Indoor localization",Carmelo {Di Franco} and Mauro Marinoni and Enrico Bini and Giorgio C. Buttazzo,https://www.sciencedirect.com/science/article/pii/S0921889017308047,https://doi.org/10.1016/j.robot.2018.06.015,0921-8890,2018,28--37,108,Robotics and Autonomous Systems,Dynamic Multidimensional Scaling with anchors and height constraints for indoor localization of mobile nodes,article,DIFRANCO201828
"Embedding a robot with a companion computer is becoming a common practice nowadays. Such computer is installed with an operatingsystem, often a Linux distribution. Moreover, Graphic Processing Units (GPUs) can be embedded on a robot, giving it the capacity of performing complex on-board computing tasks while executing a mission. It seems that a next logical transition, consist of deploying a cluster of computers among embedded computing cards. With this approach, a multi-robot system can be set as a High Performance Computing (HPC) cluster. The advantages of such infrastructure are many, from providing higher computing power up to setting scalable multi-robot systems. While HPC has been always seen as a speeding-up tool, we believe that HPC in the world of robotics can do much more than simply accelerating the execution of complex computing tasks. In this paper, we introduce the novel concept of High Performance Robotic Computing ? HPRC, an augmentation of the ideas behind traditional HPC to fit and enhance the world of robotics. As a proof of concept, we introduce novel HPC software developed to control the motion of a set of robots using the standard parallel MPI (Message Passing Interface) library. The parallel motion software includes two operation modes: Parallel motion to specific target and swarm-like behavior. Furthermore, the HPC software is virtually scalable to control any quantity of moving robots, including Unmanned Aerial Vehicles, Unmanned Ground Vehicles, etc.","High performance robotic computing ? HPRC, General-purpose computing robot, HPC cluster of robots, HPRC cluster, Parallel robotic computing node ? PRCN, General-purpose computing mission",Leonardo Camargo-Forero and Pablo Royo and Xavier Prats,https://www.sciencedirect.com/science/article/pii/S092188901830232X,https://doi.org/10.1016/j.robot.2018.05.011,0921-8890,2018,167--181,107,Robotics and Autonomous Systems,Towards high performance robotic computing,article,CAMARGOFORERO2018167
"The Internet of Robotic Things, which includes ambient assisted living systems has been pushed to be developed by the research community for reasons such as the population gap between elderly people and their caregivers. Due to the critical mission that is assigned to those systems; interruptions, failures, worse still, full malfunction should not be allowed to materialize. Such systems ought to keep running in a proper way notwithstanding problems caused either by internal and external system collapses or bad intentioned actions in their surroundings. Therefore, including survivability features must be insured to Ambient Assisted Living systems (AALs) using Humans, software Agents, Robots, Machines, and Sensors (HARMS). HARMS stands for the model that allows through the indistinguishability feature to any type of actor to communicate and interact. This work proposes a framework which takes advantage of the Cloud to overcome the state explosion problem encountered when using model checking. Model checking techniques are used to find a possible solution when a problem is already faced by the system ? instead of its original purpose to detect errors on the systems during the design stage. This paper presents the implementation of the proposed framework and validates the functionality with experiments. The conducted experiments evaluate the advantages of using cloud tools to offload the model checking capability for applications such as multi-agent systems.","Model checking, Cloud computing, Multi-agent systems, Heterogeneous agents, HARMS",Mauricio A. Gomez and Abelghani Chibani and Yacine Amirat and Eric T. Matson,https://www.sciencedirect.com/science/article/pii/S0921889017308564,https://doi.org/10.1016/j.robot.2018.05.001,0921-8890,2018,192--206,106,Robotics and Autonomous Systems,IoRT cloud survivability framework for robotic AALs using HARMS,article,GOMEZ2018192
"This paper considers the kinematic control approach for controlling an underwater vehicle-manipulator system. Three different kinematic control schemes have been applied, and the performance of each scheme is compared. The kinematic control schemes provide velocity references, while the control system aims to keep a fixed position for the manipulator?s end-effector, and at the same time compensate for slowly varying motions of the underwater vehicle. Experimental results show that the proposed full modified kinematic control scheme has better performance than the decoupled kinematic control scheme, while it nicely outperforms the full kinematic control scheme. All the control schemes are good alternatives for controlling an underwater vehicle-manipulator system using kinematic control.",,Bent Oddvar A. Haugaløkken and Erlend K. Jørgensen and Ingrid Schjølberg,https://www.sciencedirect.com/science/article/pii/S0921889018300952,https://doi.org/10.1016/j.robot.2018.08.007,0921-8890,2018,1--12,109,Robotics and Autonomous Systems,Experimental validation of end-effector stabilization for underwater vehicle-manipulator systems in subsea operations,article,HAUGALOKKEN20181
"In this paper, an Optimal Super-Twisting Algorithm (OSTA) with time delay estimation is designed based on Input/Output feedback linearization for uncertain robot manipulators. The design procedure consists on three steps. Firstly, an Input/Output feedback linearization is applied to transform the nonlinear model into a linear equivalent one. Secondly, by defining a quadratic performance, an optimal sliding surface will be designed. Finally, a super-twisting algorithm with time delay estimation is proposed for high accuracy tracking trajectory. Lyapunov theory is used to prove the finite-time convergence of the sliding surface and its derivative. This structure is used to estimate unknown dynamics and to reduce the control effort and the chattering phenomenon.","Super-twisting algorithm, Feedback linearization, Time delay estimation, Lyapunov, Uncertain robot manipulators",Yassine Kali and Maarouf Saad and Khalid Benjelloun,https://www.sciencedirect.com/science/article/pii/S0921889017304803,https://doi.org/10.1016/j.robot.2018.07.004,0921-8890,2018,87--99,108,Robotics and Autonomous Systems,Optimal super-twisting algorithm with time delay estimation for robot manipulators based on feedback linearization,article,KALI201887
"This paper proposes the design of an electrically-powered waist assistive exoskeleton wire-driven only by one actuator and its control method. The developed exoskeleton is intended to reduce muscle fatigue and further prevent back-injury of industrial workers who undergo repeated, intensive waist motions. Considering requirements specially for industrial purposes, system performances related to cost, weight, operational time, and system endurance & maintainability of the robot have to be specially pursued. Therefore, reduction in the number of actuators without deteriorating the robot?s main function can be an effective approach. Along with this concept, only the single actuator mounted on the back part of the robot is proposed to simultaneously drive both legs by wire through a differential gear mechanism. The applied differential mechanism allows natural motions generally observed in human walking with almost zero mechanical impedance, but the waist motion for lifting-up heavy objects can be assisted by the powered extension of both legs. A current control algorithm embedded in a micro-controller is specially designed to achieve objectives of the robot. In order to evaluate the waist assistance provided by the developed robot, activation signals of electromyography (EMG) on main muscles of working wearers related to waist motions were measured. Further, the usability was evaluated using the responses of a questionnaire survey. Thus, the proposed method for waist assistance by a singular actuator is verified to be conclusively effective.","Waist assistance, Lower-limb exoskeleton, Under-actuation",Hun Keon Ko and Seok Won Lee and Dong Han Koo and Inju Lee and Dong Jin Hyun,https://www.sciencedirect.com/science/article/pii/S0921889018300794,https://doi.org/10.1016/j.robot.2018.05.008,0921-8890,2018,1--9,107,Robotics and Autonomous Systems,Waist-assistive exoskeleton powered by a singular actuation mechanism for prevention of back-injury,article,KO20181
"Accurate localization is an essential technology for flexible automation. Industrial applications require mobile platforms to be precisely localized in complex environments, often subject to continuous changes and reconfiguration. Most of the approaches use precomputed maps both for localization and for interfacing robots with workers and operators. This results in increased deployment time and costs as mapping experts are required to setup the robotic systems in factory facilities. Moreover, such maps need to be updated whenever significant changes in the environment occur in order to be usable within commanding tools. To overcome those limitations, in this work we present a robust and highly accurate method for long-term LiDAR-based indoor localization that uses CAD-based architectural floor plans. The system leverages a combination of graph-based mapping techniques and Bayes filtering to maintain a sparse and up-to-date globally consistent map that represents the latest configuration of the environment. This map is aligned to the CAD drawing using prior constraints and is exploited for relative localization, thus allowing the robot to estimate its current pose with respect to the global reference frame of the floor plan. Furthermore, the map helps in limiting the disturbances caused by structures and clutter not represented in the drawing. Several long-term experiments in changing real-world environments show that our system outperforms common state-of-the-art localization methods in terms of accuracy and robustness while remaining memory and computationally efficient.","Mobile robotics, Localization, Mapping, SLAM, Adaptive systems",Federico Boniardi and Tim Caselitz and Rainer Kümmerle and Wolfram Burgard,https://www.sciencedirect.com/science/article/pii/S0921889018306092,https://doi.org/10.1016/j.robot.2018.11.003,0921-8890,2019,84--97,112,Robotics and Autonomous Systems,A pose graph-based localization system for long-term navigation in CAD floor plans,article,BONIARDI201984
"Low-level control of autonomous underwater vehicles (AUVs) has been extensively addressed by classical control techniques. However, the variable operating conditions and hostile environments faced by AUVs have driven researchers towards the formulation of adaptive control approaches. The reinforcement learning (RL) paradigm is a powerful framework which has been applied in different formulations of adaptive control strategies for AUVs. However, the limitations of RL approaches have lead towards the emergence of deep reinforcement learning which has become an attractive and promising framework for developing real adaptive control strategies to solve complex control problems for autonomous systems. However, most of the existing applications of deep RL use video images to train the decision making artificial agent but obtaining camera images only for an AUV control purpose could be costly in terms of energy consumption. Moreover, the rewards are not easily obtained directly from the video frames. In this work we develop a deep RL framework for adaptive control applications of AUVs based on an actor-critic goal-oriented deep RL architecture, which takes the available raw sensory information as input and as output the continuous control actions which are the low-level commands for the AUV?s thrusters. Experiments on a real AUV demonstrate the applicability of the stated deep RL approach for an autonomous robot control problem.","Autonomous robot, Deep reinforcement learning, AUV, Adaptive low-level control",Ignacio Carlucho and Mariano {De Paula} and Sen Wang and Yvan Petillot and Gerardo G. Acosta,https://www.sciencedirect.com/science/article/pii/S0921889018301519,https://doi.org/10.1016/j.robot.2018.05.016,0921-8890,2018,71--86,107,Robotics and Autonomous Systems,Adaptive low-level control of autonomous underwater vehicles using deep reinforcement learning,article,CARLUCHO201871
"In this paper, we propose an efficient approach to perform recognition and 3D localization of dynamic objects on images from a stereo camera, with the goal of gaining insight into traffic scenes in urban and road environments. We rely on a deep learning framework able to simultaneously identify a broad range of entities, such as vehicles, pedestrians or cyclists, with a frame rate compatible with the strict requirements of onboard automotive applications. Stereo information is later introduced to enrich the knowledge about the objects with geometrical information. The results demonstrate the capabilities of the perception system for a wide variety of situations, thus providing valuable information for a higher-level understanding of the traffic situation.","Object detection, Pose estimation, Deep learning, Intelligent vehicles",Carlos Guindel and David Martín and José María Armingol,https://www.sciencedirect.com/science/article/pii/S0921889018301751,https://doi.org/10.1016/j.robot.2018.11.010,0921-8890,2019,109--122,112,Robotics and Autonomous Systems,Traffic scene awareness for intelligent vehicles using ConvNets and stereo vision,article,GUINDEL2019109
"Accurate recognition of traffic lights in public roads is a critical step to deploy automated driving systems. Camera sensors are widely used for the object detection task. It might seem natural to employ them to traffic signal detection. However, images as captured by cameras contain a broad number of unrelated objects, causing a significant reduction in the detection accuracy. This paper presents an innovative, yet reliable method to recognize the state of traffic lights in images. With the help of accurate 3D maps and a self-localization technique in it, elements already being used in autonomous driving systems, we propose a method to improve the traffic light detection accuracy. Using the current location and looking for the traffic signals in the road, we extract the region related only to the traffic light (ROI, region of interest) in images captured by a vehicle-mounted camera, then we feed the ROIs to custom classifiers to recognize the state. Evaluation of our method was carried out in two datasets recorded during our urban public driving experiments, one taken during day light and the other obtained during sunset. The quantitative evaluations indicate that our method achieved over 97% average precision for each state and approximately 90% recall as far as 90 meters under preferable condition.","Autonomous vehicles, Vehicle environment perception, Information fusion",Manato Hirabayashi and Adi Sujiwo and Abraham Monrroy and Shinpei Kato and Masato Edahiro,https://www.sciencedirect.com/science/article/pii/S0921889018301234,https://doi.org/10.1016/j.robot.2018.10.004,0921-8890,2019,62--72,111,Robotics and Autonomous Systems,Traffic light recognition using high-definition map features,article,HIRABAYASHI201962
"As a key technology of robotic assembly system, off-line programming (OLP) is an effective way to improve processing quality and efficiency. Currently, the basic functions of OLP systems, such as trajectory planning, three-dimensional task simulation and collision detection, could not achieve high machining precision and guarantee the quality stability. Thus, robot kinematics and stiffness performance optimization need to be investigated as secondary tasks in the special OLP system, on the basis of redundant kinematics characteristic of a serial robot system with external axis. First, a singularity measurement model of robot configuration is presented under the constraint of joint-limits to achieve the avoidance of singular and joint-limits configurations. Secondly, based on the robot static stiffness model, an axial stiffness identification method has been come up with to evaluate the stiffness performance in the processing direction. Next, with the combination of singularity measurement model and axial stiffness identification method, a redundancy resolution method is put forward to plan and optimize the configuration of robot system with external axis off-line, which keeps robots away from singularity and joint-limits, and meanwhile achieve the optimum stiffness during robotic drilling process. Finally, the validity of this method in improving drilling quality and stability is verified by the application in a robotic drilling system.","Industrial robots, Off-line programming, Redundant resolution, Singularity avoidance, Joint-limits avoidance, Axial stiffness performance",Jiachen Jiao and Wei Tian and Wenhe Liao and Lin Zhang and Yin Bu,https://www.sciencedirect.com/science/article/pii/S0921889018302963,https://doi.org/10.1016/j.robot.2018.09.002,0921-8890,2018,112--123,110,Robotics and Autonomous Systems,Processing configuration off-line optimization for functionally redundant robotic drilling tasks,article,JIAO2018112
"In this paper, we propose a human-inspired framework for grasping domestic flat objects placed on planar support surfaces. In particular, three grasp strategies are proposed which aim to pinch small flat objects from different scenes. The framework uses representations of the robotic hand, the support surface and the target object which encapsulate rough information for the scene. Furthermore, the strategies exploit the environmental constraint of the support surface by establishing compliant contact with it, which leads to increased robustness against object geometry uncertainties as well as pose estimation errors possibly introduced by the perception system. This is inspired by how humans perform relative grasping tasks with object pose and geometry uncertainties by using compliant contact with the support surfaces. Finally, the strategy selection is determined by a decision making procedure which uses the current scene representation.","Human-inspired grasping, Environmental constraints, Flat objects",Iason Sarantopoulos and Zoe Doulgeri,https://www.sciencedirect.com/science/article/pii/S0921889018303415,https://doi.org/10.1016/j.robot.2018.07.005,0921-8890,2018,179--191,108,Robotics and Autonomous Systems,Human-inspired robotic grasping of flat objects,article,SARANTOPOULOS2018179
"In this paper, the geometric motion planning problem is addressed for an under-actuated mechanical system with dynamic non-holonomic constraints. Such constraints are the result of conservation of momentum that limits the mobility of the system in ambient space. However, dissipation forces due to interaction with the environment play a role enabling the system to move in constrained directions. Geometric mechanics tools are used to represent system dynamics in a structured form, which help better understand the motion planning problem. The geometric structure can be utilized to choose appropriate gaits intuitively by considering the properties of functions involved in the system dynamics. In a similar manner, dissipation forces also show the same type of geometric properties in terms of Stokes? connection and Stokes? Gamma functions. We can choose a gait intuitively without the need for integrating the system dynamics to generate motion in ambient space. We achieve this by exploiting the geometric properties of the friction model along with the natural dynamics of the system. By the proposed gait selection methodology, gaits are devised to move the system along a fiber direction. The simulation results are consistent with the results predicted by the proposed motion planning method. The proposed methodology is validated using experimental demonstration which also supports the simulation results. The proposed Stokes? Height functions and Stokes? Gamma functions can help to better understand the contribution of the dissipative forces and their anisotropy in motion of biological snakes and their robotic counterparts.","Motion planning, Geometric mechanics, Reduced order Lagrangian dynamics, Under-actuated systems, Viscous friction model, Mechanical connection, Stoke?s connection",Ahmad Ali and Sheraz Yaqub and Muhammad Usman and Khalil M. Zuhaib and A. Manan Khan and Ji-Yeong Lee and Chang-soo Han,https://www.sciencedirect.com/science/article/pii/S0921889017305067,https://doi.org/10.1016/j.robot.2018.06.002,0921-8890,2018,129--144,107,Robotics and Autonomous Systems,Motion planning for a planar mechanical system with dissipative forces,article,ALI2018129
"In this work, we describe an approach for estimation and tracking of the skeleton of the human body from camera networks exploiting only depth data. The algorithm takes advantage of multiple views by building and merging together the 3D point clouds. The final skeleton is computed from a virtual depth image generated from this point cloud by means of back-projection to a reference camera image plane. Before the back-projection, the person point cloud is frontalized with respect to the reference camera, so that the virtual depth image represents the person from a frontal viewpoint and the accuracy of the skeleton estimation algorithm is maximized. Our experiments show how the proposed approach boosts the performance with respect to other state-of-the-art approaches. Moreover, the proposed algorithm requires low computational burden, thus running in real-time.","Multi-view skeletal tracking, Markerless human body pose estimation, Depth data, Frontalization, Camera networks",Marco Carraro and Matteo Munaro and Emanuele Menegatti,https://www.sciencedirect.com/science/article/pii/S0921889018300381,https://doi.org/10.1016/j.robot.2018.09.009,0921-8890,2018,151--159,110,Robotics and Autonomous Systems,Skeleton estimation and tracking by means of depth data fusion from depth camera networks,article,CARRARO2018151
"Point cloud registration is an important and fundamental building block of mobile robotics. It forms an integral part of the processes of mapping, localization, object detection and recognition, loop closure and many other applications. Throughout the years, registration has been addressed in different ways, based on local features, global descriptor or object-based. However, all these techniques give meaningful results only if the input data are of the same type and density (resolution). Recently, with the technological revolution of 3D sensors, accurate ones producing dense clouds have appeared as well as others faster, more compatible with real-time applications, producing sparse clouds. Accuracy and speed are two sought-after concepts in every robotic application including those cited above, which involves the simultaneous use of both types of sensors, resulting in sparse?dense (or dense?sparse) point cloud registration. The difficulty of sparse to dense registration lies in the fact that there is no direct correspondence between each point in the two clouds, but rather a point equivalent to a set of points. In this paper, a novel approach that surpasses the notion of density is proposed. Its main idea consists in matching points representing each local surface of source cloud with the points representing the corresponding local surfaces in the target cloud. Experiments and comparisons with state-of-the-art methods show that our approach gives better performance. It handles registration of point clouds of different densities acquired by the same sensor with varied resolution or taken from different sensors.","Sparse to dense (dense to sparse) registration, Density change, Cluster, Points selection, Matching, ICP",M. {Lamine Tazir} and Tawsif Gokhool and Paul Checchin and Laurent Malaterre and Laurent Trassoudaine,https://www.sciencedirect.com/science/article/pii/S0921889017307005,https://doi.org/10.1016/j.robot.2018.07.003,0921-8890,2018,66--86,108,Robotics and Autonomous Systems,CICP: Cluster Iterative Closest Point for sparse?dense point cloud registration,article,LAMINETAZIR201866
"With the increasing application of wheeled mobile robots on soft terrains, the challenge of lateral and longitudinal slippage existing in the contact surface between the wheels and the terrain has attracted more attention. To address the difficulties caused by the lateral and longitudinal slippage, this paper proposes an improved linear active disturbance rejection control (LADRC) method for path tracking control of a six-wheeled corner steering rover. Based on the LADRC, the tracking differentiator and nonlinear state error feedback are introduced into the improved LADRC. By using the improved LADRC, the influence of disturbances in inputs can be attenuated and a higher regulating efficiency than LADRC can be achieved. The simulations validate the effectiveness of the proposed approach with a good tracking performance.","WMRs, Trajectory tracking control, Lateral and longitudinal slippage, Active disturbance rejection control",Chao Chen and Haibo Gao and Liang Ding and Weihua Li and Haitao Yu and Zongquan Deng,https://www.sciencedirect.com/science/article/pii/S0921889017309028,https://doi.org/10.1016/j.robot.2018.06.011,0921-8890,2018,236--245,107,Robotics and Autonomous Systems,Trajectory tracking control of WMRs with lateral and longitudinal slippage based on active disturbance rejection control,article,CHEN2018236
"The modeling of humanoid robots with many degrees-of-freedom (DoF) can be done via the complete dynamic model. However, the complexity of the model can hide the essential factor of the walking, i.e. the equilibrium of the robot. One alternative is to simplify the model by neglecting some dynamical effects like in the 3D Linear Inverted Pendulum (LIP) model. Nonetheless, the assumption that the ZMP will be at the base of the pendulum is not ensured and the resulting walking gaits can make the Zero Moment Point (ZMP) evolve outside of the convex hull of support when they are replicated on the complete model of any humanoid robot. The objective of this paper is to propose a new model for walking that has the same dimension as the 3D LIP model but considers the complete dynamics of the humanoid. The proposed model is called essential model and it can be written based on the internal states of the robot and possible external information, thereby generating models for different purposes. The main advantage of the essential model is that it allows to generate walking gaits that ensure that the Zero Moment Point (ZMP) is kept in a desired position or it follows a desired path while the gait is performed. Furthermore, impacts of the swing foot with the ground can be considered to compute periodic walking gaits. In order to show the advantages of the proposed model, numerical studies are performed to design periodic walking gaits for the humanoid robot ROMEO.","Modeling, Biped walking, Periodic motions, Humanoid robots",Víctor De-León-Gómez and Qiuyue Luo and Anne Kalouguine and J. Alfonso Pámanes and Yannick Aoustin and Christine Chevallereau,https://www.sciencedirect.com/science/article/pii/S0921889018303373,https://doi.org/10.1016/j.robot.2018.11.015,0921-8890,2019,229--243,112,Robotics and Autonomous Systems,An essential model for generating walking motions for humanoid robots,article,DELEONGOMEZ2019229
"Genetic algorithms (GAs) are widely used in machine learning and optimization. This paper proposes a time-dependent genetic algorithm (TDGA) based on real-coded genetic algorithm (RCGA) to improve the convergence performance of functions over time such as a foot trajectory. TDGA has several distinguishing features when compared with traditional RCGA. First, individuals are arranged over time, and then the individuals are optimized in sequence. Second, search spaces of design variables are newly comprised of processes of reductions for search spaces. Third, the search space for crossover operations is expanded to avoid local minima traps that can occur in new search spaces up to the previous search space before performing any reduction of search space, and boundary mutation operation is performed to the new search spaces. Computer simulations are implemented to verify the convergence performance of the robot locomotion optimized by TDGA. Then, TDGA optimizes the desired feet trajectories of quadruped robots that climb up a slope and the impedance parameters of admittance control so that quadruped robots can trot stably over irregular terrains. Simulation results clearly represent that the convergence performance is improved by TDGA, which also shows that TDGA could be broadly used in robot locomotion research.","Genetic algorithm, Quadruped robots, Slope, Admittance control, Impedance parameter, Stable locomotion",Jeong Hoon Lee and Jong Hyeon Park,https://www.sciencedirect.com/science/article/pii/S0921889018300149,https://doi.org/10.1016/j.robot.2018.10.015,0921-8890,2019,60--71,112,Robotics and Autonomous Systems,Time-dependent genetic algorithm and its application to quadruped?s locomotion,article,LEE201960
"Determining goal configurations that lead to successful grasps is a critical, time-consuming stage in reach-to-grasp planning, especially in unstructured, cluttered environments. While traditional, analytic algorithms are computation intensive and susceptible to uncertainty, modern, data-driven algorithms do not offer success guarantees and require large datasets for learning models of reach-to-grasp motion. Graspability maps are data structures which store wrist configurations that lead to successful grasps of an object. They are suitable for both direct use in reach-to-grasp motion planning, and as grasp databases for gripper design analysis and for learning grasp models. The computation of graspability maps can be based on analytical models. This facilitates the integration of analytical grasp quality guarantees with data-driven grasp planning. Yet, current graspability map computation methods are prohibitively time-consuming for many application scenarios. In the current work, we suggest a method for adaptation of graspability maps of known objects (shape primitives) to familiar and to unknown objects. The method facilitates run-time generation of graspability maps and significantly enhances their usability. Adapted maps are generated based on detecting shape primitives in the object to be grasped, scaling the a-priori generated maps to the required dimensions, and combining the scaled maps to form a compound graspability map. Simulation results confirm that map adaption does not critically reduce quality while significantly reducing computation time. A case study evaluation with objects from a public point-cloud image database corroborates the method?s ability to quickly and accurately generate high-quality graspability maps for familiar and unknown objects.","Robotic manipulators, Grasping, Graspability map",Danny Eizicovits and Sigal Berman,https://www.sciencedirect.com/science/article/pii/S0921889018300940,https://doi.org/10.1016/j.robot.2018.09.001,0921-8890,2018,1--11,110,Robotics and Autonomous Systems,Automatic graspability map generation based on shape-primitives for unknown and familiar objects,article,EIZICOVITS20181
"We present a novel approach to estimate the rotation and translation between two camera views from a minimum of five matched points in the images. Our approach simultaneously recovers the 3D structure of the points up to a common scale factor, and is immune to a variety of problems that plague existing methods that are based on the Euclidean homography or Essential matrix. Methods based on homography only function when feature points are coplanar in 3D space. Methods based on the Essential matrix often lose accuracy as the translation between two camera views goes to zero or when points are coplanar. By recovering the rotation and translation independently using quaternions, our algorithm eschews the shortcomings of these methods. Moreover, we do not impose any constraints on the 3D configuration of the points (such as coplanar or non-coplanar constraints). Our method is particularly well-suited for Position-Based Visual Servoing (PBVS) applications. Investigations using both simulations and experiments validate the new method. Comparisons between the proposed algorithm and the existing algorithms establish that our algorithm is robust to noise. A Matlab implementation of our algorithm is available online and free.","Five point algorithm, Camera pose estimation, Visual servoing, Vision based estimation, Relinearization",Kaveh Fathian and Jingfu Jin and Sung-Gil Wee and Dong-Ha Lee and Yoon-Gu Kim and Nicholas R. Gans,https://www.sciencedirect.com/science/article/pii/S0921889017307406,https://doi.org/10.1016/j.robot.2018.05.014,0921-8890,2018,45--62,107,Robotics and Autonomous Systems,Camera relative pose estimation for visual servoing using quaternions,article,FATHIAN201845
"Surgical instrument sorting tasks are usually performed by medical staff. Because of the large number and special structure of surgical instruments, the manual processing method has certain drawbacks: it is time-consuming, poses an infection risk and has potential for errors. Moreover, a relatively sharp surgical instrument poses a potential threat to the staff?s health. In this paper, to complete the sorting task accurately and avoid these threats, a coordinated control strategy based on fuzzy hybrid control is proposed for dual-arm coordinated operations. First, sorting information is obtained through identification, location and grasping pose detection of surgical instruments. Second, according to the characteristics of the dual-arm coordinated operation, a kinematics model of three tight coordination tasks is established and a passive compliant structure is applied to simplify the motion of surgical scissor stretching. Then, a hybrid fuzzy control strategy is proposed for dual-arm coordinated operations. Using this strategy, the contact force in the process of unlocking surgical scissors is adaptively adjusted. Finally, the proposed control strategy is validated using comparative analysis and in robotic experiments. The experimental results demonstrate that the proposed control strategy is suitable for a dual-arm robot to efficiently implement instrument sorting tasks.","Surgical instrument sorting, Dual-arm robot, Recognition and location, Constraint analysis, Hybrid fuzzy control",Qihan Wu and Meng Li and Xiaozhi Qi and Ying Hu and Bing Li and Jianwei Zhang,https://www.sciencedirect.com/science/article/pii/S0921889018304068,https://doi.org/10.1016/j.robot.2018.10.007,0921-8890,2019,1--12,112,Robotics and Autonomous Systems,Coordinated control of a dual-arm robot for surgical instrument sorting tasks,article,WU20191
"Tactile sensing has recently been used in robotics for object identification, grasping, and material identification. Although human tactile sensing is multimodal, existing tactile material recognition approaches use vibration information only. Moreover, material identification through tactile sensing can be solved as an continuous process, yet state of the art approaches use a batch approach where readings are taken for at least one second. This work proposes a recursive multimodal (vibration and thermal) tactile material identification approach. Using the frequency response of the vibration induced by the material and a set of thermal features, we show that it is possible to accurately identify materials in less than half a second. We conducted an exhaustive comparison of our approach with commonly used vibration descriptors and machine learning algorithms for material identification such as k-Nearest Neighbour, Artificial Neural Network and Support Vector Machines. Experimental results show that our approach identifies materials faster than existing techniques and increase the classification accuracy when multiple sensor modalities are used.","Recursive material classification, Multimodal classification, Robotic tactile sensing, Supervised learning",A. {Gómez Eguíluz} and I. Rañó and S.A. Coleman and T.M. McGinnity,https://www.sciencedirect.com/science/article/pii/S0921889017308618,https://doi.org/10.1016/j.robot.2018.05.003,0921-8890,2018,130--139,106,Robotics and Autonomous Systems,Multimodal Material identification through recursive tactile sensing,article,GOMEZEGUILUZ2018130
"Cloud robotics (CR) is a red-hot branch of the burgeoning field of service robots that is centered on the benefits of integrating infrastructure and shared services via a cloud computing environment. Although it extends the computation power and information sharing capabilities of the network robots, the development and operations (DevOps) of the CR system are currently limited for enterprise-scale projects due to the heavy framework. In fact, current developed CR systems are typical distributed monomer architectures followed by a ?top-down? design. As the scale of the applications gets larger, the operation and maintenance of CR systems will become a very difficult task. In this paper, a new architecture for a microservice-based cloud robotics system in intelligent space is proposed to solve the present dilemma. To enable this, we design a service management architecture based on a microservice to provide a highly efficient and flexible development/deployment mechanism. The container technology based on the docker engine is then used to functionally decompose the application into a set of collaborating services to ensure the software design methods, based on microservice, easy for implementation. Finally, a real experiment on SLAM (Simulation localization and mapping) in an intelligent space is implemented to verify the proposed architecture. Compared with traditional monomer architectures, the results show that the proposed framework is more productive, flexible and cost effective.","Cloud robotics, Microservice, Container technology, Cloud computing, Intelligent space, Visual SLAM",Chongkun Xia and Yunzhou Zhang and Lei Wang and Sonya Coleman and Yanbo Liu,https://www.sciencedirect.com/science/article/pii/S092188901830040X,https://doi.org/10.1016/j.robot.2018.10.001,0921-8890,2018,139--150,110,Robotics and Autonomous Systems,Microservice-based cloud robotics system for intelligent space,article,XIA2018139
"The Robot Operating System (ROS) is a popular and widely used software framework for building robotics systems. With the growth of its popularity, it has started to be used in multi-robot systems as well. However, the TCP connections that the platform relies on for connecting the so-called ROS nodes presents several issues regarding limited-bandwidth, delays, and jitter, when used in wireless multi-hop networks. In this paper, we present a thorough analysis of the problem and propose a new ROS node called Pound to improve the wireless communication performance by reducing delay and jitter in data exchanges, especially in multi-hop networks. Pound allows the use of multiple ROS masters (roscores), features data compression, and importantly, introduces a priority scheme that allows favoring more important flows over less important ones. We compare Pound to the state-of-the-art solutions through extensive experiments and show that it performs equally well, or better in all the test cases, including a control-over-network example.","Multi-robot systems, Wireless multi-hop networks, Robot operating system, Jitter, Delay",Danilo Tardioli and Ramviyas Parasuraman and Petter Ögren,https://www.sciencedirect.com/science/article/pii/S0921889017309144,https://doi.org/10.1016/j.robot.2018.10.009,0921-8890,2019,73--87,111,Robotics and Autonomous Systems,Pound: A multi-master ROS node for reducing delay and jitter in wireless multi-robot networks,article,TARDIOLI201973
"Rapidly-exploring Random Tree star (RRT*) has recently gained immense popularity in the motion planning community as it provides a probabilistically complete and asymptotically optimal solution without requiring the complete information of the obstacle space. In spite of all of its advantages, RRT* converges to optimal solution very slowly. Hence to improve the convergence rate, its bidirectional variants were introduced, the Bi-directional RRT* (B-RRT*) and Intelligent Bi-directional RRT* (IB-RRT*). However, as both variants perform pure exploration, they tend to suffer in highly cluttered environments. In order to overcome these limitations we introduce a new concept of potentially guided bidirectional trees in our proposed Potentially Guided Intelligent Bi-directional RRT* (PIB-RRT*) and Potentially Guided Bi-directional RRT* (PB-RRT*). The proposed algorithms greatly improve the convergence rate and have a more efficient memory utilization. Theoretical and experimental evaluation of the proposed algorithms have been made and compared to the latest state of the art motion planning algorithms under different challenging environmental conditions and have proven their remarkable improvement in efficiency and convergence rate.","Motion planning, Sampling based planning algorithms, RRT*, Optimal path planning, Artificial potential fields, Bidirectional trees",Zaid Tahir and Ahmed H. Qureshi and Yasar Ayaz and Raheel Nawaz,https://www.sciencedirect.com/science/article/pii/S0921889017309387,https://doi.org/10.1016/j.robot.2018.06.013,0921-8890,2018,13--27,108,Robotics and Autonomous Systems,Potentially guided bidirectionalized RRT* for fast optimal path planning in cluttered environments,article,TAHIR201813
"Smartphone-based human indoor localization was previously implemented using wireless sensor networks at the cost of sensing infrastructure deployment. Motivated by increasing research attention on location-aware human?robot interaction, we propose a robot-assisted human indoor localization scheme utilizing acoustic ranging between a self-localized mobile robot and smartphones. Data from the low-cost Kinect vision sensor are fused with smartphone-based acoustic ranging, and an extended Kalman filter based localization algorithm is developed for real-time dynamic position estimation and tracking. Real robot?smartphone experiments are performed, and performances are evaluated in various indoor environments under different environmental noises and with different human walking speed. Comparing to existing indoor smartphone localization methods, the proposed system does not rely on wireless sensing infrastructure, and has comparable localization accuracy with increased flexibility and scalability due to the mobility of the robot.","Human indoor localization, Robot-assistance, Acoustic ranging, Extended Kalman filter",Chao Jiang and Muhammad Fahad and Yi Guo and Yingying Chen,https://www.sciencedirect.com/science/article/pii/S0921889016304201,https://doi.org/10.1016/j.robot.2018.04.011,0921-8890,2018,82--94,106,Robotics and Autonomous Systems,Robot-assisted smartphone localization for human indoor tracking,article,JIANG201882
"In this work, a deep learning approach has been developed to carry out road detection by fusing LIDAR point clouds and camera images. An unstructured and sparse point cloud is first projected onto the camera image plane and then upsampled to obtain a set of dense 2D images encoding spatial information. Several fully convolutional neural networks (FCNs) are then trained to carry out road detection, either by using data from a single sensor, or by using three fusion strategies: early, late, and the newly proposed cross fusion. Whereas in the former two fusion approaches, the integration of multimodal information is carried out at a predefined depth level, the cross fusion FCN is designed to directly learn from data where to integrate information; this is accomplished by using trainable cross connections between the LIDAR and the camera processing branches. To further highlight the benefits of using a multimodal system for road detection, a data set consisting of visually challenging scenes was extracted from driving sequences of the KITTI raw data set. It was then demonstrated that, as expected, a purely camera-based FCN severely underperforms on this data set. A multimodal system, on the other hand, is still able to provide high accuracy. Finally, the proposed cross fusion FCN was evaluated on the KITTI road benchmark where it achieved excellent performance, with a MaxF score of 96.03%, ranking it among the top-performing approaches.","Intelligent vehicles, Deep learning, Sensor fusion, Road detection",Luca Caltagirone and Mauro Bellone and Lennart Svensson and Mattias Wahde,https://www.sciencedirect.com/science/article/pii/S0921889018300496,https://doi.org/10.1016/j.robot.2018.11.002,0921-8890,2019,125--131,111,Robotics and Autonomous Systems,LIDAR?camera fusion for road detection using fully convolutional neural networks,article,CALTAGIRONE2019125
"Localization in unknown environments is a fundamental requirement for robots. Egomotion estimation based on visual information is a hot research topic. However, most visual odometry (VO) or visual Simultaneous Localization and Mapping (vSLAM) approaches assume static environments. To achieve robust and precise localization in dynamic environments, we propose a novel VO based on edges and points for RGB-D cameras. In contrast to dense motion segmentation, sparse edge alignment with distance transform (DT) errors is adopted to detect the states of image areas. Features in dynamic areas are ignored in egomotion estimation with reprojection errors. Meanwhile, static weights calculated by DT errors are added to pose estimation. Furthermore, local bundle adjustment is utilized to improve the consistencies of the local map and the camera localization. The proposed approach can be implemented in real time. Experiments are implemented on the challenging sequences of the TUM RGB-D dataset. The results demonstrate that the proposed robust VO achieves more accurate and more stable localization than the state-of-the-art robust VO or SLAM approaches in dynamic environments.","Localization, Visual odometry, Dynamic environments, Edge alignment, Bundle adjustment",Erliang Yao and Hexin Zhang and Hui Xu and Haitao Song and Guoliang Zhang,https://www.sciencedirect.com/science/article/pii/S0921889018300770,https://doi.org/10.1016/j.robot.2018.06.009,0921-8890,2018,209--220,107,Robotics and Autonomous Systems,Robust RGB-D visual odometry based on edges and points,article,YAO2018209
"A perception system based on vehicle detection sensors, which are mounted on an ego vehicle, has restricted visibility because of blockage by obstacles. Estimating the risk of collision with moving vehicles in an occluded area is difficult because their locations and speeds cannot be detected. To address the occlusion problem, this paper proposes a probabilistic collision risk assessment method for a potential collision vehicle in an occluded area. The proposed method estimates the collision risk in three steps: occlusion boundary modeling of perception, motion prediction of the potential collision vehicles, and probabilistic collision risk assessment. The first step models the occlusion boundary to classify the free space and the unknown region. In the second step, the moving path of each potential collision vehicle is predicted considering its future behavior. The final step estimates the collision probability with a potential collision vehicle based on the speed distribution of the vehicles on the road. We evaluate the proposed probabilistic collision risk assessment method in several occlusion scenarios with real traffic, including an alleyway, a merging lane, and blockage by a bulky vehicle.","Roadway geometry model, Occluded vehicle, Vehicle maneuver, Collision risk assessment, Probabilistic speed modeling",Minchul Lee and Myoungho Sunwoo and Kichun Jo,https://www.sciencedirect.com/science/article/pii/S0921889017308746,https://doi.org/10.1016/j.robot.2018.05.005,0921-8890,2018,179--191,106,Robotics and Autonomous Systems,Collision risk assessment of occluded vehicle based on the motion predictions using the precise road map,article,LEE2018179
"A method for simulation-based development of robotic rock loading systems is described and tested. The idea is to first formulate a generic loading strategy as a function of the shape of the rock pile, the kinematics of the machine and a set of motion design variables that will be used by the autonomous control system. The relation between the loading strategy and resulting performance is then explored systematically using contacting multibody dynamics simulation, multiobjective optimisation and surrogate modelling. With the surrogate model it is possible to find Pareto optimal loading strategies for dig plans that are adapted to the current shape of the pile. The method is tested on a load?haul?dump machine loading from a large muck pile in an underground mine, with the loading performance measured by productivity, machine wear and rock debris spill that cause interruptions.","Robotic excavation, Autonomous loading, Rock pile, Multibody dynamics, Discrete element, Surrogate modelling",Daniel M. Lindmark and Martin Servin,https://www.sciencedirect.com/science/article/pii/S0921889017305511,https://doi.org/10.1016/j.robot.2018.04.010,0921-8890,2018,117--129,106,Robotics and Autonomous Systems,Computational exploration of robotic rock loading,article,LINDMARK2018117
"Self-assembling robots have the potential to undergo autonomous morphological adaptation. However, due to the simplicity in their hardware makeup and their limited perspective of the environment, self-assembling robots are often not able to reach their potential and adapt their morphologies to tasks or environments without external cues or prior information. In this paper, we present supervised morphogenesis ? a control methodology that makes self-assembling robots truly flexible by enabling aerial robots to exploit their elevated position and better view of the environment to initiate and control (hence supervise) morphology formation on the ground. We present results of two case studies in which we assess the feasibility of the presented methodology using real robotic hardware. In the case studies, we implemented supervised morphogenesis using two different aerial platforms and up to six self-assembling autonomous robots. We furthermore quantify the benefits attainable for self-assembling robots through cooperation with aerial robots using simulation-based studies. The research presented in this paper is a significant step towards realizing the true potential of self-assembling robots by enabling autonomous morphological adaptation to a priori unknown tasks and environments.","Self-assembling robots, Heterogeneous multirobot teams, Distributed systems, Air/ground robot teams, Robot coordination, Modular robots",Nithin Mathews and Anders Lyhne Christensen and Alessandro Stranieri and Alexander Scheidler and Marco Dorigo,https://www.sciencedirect.com/science/article/pii/S092188901730372X,https://doi.org/10.1016/j.robot.2018.11.007,0921-8890,2019,154--167,112,Robotics and Autonomous Systems,Supervised morphogenesis: Exploiting morphological flexibility of self-assembling multirobot systems through cooperation with aerial robots,article,MATHEWS2019154
"The aim of this paper is to demonstrate, based on robot results, the effectiveness and practicability of vestibular feedback to central pattern generators (CPG) employed for the locomotion of quadruped robots. We build a new quadruped robot with mechanisms enabling walking to running and apply CPGs modulated by simple vestibular sensory feedback (a body tilt multiplied by a fixed gain). As a result, the robot safely locomotes at a variety of speeds by autonomously changing the gait from walking to trotting to galloping according to speed, despite the fact that the walk and gallop are not preprogrammed. In addition, as this paper?s major contribution, we discover and demonstrate that the robot robustly runs with an emergent gallop while stepping on and over several types of unperceived obstacles, while being suddenly pulled forward, and while the physical balance is changed (i.e., a weight is put forward on the robot), by autonomously modifying the phase differences between the four legs from the basic gallop. To our knowledge, no other galloping robots have been reported that can adapt to an unperceived obstacle. We conclude that CPGs modulated by vestibular feedback is effective and practical as a gait generator for bio-inspired robots that are expected to have both the abilities of ?speed-based autonomous gait transition? and ?autonomous robust running?.","Central pattern generator, Gait transition, Quadrupedal locomotion, Robust galloping",Takahiro Fukui and Hisamu Fujisawa and Kotaro Otaka and Yasuhiro Fukuoka,https://www.sciencedirect.com/science/article/pii/S0921889018300137,https://doi.org/10.1016/j.robot.2018.10.002,0921-8890,2019,1--19,111,Robotics and Autonomous Systems,Autonomous gait transition and galloping over unperceived obstacles of a quadruped robot with CPG modulated by vestibular feedback,article,FUKUI20191
"Deep Reinforcement Learning (DRL), which can learn complex policies with high-dimensional observations as inputs, e.g., images, has been successfully applied to various tasks. Therefore, it may be suitable to apply them for robots to learn and perform daily activities like washing and folding clothes, cooking, and cleaning since such tasks are difficult for non-DRL methods that often require either (1) direct access to state variables or (2) well-designed hand-engineered features extracted from sensory inputs. However, applying DRL to real robots remains very challenging because conventional DRL algorithms require a huge number of training samples for learning, which is arduous in real robots. To alleviate this dilemma, in this paper, we propose two sample efficient DRL algorithms: Deep P-Network (DPN) and Dueling Deep P-Network (DDPN). The core idea is to combine the nature of smooth policy update with the capability of automatic feature extraction in deep neural networks to enhance the sample efficiency and learning stability with fewer samples. The proposed methods were first investigated by a robot-arm reaching task in the simulation that compared previous DRL methods and applied to two real robotic cloth manipulation tasks: (1) flipping a handkerchief and (2) folding a t-shirt with a limited number of samples. All the results suggest that our method outperformed the previous DRL methods.","Deep reinforcement learning, Robotic cloth manipulation, Dynamic policy programming",Yoshihisa Tsurumine and Yunduan Cui and Eiji Uchibe and Takamitsu Matsubara,https://www.sciencedirect.com/science/article/pii/S0921889018303245,https://doi.org/10.1016/j.robot.2018.11.004,0921-8890,2019,72--83,112,Robotics and Autonomous Systems,Deep reinforcement learning with smooth policy update: Application to robotic cloth manipulation,article,TSURUMINE201972
"We present a new approach to motion planning in mobile robotics under sensing and motion uncertainty based on state lattices with graduated fidelity. Uncertainty is predicted at planning time and used to estimate the safety of the paths. Our approach takes into account the real shape of the robot, introducing a deterministic sampling based method to estimate the probability of collision. Anytime Dynamic A*, an informed search algorithm, is used to find safe and optimal paths in the lattice. Moreover, due to the anytime search capabilities of this algorithm our planner is able to retrieve a solution very fast and refine it iteratively until the optimal one is found. We present a novel graduated fidelity approach to build a lattice whose complexity adapts to the obstacles in the environment, along with a multi-resolution heuristic based on the same idea. Thus, the running time of the planner is drastically reduced while maintaining its performance. Experimental results show the potential of the approach in several scenarios, with different robot shapes, motion models and under different uncertainty conditions. The impact of the graduated fidelity approach and the multi-resolution heuristic in the efficiency and performance of the planner is also detailed.","State lattices, Graduated fidelity, Multi-resolution, Motion planning under uncertainty",Adrián González-Sieira and Manuel Mucientes and Alberto Bugarín,https://www.sciencedirect.com/science/article/pii/S0921889018301222,https://doi.org/10.1016/j.robot.2018.08.006,0921-8890,2018,168--182,109,Robotics and Autonomous Systems,Motion planning under uncertainty in graduated fidelity lattices,article,GONZALEZSIEIRA2018168
"Linking human whole-body motion and natural language is of great interest for the generation of semantic representations of observed human behaviors as well as for the generation of robot behaviors based on natural language input. While there has been a large body of research in this area, most approaches that exist today require a symbolic representation of motions (e.g. in the form of motion primitives), which have to be defined a-priori or require complex segmentation algorithms. In contrast, recent advances in the field of neural networks and especially deep learning have demonstrated that sub-symbolic representations that can be learned end-to-end usually outperform more traditional approaches, for applications such as machine translation. In this paper we propose a generative model that learns a bidirectional mapping between human whole-body motion and natural language using deep recurrent neural networks (RNNs) and sequence-to-sequence learning. Our approach does not require any segmentation or manual feature engineering and learns a distributed representation, which is shared for all motions and descriptions. We evaluate our approach on 2 846 human whole-body motions and 6 187 natural language descriptions thereof from the KIT Motion-Language Dataset. Our results clearly demonstrate the effectiveness of the proposed model: We show that our model generates a wide variety of realistic motions only from descriptions thereof in form of a single sentence. Conversely, our model is also capable of generating correct and detailed natural language descriptions from human motions.","Human whole-body motion, Natural language, Sequence-to-sequence learning, Recurrent neural network",Matthias Plappert and Christian Mandery and Tamim Asfour,https://www.sciencedirect.com/science/article/pii/S0921889017306280,https://doi.org/10.1016/j.robot.2018.07.006,0921-8890,2018,13--26,109,Robotics and Autonomous Systems,Learning a bidirectional mapping between human whole-body motion and natural language using deep recurrent neural networks,article,PLAPPERT201813
"In recent years, attention has been focused on the relationship between black-box optimization problem and reinforcement learning problem. In this research, we propose the Mirror Descent Search (MDS) algorithm which is applicable both for black box optimization problems and reinforcement learning problems. Our method is based on the mirror descent method, which is a general optimization algorithm. The contribution of this research is roughly twofold. We propose two essential algorithms, called MDS and Accelerated Mirror Descent Search (AMDS), and two more approximate algorithms: Gaussian Mirror Descent Search (G-MDS) and Gaussian Accelerated Mirror Descent Search (G-AMDS). This research shows that the advanced methods developed in the context of the mirror descent research can be applied to reinforcement learning problem. We also clarify the relationship between an existing reinforcement learning algorithm and our method. With two evaluation experiments, we show our proposed algorithms converge faster than some state-of-the-art methods.","Reinforcement learning, Mirror descent, Bregman divergence, Accelerated mirror descent, Policy improvement with path integrals",Megumi Miyashita and Shiro Yano and Toshiyuki Kondo,https://www.sciencedirect.com/science/article/pii/S0921889017307546,https://doi.org/10.1016/j.robot.2018.04.009,0921-8890,2018,107--116,106,Robotics and Autonomous Systems,Mirror descent search and its acceleration,article,MIYASHITA2018107
"In order to move, animals in nature usually use a rhythmic movement which is highly stable and adaptable. Movement controlled by the central pattern generator (CPG) is a spontaneous behavior of the lower nervous center. When applying the CPG model to a multi-legged robot, the stability of the robot motion and the generation and transformation of the adaptive motion model are affected by the output of the CPG. Considering the challenges of strong coupling, complex controlling, and the difficulty of using the traditional CPG model to control the foot trajectory of the robot, a novel ?-Hopf harmonic oscillator with decoupled parameters is proposed. In order to increase the flexibility and reduce the complexity of controlling the robot, a Central Pattern based Backward Control (CPBC) method is proposed. This ensures that the gait, duty factor and frequency control of the robot can be individually controlled. By adjusting the corresponding parameters, the robot can freely transform between the different motion states. Simulation techniques, where the parameters are dynamically adjusted, are used to test the effects of this process on the robot. A bio-inspired legged robotic platform is designed and tested to verify the CPBC method.","Backward control, Bio-inspired legged robot, CPG, Decoupled parameters, -Hopf",Yaguang Zhu and Yongsheng Wu and Qiong Liu and Tong Guo and Rui Qin and Jizhuang Hui,https://www.sciencedirect.com/science/article/pii/S0921889018300241,https://doi.org/10.1016/j.robot.2018.05.009,0921-8890,2018,165--178,106,Robotics and Autonomous Systems,A backward control based on ?-Hopf oscillator with decoupled parameters for smooth locomotion of bio-inspired legged robot,article,ZHU2018165
"In this paper, we propose a robot photography system that can autonomously search for the optimal target viewpoint. Two technical issues of scene composition evaluation and viewpoint selection are solved by this system. A composition evaluation method for photos is developed using well-known composition rules based on Kullback?Leibler (KL) divergence, considering the directional information of each target. To reduce the calculation cost of the composition evaluation in the case where the number of targets is large, automatic target grouping is conducted via variational Bayes. The optimal viewpoint with respect to the composition is selected from a number of candidate viewpoints around the targets based on KL divergence. Finally, the fact that better composed photos can be autonomously photographed by the proposed system is validated via experiments and human evaluations.","Robot photographer, Variational Bayes, Composition evaluation, Viewpoint selection",Kai Lan and Kosuke Sekiyama,https://www.sciencedirect.com/science/article/pii/S0921889017308114,https://doi.org/10.1016/j.robot.2018.10.008,0921-8890,2019,132--144,111,Robotics and Autonomous Systems,Autonomous robot photographer with KL divergence optimization of image composition and human facial direction,article,LAN2019132
"A methodology is described for control of vertically profiling floats that uses an imperfect predictive model of ocean currents. In this approach, the floats have control only over their depth. This control authority is combined with an imperfect model of ocean currents to attempt to force the floats to maintain position. First, the impact of model accuracy on the ability to station keep (e.g. maintain X?Y position) using simulated planning and nature (ground-truth in simulation) models is studied. In this study, the impact of batch versus continuous planning is examined. In batch planning the float depth plan is derived for an extended period of time and then executed open loop. In continuous planning the depth plan is updated with the actual position and the remainder of the plan re-planned based on the new information. In these simulation results are shown that (a) active control can significantly improve station keeping with even an imperfect predictive model and (b) continuous planning can mitigate the impact of model inaccuracy. Second, the effect of using heuristic path completion estimators in search are studied. In general, using a more conservative estimator increases search quality but commensurately increases the amount of search and therefore computation time. Third are presented results from an April 2015 deployment in the Pacific Ocean that show that even with an imperfect model of ocean currents, model-based control can enhance float control performance.","Vertical profiling floats, Autonomous marine vehicle, Marine robot, Predictive control, Search",Martina Troesch and Steve Chien and Yi Chao and John Farrara and James Girton and John Dunlap,https://www.sciencedirect.com/science/article/pii/S0921889017308631,https://doi.org/10.1016/j.robot.2018.04.004,0921-8890,2018,100--114,108,Robotics and Autonomous Systems,"Autonomous control of marine floats in the presence of dynamic, uncertain ocean currents",article,TROESCH2018100
"The present study demonstrated an innovative humanoid robot applied during Rotation?Traction (RT) manipulation practice and evaluation process. A mass?damper?spring mechanical system with an electromagnetic clutch was designed to emulate the cervical spine and a 3-DOF non-planar model was built to replace the neck part. With the help of an excellent electromechanical system and appropriate control strategy, the robot could imitate the entire dynamic responses of the human cervical spine during the RT manipulation process. Moreover, a novel adaptive force tracking impedance control was adopted to ensure a variable contact force in the unknown environment to imitate the real biomechanics of the human neck. In comparison to existing impedance control methods, the proposed control scheme is not only utility but also robust against external disturbances such as varying stiffness or uncertainties of the robot. The stability of the proposed impedance control was theoretically examined. Test results revealed that the cervical spine robot could faithfully replicate the biomechanical properties of the human cervical spine during RT manipulation and it is helpful in training and evaluating interns.","Robotics, Adaptive impedance control, Rotation?traction manipulation, Cervical spine model, Biomechanical",Guancheng Li and Jian Li and Xiangdong Liu and Pingli Lu and Minshan Feng and Liguo Zhu and Liwei Shao,https://www.sciencedirect.com/science/article/pii/S0921889017304554,https://doi.org/10.1016/j.robot.2018.05.010,0921-8890,2018,116--128,107,Robotics and Autonomous Systems,An innovative robotic training system imitating the cervical spine behaviors during rotation?traction manipulation,article,LI2018116
"On-road vehicle detection is essential for perceiving driving settings, and localizing the detected vehicle helps drivers predict possible risks and avoid collisions. However, there are limited works on vehicle detection with partial appearance, and the method for partially visible vehicle localization has not been explored. In this paper, a novel framework for vehicle detection and localization with partial appearance is proposed using stereo vision and geometry. First, the original images from the stereo camera are processed to form a v-disparity map. After object detection using v-disparity, vehicle candidates are generated with prior knowledge of possible vehicle locations on the image. Deep learning-based verification completes vehicle detection. For each detected vehicle, partially visible vehicle tracking algorithm is newly introduced. To track partially visible vehicles, this algorithm detects the vehicle edge on the ground, defined as the grounded edge, and then selects a reference point for Kalman filter tracking. Finally, a rectangular box is drawn on the bird?s eye view to represent vehicle?s longitudinal and lateral location. The proposed system successfully performs partially visible vehicle detection and tracking. For testing the localization performance, the datasets in a highway and an urban setting are used and provide less than 1.5 m longitudinal error and 0.4 m lateral error in standard deviation.","Distance estimation, Partial appearance, Vehicle detection, Grounded edge and reference point, Bird?s eye view localization",Elijah S. Lee and Wongun Choi and Dongsuk Kum,https://www.sciencedirect.com/science/article/pii/S0921889018301052,https://doi.org/10.1016/j.robot.2018.11.008,0921-8890,2019,178--189,112,Robotics and Autonomous Systems,Bird?s eye view localization of surrounding vehicles: Longitudinal and lateral distance estimation with partial appearance,article,LEE2019178
"Sampling-based, search-based, and optimization-based motion planners are just some of the different approaches developed for motion planning problems. Given the wide variety of application tackled by autonomous mobile manipulators, the question ?which planner to choose? may be tough. In this paper, we review the state of the art of the most common approaches, and present a set of benchmarks with the aim to provide not only a theoretical review but also a qualitative/quantitative comparison of the algorithms. Our purpose is to provide an insight and analyze their performance with respect to different metrics. The results are based on an Underwater Vehicle Manipulator System UVMS, although they can be extended to terrestrial and aerial robots as well. The paper uses these results to formalize a set of guidelines for the selection process of the most appropriate approach, for a given problem/requirements.","Motion planning, Survey, , Manipulation, Underwater, Autonomous, Obstacle avoidance",Dina Youakim and Pere Ridao,https://www.sciencedirect.com/science/article/pii/S0921889018300368,https://doi.org/10.1016/j.robot.2018.05.006,0921-8890,2018,20--44,107,Robotics and Autonomous Systems,Motion planning survey for autonomous mobile manipulators underwater manipulator case study,article,YOUAKIM201820
"In order for robots to successfully carry out manipulation tasks, they require to exploit contact forces and variable impedance control. The conditions of such type of robotic tasks may significantly vary in dynamic environments, which demand robots to be endowed with adaptation capabilities. This can be achieved through learning methods that allow the robot not only to model a manipulation task but also to adapt to unseen situations. In this context, this paper proposes a learning-from-demonstration framework that integrates force sensing and variable impedance control to learn force-based variable stiffness skills. The proposed approach estimates full stiffness matrices from human demonstrations, which are then used along with the sensed forces to encode a probabilistic model of the task. This model is used to retrieve a time-varying stiffness profile that allows the robot to satisfactorily react to new task conditions. The proposed framework evaluates two different stiffness representations: Cholesky decomposition and a Riemannian manifold approach. We validate the proposed framework in simulation using 2D and 7D systems and a couple of real scenarios.","Learning from demonstration, Variable impedance, Robot learning, Robotic manipulation",Fares J. Abu-Dakka and Leonel Rozo and Darwin G. Caldwell,https://www.sciencedirect.com/science/article/pii/S0921889018300125,https://doi.org/10.1016/j.robot.2018.07.008,0921-8890,2018,156--167,109,Robotics and Autonomous Systems,Force-based variable impedance learning for robotic manipulation,article,ABUDAKKA2018156
"This paper presents a new approach to view-based localization and navigation in outdoor environments, which are indispensable functions for mobile robots. Several approaches have been proposed for autonomous navigation. GPS-based systems are widely used especially in the case of automobiles, however, they can be unreliable or non-operational near tall buildings. Localization with a precise 3D digital map of the target environment also enables mobile robots equipped with range sensors to estimate accurate poses, but maintaining a large-scale outdoor map is often costly. We have therefore developed a novel view-based localization method SeqSLAM++ by extending the conventional SeqSLAM in order not only to robustly estimate the robot position comparing image sequences but also to cope with changes in a robot?s heading and speed as well as view changes using wide-angle images and a Markov localization scheme. According to the direction to move provided by the SeqSLAM++, the local-level path planner navigates the robot by setting subgoals repeatedly considering the structure of the surrounding environment using a 3D LiDAR. The entire navigation system has been implemented in the ROS framework, and the effectiveness and accuracy of the proposed method was evaluated through off-line/on-line navigation experiments.","SeqSLAM, View-based localization, Navigation, Mobile robot",Shuji Oishi and Yohei Inoue and Jun Miura and Shota Tanaka,https://www.sciencedirect.com/science/article/pii/S092188901730684X,https://doi.org/10.1016/j.robot.2018.10.014,0921-8890,2019,13--21,112,Robotics and Autonomous Systems,SeqSLAM++: View-based robot localization and navigation,article,OISHI201913
"Cooperative Localisation (CL) is a robust technique used to improve localisation accuracy in multi-robot systems. However, there is a lack of research on how CL performs under different conditions. It is unclear when CL is worthwhile, and how CL performance is affected if the system changes. This information is particularly important for systems with robots that have limited power and processing, which cannot afford to constantly perform CL. This paper investigates CL under varying sensor qualities (position accuracy, yaw accuracy, sample rate), communication rates, and number of robots for both homogeneous and heterogeneous multi-robot systems. Trends are found in MATLAB simulations using the UTIAS dataset, and then validated on Kobuki robots using an OptiTrack-based system. We find that yaw accuracy has a substantial effect on performance, a communication rate that is too fast can be detrimental, and heterogeneous systems are greater candidates for cooperative localisation than homogeneous systems.","Cooperative localisation, Multi-robot, Performance analysis, Kalman filter",Nick Sullivan and Steven Grainger and Ben Cazzolato,https://www.sciencedirect.com/science/article/pii/S0921889018301969,https://doi.org/10.1016/j.robot.2018.09.010,0921-8890,2018,73--84,110,Robotics and Autonomous Systems,Analysis of cooperative localisation performance under varying sensor qualities and communication rates,article,SULLIVAN201873
"Teleoperation control of the multiple degrees-of-freedom (DOF) robot requires a strategy for improving its controllability and adaptability. A novel bilateral haptic teleoperation approach (multi-master single-slave) is proposed for a hexapod robot in which the first master control the primary task of the slave, e.g. the linear/steering motion; meanwhile, the second master can perform a minor task, e.g. to interact with the environment by leg. The designed teleoperation system consists of two parts: body-level and leg-level. In body-level subsystem, the linear/angular velocity of the slave body follow the first master?s position, and the velocity loss caused by the system disturbances is fed back to the operator in the form of haptic force. In leg-level subsystem, a modified four-channel (4CH) teleoperation control architecture is proposed for the manipulable leg, which can be regarded as a manipulator, so as to guarantee the performance of the position/force tracking in the subsystem subject to parametric uncertainties, environmental perturbation and unmeasurable interaction force. Additionally, the stability of the multi-DOF bilateral haptic teleoperation system are verified via absolute stability criterion and Lyapunov theorem, respectively. Experiments of the proposed approach demonstrate that it can result in stable and transparent bilateral teleoperation with haptic force feedback.","Hexapod robot, Bilateral teleoperation, Haptic force, Manipulable leg",Jiayu Li and Bo You and Liang Ding and Jiazhong Xu and Weihua Li and Hannan Chen and Haibo Gao,https://www.sciencedirect.com/science/article/pii/S0921889017309041,https://doi.org/10.1016/j.robot.2018.06.001,0921-8890,2018,1--12,108,Robotics and Autonomous Systems,A novel bilateral haptic teleoperation approach for hexapod robot walking and manipulating with legs,article,LI20181
"Velocity estimation is essential for multicopters to guarantee flight stability and maneuverability. For such a purpose, this paper proposes a new method for multicopter velocity estimation based on visual and inertial information in GPS-denied or confined environments. In this method, no map, artificial landmark of the environment is required, and only the off-the-shelf onboard sensors in a multicopter including a low-cost Inertial Measurement Unit (IMU), a downward-looking monocular camera and an ultrasonic range finder facing downwards are exploited to constitute the vision motion constraint. This constraint connects metric velocity with the point correspondences between successive images in which an efficient approach based on Mean Shift (MS) algorithm is developed to detect outliers and select optimal matching points. Then, it is theoretically verified that the estimation system is observable based on observability analysis. Furthermore, combined with the vision motion constraint and a multicopter dynamic model, the metric velocity is estimated using a standard Linear Kalman Filter (LKF). Finally, the proposed method is tested with a collection of synthetic data from simulation as well as flight experiments using real data from DJI Matrice 100 and Guidance. The simulation and experimental results indicate that the proposed method can accurately estimate the velocity of the multicopter in GPS-denied or confined environments.","Visual?inertial, Velocity estimation, Multicopters, Observability analysis, Mean shift, Kalman filter",Heng Deng and Usman Arif and Qiang Fu and Zhiyu Xi and Quan Quan and Kai-Yuan Cai,https://www.sciencedirect.com/science/article/pii/S0921889017308072,https://doi.org/10.1016/j.robot.2018.06.010,0921-8890,2018,262--279,107,Robotics and Autonomous Systems,Visual?inertial estimation of velocity for multicopters based on vision motion constraint,article,DENG2018262
"Motor dysfunction has become a serious threat to the health of older people and the patients with neuromuscular impairment. The application of exoskeleton to motion assistance has received increasing attention due to its promising prospects. The major contribution of this paper is to develop a joint torque estimation control strategy for a soft elbow exoskeleton to provide effective power assistance. The surface electromyography signal (sEMG) from biceps is utilized to estimate the motion intension of wearer and map into the real-time elbow joint torque. Moreover, the control strategy fusing the estimated joint torque, estimated joint angle from inertial measurement unit and encoder feedback signal is proposed to improve motion assistance performance. Finally, further experimental investigations are carried out to compare the control effectiveness of the proposed intention-based control strategy to that of the proportional control strategy. The experimental results indicate that the proposed control strategy provides better performance in elbow assistance with different loads, and the average efficiency of assistance with heavy load is about 42.66%.","Torque estimation control strategy, Soft exoskeleton, sEMG, Motion intention, Power assistance",Longhai Lu and Qingcong Wu and Xi Chen and Ziyan Shao and Bai Chen and Hongtao Wu,https://www.sciencedirect.com/science/article/pii/S0921889018305128,https://doi.org/10.1016/j.robot.2018.10.017,0921-8890,2019,88--98,111,Robotics and Autonomous Systems,Development of a sEMG-based torque estimation control strategy for a soft elbow exoskeleton,article,LU201988
"Considering the nonlinear characteristics such as backlash hysteresis and coupled motion commonly exist in cable-driven mechanism of laparoscopic surgical robot end-effector, it is a great challenge to control the motion of robotic end-effector precisely during the surgical procedure. Due to the effects of coupled motion, the surgical end-effector will not move accurately as surgeons expected. Previous studies mostly focused on the design of special compensation mechanisms and software compensation algorithms to solve coupled motion problem. However, these approaches are limited because the backlash hysteresis is ignored and the mechanism of end-effector is restricted. This paper shows an improved scheme to eliminate the coupled motion of end-effector and reduce the position tracking error. The proposed decoupling scheme is conducted in three stages. Firstly, the time and frequency domain information of the driving motor current and the motion information of surgical instrument are extracted in real-time. Thereafter, a feedforward neural network is designed to identify the movement stage of end-effector. Finally, a prediction model is designed to predict the coupling error, after that the coupling error can be eliminated by using feedforward compensation control. An experimental platform was set up to verify the effectiveness of the proposed control scheme, and the results of corresponding comparative experiments revealed that the proposed strategy can substantially improve the tracking accuracy.","Cable-driven mechanism, Coupled motion, Feedforward neural network, Prediction model",Yunlei Liang and Zhijiang Du and Weidong Wang and Zhiyuan Yan and Lining Sun,https://www.sciencedirect.com/science/article/pii/S0921889018305888,https://doi.org/10.1016/j.robot.2018.11.006,0921-8890,2019,49--59,112,Robotics and Autonomous Systems,An improved scheme for eliminating the coupled motion of surgical instruments used in laparoscopic surgical robots,article,LIANG201949
"The dynamic models of the eel robots are under-actuated, highly nonlinear and coupled. It is thus a challenging work to design the path following controller for the eel robots. This paper proposes a framework of general curved path following control for planar eel robots. An implicit equation is used for describing the general 2D curved path. For simplicity, the eel robots are assumed to have smaller lateral displacement compared to the forward motion. A modified feedback control law based on the kinematic approximation model is combined with the gait controller to realize the curved path following of the eel robots. The eel robots with different gait patterns starting from an arbitrary initial position can guarantee asymptotic convergence to any given position. The simulation results show its effectiveness to apply the path following controller to the eel robot.","Biologically inspired robot, eel robots, Path following, Non-inertial frame, Gait, Asymptotic convergence",AnFan Zhang and ShuGen Ma and Bin Li and MingHui Wang,https://www.sciencedirect.com/science/article/pii/S0921889017302300,https://doi.org/10.1016/j.robot.2018.06.014,0921-8890,2018,129--139,108,Robotics and Autonomous Systems,Curved path following control for planar eel robots,article,ZHANG2018129
"This paper presents a literature survey on aerial manipulation. First of all, an extensive study of aerial vehicles and manipulation/interaction mechanisms in aerial manipulation is presented. Various combinations of aerial vehicles and manipulators and their applications in different missions are discussed. Next, two main modeling methods and a detailed investigation of existing estimation and control techniques in aerial manipulation are explained. Finally the shortcomings of current aerial manipulation research are highlighted and a number of directions for future research are suggested.","Aerial manipulation, UAV, Quadcopter, Manipulator, Modeling, Control",Hossein {Bonyan Khamseh} and Farrokh Janabi-Sharifi and Abdelkader Abdessameud,https://www.sciencedirect.com/science/article/pii/S0921889017305535,https://doi.org/10.1016/j.robot.2018.06.012,0921-8890,2018,221--235,107,Robotics and Autonomous Systems,Aerial manipulation?A literature survey,article,BONYANKHAMSEH2018221
"The upper-limb rehabilitation exoskeleton is a critical piece of equipment for stroke patients to compensate for deficiencies of manual rehabilitation and reduce physical therapists? workloads. In this paper, configuration synthesis of an exoskeleton is completed using advanced mechanism theory. To adapt glenohumeral (GH) movements and improve exoskeletal compatibility, six passive joints were introduced into the connecting interfaces based on optimal configuration principles. The optimal configuration of the passive joints can effectively reduce the gravitational influences of the exoskeleton device and the upper extremities. A compatible exoskeleton (Co-Exos) with 11 degrees of freedom was developed while retaining a compact volume. A new approach is presented to compensate vertical GH movements. The theoretical displacements of translational joints were calculated by the kinematic model of the shoulder loop ?s. A comparison of the theoretical and measured results confirms that the passive joints exhibited good human?machine compatibility for GH movements. The hysteresis phenomenon of translational joints appeared in all experiments due to the elasticoplasticity of the upper arm and GH. In comparable experiments, the effective torque of the second active joint was reduced by an average of 41.3% when passive joints were released. The wearable comfort of Co-Exos was thus improved significantly.","Stroke, Upper-limb rehabilitation exoskeleton, Configuration synthesis, Human-machine compatibility, Passive joint, Glenohumeral joint",Leiyu Zhang and Jianfeng Li and Peng Su and Yanming Song and Mingjie Dong and Qiang Cao,https://www.sciencedirect.com/science/article/pii/S0921889018305001,https://doi.org/10.1016/j.robot.2018.10.012,0921-8890,2019,22--31,112,Robotics and Autonomous Systems,Improvement of human?machine compatibility of upper-limb rehabilitation exoskeleton using passive joints,article,ZHANG201922
"Despite the comprehensive development in the field of navigation algorithms for mobile robots, the research on performance metrics and evaluation procedures for making standardized quantitative comparison between different algorithms has gained attention only recently. This work attempts to contribute with such effort by introducing a performance metric for the assessment of collision avoidance algorithms for mobile robots. The proposed metric comprehensively evaluates the actions taken by the objects and their consequences, in a given scenario of any given collision avoidance algorithm, based on the concept of probability of collision. The contribution of the paper encompasses the definition of the metric, the methodology to estimate the metric, and the framework to apply the metric for any given scenario. Experiments and numerical simulations are conducted to validate and demonstrate the effectiveness of the proposed metric in performance evaluation and comparison among different collision avoidance algorithms.","Performance metrics, Performance evaluation, Collision avoidance algorithms, Obstacle avoidance, Mobile robots, Robot navigation, Human comfort",Yazhini {Chitra Pradeep} and Kendrick Amezquita-Semprun and Manuel {Del Rosario} and Peter C.Y. Chen,https://www.sciencedirect.com/science/article/pii/S0921889017308928,https://doi.org/10.1016/j.robot.2018.08.005,0921-8890,2018,125--138,109,Robotics and Autonomous Systems,The Pc metric: A performance measure for collision avoidance algorithms,article,CHITRAPRADEEP2018125
"We present a complete humanoid navigation scheme based on a topological map known as visual memory (VM), which is composed by a set of key images acquired offline by means of a supervised teaching phase (human-guided). Our autonomous navigation scheme integrates the humanoid localization in the VM, a visual path planner and a path follower with obstacle avoidance. We propose a pure vision-based localization algorithm that takes advantage of the topological structure of the VM to find the key image that best fits the current image in terms of common visual information. In addition, the visual path planner benefits obstacle-free paths. The VM is updated when a new obstacle is detected with an RGB-D camera mounted on the humanoid?s head. The visual path following and obstacle avoidance problems are formulated in a unified sensor-based framework in which, a hierarchy of tasks is defined, and the transitions of consecutive and hierarchical tasks are performed smoothly to avoid instability of the humanoid. An extensive experimental evaluation using the NAO platform shows the good performance of the navigation scheme.","Visual navigation, Humanoid robots, Visual memory, Obstacle avoidance",Josafat Delfin and Héctor M. Becerra and Gustavo Arechavaleta,https://www.sciencedirect.com/science/article/pii/S0921889018300873,https://doi.org/10.1016/j.robot.2018.08.010,0921-8890,2018,109--124,109,Robotics and Autonomous Systems,Humanoid navigation using a visual memory with obstacle avoidance,article,DELFIN2018109
"Developing mechanical devices to restore natural locomotion for transfemoral amputees still raises many challenges. One of them is the development of an efficient control strategy for the prosthesis active joints, with the objective of making it flexible and intuitive to use. This paper focuses on the transfemoral CYBERLEGs Beta-Prosthesis, an actuated elastic ankle?knee prosthesis embedding bio-inspired mechanisms targeting the minimization of its total power consumption. We provide the development of a bio-inspired, torque-based, controller for this device, requiring no torque sensing. Torque control is achieved by means of static modelling of the prosthesis geometrical and elastic relationships. Bench testing of the prosthesis was performed to show that this static model is able to accurately predict the actual behaviour of the device. The model was then used to build the low-level controller of the prosthesis, converting desired torques into reference positions for the joint actuators. Next, a walking experiment with a transfemoral amputee was conducted to assess the feasibility of a torque-based control approach for the prosthesis, with a simple high-level controller combining reference torque trajectories and bio-inspired joint impedances. Results validated the use of our static model for implementing the low-level controller of such an elastic and redundant prosthesis.","Rehabilitation robotics, Force control, Static modelling, Biologically inspired",Sophie Heins and Louis Flynn and Joost Geeroms and Dirk Lefeber and Renaud Ronsse,https://www.sciencedirect.com/science/article/pii/S0921889018300356,https://doi.org/10.1016/j.robot.2018.05.015,0921-8890,2018,100--115,107,Robotics and Autonomous Systems,Torque control of an active elastic transfemoral prosthesis via quasi-static modelling,article,HEINS2018100
"This work presents an approach based on multi-task, non-conventional sliding mode control and admittance control for human?robot collaboration aimed at handling applications using force feedback. The proposed robot controller is based on three tasks with different priority levels in order to cooperatively perform the safe transportation of an object with a human operator. In particular, a high-priority task is developed using non-conventional sliding mode control to guarantee safe reference parameters imposed by the task, e.g., keeping a load at a desired orientation (to prevent spill out in the case of liquids, or to reduce undue stresses that may compromise fragile items). Moreover, a second task based on a hybrid admittance control algorithm is used for the human operator to guide the robot by means of a force sensor located at the robot tool. Finally, a third low-priority task is considered for redundant robots in order to use the remaining degrees of freedom of the robot to achieve a pre-set secondary goal (e.g., singularity avoidance, remaining close to a homing configuration for increased safety, etc.) by means of the gradient projection method. The main advantages of the proposed method are robustness and low computational cost. The applicability and effectiveness of the proposed approach are substantiated by experimental results using a redundant 7R manipulator: the Sawyer collaborative robot.","Cooperative task, Robot system, Force control, Sliding mode control",J. Ernesto Solanes and Luis Gracia and Pau Muñoz-Benavent and Jaime {Valls Miro} and Marc G. Carmichael and Josep Tornero,https://www.sciencedirect.com/science/article/pii/S0921889018300630,https://doi.org/10.1016/j.robot.2018.06.003,0921-8890,2018,196--208,107,Robotics and Autonomous Systems,Human?robot collaboration for safe object transportation using force feedback,article,SOLANES2018196
"In this paper, we propose a control framework for robot-assisted minimally invasive general surgery (RA-MIS) for physical human?robot collaboration using a redundant 7-DoF serial robot. When a redundant manipulator is used in RA-MIS, the control system implemented must guarantee that the surgical tool always goes through the trocar, i.e. the medical instrument placed at the incision point on the patient?s body. In addition, the redundancy of the robot can be exploited to implement a physical human?robot collaborative strategy, allowing the medical staff and robot to work in a shared common workspace without affecting the performances of the surgical task, through a null-space compliance control strategy. However, classical null-space compliance laws are defined in joint coordinates, which have some limitations. First, an arbitrary desired joint configuration is rarely contained in the robot?s null-space, making the desired configuration unattainable. Moreover, the joint coordinates are not a direct representation of the robot?s null-space, which limits its exploitation. The control framework proposed in this paper is performed at the torque level. A manual motion mode is used to calibrate the trocar position before executing the task. Then, a cartesian compliance control strategy is activated during execution of the surgical task, enabling the robot to autonomously execute the surgical task while the tool orientation is calculated with respect to the trocar position. Furthermore, in order to preserve the surgical task when desired or undesired contacts occur, the null-space of the main task, i.e. surgical task, is used to implement a compliant motion in the robot?s body. The compliance control approach is defined in the swivel coordinates, which effectively represent the null-space of the robot, in order to easily restrict the swivel angle motion based on joint limitations or on any other physical constraint existing in the operating room. Finally, we evaluate our control framework using a robotic system including the KUKA LWR 4+ robot, demonstrating the feasibility of the null-space compliance control approach while preserving the accuracy of the surgical task.","Robot-assisted MIS, Null-space optimization, Redundant robot, Compliance control",J. Sandoval and H. Su and P. Vieyres and G. Poisson and G. Ferrigno and E. {De Momi},https://www.sciencedirect.com/science/article/pii/S0921889017305419,https://doi.org/10.1016/j.robot.2018.04.001,0921-8890,2018,95--106,106,Robotics and Autonomous Systems,Collaborative framework for robot-assisted minimally invasive surgery using a 7-DoF anthropomorphic robot,article,SANDOVAL201895
"This paper presents the concept and experimental results of a kinematics-based incremental visual servo control approach for robotic manipulators with an eye-in-hand configuration to capture non-cooperative targets autonomously. The vision system is adopted to estimate the real time position and motion of the target by an integrated algorithm of photogrammetry and the adaptive extended Kalman filter. The unknown intercept point of trajectories of the target and the end-effector is dynamically predicted and updated based on the target estimates and is served as the desired position of the end-effector. An incremental control law is developed for the robotic manipulator to avoid multiple solutions of the robotic inverse kinematics. The end-effector is then controlled by the proposed control scheme to approach the dynamically estimated interception point directly. The proposed approach is validated experimentally by custom built robotic manipulator. To demonstrate the effectiveness of the proposed approach, uncertainties, such as, joint flexibility of the robotic manipulator, backlash of actuators, nonlinear target motion, camera mounting bias, etc., have not been considered in the control law. The experimental results show that the predicted minimum tracking time is reduced asymptotically as the end-effector approaches the target, which demonstrate the proposed control scheme is effective and reliable. The advantages of the proposed control approach are: it does not require a robotic dynamic model that most of the existing robotic control based on; it avoids the multiple solution problem in the inverse kinematics; it is insensitive to system uncertainties; and it is much easier for engineering implementation.","Visual servo, Robotic capture, Non-cooperative target, Adaptive extended Kalman filter, Kinematics-based incremental control",Gangqi Dong and Zheng H. Zhu,https://www.sciencedirect.com/science/article/pii/S0921889017307273,https://doi.org/10.1016/j.robot.2018.10.011,0921-8890,2019,221--228,112,Robotics and Autonomous Systems,Kinematics-based incremental visual servo for robotic capture of non-cooperative target,article,DONG2019221
"The research on autonomous robotics has focused on the aspect of information fusion from redundant estimates. Choosing a convenient fusion policy, that reduces the impact of unmodeled noise, and is computationally efficient, is an open research issue. The objective of this work is to study the problem of underwater localization which is a challenging field of research, given the dynamic aspect of the environment. For this, we explore navigation task scenarios based on inertial and geophysical sensory. We propose a neural network framework named B-PR-F which heuristically performs adaptable fusion of information, based on the principle of contextual anticipation of the localization signal within an ordered processing neighborhood. In the framework black-box unimodal estimations are related to the task context, and the confidence on individual estimates is evaluated before fusing information. A study conducted in a virtual environment illustrates the relevance of the model in fusing information under multiple task scenarios. A real experiment shows that our model outperforms the Kalman Filter and the Augmented Monte Carlo Localization algorithms in the task. We believe that the principle proposed can be relevant to related application fields, involving the problem of state estimation from the fusion of redundant information.","Robot localization, Neural networks, Underwater robotics, Information fusion",Hendry {Ferreira Chame} and Matheus Machado {dos Santos} and Silvia Silva {da Costa Botelho},https://www.sciencedirect.com/science/article/pii/S0921889018302926,https://doi.org/10.1016/j.robot.2018.08.013,0921-8890,2018,57--72,110,Robotics and Autonomous Systems,Neural network for black-box fusion of underwater robot localization under unmodeled noise,article,FERREIRACHAME201857
"The main function of human hands is to grasp and manipulate objects, to which the thumb contributes the most. Various robotic hand rehabilitation devices have been developed for providing efficient hand function training. However, there have been few studies on thumb rehabilitation devices. Previously, we proposed a soft thumb rehabilitation device which is based on a parallel-link mechanism, driven by two different types of soft actuators. In this study, the device was integrated into a 5-digit assist system, in which fiber-reinforced elastomer actuators with improved bending angles, forces, and degrees of freedom were assembled onto a forearm socket. The device was evaluated by an enhanced Kapandji-Test, which included also a pressing force measurement in addition to the reachable positions of the thumb on the opposing fingers. The results showed that with the proposed approach, thumb functions for hand rehabilitation could be realized, which paves the way towards a full hand rehabilitation package with the 5-digit soft robotic hand rehabilitation system.","Fiber-reinforced Elastomer Actuators (FEA), Enhanced Kapandji Test, Hand rehabilitation, Thumb function, Soft actuators, Pneumatic artificial rubber muscle",Kouki Shiota and Shota Kokubu and Tapio V.J. Tarvainen and Masashi Sekine and Kahori Kita and Shao Ying Huang and Wenwei Yu,https://www.sciencedirect.com/science/article/pii/S0921889017308084,https://doi.org/10.1016/j.robot.2018.09.007,0921-8890,2019,20--30,111,Robotics and Autonomous Systems,Enhanced Kapandji test evaluation of a soft robotic thumb rehabilitation device by developing a fiber-reinforced elastomer-actuator based 5-digit assist system,article,SHIOTA201920
"Grasping objects used in daily activities is not an easy task for a robot: the diversity of shapes and volumes of objects renders specific grasping methods inefficient. In this paper, we propose a novel model-based scooping grasp for the picking of thin objects lying on a flat surface, which are typically elusive to common grippers and grasping strategies. A robotic work cell composed of a serial arm, a commercially available gripper and a 3D camera overlooking the workspace is used to demonstrate and test the algorithm. Since a commercial gripper is used, the robot is capable of grasping a large variety of objects, in addition to the targeted thin objects. An experiment based on a test set of 80 objects results in an overall grasp success rate of 84%, which demonstrates the potential of the novel scooping grasp to extend the capabilities of existing grippers.","Grasping, Unknown objects, Underactuated gripper, Scooping, Lateral grasping",François Lévesque and Bruno Sauvet and Philippe Cardou and Clément Gosselin,https://www.sciencedirect.com/science/article/pii/S0921889017308898,https://doi.org/10.1016/j.robot.2018.04.003,0921-8890,2018,14--25,106,Robotics and Autonomous Systems,A model-based scooping grasp for the autonomous picking of unknown objects with a two-fingered gripper,article,LEVESQUE201814
"Robotic hand plays a very important role as it is required to hold and place the object at the desired location. There has been a lot of research on the flexible pneumatic rubber or polymer based actuators for soft gripper applications. This paper is investigating asymmetric bellow flexible pneumatic actuator (ABFPA) as a bending joint made of suitable rubber material in the construction of a novel underactuated multi-jointed, multi-fingered soft robotic hand for prosthetic application. The proposed asymmetric actuator has a single internal chamber and is simple, compact and easy to manufacture. Several actuator designs are analyzed and validated experimentally. It is found that the effect of shape and eccentricity of the ABFPA plays an important role in the bending of the actuator. By proper selection of materials and manufacturing of the ABFPA with reinforcement, a versatile dexterous hand can be fabricated. The present work has paved the way for extensive research on this innovative technique as it holds out the true potential for innumerable and very interesting application in various areas.","Asymmetric bellow flexible pneumatic actuator, Finite element analysis, Multi-fingered soft Robotic hand",{Mata Amritanandamayi Devi} and Ganesha Udupa and Pramod Sreedharan,https://www.sciencedirect.com/science/article/pii/S092188901730307X,https://doi.org/10.1016/j.robot.2017.11.005,0921-8890,2018,267--277,100,Robotics and Autonomous Systems,A novel underactuated multi-fingered soft robotic hand for prosthetic application,article,MATAAMRITANANDAMAYIDEVI2018267
"A vision-based obstacle detection system is a key enabler for the development of autonomous robots and vehicles and intelligent transportation systems. This paper addresses the problem of urban scene monitoring and tracking of obstacles based on unsupervised, deep-learning approaches. Here, we design an innovative hybrid encoder that integrates deep Boltzmann machines (DBM) and auto-encoders (AE). This hybrid auto-encode (HAE) model combines the greedy learning features of DBM with the dimensionality reduction capacity of AE to accurately and reliably detect the presence of obstacles. We combine the proposed hybrid model with the one-class support vector machines (OCSVM) to visually monitor an urban scene. We also propose an efficient approach to estimating obstacles location and track their positions via scene densities. Specifically, we address obstacle detection as an anomaly detection problem. If an obstacle is detected by the OCSVM algorithm, then localization and tracking algorithm is executed. We validated the effectiveness of our approach by using experimental data from two publicly available dataset, the Malaga stereovision urban dataset (MSVUD) and the Daimler urban segmentation dataset (DUSD). Results show the capacity of the proposed approach to reliably detect obstacles.","Deep learning, DBM, Autoencoder, OCSVM, Monitoring, Stereovision",Abdelkader Dairi and Fouzi Harrou and Mohamed Senouci and Ying Sun,https://www.sciencedirect.com/science/article/pii/S0921889017304736,https://doi.org/10.1016/j.robot.2017.11.014,0921-8890,2018,287--301,100,Robotics and Autonomous Systems,Unsupervised obstacle detection in driving environments using deep-learning-based stereovision,article,DAIRI2018287
"This paper deals with the problem of purposefully failing (breaking) or yielding objects by a robotic gripper. Robotic harvesting is considered as an application domain that motivates this study. A definition of a failure task is first formulated using failure theories. Next, a grasp quality measure is presented to characterize a suitable grasp configuration and systematically control the failure behavior of the object. This approach combines the failure task and the capability of the gripper for wrench insertion. The friction between the object and the gripper is used to formulate the capability of the gripper for wrench insertion. A new method inspired by the human pre-manipulation process is introduced to utilize the gripper itself as the measurement tool and obtain a friction model. The developed friction model is capable of capturing the anisotropic behavior of materials which is the case for most fruits and vegetables. The evaluation method proposed in this study is formulated as a quasistatic grasp problem and can include both fully-actuated and under-actuated grippers. The proposed approach for purposefully breaking objects is validated using experimental results. Objects with different material properties are used to prove the generality of the method. KUKA LightWeight Robot IV is used as the manipulator.","Agricultural robotics, Robotic grasp, Grasp evaluation, Friction modeling",Mahyar Abdeetedal and Mehrdad R. Kermani,https://www.sciencedirect.com/science/article/pii/S092188901730266X,https://doi.org/10.1016/j.robot.2018.03.003,0921-8890,2018,47--58,105,Robotics and Autonomous Systems,Grasp synthesis for purposeful fracturing of object,article,ABDEETEDAL201847
"Driver inattention is one of the main causes of traffic accidents. To avoid such accidents, advanced driver assistance system that passively monitors the driver?s activities is needed. In this paper, we present a novel method to estimate a head pose from a monocular camera. The proposed algorithm is based on multi-task learning deep neural network that uses a small grayscale image. The network jointly detects multi-view faces and estimates head pose even under poor environment conditions such as illumination change, vibration, large pose change, and occlusion. We also propose a multi-task learning method that does not bias on a specific task with different datasets. Moreover, in order to fertilize training dataset, we establish and release the RCVFace dataset that has accurate head poses. The proposed framework outperforms state-of-the-art approaches quantitatively and qualitatively with an average head pose mean error of less than 4° in real-time. The algorithm applies to driver monitoring system that is crucial for driver safety.","Head pose, Advanced driver assistance system, Deep learning, Convolutional neural network",Byungtae Ahn and Dong-Geol Choi and Jaesik Park and In So Kweon,https://www.sciencedirect.com/science/article/pii/S0921889017303524,https://doi.org/10.1016/j.robot.2018.01.005,0921-8890,2018,1--12,103,Robotics and Autonomous Systems,Real-time head pose estimation using multi-task deep neural network,article,AHN20181
"In this work, we present a new modeling approach that generates precise (low variance) and accurate (low mean error) wireless signal strength mappings. In robot localization, these mappings are used to compute the likelihood of locations conditioned to new sensor measurements. Therefore, both mean and variance predictions are required. Gaussian processes have been successfully used for learning highly accurate mappings. However, they generalize poorly at locations far from their training inputs, making those predictions have high variance (low precision). In this work, we address this issue by incorporating path loss models, which are parametric functions that although lacking in accuracy, generalize well. Path loss models are used together with Gaussian processes to compute mean predictions and most importantly, to bound Gaussian processes? predicted variances. Through extensive testing done with our open source framework, we demonstrate the ability of our approach to generating precise and accurate mappings, and the increased localization accuracy of Monte Carlo localization algorithms when using them; with all our datasets and software been made readily available online for the community.","Robot localization, Wireless sensor model, Signal strength mapping, Gaussian processes",Renato Miyagusuku and Atsushi Yamashita and Hajime Asama,https://www.sciencedirect.com/science/article/pii/S0921889017303925,https://doi.org/10.1016/j.robot.2018.02.011,0921-8890,2018,134--150,103,Robotics and Autonomous Systems,Precise and accurate wireless signal strength mappings using Gaussian processes and path loss models,article,MIYAGUSUKU2018134
"This paper presents an efficient approach to contact force distribution, which is aimed at computing optimal contact forces to generate the required wrench for grasping an object. It has been derived in the previous work that this problem can be reduced to computing the intersection of the ray originating from the origin along the required wrench with the boundary of the grasp wrench set. Noticing that the grasp wrench set is fixed once contact positions are determined, we propose an algorithm to pre-compute a hierarchy of polytopes in the grasp wrench set and a list of facets from the interior of the grasp wrench set to its boundary. Then, the ray?s intersection can be quickly found by searching the list of facets and optimal contact forces can be computed in real time. Numerical examples show that the online computation of the proposed approach is one order of magnitude faster than the latest algorithm to compute the ray?s intersection and two orders of magnitude faster than general-purpose optimization algorithms. This approach to contact force distribution is an iterative solution that can run until reaching a desired accuracy.","Contact force, Grasping, Multifingered robot hand, Grasp wrench set, Polytope",Yu Zheng,https://www.sciencedirect.com/science/article/pii/S0921889017301902,https://doi.org/10.1016/j.robot.2017.10.014,0921-8890,2018,97--109,99,Robotics and Autonomous Systems,Real-time contact force distribution using a polytope hierarchy in the grasp wrench set,article,ZHENG201897
"One of the most intriguing research challenges in legged locomotion is robot performance on compliant terrains. The foot-terrain interaction is usually tackled by disregarding some of the effects of ground deformation, like permanent deformation and compaction; however this approach restricts their application to stiff environments. In this work, the foot-terrain interaction is studied, and used in developing a controller immune to terrain compliance. An impact dynamics model is developed, employing a viscoplastic extension of viscoelastic impact models, and used to study the performance of a monopod robot. To include the effects of compliance, a model of the robot that incorporates the description of the foot-terrain interaction is presented. A novel monopod controller immune to ground energy dissipation is developed, which does not require knowledge of ground parameters. The controller adapts to terrain changes quickly, successfully tackles the effects of slip during touchdown, and copes with the problems, which arise during hard impacts, as the terrain becomes stiffer. Simulation results demonstrate the validity of the developed analysis.","Legged robots, Hopping robots, Contact modeling, Field robots, Legged robot control",Vasileios Vasilopoulos and Iosif S. Paraskevas and Evangelos G. Papadopoulos,https://www.sciencedirect.com/science/article/pii/S0921889017300659,https://doi.org/10.1016/j.robot.2018.01.004,0921-8890,2018,13--26,102,Robotics and Autonomous Systems,Monopod hopping on compliant terrains,article,VASILOPOULOS201813
"Recent advances in behavioural and computational neuroscience, cognitive robotics, and in the hardware implementation of large-scale neural networks, provide the opportunity for an accelerated understanding of brain functions and for the design of interactive robotic systems based on brain-inspired control systems. This is especially the case in the domain of action and language learning, given the significant scientific and technological developments in this field. In this work we describe how a neuroanatomically grounded spiking neural network for visual attention has been extended with a word learning capability and integrated with the iCub humanoid robot to demonstrate attention-led object naming. Experiments were carried out with both a simulated and a real iCub robot platform with successful results. The iCub robot is capable of associating a label to an object with a ?preferred? orientation when visual and word stimuli are presented concurrently in the scene, as well as attending to said object, thus naming it. After learning is complete, the name of the object can be recalled successfully when only the visual input is present, even when the object has been moved from its original position or when other objects are present as distractors.","Neurorobotics, Object naming, Visual attention, Biological inspired models, Spiking neural networks",Daniel {Hernández García} and Samantha Adams and Alex Rast and Thomas Wennekers and Steve Furber and Angelo Cangelosi,https://www.sciencedirect.com/science/article/pii/S0921889017302439,https://doi.org/10.1016/j.robot.2018.02.010,0921-8890,2018,56--71,104,Robotics and Autonomous Systems,Visual attention and object naming in humanoid robots using a bio-inspired spiking neural network,article,HERNANDEZGARCIA201856
"To reduce the influence of gear backlash, a novel gait named non-reciprocating legged gait for the eccentric paddle (ePaddle) mechanism has been proposed in our previous study. In the gait, all the actuators rotated in one direction without the reciprocating. Based on force analysis of the supporting paddle, this work found that the locomotion performance of the mechanism can be further improved by keeping the supporting paddle vertical for a longer time of the supporting phase. Thus, vertical parameter which denotes the time rate of vertical state to supporting phase is proposed for gait planning. The experiments are performed to verify the validity of the proposed optimized non-reciprocating legged gait, and to identify the effects of the locomotion velocity, period, and vertical parameter on output torque and power of the mechanism. It can be found that comparing with the non-reciprocating legged gait, the locomotion performance of the mechanism is significantly improved by the optimized gait.","ePaddle mechanism, Non-reciprocating legged gait, Gait optimization, Gait planning",Huayan Pu and Chang Liu and Yi Sun and Yang Yang and Jun Zou and Na Liu and Shaorong Xie and Yan Peng and Jun Luo,https://www.sciencedirect.com/science/article/pii/S0921889017304979,https://doi.org/10.1016/j.robot.2018.02.009,0921-8890,2018,83--92,103,Robotics and Autonomous Systems,Optimized non-reciprocating legged gait for an eccentric paddle mechanism,article,PU201883
"This work presents a navigational approach that takes into consideration the perception of comfort by a human passenger. Comfort is the state of being at ease and free from stress; thus, comfortable navigation is a ride that, in addition to being safe, is perceived by the passenger as being free from anxiety and stress. This study considers how to compute passenger comfortable paths. To compute such paths, passenger discomfort is studied in locations with good visibility and those with no visibility. In locations with good visibility, passenger preference to ride in the road is studied. For locations with non-visible areas, the relationship between passenger visibility and discomfort is studied. Autonomous-navigation experiments are performed to build a map of human discomfort that is used to compute global paths. A path planner is proposed that minimizes a three-variable cost function: location discomfort cost, area visibility cost, and path length cost. Planner parameters are calibrated toward a composite trajectory histogram built with data taken from participant self-driving trajectories. Finally, autonomous navigation experiments with 30 participants show that the proposed approach is rated as more comfortable than the state-of-the-art shortest planner approach.","HRI, Human factors, Human comfort, Autonomous navigation",Yoichi Morales and Atsushi Watanabe and Florent Ferreri and Jani Even and Kazuhiro Shinozawa and Norihiro Hagita,https://www.sciencedirect.com/science/article/pii/S0921889016302585,https://doi.org/10.1016/j.robot.2018.02.002,0921-8890,2018,13--26,103,Robotics and Autonomous Systems,Passenger discomfort map for autonomous navigation in a robotic wheelchair,article,MORALES201813
"Collaboration is essential for effective performance by groups of robots in disaster response settings. Here we are particularly interested in heterogeneous robots that collaborate in complex scenarios with incomplete, dynamically changing information. In detail, we consider an automated victim search setting, where unmanned aerial vehicles (UAVs) with different capabilities work together to scan for mobile phones and find and provide information about possible victims near these phone locations. The state of the art for such collaboration is robot control based on independent planning for robots with different tasks and typically incorporates uncertainty with only a limited scope. In contrast, in this paper, we take into account complex relations between robots with different tasks. As a result, we create a joint, full-horizon plan for the whole robot team by optimising over the uncertainty of future information gain using an online planner with hindsight optimisation. This joint plan is also used for further optimisation of individual UAV paths based on the long-term plans of all robots. We evaluate our planner?s performance in a realistic simulation environment based on a real disaster and find that our approach finds victims 25% faster compared to current state-of-the-art approaches.","Search and rescue, Task allocation, Hindsight optimisation, Path planning, Multi-robot teams, Particle filter",Zoltán Beck and W.T. Luke Teacy and Alex Rogers and Nicholas R. Jennings,https://www.sciencedirect.com/science/article/pii/S0921889016307515,https://doi.org/10.1016/j.robot.2017.09.014,0921-8890,2018,251--266,100,Robotics and Autonomous Systems,Collaborative online planning for automated victim search in disaster response,article,BECK2018251
"Wireless Sensor Network (WSN) is emerging as a valuable resolution to distant monitoring and control issues. These are used to keep an eye on the remote, hazardous, antagonistic, and large-scale target-regions. Random dispersion of Sensor Nodes (SNs) from air is the most suited technique to set up WSN in such regions, but it endure various imperfections, i.e., a large number of SNs are needed to attain preferred coverage level. Moreover, its randomness may be hampered by atmospheric winds while dropping from air. In this research article three models for the precise placement of SNs have been proposed. Each successive model is an enhancement and refinement of its base model. The proposed models utilize the potential attained as a result of high falling height to position the SNs on their preferred locations (PLs). All the PLs are computed initially and SNs are equipped with a small sized economical carrier glider (CG) which floats them to their PL. The movement of a glider is controlled by the piloting SN. The first model defines the significance of a virtual path and the technique used by a CG to follow it to reach its PL. But, it suffers from a path swerving problem. The second model incorporates the virtual-path updating mechanism in the basic model. This rectifies the problem of path swerving and makes it resistant to the winds. The third model further refines its base model by introducing a radius reduction technique to enhance its precision and energy efficiency. The proposed models use an obstinate technique to maintain the direction of movement of a floating CG towards the PL in order to deal with atmospheric winds.","Sensor node, Deployment, Coverage, Wireless Sensor Network, Carrier glider",Sharma Vikrant and Patel R.B. and Bhadauria H.S. and Prasad D.,https://www.sciencedirect.com/science/article/pii/S0921889016306145,https://doi.org/10.1016/j.robot.2017.10.015,0921-8890,2018,1--13,100,Robotics and Autonomous Systems,Glider assisted schemes to deploy sensor nodes in Wireless Sensor Networks,article,VIKRANT20181
"Intelligent path planning is a significant tool for field of industrial robot. This field has attracted the attention of numerous researchers due to the great market demands, broad application prospects, and large potential development. Due to the limitation of neighborhood, the path search by the original A* algorithm is more likely to fail, and the solved path may contain too many local paths. In this study, an improved A* algorithm is proposed to solve the robot path planning problem. The first improvement of the advanced method is the local path between the current node and the goal node, which is planned before the next search in the neighborhood of the current node. And the local path will be adopted directly if it is safe and collisionless. The second advantage of this method is the utilization of post-processing stage to optimize the resulting path, by straightening the local path to reduce the number of local paths as well as the path length. In order to verify the theoretical advantages of the improved A* algorithm, a series of two-dimensional figures of the robot task was presented in this paper. In addition, some comparative experiments in the virtual and real robot manipulator platform are performed to examine the improved A* algorithm. Experimental results show that the search success rate of the improved A* algorithm is higher than the original A* algorithm, along with a shorter and smoother path could be obtained by the improved A* algorithm. Therefore, the success rate of robot path planning and the optimal extent of the robot path are effectively improved by the improved A* algorithm.","Robot manipulator, Path planning, Improved A* algorithm, Path optimization",Bing Fu and Lin Chen and Yuntao Zhou and Dong Zheng and Zhiqi Wei and Jun Dai and Haihong Pan,https://www.sciencedirect.com/science/article/pii/S0921889017306590,https://doi.org/10.1016/j.robot.2018.04.007,0921-8890,2018,26--37,106,Robotics and Autonomous Systems,An improved A* algorithm for the industrial robot path planning with high success rate and short length,article,FU201826
"The high probability of hardware failures prevents many advanced robots (e.g., legged robots) from being confidently deployed in real-world situations (e.g., post-disaster rescue). Instead of attempting to diagnose the failures, robots could adapt by trial-and-error in order to be able to complete their tasks. In this situation, damage recovery can be seen as a Reinforcement Learning (RL) problem. However, the best RL algorithms for robotics require the robot and the environment to be reset to an initial state after each episode, that is, the robot is not learning autonomously. In addition, most of the RL methods for robotics do not scale well with complex robots (e.g., walking robots) and either cannot be used at all or take too long to converge to a solution (e.g., hours of learning). In this paper, we introduce a novel learning algorithm called ?Reset-free Trial-and-Error? (RTE) that (1) breaks the complexity by pre-generating hundreds of possible behaviors with a dynamics simulator of the intact robot, and (2) allows complex robots to quickly recover from damage while completing their tasks and taking the environment into account. We evaluate our algorithm on a simulated wheeled robot, a simulated six-legged robot, and a real six-legged walking robot that are damaged in several ways (e.g., a missing leg, a shortened leg, faulty motor, etc.) and whose objective is to reach a sequence of targets in an arena. Our experiments show that the robots can recover most of their locomotion abilities in an environment with obstacles, and without any human intervention.","Robot damage recovery, Autonomous systems, Robotics, Trial-and-Error learning, Reinforcement learning",Konstantinos Chatzilygeroudis and Vassilis Vassiliades and Jean-Baptiste Mouret,https://www.sciencedirect.com/science/article/pii/S0921889017302440,https://doi.org/10.1016/j.robot.2017.11.010,0921-8890,2018,236--250,100,Robotics and Autonomous Systems,Reset-free Trial-and-Error Learning for Robot Damage Recovery,article,CHATZILYGEROUDIS2018236
"Thirty-five papers from the ethological literature were surveyed with the perception and reaction of flying animals to autonomous navigation tasks organized and analyzed using a schema theoretic framework. Flying animals are an existence proof of autonomous collision-free flight in unknown and disordered environments. Because they successfully avoid obstacles, self-orient, and evade predators and capture prey to survive, the collected information could inform the design of biologically-inspired behaviors for control of a small unmanned aerial system (SUAS) to improve the current state-of-the art in autonomous obstacle avoidance. Five observations were derived from the surveyed papers: sensing is done by vision in lighted scenarios and sonar in darkness, one sensor is always dominant, adaptive sensing is beneficial, no preference was identified for lateral versus vertical avoidance maneuvers, and reducing speed is consistently seen across species in response to objects in the flight path. Additionally, the questions of defining clutter and scale of speed reduction left unanswered by the literature were discussed. Finally, three rules for control of a SUAS in an unknown environment that restricts maneuverability were identified. These are the distance to begin maneuvers to avoid an obstacle in the flight path, the direction to adjust the flight path, and the role of centered flight in determining the adjustment.","Bio-inspired, Behavior-based robotics, Animal behavior, Small unmanned aerial systems",Traci A. Sarmiento and Robin R. Murphy,https://www.sciencedirect.com/science/article/pii/S0921889017301197,https://doi.org/10.1016/j.robot.2017.09.002,0921-8890,2018,17--29,99,Robotics and Autonomous Systems,Insights on obstacle avoidance for small unmanned aerial systems from a study of flying animal behavior,article,SARMIENTO201817
"This paper addresses ?unified bipedal gait? control, which autonomously selects the energy-minimized gait from walking and running at any feasible gait speeds. Humans select walking/running at low/high speed in pursuit of energy minimization and transition between them naturally. Despite the quite different behaviors of walking and running, human gaits share an inherent controller. The unified bipedal gait uses the inherent controller, which implements passive dynamic autonomous control (PDAC) based on a damping and spring-loaded inverted pendulum (D-SLIP) model. Although this D-SLIP could cause chaotic motions, compliance in the D-SLIP dynamics switches behaviors between walking and running, that is, low/high compliant legs for walking/running. This property is employed by the virtual holonomic constraint of the PDAC to extract the required characteristics of walking/running from the D-SLIP dynamics while restraining the chaotic motions for asymptotic stability. As a result, the unified bipedal gait bifurcates to walking and running via autonomous transition to minimize energy cost at any feasible gait speeds.","3-D bipedal gait, Limit cycle, Transition motion, Energy minimization, Passive dynamic autonomous control, Unified bipedal gait",Taisuke Kobayashi and Kosuke Sekiyama and Yasuhisa Hasegawa and Tadayoshi Aoyama and Toshio Fukuda,https://www.sciencedirect.com/science/article/pii/S0921889017303251,https://doi.org/10.1016/j.robot.2018.02.005,0921-8890,2018,27--41,103,Robotics and Autonomous Systems,Unified bipedal gait for autonomous transition between walking and running in pursuit of energy minimization,article,KOBAYASHI201827
"This paper presents a new approach for predicting slippage associated with individual wheels in off-road mobile robots. More specifically, machine learning regression algorithms are trained considering proprioceptive sensing. This contribution is validated by using the MIT single-wheel testbed equipped with an MSL spare wheel. The combination of IMU-related and torque-related features outperforms the torque-related features only. Gaussian process regression results in a proper trade-off between accuracy and computation time. Another advantage of this algorithm is that it returns the variance associated with each prediction, which might be used for future route planning and control tasks. The paper also provides a comparison between machine learning regression and classification algorithms.","Gaussian process regression, Inertial measurement unit (IMU), Machine learning regression, Mars science laboratory (MSL) wheel, Slip",Ramon Gonzalez and Mirko Fiacchini and Karl Iagnemma,https://www.sciencedirect.com/science/article/pii/S0921889018300174,https://doi.org/10.1016/j.robot.2018.03.013,0921-8890,2018,85--93,105,Robotics and Autonomous Systems,Slippage prediction for off-road mobile robots via machine learning regression and proprioceptive sensing,article,GONZALEZ201885
"This work proposes a robust visual odometry method for structured environments that combines point features with line and plane segments, extracted through an RGB-D camera. Noisy depth maps are processed by a probabilistic depth fusion framework based on Mixtures of Gaussians to denoise and derive the depth uncertainty, which is then propagated throughout the visual odometry pipeline. Probabilistic 3D plane and line fitting solutions are used to model the uncertainties of the feature parameters and pose is estimated by combining the three types of primitives based on their uncertainties. Performance evaluation on RGB-D sequences collected in this work and two public RGB-D datasets: TUM and ICL-NUIM show the benefit of using the proposed depth fusion framework and combining the three feature-types, particularly in scenes with low-textured surfaces, dynamic objects and missing depth measurements.","Visual odometry, Probabilistic plane and line extraction, Depth fusion, Depth uncertainty, Structured environments",Pedro F. Proença and Yang Gao,https://www.sciencedirect.com/science/article/pii/S0921889017303378,https://doi.org/10.1016/j.robot.2018.02.018,0921-8890,2018,25--39,104,Robotics and Autonomous Systems,"Probabilistic RGB-D odometry based on points, lines and planes under depth uncertainty",article,PROENCA201825
"A robot introduced into an animal group, accepted by the animals as conspecifics, and capable of interacting with them is an efficient tool for ethological research, particularly in studies of collective and social behaviour. In this paper, we present the implementation of an autonomous mobile robot developed by the authors to study group behaviour of chicks of the domestic chicken (Gallus gallus domesticus). We discuss the design of the robot and of the experimental framework that we built to run animal?robot experiments. The robot design was experimentally validated, we demonstrated that the robot can be socially integrated into animal groups. The designed system extends the current state of the art in the field of animal?robot interaction in general and the birds study in particular by combining such advantages as (1) the robot being a part of the group, (2) the possibility of mixed multi-robot, multi-animal groups, and (3) close-loop control of robots. It opens new opportunities in the study of behaviour in domestic fowl by using mobile robots; being socially integrated into the animal group, robots can profit from the positive feedback mechanism that plays key roles in animal collective behaviour. They have potential applications in various domains, from pure scientific research to applied areas such as control and ensuring welfare of poultry.","Animal?robot interaction, Autonomous mobile robots, Visual tracking, Sound localisation, Collective animal behaviour",A. Gribovskiy and J. Halloy and J.L. Deneubourg and F. Mondada,https://www.sciencedirect.com/science/article/pii/S0921889017306486,https://doi.org/10.1016/j.robot.2018.02.003,0921-8890,2018,42--55,103,Robotics and Autonomous Systems,Designing a socially integrated mobile robot for ethological research,article,GRIBOVSKIY201842
"In this paper, an accurate real-time ball trajectory estimation approach working on the onboard stereo camera system for the humanoid ping-pong robot has been presented. As the asynchronous observations from different cameras will great reduce the accuracy of the trajectory estimation, the proposed approach will main focus on increasing the estimation accuracy under those asynchronous observations via concerning the flying ball?s motion consistency. The approximate polynomial trajectory model for the flying ball is built to optimize the best parameters from the asynchronous observations in each discrete temporal interval. The experiments show the proposed approach can performance much better than the method that ignores the asynchrony and can achieve the similar performance as the hardware-triggered synchronizing based method, which cannot be deployed in the real onboard vision system due to the limited bandwidth and real-time output requirement.","Humanoid ping-pong robot, Onboard vision, Trajectory estimation",Yong Liu and Liang Liu,https://www.sciencedirect.com/science/article/pii/S0921889017306929,https://doi.org/10.1016/j.robot.2017.12.004,0921-8890,2018,34--44,101,Robotics and Autonomous Systems,Accurate real-time ball trajectory estimation with onboard stereo camera system for humanoid ping-pong robot,article,LIU201834
"One challenge in designing side-by-side robotic wheelchairs is to improve the comfort of the users, caregivers and surrounding people in crowded environments. Among different scenarios that a side-by-side robotic wheelchair has to deal with, crossing pedestrians is a common situation. Yet techniques developed for tackling the problem of passing pedestrians have still failed to take into account enough factors related to human walking behavior, therefore the navigation plan is not natural. To tackle this problem, this paper proposes a novel navigation model for side-by-side robotic wheelchairs that considers the Friendly Link factor and Preferred Walking Velocity related to the comfort of wheelchair users, caregivers and pedestrians. The model is carried out based on an experimental observation and data collection. The developed model is then validated by comparing the distance errors between the moving solutions of the new model and previous methods with the real solutions of humans based on a natural walking scenario. The experimental results show that the performance of the proposed technique is significantly better than that of previous techniques.",,Vinh The Nguyen and Chandimal Jayawardena and Iman Ardekani,https://www.sciencedirect.com/science/article/pii/S0921889017300027,https://doi.org/10.1016/j.robot.2017.10.008,0921-8890,2018,27--40,100,Robotics and Autonomous Systems,A navigation model for side-by-side robotic wheelchairs for optimizing social comfort in crossing situations,article,NGUYEN201827
"This paper seeks insight into stabilization mechanisms for periodic walking gaits in 3D bipedal robots. Based on this insight, a control strategy based on virtual constraints, which imposes coordination between joints rather than a temporal evolution, will be proposed for achieving asymptotic convergence toward a periodic motion. For planar bipeds with one degree of underactuation, it is known that a vertical displacement of the center of mass ? with downward velocity at the step transition ? inducesstability of a walking gait. This paper concerns the qualitative extension of this type of property to 3D walking with two degrees of underactuation. It is shown that a condition on the position of the center of mass in the horizontal plane at the transition between steps induces synchronization between the motions in the sagittal and frontal planes. A combination of the conditions for self-synchronization and vertical oscillations leads to stable gaits. The algorithm for self-stabilization of 3D walking gaits is first developed for a simplified model of a walking robot (an inverted pendulum with variable length legs), and then it is extended to a complex model of the humanoid robot Romeo using the notion of Hybrid Zero Dynamics. Simulations of the model of the robot illustrate the efficacy of the method and its robustness.","Robotics, Feedback control, Self-stability, Legged robots, Mechanical systems, Hybrid systems, Periodic solutions",Christine Chevallereau and Hamed Razavi and Damien Six and Yannick Aoustin and Jessy Grizzle,https://www.sciencedirect.com/science/article/pii/S0921889017300544,https://doi.org/10.1016/j.robot.2017.10.018,0921-8890,2018,43--60,100,Robotics and Autonomous Systems,Self-synchronization and self-stabilization of 3D bipedal walking gaits,article,CHEVALLEREAU201843
"Robotic solutions for delivery tasks in urban and unstructured areas have represented a solid and considerable field of research in recent years. The aim of the proposed paper is to present the technical feasibility and usability of a robotic solution able to carry items from outdoor areas up to the user?s apartment and vice-versa. The proposed solution is based on three heterogeneous mobile platforms, working in three different environments (domestic, condominium, outdoor), able to cooperate among themselves and with other machines in the framework (i.e. the elevator of the condominium). The evaluation was performed in realistic environments involving 30 end-users.","Service robotics, Cooperative robotics, Delivery, User centered design",Raffaele Limosani and Raffele Esposito and Alessandro Manzi and Giancarlo Teti and Filippo Cavallo and Paolo Dario,https://www.sciencedirect.com/science/article/pii/S0921889016302457,https://doi.org/10.1016/j.robot.2018.02.001,0921-8890,2018,56--67,103,Robotics and Autonomous Systems,Robotic delivery service in combined outdoor?indoor environments: technical analysis and user evaluation,article,LIMOSANI201856
"With a focus on a number of state-of-the-art techniques in the area of autonomous non-rigid space systems control, realization of a comprehensive strategy is worthy of investigation to handle a set of parameters of the present overactuated processes with model uncertainties. In a word, the subject behind the research is to guarantee the desirable performance of a class of the autonomous space systems, which can be considered through the moments of inertia, the central of mass, the profile of the thrust vector and the misalignments of the propellant engine to deal with mission operation plans. There is the attitude cascade strategy including the low thrust three-axis engine off mode control, the low thrust x-axis engine on mode control and finally the high thrust y,z-axis engine on mode control, respectively. The control strategy is realized in a number of loops, as long as the on and off modes of the propellant engine are focused on the Euler angles control, in finite burn time, and quaternion vector control, in non-burn time, respectively, in line with parameters variations. It is to note that the parameters variations are coherently different in each one of the engine modes. The dynamics of high-low thrusters are taken into real consideration, where the control allocations in association with the pulse-width pulse-frequency modulators are employed to cope with a set of on?off reaction thrusters. The investigated results are finally analyzed in line with some related well-known benchmarks to verify the approach performance. The main contribution and motivation of the strategy investigated here is to propose a novel three-axis comprehensive cascade robust control solution to be able to deal with the parameters of autonomous non-rigid space systems under control with model uncertainties, in a synchronous manner, once the results regarding the tracking of the three-axis referenced commands are efficient with high accuracy along with the recent potential outcomes, researched in this area.","Comprehensive cascade control strategy, Propellant engine modes control, Autonomous non-rigid space systems, Model uncertainties",A.H. Mazinan,https://www.sciencedirect.com/science/article/pii/S0921889015301056,https://doi.org/10.1016/j.robot.2015.12.004,0921-8890,2022,102587,155,Robotics and Autonomous Systems,On comprehensive cascade control strategy considering a class of overactuated autonomous non-rigid space systems with model uncertainties,article,MAZINAN2022102587
"Inverse kinematic (IK) problems based on the product of exponentials (POE) model are often transformed to a series of Paden?Kahan subproblems, which are based on geometric methods with geometric constraints. The focus of subproblem is to solve the 3rd order subproblems, among which the 3R-type subproblem is the most prevalent. In this paper, a general frame for the inverse solution of arbitrary 3R types, without geometric constraints, is presented. It can be applied in different 3R types of practical cases, including those with parallel, intersecting, and skewed relationships. This paper mainly focuses on: (1) developing a real algebraic geometric (RAG) method based on the properties of the screw theory and the Rodrigues? rotation formula; (2) obtaining the closed-form solutions for arbitrary 3R subproblems, and ensuring the accuracies of these solutions; (3) expanding the Paden?Kahan subproblems and meeting the demands of online real-time applications; and finally, (4) verifying the effectiveness of the RAG method, through comparisons with the geometric method, using simulations and real experiments. The proposed frame can be widely applied in series, reconfigurable, and other types of robots.","Inverse kinematics, Product of exponentials (POE), Screw theory, Rodrigues? rotation formula",Haixia Wang and Xiao Lu and Chunyang Sheng and Zhiguo Zhang and Wei Cui and Yuxia Li,https://www.sciencedirect.com/science/article/pii/S0921889017307571,https://doi.org/10.1016/j.robot.2018.04.002,0921-8890,2018,138--145,105,Robotics and Autonomous Systems,General frame for arbitrary 3R subproblems based on the POE model,article,WANG2018138
"The closed-loop dynamic control of parallel mechanisms is a challenging field due to the high complexity of their dynamic behavior, especially those with prismatic actuators. Prismatic joints usually provide considerable amount of friction which could vary along its axis. This paper addresses the application of different control algorithms in order to tackle the challenges in closed-loop control of an overconstrained 3-DOF decoupled parallel mechanism which compromises three prismatic actuators with variable frictions along each axis. In addition, a Kinect vision sensor, as the position feedback, is installed. Since the Kinect RGB sensor performs at 30 frame per second, there is a 33 ms delay in the feedback of the control unit which restricts the control loop frequency to maximum value of 30 Hz. Then, based on the models obtained from the identifications of step response, kinetic friction and inverse dynamic model, various attempts have been made in order to obtain a controller with a reasonably performance. First, the conventional PID and sliding mode controllers are applied. Then, the position?velocity controller based on the obtained experience of the mechanism performance is proposed, in which a feedforward unit as the friction compensator is added to the latter feedback-based control units. Eventually, a feedback?feedforward controller based on PID controller and a compensator based on the identified inverse dynamic model is applied to the mechanism which was able to improve the performance of the control unit to a sufficient level.","Dynamic control, Inverse dynamics, Overconstrained parallel mechanisms, PID controller, Sliding mode controller, Feedforward compensator, Vision feedback",Mohammad Sharifzadeh and Mehdi {Tale Masouleh} and Ahmad Kalhor and Pourya Shahverdi,https://www.sciencedirect.com/science/article/pii/S0921889017305390,https://doi.org/10.1016/j.robot.2018.01.003,0921-8890,2018,27--43,102,Robotics and Autonomous Systems,An experimental dynamic identification & control of an overconstrained 3-DOF parallel mechanism in presence of variable friction and feedback delay,article,SHARIFZADEH201827
"Robot arms that operate in unstructured and dynamic environments often need to establish contact with a planar surface, while avoiding the appearance of excessive contact forces. This is a difficult task given that exact knowledge of the robot or the environment model parameters is not available. In this paper a novel, continuous in time, controller is designed, capable of establishing and maintaining contact of the robot with a planar surface of unknown stiffness and position. The proposed control scheme guarantees that the resulted contact force, normal to the surface, is a priori bounded by user-defined bounds, while imposing prescribed transient and steady-state performance attributes on the post-contact position and orientation error response. All remaining closed-loop signals are also kept bounded. The controller is validated via experimental studies performed on a KUKA LWR 4+ robot. Additionally, a comparison is conducted with a relative approach from the literature. The results verify the theoretical findings.",,George S. Kanakis and Fotios Dimeas and George A. Rovithakis and Zoe Doulgeri,https://www.sciencedirect.com/science/article/pii/S0921889017308266,https://doi.org/10.1016/j.robot.2018.03.005,0921-8890,2018,99--108,104,Robotics and Autonomous Systems,Prescribed contact establishment of a robot with a planar surface under position and stiffness uncertainties,article,KANAKIS201899
"For autonomous pole-climbing robots, mapping and recognition of truss-style structures is a challenging task. To build an autonomous climbing system, a truss modeling and recognition system is proposed and applied to autonomous climbing. The system consists of three parts: environment modeling, segmentation by a proposed algorithm called Pouring Algorithm, as well as Truss Parametric Expression Algorithm (TPEA). The experiments show that our study is able to model the truss and extract the parametric expression with a 7.11 mm absolute error of the pole radius and a 9.38% relative error of the pole length. In addition, an autonomous climbing experiment based on our system with a climbing robot is illustrated, verifying the ability of our work to meet the requirement of autonomous climbing.","Autonomous climbing robot, Parametric expression, Truss-style structure",Weinan Chen and Shichao Gu and Lei Zhu and Hong Zhang and Haifei Zhu and Yisheng Guan,https://www.sciencedirect.com/science/article/pii/S0921889017303093,https://doi.org/10.1016/j.robot.2018.01.002,0921-8890,2018,126--137,101,Robotics and Autonomous Systems,Representation of truss-style structures for autonomous climbing of biped pole-climbing robots,article,CHEN2018126
"In order to generally deal with the rotor-type UAV?s collision-free motion planning problem in the unknown static environment, we propose a non-holonomic solution via integration of the KF-based SLAM technique and governing force design. The traditional SLAM is modified and reduced as a low-complexity form according to the fact that too early detected obstacle information can be regarded as nearly frozen after sufficient correction. The artificial force terms are designed in a intuitive and smart way, through employment of the wall-following rule and lessons from historical and current experience, which are taught by the bat?s predation process. Further, they are converted to the real-time thrust vector expectation. Multiple simulation tests in both continuous and discrete scenes indicate that: (1) using slight sacrifice on the state estimate covariance can exchange pronounced reduction on structural complexity of the complete SLAM in return; (2) the LBAFD can not only mitigate limitations on the path oscillation, no passage between closely spaced obstacles and goal unreachability, but also lead to a high flying and exploration efficiency; (3) the integrated method demonstrates a relatively stable performance under different parameter settings and is even unconcerned to the surrounding characteristics.","Collision-free planning, SLAM, Complexity reduction, Artificial force, Learning strategy, Wall-following rule",Lei Liu and Rui Guo and Junan Wu,https://www.sciencedirect.com/science/article/pii/S0921889017303020,https://doi.org/10.1016/j.robot.2017.10.017,0921-8890,2018,132--149,100,Robotics and Autonomous Systems,A collision-free motion planning method by integrating complexity-reduction SLAM and learning-based artificial force design,article,LIU2018132
"Effective robot programming by demonstration requires the availability of multiple demonstrations to learn about all relevant aspects of the demonstrated skill or task. Typically, a human teacher must demonstrate several variants of the desired task to generate a sufficient amount of data to reliably learn it. Here a problem often arises that there is a large variability in the speed of execution across human demonstrations. This can cause problems when multiple demonstrations are compared to extract the relevant information for learning. In this paper we propose an extension of dynamic movement primitives called arc-length dynamic movement primitives, where spatial and temporal components of motion are well separated. We show theoretically and experimentally that the proposed representation can be effectively applied for robot skill learning and action recognition even when there are large variations in the speed of demonstrated movements.","Programming by demonstration, Skill learning, Action recognition, Dynamic movement primitives",Timotej Ga?par and Bojan Nemec and Jun Morimoto and Ale? Ude,https://www.sciencedirect.com/science/article/pii/S0921889017302695,https://doi.org/10.1016/j.robot.2017.11.012,0921-8890,2018,225--235,100,Robotics and Autonomous Systems,Skill learning and action recognition by arc-length dynamic movement primitives,article,GASPAR2018225
"This paper describes how to achieve highly accurate unsupervised spatial lexical acquisition from speech-recognition results including phoneme recognition errors. In most research into lexical acquisition, the robot has no pre-existing lexical knowledge. The robot acquires sequences of some phonemes as words from continuous speech signals. In a previous study, we proposed a nonparametric Bayesian spatial concept acquisition method (SpCoA) that integrates the robot?s position and words obtained by unsupervised word segmentation from uncertain syllable recognition results. However, SpCoA has a very critical problem to be solved in lexical acquisition; the boundaries of word segmentation are incorrect in many cases because of many phoneme recognition errors. Therefore, we propose an unsupervised machine learning method (SpCoA++) for the robust lexical acquisition of novel words relating to places visited by the robot. The proposed SpCoA++ method performs an iterative estimation of learning spatial concepts and updating a language model using place information. SpCoA++ can select a candidate including many words that better represent places from multiple word-segmentation results by maximizing the mutual information between segmented words and spatial concepts. The experimental results demonstrate a significant improvement of the phoneme accuracy rate of learned words relating to place in the proposed method by word-segmentation results based on place information, in comparison to the conventional methods. We indicate that the proposed method enables the robot to acquire words from speech signals more accurately, and improves the estimation accuracy of the spatial concepts.","Ambiguous speech recognition, Bayesian nonparametrics, Lexical acquisition, Place categorization, Spatial concept acquisition, Unsupervised word segmentation",Akira Taniguchi and Tadahiro Taniguchi and Tetsunari Inamura,https://www.sciencedirect.com/science/article/pii/S0921889017302178,https://doi.org/10.1016/j.robot.2017.10.013,0921-8890,2018,166--180,99,Robotics and Autonomous Systems,Unsupervised spatial lexical acquisition by updating a language model with place clues,article,TANIGUCHI2018166
"Cooperative manipulation of a rigid object is challenging and represents an interesting and active research area, especially when these robots are subject to joint and task prioritization constraints. In cooperative manipulation, a primary task is to maintain the coordination of motions, to avoid severe damage caused by the violation of kinematic constraints imposed by the closed chain mechanism. This paper proposes a kinematic controller for dual-arm cooperative manipulation that ensures safety by providing relative coordinated motion as highest priority task and joint limit avoidance and world-space trajectory following at a lower priority. The coordination of motions is based on modular relative Jacobian formulation. The approach is applicable to systems composed of redundant or non-redundant manipulators. Experiments in simulation demonstrate the behavior of the approach under different redundancy configurations. Experiments on two robots with different number of redundant motions show the applicability of the proposed approach to cooperative manipulation under joint limit constraints.","Cooperative manipulators, Dual-arm manipulation, Relative Jacobian, Joint limit avoidance, Redundancy resolution",Davide Ortenzi and Rajkumar Muthusamy and Alessandro Freddi and Andrea Monteriù and Ville Kyrki,https://www.sciencedirect.com/science/article/pii/S0921889017300672,https://doi.org/10.1016/j.robot.2017.10.005,0921-8890,2018,110--120,99,Robotics and Autonomous Systems,Dual-arm cooperative manipulation under joint limit constraints,article,ORTENZI2018110
"Although in recent years there have been quite a few studies aimed at the navigation of robots in cluttered environments, few of these have addressed the problem of robots navigating while moving a large or heavy objects. This is especially useful when transporting loads with variable weights and shapes without having to change the robot hardware. Inspired by the wide use of makeshift carts by humans, we tackle, in this work, the problem of a humanoid robot navigating in a cluttered environment while displacing a heavy load that lies on a cart-like object. We present a complete navigation scheme, from the incremental construction of a map of the environment and the computation of collision-free trajectories to the control to execute these trajectories. Our contributions are as follows: (1) a whole-body control scheme that makes the humanoid use its hands and arms to control the motions of the cart?load system (e.g. tight turns) (2) a sensorless approach to automatically select the appropriate primitive set according to the load weight (3) a motion planning algorithm to find an obstacle-free trajectory using the appropriate primitive set and the constructed map of the environment as input (4) an efficient filtering technique to remove the cart from the field of view of the robot while improving the general performances of the SLAM algorithms and (5) a continuous and consistent odometry data formed by fusing the visual and the robot odometry information. We present experiments conducted on a real Nao robot, equipped with an RGB-D sensor mounted on its head, pushing a cart with different loads. Our experiments show that the payload can be significantly increased without changing the robot?s main hardware, and therefore enacting the capacity of humanoid robots in real-life situations.","Humanoid robot, Localization and mapping, Navigation, Whole-body control, Motion planning",Antoine Rioux and Wael Suleiman,https://www.sciencedirect.com/science/article/pii/S0921889015303043,https://doi.org/10.1016/j.robot.2017.10.001,0921-8890,2018,50--62,99,Robotics and Autonomous Systems,Autonomous SLAM based humanoid navigation in a cluttered environment while transporting a heavy load,article,RIOUX201850
"This paper deals with range-only simultaneous localization and mapping (RO-SLAM), which is of particular interest in aerial robotics where low-weight range-only devices can provide a complementary continuous estimation between robot and landmarks when using radio-based sensors. Range-only sensors work at greater distances when compared to other commonly used sensors in aerial robotics and they are low-cost. However, the spherical shell uniform distribution inherent to range-only observations poses significant technological challenges, restricting the approaches that can be used to solve this problem. This paper presents an undelayed multi-hypothesis Extended Kalman Filter (EKF) approach based on Gaussian Mixture Models (GMM) and a reduced parameterization of the state vector to improve its efficiency. The paper also proposes a new robot-to-landmark and landmark-to-landmark range-only observation model for EKF-SLAM which takes advantage of the reduced parameterization. Finally, a new scheme is proposed for updating hypothesis weights based on an independence of beacon parameters. The method is firstly validated with simulations comparing the results with other state-of-the-art methods and later validated with real experiments for 3D RO-SLAM using several radio-based range-only sensors and an aerial robot.","Range-only simultaneous localization and mapping, Robot localization, Kalman filtering, Gaussian mixture models",Felipe R.Fabresse and Fernando Caballero and Iván Maza and Aníbal Ollero,https://www.sciencedirect.com/science/article/pii/S0921889017302610,https://doi.org/10.1016/j.robot.2018.02.014,0921-8890,2018,40--55,104,Robotics and Autonomous Systems,An efficient approach for undelayed range-only SLAM based on Gaussian mixtures expectation,article,RFABRESSE201840
"The underactuated hand has the advantage of adaptation for grasping irregularly shaped objects by combining the active actuators with passive springs to achieving a stable grasp. The design of the spring parameter will affect the region of the stable grasp. This paper presents a metric to design the spring stiffness to keep the tradeoff between the adaption of objects and ability of stable grasp. Firstly, the relationship between the spring stiffness and stable region is qualified and visualized according to grasp-state plane together with the spring stiffness?s delimiter between regimes. Then, a quantitative way by analytical equations and graphs is proposed to evaluate the grasp stabilization with respect to spring stiffness. Finally, applications of designing the optimal spring stiffness by giving the particular conditions are presented to validate the efficiency of the proposed method.","Underactuated fingers, The delimiter of spring stiffness, Grasp stabilization, Adaptation of grasping",Jing Cui and Shaobo Yan and Jian Hu and ZhongYi Chu,https://www.sciencedirect.com/science/article/pii/S0921889017300039,https://doi.org/10.1016/j.robot.2018.01.001,0921-8890,2018,1--12,102,Robotics and Autonomous Systems,A metric to design spring stiffness of underactuated fingers for stable grasp,article,CUI20181
"This paper investigates the use of reinforcement learning for the path planning of an autonomous triangular marine platform in unknown environments under various environmental disturbances. The marine platform is over-actuated, i.e. it has more control inputs than degrees of freedom. The proposed approach uses a high-level online least-squared policy iteration scheme for value function approximation in order to estimate sub-optimal policy. The chosen action is considered as the desired input to a fast and efficient low-level velocity controller. We evaluate our approach in a simulated environment, including the dynamic model of the platform, the dynamics and limitations of the actuators, and the presence of wind, wave, and sea current disturbances. Simulation results are presented that demonstrate the performance of the proposed approach. Despite the model dynamics, the actuation dynamics and constrains, and the environmental disturbances, the presented results are promising.","Reinforcement learning, Over-actuated control, Marine vehicle, Autonomous navigation",Konstantinos Blekas and Kostas Vlachos,https://www.sciencedirect.com/science/article/pii/S0921889017301884,https://doi.org/10.1016/j.robot.2017.12.009,0921-8890,2018,93--102,101,Robotics and Autonomous Systems,RL-based path planning for an over-actuated floating vehicle under disturbances,article,BLEKAS201893
"This study presents an autonomous guided vehicle (AGV) with simultaneous localization and map building (SLAM) based on matching method, and extended Kalman filter SLAM. In general, the AGV is a large mobile robot that is used in transportation to carry cargoes, and it is guided using wired or wireless guidance systems. The guidance system based AGV accounts for a majority of robots in the mobile robot industry. However, in semiconductor factories, landmarks are unavailable; hence, the existing system has not been used in the mentioned environments. Therefore, the SLAM technology is applied in the environments, and can guide the AGV without landmarks. However, the accuracy of the SLAM can be low owing to measurement error of sensors and a cumulative calculation caused by localization sensors. Therefore, the accuracy is frequently assumed to be incorrect; moreover, the accuracy of the built map is low. In order to solve the problems, this study proposes the AGV with the SLAM based on matching methods; two matching method; geometric matching method and iterative closest point algorithm. The performance of the proposed method is compared with typical methods such as singular value decomposition / RIGID transformation based technologies using feature-point-based SLAM and is compared with the aforementioned two methods using the extended Kalman filter SLAM. The proposed method is more efficient than the typical methods used in the comparison.","Indoor SLAM, Geometric matching method, ICP matching method, EKF SLAM",Hyunhak Cho and Eun Kyeong Kim and Sungshin Kim,https://www.sciencedirect.com/science/article/pii/S0921889017301367,https://doi.org/10.1016/j.robot.2017.11.011,0921-8890,2018,206--224,100,Robotics and Autonomous Systems,Indoor SLAM application using geometric and ICP matching methods based on line features,article,CHO2018206
"Cyber-security for robotic systems is a growing concern. Many mobile robots rely heavily on Real Time Location Systems to operate safely in different environments. As a result, Real Time Location Systems have become a vector of attack for robots and autonomous systems, a situation which has not been studied well. This article shows that cyber-attacks on Real Time Location Systems can be detected by a system built using supervised learning. Furthermore it shows that some type of cyber-attacks on Real Time Location Systems, specifically Denial of Service and Spoofing, can be detected by a system built using Machine Learning techniques. In order to construct models capable of detecting those attacks, different supervised learning algorithms have been tested and validated using a dataset of real data recorded by a wheeled robot and a commercial Real Time Location System, based on Ultra Wideband beacons. Experimental results with a cross-validation analysis have shown that Multi-Layer Perceptron classifiers get the highest test score and the lowest validation error. Moreover, it is the model with less overfitting and more sensitivity for detecting Denial of Service and Spoofing cyber-attacks on Real Time Location Systems.","Cyber-security, Indoor positioning, Robotics, Cyber-attack, Beacon, Machine learning",Ángel Manuel Guerrero-Higueras and Noemí DeCastro-García and Vicente Matellán,https://www.sciencedirect.com/science/article/pii/S092188901730283X,https://doi.org/10.1016/j.robot.2017.10.006,0921-8890,2018,75--83,99,Robotics and Autonomous Systems,Detection of Cyber-attacks to indoor real time localization systems for autonomous robots,article,GUERREROHIGUERAS201875
"A significant limitation of most previous target trapping algorithms for swarm robots is that the target shape needs to be predefined and only some regular Euclidean shapes can be applied. Besides, splitting and merging of multiple shapes depending on moving targets have not been considered by previous methods. This may be inadequate for dealing with the problem of entrapment in dynamic targets. This paper proposes a flexible shape formation algorithm by using Radial Basis Implicit Function (RBIF) to realize the multi-target trapping task that needs the transformation of trapping shape response to dynamic targets. With this flexible shape formation method, we improve previous methods by allowing most distribution of group targets to be entrapped without a predefined shape and robots to split/merge with regards to the moving targets. The previous bound on the number of reference points for a target shape is triple the number of targets, while it becomes less by considering the convex hulls of targets in the new method. Numerical simulations of static/dynamic scenarios, obstacle avoidance, noise and self-reorganization have been performed to validate the effectiveness and flexibility of the proposed approach for multi-target trapping.","Multi-target trapping, Self-organization, Pattern formation, Swarm robots",Shuai Zhang and Mingyong Liu and Xiaokang Lei and Yunke Huang and Feihu Zhang,https://www.sciencedirect.com/science/article/pii/S0921889017306024,https://doi.org/10.1016/j.robot.2018.04.008,0921-8890,2018,1--13,106,Robotics and Autonomous Systems,Multi-target trapping with swarm robots based on pattern formation,article,ZHANG20181
"In this paper, we present an approach to the problem of Robot Learning from Demonstration (RLfD) in a dynamic environment, i.e. an environment whose state changes throughout the course of performing a task. RLfD mostly has been successfully exploited only in non-varying environments to reduce the programming time and cost, e.g. fixed manufacturing workspaces. Non-conventional production lines necessitate Human?Robot Collaboration (HRC) implying robots and humans must work in shared workspaces. In such conditions, the robot needs to avoid colliding with the objects that are moved by humans in the workspace. Therefore, not only is the robot: (i) required to learn a task model from demonstrations; but also, (ii) must learn a control policy to avoid a stationary obstacle. Furthermore, (iii) it needs to build a control policy from demonstration to avoid moving obstacles. Here, we present an incremental approach to RLfD addressing all these three problems. We demonstrate the effectiveness of the proposed RLfD approach, by a series of pick-and-place experiments by an ABB YuMi robot. The experimental results show that a person can work in a workspace shared with a robot where the robot successfully avoids colliding with him.","Robot learning from demonstration, Dynamic environment, Moving obstacles",Amir M. {Ghalamzan E.} and Matteo Ragaglia,https://www.sciencedirect.com/science/article/pii/S0921889017302981,https://doi.org/10.1016/j.robot.2017.12.001,0921-8890,2018,45--56,101,Robotics and Autonomous Systems,Robot learning from demonstrations: Emulation learning in environments with moving obstacles,article,GHALAMZANE201845
"In this work, by reformulating screw theory (generalization of quaternions) in the conformal geometric algebra framework, we address the interpolation, virtual reality, graphics engineering, haptics. We derive intuitive geometric equations to handle surface operations like in kidney surgery. The interpolation can handle the interpolation and dilation in 3D of points, lines, planes, circles and spheres. With this procedure, we interpolate trajectories of surgical instrument. Using quaternions, we formulate the quaternion spike neural network for control. This new neural network structure is based on Spike Neural Networks and developed using the quaternion algebra. The real valued training algorithm was extended so that it could make adjustments of the weights according to the properties and product of the quaternion algebra. In this spike neural network, we are taking into account two relevant ideas the use of Spike neural network which is the best model for oculo-motor control and the role of geometric computing. As illustration. the quaternion spike neural network is applied for control of robot manipulator. The experimental analysis shows promising possibilities for the use of this powerful geometric language to handle multiple tasks in human?machine interaction and robotics.","Geometric algebra, Conformal geometric algebra, Quaternion algebra, Graphics engineering, Interpolation, Haptics, Non-linear control, Spike neural networks, Quaternion spike neural networks, Human?machine interaction, Robotics, Medical robotics",Eduardo Bayro-Corrochano and Luis Lechuga-Gutiérrez and Marcela Garza-Burgos,https://www.sciencedirect.com/science/article/pii/S0921889017303317,https://doi.org/10.1016/j.robot.2018.02.015,0921-8890,2018,72--84,104,Robotics and Autonomous Systems,Geometric techniques for robotics and HMI: Interpolation and haptics in conformal geometric algebra and control using quaternion spike neural networks,article,BAYROCORROCHANO201872
"Obstacle avoidance is a necessary behavior to guarantee the safety of an unmanned aerial vehicle (UAV). However, it is a challenge for the UAV to detect and avoid high-speed flying obstacles such as other UAVs or birds. In this paper, we propose a generic framework that integrates an autonomous obstacle detection module and a reinforcement learning (RL) module to develop reactive obstacle avoidance behavior for a UAV. In the obstacle detection module, we design a saliency detection algorithm using deep convolution neural networks (CNNs) to extract monocular visual cues. The algorithm imitates human?s visual detection system, and it can accurately estimate the location of obstacles in the field of view (FOV). The RL module uses an actor?critic structure that chooses the RBF neural network to approximate the value function and control policy in continuous state and action spaces. We have tested the effectiveness of the proposed learning framework in a semi-physical experiment. The results show that the proposed saliency detection algorithm performs better than state-of-the-art, and the RL algorithm can learn the avoidance behavior from the manual experiences.","UAV, Flying obstacle avoidance, Convolution neural networks based saliency detection, Reinforcement learning",Zhaowei Ma and Chang Wang and Yifeng Niu and Xiangke Wang and Lincheng Shen,https://www.sciencedirect.com/science/article/pii/S0921889017301136,https://doi.org/10.1016/j.robot.2017.10.009,0921-8890,2018,108--118,100,Robotics and Autonomous Systems,A saliency-based reinforcement learning approach for a UAV to avoid flying obstacles,article,MA2018108
"Grasp detection is an active research branch in robotic field. Most existing works have made strong assumptions, such as the fixed object position and monotonous manipulation background, which facilitate the detection of graspable objects. But the real manipulation condition could be much more complicated. In this work, we propose a novel object perception method. It is able to accurately detect the object, as well as those in cluttered background, and guide the movement of robotic arm to reach a proper grasping state. First, we translate and align the initial proposals according to the structured edge distribution. The aligned proposals have a larger overlap with ground truth at the expense of a little drop in precision. Then, for each superpixel inside the proposal, we use its contrast to high-contrast superpixels and background superpixels, weighted by distance bias, to determine whether it should be included in the refined proposal. Experimental results on both benchmark dataset and robotic task have verified the effectiveness of the proposed method.","Robotic grasping, Object detection, Structured edge, Superpixel, Local cues",Lu Chen and Panfeng Huang and Zhou Zhao,https://www.sciencedirect.com/science/article/pii/S092188901730653X,https://doi.org/10.1016/j.robot.2017.11.015,0921-8890,2018,194--205,100,Robotics and Autonomous Systems,Refining object proposals using structured edge and superpixel contrast in robotic grasping,article,CHEN2018194
"This paper presents a novel unmanned aerial vehicle platform based on a three rotor configuration, which can achieve the highest level of maneuverability in all 6 dimensions (i.e. 3D position and 3D attitude). The three propellers can be tilted independently to obtain full force and torque vectoring authority, such that this new aerial robotic platform can overcome the limitations of a classic quadrotor UAV that cannot change its attitude while hovering at a stationary position. A robust feedback linearization controller is developed to deal with this highly coupled and nonlinear dynamics of the proposed tri-rotor UAV, which linearizes the dynamics globally using geometric transformations to produce a linear model that matches the Jacobi linearization of the nonlinear dynamics at the operating point of interest. A distributed formation control tracking protocol is then proposed to control a swarm of tri-rotor UAVs. The 3D position and 3D attitude of each vehicle can be controlled independently to follow a desired time-varying formation. The effectiveness of the designed control strategy is illustrated in a realistic virtual reality simulation environment based on real hardware parameters from a physical construction.","Aerial robotics, Distributed systems, Formation control, Optimal control, Multi-agent, Unmanned aerial vehicles",Junyan Hu and Alexander Lanzon,https://www.sciencedirect.com/science/article/pii/S0921889017308163,https://doi.org/10.1016/j.robot.2018.02.019,0921-8890,2018,162--174,103,Robotics and Autonomous Systems,An innovative tri-rotor drone and associated distributed aerial drone swarm control,article,HU2018162
"In this paper, a novel approach to ego-motion estimation is proposed based on visual and inertial sensors, named Omnidirectional Visual-Inertial Odometry (OVIO). The proposed approach combines omnidirectional visual features with inertial measurements within the Multi-State Constraint Kalman Filter (MSCKF). In contrast with other visual inertial odometry methods that use visual features captured by perspective cameras, the proposed approach utilizes spherical images obtained by an omnidirectional camera to obtain more accurate estimates of the position and orientation of the camera. Because the standard perspective model is unsuitable for omnidirectional cameras, a measurement model on a plane tangent to the unit sphere rather than on the image plane is defined. The key hypothesis of OVIO is that a wider field of view allows the incorporation of more visual features from the surrounding environment, thereby improving the accuracy and robustness of the ego-motion estimation. Moreover, by using an omnidirectional camera, a situation where there is not enough texture is less likely to arise. Experimental evaluation of OVIO using synthetic and real video sequences captured by a fish-eye camera in both indoor and outdoor environments shows the superior performance of the proposed OVIO as compared to the MSCKF using a perspective camera in both positioning and attitude estimation.","Pose estimation, Kalman filter, Omnidirectional camera, INS, Visual-Inertial Odometry",Milad Ramezani and Kourosh Khoshelham and Clive Fraser,https://www.sciencedirect.com/science/article/pii/S0921889017308734,https://doi.org/10.1016/j.robot.2018.03.007,0921-8890,2018,26--37,105,Robotics and Autonomous Systems,Pose estimation by Omnidirectional Visual-Inertial Odometry,article,RAMEZANI201826
"Robotic software frameworks simplify the development of robotic applications. The more powerful ones help to build such applications as a distributed collection of interoperating software nodes. The communications inside those robotic systems are amenable of being attacked and vulnerable to the security threats present on any networked system. With the robots increasingly entering in people?s daily lives, like autonomous cars, drones, etc. security on them is a central issue gaining attention. This paper studies several well known communication middleware used by robotic frameworks running on robots with regular computers, and their support for cybersecurity. It analyzes their performance when transmitting regular robotic data of different sizes, with or without security features, on several network settings. The experiments show that security, when available, does not significantly decrease the quality of the robotic data communication in terms of latency and packet loss rate.","Security, Communications, Middleware, Frameworks, Robotics",Francisco Martín and Enrique Soriano and José M. Cañas,https://www.sciencedirect.com/science/article/pii/S0921889017303044,https://doi.org/10.1016/j.robot.2017.11.002,0921-8890,2018,95--107,100,Robotics and Autonomous Systems,Quantitative analysis of security in distributed robotic frameworks,article,MARTIN201895
"This article presents the development of a power augmentation and rehabilitation exoskeleton based on a novel actuator. The proposed soft actuators are extensor bending pneumatic artificial muscles. This type of soft actuator is derived from extending McKibben artificial muscles by reinforcing one side to prevent extension. This research has experimentally assessed the performance of this new actuator and an output force mathematical model for it has been developed. This new mathematical model based on the geometrical parameters of the extensor bending pneumatic artificial muscle determines the output force as a function of the input pressure. This model is examined experimentally for different actuator sizes. After promising initial experimental results, further model enhancements were made to improve the model of the proposed actuator. To demonstrate the new bending actuators a power augmentation and rehabilitation soft glove has been developed. This soft hand exoskeleton is able to fit any adult hand size without the need for any mechanical system changes or calibration. EMG signals from the human hand have been monitored to prove the performance of this new design of soft exoskeleton. This power augmentation and rehabilitation wearable robot has been shown to reduce the amount of muscles effort needed to perform a number of simple grasps.","Soft robotics, Soft mechanism, Wearable robot, Artificial pneumatic rubber muscle, Modelling",Hassanin Al-Fahaam and Steve Davis and Samia Nefti-Meziani,https://www.sciencedirect.com/science/article/pii/S0921889017302592,https://doi.org/10.1016/j.robot.2017.10.010,0921-8890,2018,63--74,99,Robotics and Autonomous Systems,The design and mathematical modelling of novel extensor bending pneumatic artificial muscles (EBPAMs) for soft exoskeletons,article,ALFAHAAM201863
"Miniaturized grippers that possess an untethered structure are suitable for a wide range of tasks, ranging from micromanipulation and microassembly to minimally invasive surgical interventions. In order to robustly perform such tasks, it is critical to properly estimate their overall configuration. Previous studies on tracking and control of miniaturized agents estimated mainly their 2D pixel position, mostly using cameras and optical images as a feedback modality. This paper presents a novel solution to the problem of estimating and tracking the 3D position, orientation and configuration of the tips of submillimeter grippers from marker-less visual observations. We consider this as an optimization problem, which is solved using a variant of the Particle Swarm Optimization algorithm. The proposed approach has been implemented in a Graphics Processing Unit (GPU) which allows a user to track the submillimeter agents online. The proposed approach has been evaluated on several image sequences obtained from a camera and on B-mode ultrasound images obtained from an ultrasound probe. The sequences show the grippers moving, rotating, opening/closing and grasping biological material. Qualitative results obtained using both hydrogel (soft) and metallic (hard) grippers with different shapes and sizes ranging from 750 microns to 4 mm (tip to tip), demonstrate the capability of the proposed method to track the agent in all the video sequences. Quantitative results obtained by processing synthetic data reveal a tracking position error of 25 ± 7?m and orientation error of 1.7 ± 1.3 degrees. We believe that the proposed technique can be applied to different stimuli responsive miniaturized agents, allowing the user to estimate the full configuration of complex agents from visual marker-less observations.","Model-based tracker, Graphics Processing Unit, Particle Swarm Optimization, Miniaturized grippers",Stefano Scheggi and ChangKyu Yoon and Arijit Ghosh and David H. Gracias and Sarthak Misra,https://www.sciencedirect.com/science/article/pii/S0921889017304499,https://doi.org/10.1016/j.robot.2017.11.003,0921-8890,2018,111--121,103,Robotics and Autonomous Systems,A GPU-accelerated model-based tracker for untethered submillimeter grippers,article,SCHEGGI2018111
"This paper investigates the conception of a real-time decision system for colored object recognition using cheap and uncalibrated cameras. The proposed decision system, embedded in a humanoid robot evolving in an uncontrolled environment, is based on the collaboration between a fuzzy system and a data multi-sensory fusion methodology. Based on the ability of fuzzy systems to exhibit any type of behavior mapping, the color recognition problem using a single camera is viewed as a Takagi?Sugeno fuzzy system with Constant Conclusions (TSCC). Indeed, the behavior between the HSV triplet extracted from the image (captured by the robot?s camera) and the recognized colored object is represented by a TSCC. In this context, it is well known that a single sensory system is only capable of supplying partial information and is consequently limited in its ability to interpret complex situations, especially in imprecise and uncertain environments where ambiguities and conflicts among colors are often present. In other words, a decision system based on a single camera cannot reflect real situations and can affect the reliability and the quality of the color recognition. In order to overcome this problem, the integration of more than one camera in the recognition process is proposed. The data provided from these cameras is always affected by some level of impreciseness as well as uncertainty in the measurements. So, the proposed multi-camera fusion strategy based on evidence theory should be able to express such imperfections effectively, to reduce their effects, to exploit the data redundancy, to integrate the reliability of sources and to improve the color recognition accuracy. The feasibility and the validity of the proposed methodology are experimentally validated according to an embedded real-time implementation on the NAO humanoid robot.","Colored recognition system, HSV color space, Fuzzy systems (FS), Takagi?Sugeno with constant conclusions (TSCC), Evidence theory, NAO humanoid robot, Multi-camera information fusion",Reda Boukezzoula and Didier Coquin and Thanh-Long Nguyen and Stéphane Perrin,https://www.sciencedirect.com/science/article/pii/S0921889017306279,https://doi.org/10.1016/j.robot.2017.12.002,0921-8890,2018,302--316,100,Robotics and Autonomous Systems,Multi-sensor information fusion: Combination of fuzzy systems and evidence theory approaches in color recognition for the NAO humanoid robot,article,BOUKEZZOULA2018302
"This paper proposes a distributed algorithm for cooperatively manipulating an object rigidly grasped by a team of mobile manipulators. In order to increase the flexibility of the multi-robot cell and differently from other approaches, it is assumed that the object is completely unknown and there is not information exchange between robots. The devised strategy includes two stages: at the first stage, each robot estimates the object kinematic and dynamic parameters by applying specific contact wrenches, while, in the second stage, the estimated parameters are exploited within a distributed cooperative control framework that can be adopted, for instance, to control the interaction wrench exerted by the environment on the object or to implement a zero-force control algorithm. In addition to the total absence of communication and differently from existing solutions, the proposed technique assumes that each robot has not knowledge of the number of cooperative agents in the team and, remarkably, it is devised in the 3-dimensional space with the aim of handling both the position and the orientation of the object. Finally, the feasibility of the approach is proven via numerical simulations.","Distributed estimation, Distributed cooperative manipulation",Alessandro Marino and Francesco Pierri,https://www.sciencedirect.com/science/article/pii/S0921889017307807,https://doi.org/10.1016/j.robot.2018.02.007,0921-8890,2018,122--133,103,Robotics and Autonomous Systems,A two stage approach for distributed cooperative manipulation of an unknown object without explicit communication and unknown number of robots,article,MARINO2018122
"Monocular optical flow has been widely used to detect obstacles in Micro Air Vehicles (MAVs) during visual navigation. However, this approach requires significant movement, which reduces the efficiency of navigation and may even introduce risks in narrow spaces. In this paper, we introduce a novel setup of self-supervised learning (SSL), in which optical flow cues serve as a scaffold to learn the visual appearance of obstacles in the environment. We apply it to a landing task, in which initially ?surface roughness? is estimated from the optical flow field in order to detect obstacles. Subsequently, a linear regression function is learned that maps appearance features represented by texton distributions to the roughness estimate. After learning, the MAV can detect obstacles by just analyzing a still image. This allows the MAV to search for a landing spot without moving. We first demonstrate this principle to work with offline tests involving images captured from an on-board camera and then demonstrate the principle in flight. Although surface roughness is a property of the entire flow field in the global image, the appearance learning even allows for the pixel-wise segmentation of obstacles.","Self-supervised learning, Aerial robotics, Bio-inspiration, Optical flow, Obstacle appearance, Autonomous landing",H.W. Ho and C. {De Wagter} and B.D.W. Remes and G.C.H.E. {de Croon},https://www.sciencedirect.com/science/article/pii/S0921889017305626,https://doi.org/10.1016/j.robot.2017.10.004,0921-8890,2018,78--94,100,Robotics and Autonomous Systems,Optical-flow based self-supervised learning of obstacle appearance applied to MAV landing,article,HO201878
"Legged robots have advanced potential to move in complex environment accomplishing operating, rescuing and detecting tasks. In real applications, bypassing large obstacles is a more common choice for legged robots comparing with walking over and climbing the obstacles. However, few papers involve the obstacle avoidance approach for legged robots. An obstacle avoidance and motion planning scheme for a hexapod robot is presented in this paper. The scheme takes advantage of the superior mobility of the legged robot and fulfills requirements of walking stability and kinematic feasibility. Firstly, a novel obstacle avoidance trajectory planning method is proposed, which is inspired by the superior mobility of the legged robot. Then, a motion generation approach for the legged robot is developed to control the robot to walk along the planned trajectory. The approach coordinates the body motion and the feet motions to fulfill requirements of walking stability and kinematic feasibility simultaneously. Finally, the scheme is integrated on a hexapod robot and tested by real experiments.","Obstacle avoidance, Hexapod robot, Trajectory planning, Gait motion generation, Parallel mechanism",Yue Zhao and Xun Chai and Feng Gao and Chenkun Qi,https://www.sciencedirect.com/science/article/pii/S0921889017303329,https://doi.org/10.1016/j.robot.2018.01.007,0921-8890,2018,199--212,103,Robotics and Autonomous Systems,Obstacle avoidance and motion planning scheme for a hexapod robot Octopus-III,article,ZHAO2018199
"This article presents the design and experimental evaluation of a novel sliding mode control scheme, being applied to the case of an articulated vehicle. The proposed sliding mode controller is based on a novel continuous sliding surface, being introduced for reducing the chattering phenomenon, while achieving a better tracking performance and a fast minimization of the corresponding tracking error. The derivation of the sliding mode controller relies on the fully nonlinear kinematic model of the articulated vehicle, while the overall stability of the control scheme is proven based on the Lyapunov?s stability condition. The performance of the established control scheme is being experimentally evaluated through multiple path tracking scenarios on a small scale and fully realistic articulated vehicle.","Sliding mode control, Articulated vehicle, Path tracking",T. Nayl and G. Nikolakopoulos and T. Gustafsson and D. Kominiak and R. Nyberg,https://www.sciencedirect.com/science/article/pii/S0921889017301823,https://doi.org/10.1016/j.robot.2018.01.006,0921-8890,2018,213--221,103,Robotics and Autonomous Systems,Design and experimental evaluation of a novel sliding mode controller for an articulated vehicle,article,NAYL2018213
"This paper tackles the problem of controlling the position and orientation, expressed in a singularity-free representation form, of the end-effector of a redundant robot, while addressing an active compliant behaviour within the null-space. The manuscript extends the work in Sadeghian et al. (2014) by explicitly addressing the orientation part. In order to successfully accomplish the task, a dynamic controller is designed without need of any exteroceptive sensors information. A rigorous stability analysis is provided to confirm the developed theory. Experiments are finally carried out to bolster the performance of the proposed approach.","Redundant robots, Null-space compliance, Singularity-free orientation representation",Fabio Vigoriti and Fabio Ruggiero and Vincenzo Lippiello and Luigi Villani,https://www.sciencedirect.com/science/article/pii/S0921889017301306,https://doi.org/10.1016/j.robot.2017.11.007,0921-8890,2018,186--193,100,Robotics and Autonomous Systems,Control of redundant robot arms with null-space compliance and singularity-free orientation representation,article,VIGORITI2018186
"This paper investigates the dynamic equations of an N-flexible link manipulator with revolute?prismatic joints while considering the effects of manipulator locomotion by the mobile platform bound by non-holonomic kinematic constraints. Such constraints, in addition to creating dynamic interaction between manipulator and platform, cause serious motion limitations and introduction of more computational complexity. The manipulator?s flexible links are modeled by the assumed mode method, where the Timoshenko beam theory is used for the substitution of the assumed mode shapes. The internal and external damping effects are also studied for the model precision. Moreover, revolute?prismatic joints in each arm are exploited to develop the robot mobility. The new joint structure makes it possible to use mobile manipulators with long flexible links. However, in regard to the variations of links length caused by prismatic joints, time-varying dynamic equations are obtained, leading to comparatively complex and lengthy formulations. Therefore, the Gibbs?Appell formulation is utilized as an alternative to the Lagrange equations to facilitate the process of deriving the motion equations. In addition, the non-dimensional form of the Timoshenko beam theory mode shapes is recommended to circumvent the computation of time step mode shapes. It is also necessary to examine the system tip-over stability based on long and variable-length arms, lightweight base, and widespread environmental factors using the zero moment point methods. Finally, a numerical simulation for a mobile manipulator, with two flexible links and revolute?prismatic joints is carried out to demonstrate the performance of the presented model for such complex systems. Different amounts of link elasticity and the effects of internal and external damping coefficients are separately studied. The results are verified by recent fixed base flexible manipulators employing revolute?prismatic joints as well as the IUST Revolute?Prismatic joints experimental setup incorporating rigid links.","Flexible link mobile manipulators, Revolute?Prismatic joint, Recursive Gibbs?Appell formulation, Timoshenko beams theory, Non-holonomic constrains, Tip-over stability, Experimental R?P joints setup",M.H. Korayem and S.F. Dehkordi,https://www.sciencedirect.com/science/article/pii/S092188901730828X,https://doi.org/10.1016/j.robot.2018.02.013,0921-8890,2018,175--198,103,Robotics and Autonomous Systems,Derivation of motion equation for mobile manipulator with viscoelastic links and revolute?prismatic flexible joints via recursive Gibbs?Appell formulations,article,KORAYEM2018175
"Traditional climbing robots that use vacuum suckers have some technical problems, e.g., inability to climb coarse walls, frictional resistance and abrasion of suckers, and poor obstacle-surmounting ability. In this study, a new negative pressure adsorption mechanism is applied to the design of a climbing robot. This mechanism generates and maintains negative pressure and adsorption force by using the air?s rotational inertia effect; therefore, the structure incorporating this mechanism is called the rotational-flow adsorption unit. The most important characteristic of the adsorption unit is that it can function without being in contact with the wall, which fundamentally solves these technical problems associated with traditional climbing robots. In this study, we designed a square-shaped rotational-flow adsorption unit to improve the robot?s load ability (18% increase in the adsorption force) and designed a soft skirt structure to improve the robot?s obstacle-surmounting ability (e.g., passing through 15-mm-high bulges). Finally, we fabricated a prototype of the climbing robot and tested it on several actual walls (extremely coarse wall, wall containing deep groove, and wall containing large bulges). The test results show that our prototype robot can move stably on coarse walls and can pass over large grooves and bulges easily.","Climbing robot, Adsorption unit, Rotational flow, Load ability, Obstacle-surmounting ability",Qiang Zhou and Xin Li,https://www.sciencedirect.com/science/article/pii/S0921889016307710,https://doi.org/10.1016/j.robot.2018.03.008,0921-8890,2018,112--120,105,Robotics and Autonomous Systems,Experimental investigation on climbing robot using rotation-flow adsorption unit,article,ZHOU2018112
"Petri nets (PNs) are capable of modeling nearly any conceivable system and can provide a better understanding of the idealized action sequence in which to most effectively describe or execute said system through their powerful analytical capabilities. However, because real world instances are rarely as consistent and ideal as simulated models, basic PN modeling and simulation properties may be insufficient in practical application. We remedy this through specialization in Fuzzy Petri nets (FPNs). Fuzzy logic is incorporated to better model a self-navigating robot algorithm, thanks to its versatile multi-valued logic reasoning. By using FPNs, it is possible to simulate, assess, and communicate the process and reasoning of the navigational algorithm and apply it to real world programming. In this paper, we propose a series of specific fuzzy algorithms intended to be implemented in concert on a mobile robot platform in order to optimize the sequence of actions needed for a given task, primarily the navigation of an unknown maze. A set of varied maze configurations were developed and simulated as PN and FPN models, providing a testing environment to examine the efficiency of several methodologies. Five methods, including an original proposal in this paper, were compared across 30,000 simulations, evaluating in particular performance in processing cost in time. Our experiments concluded with results suggesting a very competitive task completion time at a considerable fraction in processing cost compared to the closest performing alternatives.","Petri nets, Fuzzy Petri nets, Fuzzy logic, Modeling and simulation, Autonomous Robot navigation",Seung-yun Kim and Yilin Yang,https://www.sciencedirect.com/science/article/pii/S0921889016302263,https://doi.org/10.1016/j.robot.2017.11.008,0921-8890,2018,153--165,101,Robotics and Autonomous Systems,A self-navigating robot using Fuzzy Petri nets,article,KIM2018153
"The traditional constant impedance control is a simple but effective method widely used in many fields including contact force tracking. Using this method, the location of the environment relative to the robot and the stiffness of the environment must be known, and usually the desired force is constant. However, for applications in dynamic contact force tracking in uncertain environment, it is not an effective solution. In this paper, a new adaptive variable impedance control is proposed for force tracking which has the capability to track the dynamic desired force and compensate for uncertainties (in terms of unknown geometrical and mechanical properties) in environment. In this study, the contact force model of robot end-effector and the environment is analyzed. Specifically, the contact force is used as the feedback force of a position-based impedance controller to actively track the dynamic desired force in uncertain environment. To adapt any environment stiffness uncertainties, a modified impedance control is proposed. To reduce the force tracking error caused by environment location uncertainty, an adaptive variable impedance control is implemented for the first time by adjusting the impedance parameters on-line based on the tracking error to compensate the unknown environment and the dynamic desired force. Furthermore, stability and convergence of the adaptive variable impedance control are demonstrated for a stable force tracking execution. Simulations and experiments to compare the performance of force tracking with the constant impedance control and the adaptive variable impedance control, perspectively, are conducted. The results strongly prove that the proposed approach can achieve better force tracking performance than the constant impedance control.","Adaptive variable impedance control, Contact force tracking, Uncertain environment, Modified impedance control, Uncertainties",Jinjun Duan and Yahui Gan and Ming Chen and Xianzhong Dai,https://www.sciencedirect.com/science/article/pii/S0921889017307480,https://doi.org/10.1016/j.robot.2018.01.009,0921-8890,2018,54--65,102,Robotics and Autonomous Systems,Adaptive variable impedance control for dynamic contact force tracking in uncertain environment,article,DUAN201854
"AZIMUT-3 is a nonholonomic omnidirectional platform design using sidewards off-centred compliant wheels. This design makes it possible to experiment with the use of the chassis? instantaneous centre of rotation (ICR) for motion control. Research on ICR-based motion controllers has focused on handling structural singularities and misses a more general consideration of the chassis? kinematic and physical constraints like steering, velocity and acceleration constraints. This paper presents the design of an ICR-based motion controller for AZIMUT-3. Leveraging a new parametrization of the motion state space and the associated representation in R3 (collectively referred to as the H representation) and adapting a time scaling principle initially developed for manipulator trajectories, the designed motion controller is able to handle actuators coordination and their physical limits, as well as structural singularities. Results of tests done with the platform are presented, demonstrating the applicability of the proposed motion controller in efficiently handling these issues.","Instantaneous centre of rotation (ICR), Nonholonomic omnidirectional robots, Motion control, Kinematics, Wheeled robots",Lionel Clavien and Michel Lauria and François Michaud,https://www.sciencedirect.com/science/article/pii/S0921889017305997,https://doi.org/10.1016/j.robot.2018.03.014,0921-8890,2018,58--68,106,Robotics and Autonomous Systems,Instantaneous centre of rotation based motion control for omnidirectional mobile robots with sidewards off-centred wheels,article,CLAVIEN201858
"Patients with disorders such as spinal cord injury, cerebral palsy and stroke can perform full gait when assisted, which progressively helps them regain the ability to walk. A very common way to create assistive effects is aquatic therapy. Aquatic environment also creates resistive effects desired for strength building. In this study, realization of a virtual fluid environment on a robotic gait trainer is presented as an alternative method. A model was created to determine torques and forces acting on the human body while performing gait in a fluid environment. The developed model was implemented on a robotic gait trainer. By adjusting the virtual fluid model parameters, precise control over assistive and resistive effects during gait was achieved without enforcing any pre-defined gait pattern. The real-time gait phase information required by the fluid model to determine torques was provided with a developed algorithm which only uses kinematic gait data. Experiments with healthy subjects were done using the robotic gait trainer to verify the gait phase algorithm, and to compare gait characteristics obtained in virtual land and water environments with the literature. Additional experiments were performed with the robotic system to assess effects of changing fluid model parameters to healthy subject ga it characteristics. The results show that force and torque effects of virtual fluid environment on robotic gait trainer were achieved. The gait phase algorithm was shown to provide smooth transition between phases. Also, significant changes in gait characteristics were observed by modifying fluid model parameters.","Robotics, Rehabilitation, Assistive, Medical, Aquatic therapy, Locomotor training",Tayfun Efe Ertop and Tolga Yuksel and Erhan ilhan Konukseven,https://www.sciencedirect.com/science/article/pii/S0921889017304268,https://doi.org/10.1016/j.robot.2018.02.012,0921-8890,2018,59--68,105,Robotics and Autonomous Systems,Realization of human gait in virtual fluid environment on a robotic gait trainer for therapeutic purposes,article,ERTOP201859
"Semantic maps add to classic robot maps spatially grounded object instances anchored in a suitable way for knowledge representation and reasoning. They enable a robot to solve reasoning problems of geometrical, topological, ontological and logical nature in addition to localization and path planning. Recent literature on semantic mapping lacks effective and efficient approaches for grounding qualitative spatial relations through analysis of the quantitative geometric data of the mapped entities. Yet, such qualitative relations are essential to perform spatial and ontological reasoning about objects in the robot?s surroundings. This article contributes a framework for semantic map representation, called SEMAP, to overcome this missing aspect. It is able to manage full 3D maps with geometric object models and the corresponding semantic annotations as well as their relative spatial relations. For that, spatial database technology is used to solve the representational and querying problems efficiently. This article describes the extensions necessary to make a spatial database suitable for robotic applications. Especially, we add 3D spatial operators and a tree of transformations to represent relative position information. We evaluate the implemented capabilities and present real life use cases of SEMAP in different application domains.","Semantic mapping, Spatial analysis, Knowledge representation",Henning Deeken and Thomas Wiemann and Joachim Hertzberg,https://www.sciencedirect.com/science/article/pii/S0921889017306565,https://doi.org/10.1016/j.robot.2018.03.011,0921-8890,2018,146--165,105,Robotics and Autonomous Systems,Grounding semantic maps in spatial databases,article,DEEKEN2018146
"In this paper we focus on extracting a parametrization of asymmetrical bimanual tasks from human demonstration. Two arms coordinate while being in physical contact and fulfilling complementary aspects of the task: one arm is mostly assistive while the other performs active manipulation. Such a task can be executed either autonomously by a bimanual robot, or collaboratively by a single robotic arm performing the assistive or active role in collaboration with a human. We thus decompose the demonstrated task in a set of actions and for each action we extract: the role of the arms as master or slave, the type of coupling as force?motion or motion?motion coupling with the corresponding stiffness modulation, and the transition condition. We discuss how this applies to the three execution cases mentioned above. Additionally for the collaborative case we study hand-related features that allow the robot to anticipate and adapt to the user?s actions. We validate our approach on common daily tasks.","Task representation, Dual arm manipulation, Force and tactile sensing, Learning and adaptive systems",Lucia Pais Ureche and Aude Billard,https://www.sciencedirect.com/science/article/pii/S0921889017300465,https://doi.org/10.1016/j.robot.2017.12.011,0921-8890,2018,222--235,103,Robotics and Autonomous Systems,Constraints extraction from asymmetrical bimanual tasks and their use in coordinated behavior,article,URECHE2018222
"This paper describes a new, innovative method by which multiple mobile robots can be detected by a laser scanner. Each robot incorporates bars in its construction which generate a significant pattern in the laser scan. The proposed technique allows a robust detection and control of successively moving robots, despite the partial shadowing through the bars. In this paper the optimal number of bars and their best arrangement for detection is shown. Furthermore the impact of different bar diameters is described. Increased visibility of the bars by the use of multiple laser scanners and their positioning to ensure detection of the robots is also described. Finally it describes the accuracy that can be achieved with this system. The position accuracy was determined by trials on an actual system. Simulations and experiments confirm that this is a reliable and precise method for position determination of multiple robots using a single sensor.","Mobile robots, Multi-robot system, Robot tracking system, Intelligent space, Multi-robot localization",Rainer Halmheu and Boris Otto and Johann Hegel,https://www.sciencedirect.com/science/article/pii/S0921889017304943,https://doi.org/10.1016/j.robot.2017.12.007,0921-8890,2018,103--113,101,Robotics and Autonomous Systems,Layout optimization of a system for successive laser scanner detection and control of mobile robots,article,HALMHEU2018103
,,Pericle Salvini,https://www.sciencedirect.com/science/article/pii/S0921889016303505,https://doi.org/10.1016/j.robot.2017.03.007,0921-8890,2018,278--286,100,Robotics and Autonomous Systems,Urban robotics: Towards responsible innovations for our cities,article,SALVINI2018278
"In highly dynamic tasks that involve moving targets, planning is necessary to figure out when, where and how to intercept the target. In robotic table tennis in particular, motion planning can be very challenging due to time constraints, dimension of the search space and joint limits. Conventional planning algorithms often rely on a fixed virtual hitting plane to construct robot striking trajectories. These algorithms, however, generate restrictive strokes and can result in unnatural strategies when compared with human playing. In this paper, we introduce a new trajectory generation framework for robotic table tennis that does not involve a fixed hitting plane. A free-time optimal control approach is used to derive two different trajectory optimizers. The resulting two algorithms, Focused Player and Defensive Player, encode two different play-styles. We evaluate their performance in simulation and in our robot table tennis platform with a high speed cable-driven seven DOF robot arm. The algorithms return the balls with a higher probability to the opponent?s court when compared with a virtual hitting plane based method. Moreover, both can be run online and the trajectories can be corrected with new ball observations.","Optimal control, Motion planning, Optimization, Robot table tennis",Okan Koç and Guilherme Maeda and Jan Peters,https://www.sciencedirect.com/science/article/pii/S0921889017306164,https://doi.org/10.1016/j.robot.2018.03.012,0921-8890,2018,121--137,105,Robotics and Autonomous Systems,Online optimal trajectory generation for robot table tennis,article,KOC2018121
"In this paper, we present a directional antenna-based leader?follower robotic relay system capable of building end-to-end communication in complicated and dynamically changing environments. The proposed system consists of multiple networked robots ? one is a mobile end node and the others are leaders or followers acting as radio relays. Every follower uses directional antennas to relay a communication radio and to estimate the location of the leader robot as a sensory device. For bearing estimation, we employ a weight centroid algorithm (WCA) and present a theoretical analysis of the use of WCA for this work. Using a robotic convoy method, we develop online, distributed control strategies that satisfy the scalability requirements of robotic network systems and enable cooperating robots to work independently. The performance of the proposed system is evaluated by conducting extensive real-world experiments that successfully build actual communication between two end nodes.","Multi-Robot system, Relay robots, Robotic convoy system, Wireless communications, Directional antennas, Weighted centroid algorithm",Byung-Cheol Min and Ramviyas Parasuraman and Sangjun Lee and Jin-Woo Jung and Eric T. Matson,https://www.sciencedirect.com/science/article/pii/S0921889017304141,https://doi.org/10.1016/j.robot.2017.11.013,0921-8890,2018,57--73,101,Robotics and Autonomous Systems,A directional antenna based leader?follower relay system for end-to-end robot communications,article,MIN201857
"Object recognition is essential to enable robots to interact with their environment. Robots should be capable, on one hand of recognizing previously experienced objects, and on the other, of using the experienced objects for learning novel objects, i.e. objects for which training data are not available. Recognition of such novel objects can be achieved with Zero-Shot Learning (ZSL). In this work, we show the potential of ZSL for haptic recognition. First, we design a zero-shot haptic recognition algorithm and, using the extensive PHAC-2 database (Chu et al., 2015) as well as our own, we adapt, analyze and optimize the ZSL for the challenges and constraints characteristic of haptic recognition. Finally, we apply the optimized algorithm for haptic recognition of daily-life objects using an anthropomorphic robot hand. Our algorithm enables the robot to recognize eight of the ten novel objects handed to it.","Haptic recognition, Zero-Shot Learning, Attribute-based description, Robotic hand",Zineb Abderrahmane and Gowrishankar Ganesh and André Crosnier and Andrea Cherubini,https://www.sciencedirect.com/science/article/pii/S0921889017307492,https://doi.org/10.1016/j.robot.2018.03.002,0921-8890,2018,11--25,105,Robotics and Autonomous Systems,Haptic Zero-Shot Learning: Recognition of objects never touched before,article,ABDERRAHMANE201811
"An Orthogonal Defense Mechanism (ODM) was designed and implemented to improve the detection of cyber attacks on an operational water treatment plant (WTreat). Successive design iterations led to an architecture that was prototyped and experimentally evaluated. ODM unobtrusively monitors WTreat using an independent network and gathers data from multiple data sources to corroborate the state of the plant using a state model. ODM is independent of, i.e. orthogonal to, any detection and defense mechanism, such as rule-based intrusion detection, that may otherwise exist in WTreat. ODM uses invariants created from plant design to detect and report anomalies in processes. While the architecture of OD, and its prototype, are specific to a water treatment plant, the underlying design ideas are generic and could be applied to other public infrastructure systems.","Attack detection, Cyber attacks, Cyber-physical systems, Intelligent checker, Orthogonal defense, ICS security, Water treatment plant",Siddhant Shrivastava and Sridhar Adepu and Aditya Mathur,https://www.sciencedirect.com/science/article/pii/S0921889017302890,https://doi.org/10.1016/j.robot.2017.12.005,0921-8890,2018,114--125,101,Robotics and Autonomous Systems,Design and assessment of an Orthogonal Defense Mechanism for a water treatment facility,article,SHRIVASTAVA2018114
"Making robots collaborate safely with humans has created a new design paradigm involving the biomimetic mechanical behavior of robots? joints. However, few authors have contributed to the problems of safety in pure linear motion, i.e. a prismatic joint, in contrast to rotary motion. The contribution of this work is to present a new design that is capable of achieving, passively, an implementation of nonlinear elastic behavior for prismatic joints?the so-called Prismatic Compliant Joint (PCJ). This new device is based on the association of a six-bar mechanism with a linear spring. Hence, this structure generates a nonlinear stiffness behavior under a specified external force. The elastic characteristics of the PCJ are derived from a generic biological muscle mechanical behavior model and then customized according to the force-safety criteria of physical Human/Robot Interaction (pHRI) into a Hunt?Crossley contact model. A further investigation is carried out, via simulation, to verify the shock absorption capacity of the PCJ with a dummy head obstacle. In order to fit the PCJ response curve to the established safety measures, an optimization based on a genetic algorithm method is employed to tune the PCJ?s intrinsic parameters subject to some chosen constraints.","Biomimetics, Mechanical design, Prismatic Compliant Joint, Safety, Passive Compliance",Y. Ayoubi and M.A. Laribi and F. Courrèges and S. Zeghloul and M. Arsicault,https://www.sciencedirect.com/science/article/pii/S0921889017304396,https://doi.org/10.1016/j.robot.2018.01.008,0921-8890,2018,44--53,102,Robotics and Autonomous Systems,Complete design methodology of biomimetic safety device for cobots? prismatic joints,article,AYOUBI201844
"In this paper, a new concept for a distributed space transportation system is proposed and a corresponding decentralized cooperative control scheme is investigated. First, for a leaderless team of homogeneous space robots transporting a large object in orbit, a systematic control architecture that includes information flow is developed. Second, based on relative orbit dynamics, a rendezvous guidance law and a rigid formation control law are designed, and the necessary communication topology for the space robot team is discussed. Third, to guarantee the consensus of the motion of the large object with the robot team, both orbital maneuver control and attitude control for the large object are studied Emphasis is placed not on the attitude control law but on the force distribution problem, for which an algorithm exploiting a special property of trigonometric functions is proposed to transfer the necessary attitude control torque to the distributed forces. To support the above control method, an estimation of the motion of the formation center contributed by each robot in a decentralized manner is developed using a Kalman filter. Fourth, the robustness of the system to the failure of one robot is analyzed, and four effective typical fault response modes are proposed. Finally, numerical simulations validated the performance, robustness and practicability of the developed control scheme.","Distributed space transportation system, Decentralized attitude determination, Force distribution algorithm, Rendezvous guidance, Formation control",Yunhe Meng and Qifeng Chen and Ahmed Rahmani,https://www.sciencedirect.com/science/article/pii/S0921889017304153,https://doi.org/10.1016/j.robot.2017.12.006,0921-8890,2018,1--19,101,Robotics and Autonomous Systems,A decentralized cooperative control scheme for a distributed space transportation system,article,MENG20181
"Multiple target tracking in crowded urban environments is a daunting task. High crowdedness complicates motion modeling, and occlusion makes tracking difficult as well. Based on the variable-structure multiple-model (VSMM) estimation framework, this paper extends an interacting object tracking (IOT) scheme with occlusion detection and a virtual measurement model for occluded areas. IOT is composed of a scene interaction model and a neighboring object interaction model. The scene interaction model considers the long-term interactions of a moving object and surroundings, and the neighboring object interaction model considers three short-term interactions. With these interacting object models, the motion feature of a moving object can be represented with the weight of each model. A virtual measurement model is proposed to exploit the motion feature with the IOT scheme under occlusion. The proposed approach was validated using a stationary 2D LIDAR. To verify in occlusion, a 3D LIDAR based benchmark system was developed to extract occluded moving segments. The ample experimental results show that the proposed IOT scheme tracks over 57% of occluded moving objects in an urban intersection.","Multitarget tracking, Interaction, LIDAR",Jiun-Fu Chen and Chieh-Chih Wang and Cheng-Fu Chou,https://www.sciencedirect.com/science/article/pii/S0921889017301288,https://doi.org/10.1016/j.robot.2018.02.004,0921-8890,2018,68--82,103,Robotics and Autonomous Systems,Multiple target tracking in occlusion area with interacting object models in urban environments,article,CHEN201868
"Due to less appropriate sensors for representing the pose of soft robotic hand, the soft robotic hand usually works in an open loop control system. In this paper, only two simple sensors were used in a soft pneumatic gripper (SPG) control system to make it possess innervated-like ability. The control system was conducted with only two sensors, air pressure sensor and bending sensor where the air pressure sensor is able to detect grasping force and the bending sensor is able to detect grasping position The bending sensor was characterized by testing on pressure vs. bending and bending vs. size relationships. The principle of circular-shaped object size recognition was presented in Algorithm 1. Multi-group tests had been done on grasping different size and material objects, and test results had a strong effect on size recognition ability of the SPG. Finally, adaptive grasping control process was presented in Algorithm 2. The tests on grasping the same size objects had been done. The test results demonstrate that the SPG is able to maintain stable grasping state for a long time based on size recognition ability no matter what material the object is. At the same time, it had no effect on the grasping state at the time of existing disturbance, which had been verified by four different disturbance tests. The SPG will benefit the development of soft robotics field in picking and sorting fruits and vegetables, and an application of the SPG affixed on the home-made palletizing robot was described and conducted at last.","Soft pneumatic gripper, Bending sensor, Air pressure sensor, Size recognition, Adaptive grasping",Yang Chen and Shaofei Guo and Cunfeng Li and Hui Yang and Lina Hao,https://www.sciencedirect.com/science/article/pii/S092188901730547X,https://doi.org/10.1016/j.robot.2018.02.020,0921-8890,2018,14--24,104,Robotics and Autonomous Systems,Size recognition and adaptive grasping using an integration of actuating and sensing soft pneumatic gripper,article,CHEN201814
"The concept of postural synergy is recently being widely applied to the mechanical design of prosthesis. However, there are few research literatures on the application of postural synergy in the mechanical design of an exoskeletal rehabilitation robot. In this paper, the reaching movements of human arm are analysed by the principal component analysis method and two most significant synergies of the joints of human arm, which can account for more than 80% of the variation, are extracted. We propose a postural synergy based method to design the kinematic transmission mechanism for a multi-joint upper-limb exoskeletal rehabilitation robot with two actuators. Additionally, the configuration of passive joints and balance weights is put forward to improve the performance of the robot. The postural synergy based design method is formulated for replicating human arm reaching movements. Finally, tests are taken on the prototype to validate the proposed method. Furthermore, the proposed method can be potentially extended to the design of underactuated robotic arm or manipulator which is just required to perform the specific types of movements.","Postural synergies, Principal component analysis, Mechanical design, Exoskeletal rehabilitation robot",Kai Liu and Cai-Hua Xiong and Lei He and Wen-Bin Chen and Xiao-Lin Huang,https://www.sciencedirect.com/science/article/pii/S0921889016308260,https://doi.org/10.1016/j.robot.2017.10.003,0921-8890,2018,84--96,99,Robotics and Autonomous Systems,Postural synergy based design of exoskeleton robot replicating human arm reaching movements,article,LIU201884
"This article presents the development of a robot-integrated smart home (RiSH) which can be used for research in assistive technologies for elderly care. The RiSH integrates a home service robot, a home sensor network, a body sensor network, a mobile device, cloud servers, and remote caregivers. A layered architecture is proposed to guide the design and implementation of the RiSH software. Basic service functions are developed to allow the RiSH to recognize human body activity using an inertial measurement unit (IMU) and the home service robot to perceive the environment through audio signals. Based on these functions, we developed two low-level applications: (1) particle filter-based human localization and tracking using wearable motion sensors and distributed binary sensors; (2) Dynamic Bayesian Network-based human activity recognition using microphones and distributed binary sensors. Both applications extend the robot?s perception beyond its onboard sensors. Utilizing the low-level applications, a high-level application is realized that detects and responds to human falls. We conducted experiments in our RiSH testbed to evaluate auditory perception services, human body activity recognition, human position tracking, sound-based human activity monitoring, and fall detection and rescue. Twelve human subjects were asked to conduct daily activities in the testbed and mimic falls. All data of their movement, body activities, and sound events were collected by the robot. Human trajectories were estimated with a root mean square error of less than 0.2 m. The robot was able to recognize 37 human activities through sound events with an average accuracy of 88% and detect falling sounds with an accuracy of 80% at the frame level. The experiments show the operation of the various components in the RiSH and the capabilities of the home service robot in monitoring and assisting the resident.","Elderly care, Smart home, Home service robot, Assistive technology",Ha Manh Do and Minh Pham and Weihua Sheng and Dan Yang and Meiqin Liu,https://www.sciencedirect.com/science/article/pii/S0921889017300477,https://doi.org/10.1016/j.robot.2017.12.008,0921-8890,2018,74--92,101,Robotics and Autonomous Systems,RiSH: A robot-integrated smart home for elderly care,article,DO201874
"Development of Simultaneous Localization and Mapping (SLAM) systems in the era of autonomous navigation and the growing demand for autonomous robots have put into question how to reduce the computational complexity and make use of SLAM algorithms to operate in real time. Our work, aims to take advantage of low-power embedded architectures to implement SLAM algorithms. Precisely, we evaluate the promise held by the new modern low power architectures in accelerating the execution time of SLAM algorithms. Throughout this, we map and implement 4 well-known SLAM algorithms that find utility in very different robot applications and autonomous navigation, on different architectures based embedded systems. We present first a processing time evaluation of these algorithms on different CPU based architectures. Results demonstrate that FastSLAM2.0 allows a compromise between the computation time and the consistency of the localization results. The algorithm has been modified to be adapted to large environments. It is then optimized for parallel implementations on GPU and FPGA. A comparative study of the resulting implementations is given. Our results show that an embedded FPGA based SoC architecture is an interesting alternative for a SLAM algorithm implementation using the hardware?software co-design approach. Hence, the system meets performance requirements of a robot to operate in real-time constraints.","SLAM algorithms, Heterogeneous architectures, GPU, CPU, FPGA, Hardware?software codesign",Mohamed Abouzahir and Abdelhafid Elouardi and Rachid Latif and Samir Bouaziz and Abdelouahed Tajer,https://www.sciencedirect.com/science/article/pii/S0921889017301963,https://doi.org/10.1016/j.robot.2017.10.019,0921-8890,2018,14--26,100,Robotics and Autonomous Systems,Embedding SLAM algorithms: Has it come of age?,article,ABOUZAHIR201814
"This paper proposes a novel filter for sensor-based bearing-only simultaneous localization and mapping in three dimensions with globally exponentially stable (GES) error dynamics. A nonlinear system is designed, its output transformed, and its dynamics augmented so that the proposed formulation can be considered as linear time-varying for the purpose of observability analysis. This allows the establishment of observability results related to the original nonlinear system that naturally lead to the design of a Kalman filter with GES error dynamics. The performance of the proposed algorithm is assessed resorting to real experiments based on the Rawseeds dataset as well as further realistic simulations.","Simultaneous localization and mapping, 3-D mapping, Sensor fusion, Monocular vision, Global exponential stability",Pedro Lourenço and Pedro Batista and Paulo Oliveira and Carlos Silvestre,https://www.sciencedirect.com/science/article/pii/S0921889017300234,https://doi.org/10.1016/j.robot.2017.11.001,0921-8890,2018,61--77,100,Robotics and Autonomous Systems,A globally exponentially stable filter for bearing-only simultaneous localization and mapping with monocular vision,article,LOURENCO201861
"Spherical motion generators are increasingly needed for constructing robots, manipulators and pointing devices. This paper presents a novel design of spherical motion generator built on the basis of a spherical parallel manipulator. The new motion generator integrates the electromagnetic actuator with the co-axial 3-RRR spherical parallel manipulator, thus leads to a more compact and light-weight structure with the advantages of no backlash, high stiffness and low inertia. In this paper, the inverse kinematics and dynamics of the spherical parallel manipulator are described. The analytical torque model of this spherical motion generator is developed and compared with the numerical finite element method by Ansoft Maxwell. The models allow for comprehensive design analysis and parameter optimization. It is shown that the proposed SMG has better performance with larger workspace and output torques than the existing permanent magnet spherical motors with comparable dimensions. Upon the developed model, a motion control method is developed for tracking trajectory to demonstrate the application of the analytical model.","Spherical motion generator, Permanent magnet spherical motor, Spherical parallel manipulator, Torque model, Trajectory tracking control",Xuerong Li and Jingmeng Liu and Weihai Chen and Shaoping Bai,https://www.sciencedirect.com/science/article/pii/S092188901830023X,https://doi.org/10.1016/j.robot.2018.04.006,0921-8890,2018,69--81,106,Robotics and Autonomous Systems,"Integrated design, modeling and analysis of a novel spherical motion generator driven by electromagnetic principle",article,LI201869
"This paper proposes a new approach, interval Simultaneous Localization and Mapping (i-SLAM), which addresses the robotic mapping problem in the context of interval methods, where the robot sensor noise is assumed bounded. With no prior knowledge about the noise distribution or its probability density function, we derive and present necessary conditions to guarantee the map convergence even in the presence of nonlinear observation and motion models. These conditions may require the presence of some anchoring landmarks with known locations. The performance of i-SLAM is compared with the probabilistic counterparts in terms of accuracy and efficiency.","Nonlinear models, Real analysis, SLAM convergence, Interval methods",Mohamed Mustafa and Alexandru Stancu and Nicolas Delanoue and Eduard Codres,https://www.sciencedirect.com/science/article/pii/S0921889017303986,https://doi.org/10.1016/j.robot.2017.11.009,0921-8890,2018,160--170,100,Robotics and Autonomous Systems,Guaranteed SLAM?An interval approach,article,MUSTAFA2018160
"Bimanual gestures are of the utmost importance for the study of motor coordination in humans and in everyday activities. A reliable detection of bimanual gestures in unconstrained environments is fundamental for their clinical study and to assess common activities of daily living. This paper investigates techniques for a reliable, unconstrained detection and classification of bimanual gestures. The work assumes the availability of inertial data originating from the two hands/arms, builds upon a previously developed technique for gesture modeling based on Gaussian Mixture Modeling (GMM) and Gaussian Mixture Regression (GMR), and compares different modeling and classification techniques, which are based on a number of assumptions inspired by literature about how bimanual gestures are represented and modeled in the brain. Experiments show results related to 5 everyday bimanual activities, which have been selected on the basis of three main parameters: (not) constraining the two hands by a physical tool, (not) requiring a specific sequence of single-hand gestures, being recursive (or not). In the best performing combination of modeling approach and classification technique, we achieve overall accuracy, precision, recall and F1-score above 80%.","Human activity recognition, Gesture recognition, Wearable sensors, Inertial sensors",Divya Shah and Ernesto Denicia and Tiago Pimentel and Barbara Bruno and Fulvio Mastrogiovanni,https://www.sciencedirect.com/science/article/pii/S0921889016303773,https://doi.org/10.1016/j.robot.2017.09.016,0921-8890,2018,30--49,99,Robotics and Autonomous Systems,"Detection of bimanual gestures everywhere: Why it matters, what we need and what is missing",article,SHAH201830
"Robot-assisted bilateral upper limb training typically requires two robotic devices that work cooperatively with a human user. The determination of appropriate movement trajectories is essential to avoid interference of the robotic systems and ensure an appropriate intersecting workspace with user limbs. This paper proposes a new three-stage trajectory generation method for bilateral upper limb training using interference analysis. These three stages include workspace analysis of robots and human hands, trajectory generation within the intersecting workspace, and interference analysis for training safety verification. This trajectory generation method is also implemented with subject-specific adaptation based on anthropometry of an individual. Experiments were conducted on seven healthy subjects with a variety of body sizes. All participants gave positive feedback on the suitability of the predefined training trajectories, and no robot interference was detected. This three-stage method provides guidelines for the standardization of robot-assisted bilateral upper limb training protocols. Future work will focus on proposing an adaptive trajectory generation algorithm with efficacy evaluation on a larger sample of subjects.","Robot-assisted, Bilateral, Upper limb, Trajectory generation, Workspace, Interference analysis",Qing Miao and Andrew McDaid and Mingming Zhang and Parham Kebria and Hongsheng Li,https://www.sciencedirect.com/science/article/pii/S0921889017309168,https://doi.org/10.1016/j.robot.2018.03.010,0921-8890,2018,38--46,105,Robotics and Autonomous Systems,A three-stage trajectory generation method for robot-assisted bilateral upper limb training with subject-specific adaptation,article,MIAO201838
"This paper presents three distinct techniques, aimed at the online active impedance regulation of compliant humanoid robots, which endeavours to induce a state of balance to the system once it has been perturbed. The presence of passive elastic elements in the drives powering this class of robots leads to under-actuation, thereby rendering the control of compliant robots an intricate task. Consequently, the impedance regulation procedures proposed in this paper directly account for these elastic elements. In order to acquire an indication of the robot?s state of balance in an online fashion, an energy (Lyapunov) function is introduced, whose sign then allows one to ascertain whether the robot is converging to or diverging from, a desired equilibrium position. Computing this function?s time derivative unequivocally gives the energy-injecting nature of the active stiffness regulation, and reveals that active damping regulation has no bearing on the system?s state of stability. Furthermore, the velocity margin notion is interpreted as a velocity value beyond which the system?s balance might be jeopardized, or below which the robot will be guaranteed to remain stable. As a result, the unidirectional and bidirectional impedance optimization methods rely upon the use of bounds that have been defined based on the energy function?s derivative, in addition to the velocity margin. Contrarily, the third technique?s functionality revolves solely around the use of Lyapunov Stability Margins (LSMs). A series of experiments carried out using the COmpliant huMANoid (COMAN), demonstrates the superior balancing results acquired when using the bidirectional scheme, as compared to utilizing the two alternative techniques.",,Emmanouil Spyrakos-Papastavridis and Navvab Kashiri and Peter R.N. Childs and Nikos G. Tsagarakis,https://www.sciencedirect.com/science/article/pii/S0921889017306176,https://doi.org/10.1016/j.robot.2018.03.001,0921-8890,2018,85--98,104,Robotics and Autonomous Systems,Online impedance regulation techniques for compliant humanoid balancing,article,SPYRAKOSPAPASTAVRIDIS201885
"Rhythmic activities such as swimming stroke in the human body are learnable through conscious trainings. Inspiringly, the main objective of this study is to develop a control framework to reproduce the described functionality in the imitating robots. To do so, a two layer supervisory controller is proposed. The high-level controller, which acts as the conscious controller during trainings, is a supervisory dynamic-based controller and uses all system sensory data to generate stable rhythmic movements. On the other hand, the low-level controller in this structure is a distributed trajectory-based controller network. Each node in this network is an oscillatory dynamical system which has the ability to learn and reproduce the desired trajectory. Also, each node has a critic agent which evaluates the control eligibility of the low-level controllers for controlling the system. Then, based on the evaluation, these agents decide to assign the control of the system to the high-level controller or the low-level controllers. By using this structure, the system controller will act as simple and computing efficient as trajectory-based controllers and will perform as stably and robustly as dynamic-based controllers. At last, the applicability of this framework is demonstrated on a fully actuated robot and on an under-actuated biped robot.","Rhythmic activity, Online learning, Distributed control, Supervisory control, Biped robot",M. Yazdani and H. Salarieh and M. {Saadat Foumani},https://www.sciencedirect.com/science/article/pii/S0921889017300192,https://doi.org/10.1016/j.robot.2017.12.003,0921-8890,2018,20--33,101,Robotics and Autonomous Systems,Decentralized control of rhythmic activities in fully-actuated/under-actuated robots,article,YAZDANI201820
"In order to move safely and accurately, mobile platforms using steerable wheels require adequate coordination of their actuators. One possibility to achieve actuator coordination is to control the motion of the chassis? instantaneous centre of rotation (ICR) and motion around it. Considering the chassis as a rigid body, the ICR is located at the intersection of each wheel?s zero motion axis. In practice however, these axes may not concur, in particular when compliant actuators are used for wheel steering. They then no more define precisely an ICR and only an estimation of its position can be computed. Moreover, most parametrizations of the ICR position bring in singularities with no physical meaning, which hinder estimation. This paper introduces the H representation, a new parametrization of the motion state space free of any non-structural singularities, and presents an algorithm which estimates the ICR within the joint space. The proposed approach is compared in terms of reliability, efficiency, accuracy and robustness with three methods working within the operational space. Results suggest that the proposed estimation approach provides the best compromise for these performance indicators.","Instantaneous centre of rotation (ICR), Nonholonomic omnidirectional robots, Motion control, Kinematics, Wheeled robots",Lionel Clavien and Michel Lauria and François Michaud,https://www.sciencedirect.com/science/article/pii/S0921889017305894,https://doi.org/10.1016/j.robot.2018.03.009,0921-8890,2018,47--57,106,Robotics and Autonomous Systems,Estimation of the instantaneous centre of rotation with nonholonomic omnidirectional mobile robots,article,CLAVIEN201847
"Map building of indoor environments is considered a basic building block for autonomous mobile robots, enabling, among others, self-localization and efficient path planning. While the mainstream approach stores maps as occupancy grids of regular cells, some works have advocated for the use of maps composed of line segments to represent the boundary of obstacles, leveraging on their more compact size. In order to limit both the growth of the corresponding data structures and the effort in processing these maps, a number of methods have been proposed for merging together redundant line segments that represent the same portion of the environment. In this paper, we experimentally compare some of the most significant methods for merging line segments in maps by applying them to publicly available data sets. At the end, we propose some guidelines to choose the appropriate method.","Map merging, Line segment maps",Francesco Amigoni and Alberto {Quattrini Li},https://www.sciencedirect.com/science/article/pii/S0921889016304171,https://doi.org/10.1016/j.robot.2017.10.016,0921-8890,2018,135--147,99,Robotics and Autonomous Systems,Comparing methods for merging redundant line segments in maps,article,AMIGONI2018135
"This paper develops a novel shared control scheme for online-switching tele-operated and autonomous system with time-varying delays. Type-2 Takagi?Sugeno (T?S) fuzzy model is used to describe the dynamics of master and slave robots in this system. A novel non-singular fast terminal siding mode (NFTSM)-based algorithm combined with an extended wave-based time domain passivity approach (TDPA) is presented to enhance the master?slave motion synchronization in the tele-operated mode and reference-slave motion synchronization in the autonomous mode, while simultaneously ensuring the stability of the overall system in the presence of arbitrary time delays. In addition, based on the Type-2 Fuzzy model, a new torque observer is designed to estimate the external torques and then the torque tracking method is employed in the control laws to let the slave apply the designated force to further improve the operator?s force perception for the environment. The stability of the closed-loop system is proven using the Lyapunov?Krasovskii functions. Finally, experiments using two haptic devices prove the superiority of the proposed strategy.","Online-switching tele-operated and autonomous system, Type-2 T?S fuzzy system, Time-varying delays",Da Sun and Qianfang Liao and Hongliang Ren,https://www.sciencedirect.com/science/article/pii/S0921889017304967,https://doi.org/10.1016/j.robot.2017.12.010,0921-8890,2018,138--152,101,Robotics and Autonomous Systems,Type-2 Fuzzy logic based time-delayed shared control in online-switching tele-operated and autonomous systems,article,SUN2018138
"This paper proposes a resource-based task allocation algorithm for multi-robot systems. During mission operations, robots continuously consume their resources which must be refilled during their operations. Unlike other existing auction-based algorithms in which robots do not account for their resources in task allocations, the proposed algorithm considers the resources of the robots to generate their costs. In this algorithm, robots calculate the task performance estimation considering all the possibilities of visiting different combinations of refill stations based on their resource levels. This enables the robots to reduce unnecessary wastage of time and resources during the mission. The effectiveness of the proposed algorithm with respect to task completion time, resource consumption, and communication overhead is theoretically analyzed and is also demonstrated from the simulation of the delivery mission.","Multi-robot systems, Decentralized coordination, Resource-based task allocation",Dong-Hyun Lee,https://www.sciencedirect.com/science/article/pii/S092188901730310X,https://doi.org/10.1016/j.robot.2018.02.016,0921-8890,2018,151--161,103,Robotics and Autonomous Systems,Resource-based task allocation for multi-robot systems,article,LEE2018151
"This paper proposes a new concept, the Admissible Gap (AG), for reactive collision avoidance. A gap is called admissible if it is possible to find a collision-free motion control that guides a robot through it, while respecting the vehicle constraints. By utilizing this concept, a new navigation approach was developed, achieving an outstanding performance in unknown dense environments. Unlike the widely used gap-based methods, our approach directly accounts for the exact shape and kinematics, rather than finding a direction solution and turning it later into a collision-free admissible motion. The key idea is to analyze the structure of obstacles and virtually locate an admissible gap, once traversed, the robot makes progress towards the goal. For this purpose, we introduce a strategy of traversing gaps that respect the kinematic constraints and provides a compromise between path length and motion safety. We also propose a new methodology for extracting gaps that eliminates useless ones, thus reducing oscillations. Experimental results along with performance evaluation demonstrate the outstanding behavior of the proposed AG approach. Furthermore, a comparison with existing state-of-the-art methods shows that the AG approach achieves the best results in terms of efficiency, robustness, safety, and smoothness.","Mobile robot, Collision avoidance, Reactive navigation, Laser rangefinder, Sensor-based motion planning",Muhannad Mujahed and Dirk Fischer and Bärbel Mertsching,https://www.sciencedirect.com/science/article/pii/S0921889017306905,https://doi.org/10.1016/j.robot.2018.02.008,0921-8890,2018,93--110,103,Robotics and Autonomous Systems,Admissible gap navigation: A new collision avoidance approach,article,MUJAHED201893
"This paper presents a position control scheme for flexible joint robot (FJR). Traditional energy shaping controller with gravity compensation is revisited first and some drawbacks are analyzed; on this basis, a nonlinear state feedback controller along with energy shaping is provided, which can enhance the residual vibration suppression and reduce the overshoots of motor position. Boundedness analysis is presented and global convergence is analytically proven. Experiment results illustrate effectiveness of the proposed scheme.",,Wei Yin and Lei Sun and Meng Wang and Jingtai Liu,https://www.sciencedirect.com/science/article/pii/S0921889017303238,https://doi.org/10.1016/j.robot.2017.10.007,0921-8890,2018,121--134,99,Robotics and Autonomous Systems,Nonlinear state feedback position control for flexible joint robot with energy shaping,article,YIN2018121
"This paper provides a new framework for the collective motion control of a team of n-link doubly nonholonomic mobile manipulators in a constrained environment. A continuous decentralized motion planner is proposed. It guarantees the establishment and strict maintenance of a team formation using the Lyapunov-based control scheme (LbCS), which takes into account all the practical limitations, and the constraints due to fixed obstacles, nonholonomy and globally rigid formation requirements. The control scheme inherently utilizes artificial potential fields within an overarching leader?follower framework to mobilize the prescribed globally rigid formation. The designated leader of the team is modeled as a moving reference point, referred to as the virtual leader. With its protective polygonal region, it directs the motion of the team and manipulate the geometry of the formation. It is the authors? belief that this navigation and globally rigid formation control problem of n-link doubly nonholonomic mobile manipulators is treated for the first time with the use of continuous time-invariant control laws within the framework of LbCS and a variant of the leader?follower scheme. The effectiveness of the motion planner and the resulting acceleration-based control laws are demonstrated via computer simulations.","Lyapunov-based control scheme, Doubly nonholonomic manipulators, Kinodynamic constraints, Globally rigid formation, Leader?follower, Ghost target",Bibhya Sharma and Shonal Singh and Jito Vanualailai and Avinesh Prasad,https://www.sciencedirect.com/science/article/pii/S0921889017306504,https://doi.org/10.1016/j.robot.2018.02.006,0921-8890,2018,69--84,105,Robotics and Autonomous Systems,Globally rigid formation of n-link doubly nonholonomic mobile manipulators,article,SHARMA201869
"An underwater manipulator is a complex system, highly non-linear and subject to disturbances caused by underwater effects. To obtain a reliable system, robust control strategies have to be designed for the manipulator. The main contribution of this paper is the development of the low-level position/force control structure for an underwater manipulator. The proposed control strategy is planned in the operational space and combines together the parallel control structure for position/force applications with the sliding mode theory and the manipulator model information. The dynamic model of the system incorporates the hydrodynamic effects and an approximation of the end-effector force contact with the environment. This paper presents a method for computing the interaction force at the end-effector in the absence of a force?torque sensor. The control structure is validated through a Lyapunov-stability approach and experimental results. The control structure is tested on a 6 degrees-of-freedom underwater manipulator interacting with the underwater environment.","Underwater manipulation, Control, Task space, Model based, Robust control, Hybrid control",Corina Barbalata and Matthew W. Dunnigan and Yvan Petillot,https://www.sciencedirect.com/science/article/pii/S092188901730386X,https://doi.org/10.1016/j.robot.2017.11.004,0921-8890,2018,150--159,100,Robotics and Autonomous Systems,Position/force operational space control for underwater manipulation,article,BARBALATA2018150
"We propose an approach for instructing a robot using natural language to solve complex tasks in a dynamic environment. In this study, we elaborate on a framework that allows a humanoid robot to understand natural language, derive symbolic representations of its sensorimotor experience, generate complex plans according to the current world state, and monitor plan execution. The presented development supports replacing missing objects and suggesting possible object locations. It is a realization of the concept of structural bootstrapping developed in the context of the European project Xperience. The framework is implemented within the robot development environment ArmarX. We evaluate the framework on the humanoid robot ARMAR-III in the context of two experiments: a demonstration of the real execution of a complex task in the kitchen environment on ARMAR-III and an experiment with untrained users in a simulation environment.","Structural bootstrapping, Natural language understanding, Planning, Task execution, Object replacement, Humanoid robotics",Mirko Wächter and Ekaterina Ovchinnikova and Valerij Wittenbeck and Peter Kaiser and Sandor Szedmak and Wail Mustafa and Dirk Kraft and Norbert Krüger and Justus Piater and Tamim Asfour,https://www.sciencedirect.com/science/article/pii/S092188901730074X,https://doi.org/10.1016/j.robot.2017.10.012,0921-8890,2018,148--165,99,Robotics and Autonomous Systems,"Integrating multi-purpose natural language understanding, robot?s memory, and symbolic planning for task execution in humanoid robots",article,WACHTER2018148
"A new obstacle detection algorithm for unmanned surface vehicles (USVs) is presented. A state-of-the-art graphical model for semantic segmentation is extended to incorporate boat pitch and roll measurements from the on-board inertial measurement unit (IMU), and a stereo verification algorithm that consolidates tentative detections obtained from the segmentation is proposed. The IMU readings are used to estimate the location of horizon line in the image, which automatically adjusts the priors in the probabilistic semantic segmentation model. We derive the equations for projecting the horizon into images, propose an efficient optimization algorithm for the extended graphical model, and offer a practical IMU?camera?USV calibration procedure. Using an USV equipped with multiple synchronized sensors, we captured a new challenging multi-modal dataset, and annotated its images with water edge and obstacles. Experimental results show that the proposed algorithm significantly outperforms the state of the art, with nearly 30% improvement in water-edge detection accuracy, an over 21% reduction of false positive rate, an almost 60% reduction of false negative rate, and an over 65% increase of true positive rate, while its Matlab implementation runs in real-time.","Computer vision, Inertial measurement unit, Marine navigation, Obstacle detection, Sensor fusion, Semantic segmentation, Stereo vision, Unmanned surface vehicles",Borja Bovcon and Rok Mandeljc and Janez Per? and Matej Kristan,https://www.sciencedirect.com/science/article/pii/S0921889017305808,https://doi.org/10.1016/j.robot.2018.02.017,0921-8890,2018,1--13,104,Robotics and Autonomous Systems,Stereo obstacle detection for unmanned surface vehicles by IMU-assisted semantic segmentation,article,BOVCON20181
"In developing path tracking controller for autonomous vehicles, a properly tuned controller will work well for a certain range of driving conditions but may need to be re-tuned for others. This study presents the development of an adaptive controller with fuzzy supervisory system for trajectory tracking control of an autonomous armoured vehicle. A knowledge database is built using Particle Swarm Optimisation which is the mainframe of the Fuzzy supervisory system in adapting to various trajectories and speed. The proposed controller is simulated on a nonlinear vehicle model, and experimental results for the controller are presented to evaluate the proposed controller.","Armoured vehicle, Autonomous trajectory tracking, Path tracking, Stanley controller, Particle swarm optimisation, Fuzzy supervisory",Noor Hafizah Amer and Khisbullah Hudha and Hairi Zamzuri and Vimal Rau Aparow and Amar Faiz Zainal Abidin and Zulkiffli Abd Kadir and Muhamad Murrad,https://www.sciencedirect.com/science/article/pii/S0921889018300903,https://doi.org/10.1016/j.robot.2018.03.006,0921-8890,2018,94--111,105,Robotics and Autonomous Systems,Adaptive modified Stanley controller with fuzzy supervisory system for trajectory tracking of an autonomous armoured vehicle,article,AMER201894
"Acquiring robot assembly skills through human demonstration is an important research problem and can be used to quickly program robots in future manufacturing industries. To teach robots complex assembly skills, the robots should be able to recognize the objects (parts and tools) involved, the actions applied, and the effect of the actions on the parts. It is non-trivial to recognize the subtle assembly actions. To estimate the effect of the actions on the assembly part is also challenging due to the small part sizes. In this paper, using a RGB-D camera, we build a Portable Assembly Demonstration (PAD) system which can automatically recognize the objects (parts/tools) involved, the actions conducted and the assembly states characterizing the spatial relationship among the parts. The experiment results proved that this PAD system can generate a high level assembly script with decent accuracy in object and action recognition as well as assembly state estimation. The assembly script is successfully implemented on a Baxter robot.","Object recognition, Action recognition, Assembly state estimation, Learning by demonstration",Ye Gu and Weihua Sheng and Christopher Crick and Yongsheng Ou,https://www.sciencedirect.com/science/article/pii/S0921889016303888,https://doi.org/10.1016/j.robot.2017.10.002,0921-8890,2018,1--16,99,Robotics and Autonomous Systems,Automated assembly skill acquisition and implementation through human demonstration,article,GU20181
"This paper studies a reliable control strategy for a bionic-ape brachiation robot with dual-arm hands, a four-link brachiate mechanism, which swings and grasps branches like a gibbon. Based on the analysis of the brachiation of gibbons and humans, the big damping nonholonomic constraints model is introduced. A control strategy which combines the energy pumping control with the big damping turn-back angle feedback control is proposed. The grasping motion was divided into several processes: the swing-up self-starting phase, the energy rising phase, the transition phase and the grasping phase. A self-starting controller is designed for swing-up motion from a downward stable position. In the energy rising phase, an energy pumping control law is deduced based on Lyapunov stability theory, and the singularity and convergence of the system are analyzed. The system energy is calculated periodically to determine if the robot gets enough energy for grasping, so that it could shift into the transition phase. A position?orientation control method is adopted to realize that the gripper grasps target bars in the desired position, orientation and speed. By means of ADAMS-MATLAB co-simulation, the bionic-ape robot achieves smooth swing-grasp motions under different heights and horizontal distances. The simulation results indicate that this method has advantages of universality and reliability in a grasping target bar. Therefore, the effectiveness of the proposed control strategy is validated.","Big damping nonholonomic constraints, Underactuated control, Energy pumping, Turn-back angle feedback, Lyapunov stability theory, Position?orientation control",Weiguo Wu and Minchang Huang and Xiadong Gu,https://www.sciencedirect.com/science/article/pii/S0921889016306996,https://doi.org/10.1016/j.robot.2017.11.006,0921-8890,2018,119--131,100,Robotics and Autonomous Systems,Underactuated control of a bionic-ape robot based on the energy pumping method and big damping condition turn-back angle feedback,article,WU2018119
"This study proposes an online walking-pattern generation algorithm with footstep adjustment. The algorithm enables a biped walking robot to effectively recover balance following external disturbance. The external disturbance is measured as a capture-point error, and a desired zero-moment point (ZMP) is determined to compensate for the capture-point error through a capture-point control method. To follow the desired ZMP, the optimal ZMP and the position of the foot to be changed are determined through model predictive control (MPC). In the MPC, quadratic programming is implemented considering a cost function that minimizes the ZMP error, the constraints that the ZMP maintains within the support polygon, and the constraints on the varying foot positions. The proposed algorithm helps a humanoid robot (DRC-HUBO+) to regain balance following disturbance, i.e., from strong pushing or stepping on unexpected obstacles.","Humanoid robot, Biped walking, Walking pattern, Model predictive control, Footstep adjustment, Capture point",Hyun-Min Joe and Jun-Ho Oh,https://www.sciencedirect.com/science/article/pii/S0921889017305493,https://doi.org/10.1016/j.robot.2018.03.004,0921-8890,2018,1--10,105,Robotics and Autonomous Systems,Balance recovery through model predictive control based on capture point dynamics for biped walking robot,article,JOE20181
